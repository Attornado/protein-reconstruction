{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torchinfo\n",
    "import torch_geometric.utils.convert as tgc\n",
    "import numpy as np\n",
    "from typing import final\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "from models.layers import GATConvBlock, SAGEConvBlock, GCN2ConvBlock, GCNConvBlock\n",
    "from models.pretraining.encoders import SimpleGCNEncoder, ResGCN2ConvEncoder, RevSAGEConvEncoder, RevGATConvEncoder\n",
    "from models.pretraining.gae import GAEv2\n",
    "from models.pretraining.vgae import VGAEv2, VGEncoder\n",
    "from models.classification.classifiers import ProtMoveNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define graph and plot it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "_POSITION_ATTRIBUTE: final = \"pos\"\n",
    "_X_MIN: final = 0\n",
    "_X_MAX: final = 2\n",
    "_Y_MIN: final = 0\n",
    "_Y_MAX: final = 2\n",
    "g = nx.Graph()\n",
    "g.add_node(0, x=[1., 0., 1.2, 1.1, 0.2, 0.1])\n",
    "g.add_node(1, x=[0., 1., 0, 1.2, 1.1, 0.2])\n",
    "g.add_node(2, x=[0.4, 1., 0.1, 0.2, 0.7, 0.3])\n",
    "g.add_node(3, x=[1., 1.2, 0.9, 0.9, 0.5, 0.4])\n",
    "g.add_node(4, x=[1., 1.3, 0.4, 0.3, 1.8, 0.45])\n",
    "g.add_edge(1, 0, edge_weight=1.0)\n",
    "g.add_edge(1, 2, edge_weight=2.)\n",
    "g.add_edge(2, 0, edge_weight=1.)\n",
    "g.add_edge(3, 2, edge_weight=1.)\n",
    "g.add_edge(4, 2, edge_weight=1.)\n",
    "\n",
    "print(g.nodes(data=True))\n",
    "print(g.edges(data=True))\n",
    "print(\"ciao\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {'x': [1.0, 0.0, 1.2, 1.1, 0.2, 0.1]}), (1, {'x': [0.0, 1.0, 0, 1.2, 1.1, 0.2]}), (2, {'x': [0.4, 1.0, 0.1, 0.2, 0.7, 0.3]}), (3, {'x': [1.0, 1.2, 0.9, 0.9, 0.5, 0.4]}), (4, {'x': [1.0, 1.3, 0.4, 0.3, 1.8, 0.45]})]\n",
      "[(0, 1, {'edge_weight': 1.0}), (0, 2, {'edge_weight': 1.0}), (1, 2, {'edge_weight': 2.0}), (2, 3, {'edge_weight': 1.0}), (2, 4, {'edge_weight': 1.0})]\n",
      "ciao\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "#888",
          "width": 0.5
         },
         "mode": "lines",
         "x": [
          -1.5678997081084,
          -1.9928346782702087,
          null,
          -1.5678997081084,
          1.100635585684146,
          null,
          -1.9928346782702087,
          1.100635585684146,
          null,
          1.100635585684146,
          1.9721135459650563,
          null,
          1.100635585684146,
          -1.236006783706319,
          null
         ],
         "y": [
          0.37354828457663247,
          -1.2879217379005448,
          null,
          0.37354828457663247,
          -0.1724998364431401,
          null,
          -1.2879217379005448,
          -0.1724998364431401,
          null,
          -0.1724998364431401,
          -1.0054266612186133,
          null,
          -0.1724998364431401,
          1.615559467056341,
          null
         ],
         "type": "scatter"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           2,
           2,
           4,
           1,
           1
          ],
          "colorbar": {
           "thickness": 15,
           "title": {
            "side": "right",
            "text": "Node Connections"
           },
           "xanchor": "left"
          },
          "colorscale": [
           [
            0.0,
            "rgb(255,255,217)"
           ],
           [
            0.125,
            "rgb(237,248,177)"
           ],
           [
            0.25,
            "rgb(199,233,180)"
           ],
           [
            0.375,
            "rgb(127,205,187)"
           ],
           [
            0.5,
            "rgb(65,182,196)"
           ],
           [
            0.625,
            "rgb(29,145,192)"
           ],
           [
            0.75,
            "rgb(34,94,168)"
           ],
           [
            0.875,
            "rgb(37,52,148)"
           ],
           [
            1.0,
            "rgb(8,29,88)"
           ]
          ],
          "line": {
           "width": 2
          },
          "reversescale": true,
          "showscale": true,
          "size": 10
         },
         "mode": "markers",
         "text": [
          "node 0, # of connections: 2",
          "node 1, # of connections: 2",
          "node 2, # of connections: 4",
          "node 3, # of connections: 1",
          "node 4, # of connections: 1"
         ],
         "x": [
          -1.5678997081084,
          -1.9928346782702087,
          1.100635585684146,
          1.9721135459650563,
          -1.236006783706319
         ],
         "y": [
          0.37354828457663247,
          -1.2879217379005448,
          -0.1724998364431401,
          -1.0054266612186133,
          1.615559467056341
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>",
          "x": 0.005,
          "xref": "paper",
          "y": -0.002,
          "yref": "paper"
         }
        ],
        "hovermode": "closest",
        "margin": {
         "b": 20,
         "l": 5,
         "r": 5,
         "t": 40
        },
        "showlegend": false,
        "title": {
         "font": {
          "size": 16
         },
         "text": "<br>Network graph made with Python"
        },
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"99cfa973-d2b4-4ff0-937f-881b8735cfcc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"99cfa973-d2b4-4ff0-937f-881b8735cfcc\")) {                    Plotly.newPlot(                        \"99cfa973-d2b4-4ff0-937f-881b8735cfcc\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[-1.5678997081084,-1.9928346782702087,null,-1.5678997081084,1.100635585684146,null,-1.9928346782702087,1.100635585684146,null,1.100635585684146,1.9721135459650563,null,1.100635585684146,-1.236006783706319,null],\"y\":[0.37354828457663247,-1.2879217379005448,null,0.37354828457663247,-0.1724998364431401,null,-1.2879217379005448,-0.1724998364431401,null,-0.1724998364431401,-1.0054266612186133,null,-0.1724998364431401,1.615559467056341,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[2,2,4,1,1],\"colorbar\":{\"thickness\":15,\"title\":{\"side\":\"right\",\"text\":\"Node Connections\"},\"xanchor\":\"left\"},\"colorscale\":[[0.0,\"rgb(255,255,217)\"],[0.125,\"rgb(237,248,177)\"],[0.25,\"rgb(199,233,180)\"],[0.375,\"rgb(127,205,187)\"],[0.5,\"rgb(65,182,196)\"],[0.625,\"rgb(29,145,192)\"],[0.75,\"rgb(34,94,168)\"],[0.875,\"rgb(37,52,148)\"],[1.0,\"rgb(8,29,88)\"]],\"line\":{\"width\":2},\"reversescale\":true,\"showscale\":true,\"size\":10},\"mode\":\"markers\",\"text\":[\"node 0, # of connections: 2\",\"node 1, # of connections: 2\",\"node 2, # of connections: 4\",\"node 3, # of connections: 1\",\"node 4, # of connections: 1\"],\"x\":[-1.5678997081084,-1.9928346782702087,1.100635585684146,1.9721135459650563,-1.236006783706319],\"y\":[0.37354828457663247,-1.2879217379005448,-0.1724998364431401,-1.0054266612186133,1.615559467056341],\"type\":\"scatter\"}],                        {\"annotations\":[{\"showarrow\":false,\"text\":\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\"x\":0.005,\"xref\":\"paper\",\"y\":-0.002,\"yref\":\"paper\"}],\"hovermode\":\"closest\",\"margin\":{\"b\":20,\"l\":5,\"r\":5,\"t\":40},\"showlegend\":false,\"title\":{\"font\":{\"size\":16},\"text\":\"<br>Network graph made with Python\"},\"xaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('99cfa973-d2b4-4ff0-937f-881b8735cfcc');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(nx.get_node_attributes(g, \"pos\",)) == 0:\n",
    "    pos = {i: (random.gauss(_X_MIN, _X_MAX), random.gauss(_Y_MIN, _Y_MAX)) for i in g.nodes}\n",
    "    nx.set_node_attributes(g, pos, \"pos\")\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in g.edges():\n",
    "    x0, y0 = g.nodes[edge[0]]['pos']\n",
    "    x1, y1 = g.nodes[edge[1]]['pos']\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in g.nodes():\n",
    "    x, y = g.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(g.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append(f'node {node}, # of connections: ' + str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text\n",
    "\n",
    "# noinspection PyTypeChecker\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                layout=go.Layout(\n",
    "                    title='<br>Network graph made with Python',\n",
    "                    titlefont_size=16,\n",
    "                    showlegend=False,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=20,l=5,r=5,t=40),\n",
    "                    annotations=[ dict(\n",
    "                        text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "                        showarrow=False,\n",
    "                        xref=\"paper\", yref=\"paper\",\n",
    "                        x=0.005, y=-0.002 ) ],\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert graph in PyTorch geometric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5, 6], edge_index=[2, 10], pos=[5, 2], edge_weight=[10])\n",
      "tensor([1., 1., 1., 2., 1., 2., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "pyg = tgc.from_networkx(g)\n",
    "print(pyg)\n",
    "print(pyg.edge_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=1)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=1.0)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.5, beta=1.0)\n",
      ")\n",
      "tensor([[-0.3709, -0.2233, -0.4536],\n",
      "        [-0.1649, -0.5713, -0.4150],\n",
      "        [-0.3076, -0.1759, -0.2775],\n",
      "        [-1.0120, -0.1606, -0.2418],\n",
      "        [-0.6276, -0.0081, -0.4063]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.6968,  0.3506,  1.2413],\n",
      "        [-0.6704,  0.3626,  1.2475],\n",
      "        [-0.8584,  0.5465,  1.1797],\n",
      "        [-1.3711,  1.0990,  1.2011],\n",
      "        [-1.2761,  1.3425,  1.1560]], grad_fn=<AsStridedBackward0>)\n",
      "tensor([[ 0.1076,  0.9324,  0.3138],\n",
      "        [ 0.4028,  0.8551,  0.1689],\n",
      "        [-0.2554,  0.8704, -0.3433],\n",
      "        [-0.4926,  1.1281, -0.0293],\n",
      "        [ 0.1113,  0.4684, -0.0168]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.4683, -0.3413,  1.2562],\n",
      "        [-0.1504, -0.7945,  0.4208],\n",
      "        [-0.2654, -0.8844,  0.8224],\n",
      "        [ 0.1835, -0.1617,  1.2931],\n",
      "        [-0.1159, -0.5473,  0.9223]], grad_fn=<AddBackward0>)\n",
      "tensor([[-1.9999,  1.5309, -1.9056],\n",
      "        [-1.8079,  2.6288, -2.0768],\n",
      "        [-3.8189,  1.9095, -2.8782],\n",
      "        [-0.7760,  1.3052, -0.9253],\n",
      "        [-0.7760,  1.3052, -0.9253]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.6409, -0.4027, -0.9155],\n",
      "        [-0.4371, -0.3748, -0.9423],\n",
      "        [-0.6568, -0.7377, -1.3607],\n",
      "        [ 0.0941, -0.1870, -0.5325],\n",
      "        [ 0.0809, -0.4652, -0.6943]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.6100,  1.0049, -0.3129,  0.4855,  1.5563,  0.7506],\n",
      "        [ 0.7244,  1.4697, -0.5180,  0.8383,  1.2021,  0.3540],\n",
      "        [ 0.9076,  1.3878, -0.7606,  0.2814,  1.1617,  0.2054],\n",
      "        [ 1.0653,  1.5142, -0.8436, -0.0017,  1.4998,  0.6607],\n",
      "        [ 1.2080,  1.6673, -1.0453,  0.3589,  1.4387, -0.2571]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0044,  0.3989,  0.9576, -0.3173,  0.5324,  0.4138],\n",
      "        [-0.5770,  0.9003,  0.9987, -0.5620, -0.4785,  0.3035],\n",
      "        [-0.5553,  0.5699,  0.8587, -0.7764, -0.5773,  0.1416],\n",
      "        [-0.3080,  0.5895,  0.6610, -0.8713, -0.1006,  0.3788],\n",
      "        [-0.7093,  0.1305,  1.0862, -0.9146, -1.0763, -0.2679]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gat0 = GATConvBlock(6, 3, dropout=0.3, heads=2, edge_dim=1)\n",
    "gat1 = GATConvBlock(6, 3, heads=1, edge_dim=1, concat=True)\n",
    "\n",
    "sage0 = SAGEConvBlock(6, 3, project=True)\n",
    "sage1 = SAGEConvBlock(6, 3, project=False)\n",
    "\n",
    "gcn0 = GCNConvBlock(6, 3, normalize=False)\n",
    "gcn1 = GCNConvBlock(6, 3, normalize=True)\n",
    "\n",
    "gcn20 = GCN2ConvBlock(6, 0.6)\n",
    "gcn21 = GCN2ConvBlock(6, 0.5)\n",
    "\n",
    "print(gat0)\n",
    "print(gat1)\n",
    "print(sage0)\n",
    "print(sage1)\n",
    "print(gcn0)\n",
    "print(gcn1)\n",
    "print(gcn20)\n",
    "print(gcn21)\n",
    "\n",
    "print(gat0(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(gat1(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(sage0(pyg.x, edge_index=pyg.edge_index))\n",
    "print(sage1(pyg.x, edge_index=pyg.edge_index))\n",
    "print(gcn0(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn1(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn20(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn21(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate encoders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             268\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             268\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[-0.0347, -0.4085, -0.4187],\n",
      "        [-0.0460, -0.4407, -0.4185],\n",
      "        [-0.0291, -0.3768, -0.4056],\n",
      "        [-0.0341, -0.4242, -0.4332],\n",
      "        [-0.0205, -0.3176, -0.3767]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             40\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             40\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             40\n",
      "│    └─GroupAddRev: 2-4                                 --\n",
      "│    │    └─ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[-0.8882, -0.4690,  0.4174],\n",
      "        [-0.8579, -0.1566,  0.2275],\n",
      "        [-0.6484,  0.3228, -0.0583],\n",
      "        [-0.8608, -0.1914,  0.2487],\n",
      "        [-0.8528, -0.1381,  0.2163]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            15\n",
      "├─LayerNorm: 1-3                         8\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCNConvBlock: 2-1                 --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCNConv: 3-2                 30\n",
      "│    └─GCNConvBlock: 2-2                 --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCNConv: 3-4                 30\n",
      "│    └─GCNConvBlock: 2-3                 --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCNConv: 3-6                 24\n",
      "│    └─GCNConvBlock: 2-4                 --\n",
      "│    │    └─LayerNorm: 3-7               8\n",
      "│    │    └─GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[0.3969, 1.0275, 0.3226],\n",
      "        [0.4003, 1.0301, 0.3258],\n",
      "        [0.4061, 1.0337, 0.3306],\n",
      "        [0.4141, 1.0369, 0.3358],\n",
      "        [0.4149, 1.0371, 0.3362]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 Encoder\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            18\n",
      "├─LayerNorm: 1-3                         10\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCN2ConvBlock: 2-1                --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCN2Conv: 3-2                25\n",
      "│    └─GCN2ConvBlock: 2-2                --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCN2Conv: 3-4                25\n",
      "│    └─GCN2ConvBlock: 2-3                --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCN2Conv: 3-6                25\n",
      "│    └─GCN2ConvBlock: 2-4                --\n",
      "│    │    └─LayerNorm: 3-7               10\n",
      "│    │    └─GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[-0.5356, -0.7017, -0.2937],\n",
      "        [-0.5355, -0.7017, -0.2934],\n",
      "        [-0.5359, -0.7014, -0.2958],\n",
      "        [-0.5363, -0.7009, -0.2983],\n",
      "        [-0.5358, -0.7014, -0.2954]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gat_enc = RevGATConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=3,\n",
    "    dropout=0.0,\n",
    "    version=\"v2\",\n",
    "    edge_dim=1,\n",
    "    heads=8,\n",
    "    num_groups=2,\n",
    "    concat=False,\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual GAT Encoder\")\n",
    "print(gat_enc)\n",
    "print(torchinfo.summary(gat_enc))\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "sage_enc = RevSAGEConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0,\n",
    "    project=True,\n",
    "    root_weight=True,\n",
    "    num_groups=2,\n",
    "    aggr='mean',\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "print(sage_enc)\n",
    "print(torchinfo.summary(sage_enc))\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn_enc = SimpleGCNEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    conv_dims=[5, 5, 4, 4],\n",
    "    dropout=0.0,\n",
    "    improved=True\n",
    ")\n",
    "print(\"Simple GCN Encoder\")\n",
    "print(gcn_enc)\n",
    "print(torchinfo.summary(gcn_enc))\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn2_enc = ResGCN2ConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    alpha=0.3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0\n",
    ")\n",
    "print(\"ResGCN2 Encoder\")\n",
    "print(gcn2_enc)\n",
    "print(torchinfo.summary(gcn2_enc))\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test encoders serialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             268\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             268\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-0.0347, -0.4085, -0.4187],\n",
      "        [-0.0460, -0.4407, -0.4185],\n",
      "        [-0.0291, -0.3768, -0.4056],\n",
      "        [-0.0341, -0.4242, -0.4332],\n",
      "        [-0.0205, -0.3176, -0.3767]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-0.0347, -0.4085, -0.4187],\n",
      "        [-0.0460, -0.4407, -0.4185],\n",
      "        [-0.0291, -0.3768, -0.4056],\n",
      "        [-0.0341, -0.4242, -0.4332],\n",
      "        [-0.0205, -0.3176, -0.3767]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             40\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             40\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             40\n",
      "│    └─GroupAddRev: 2-4                                 --\n",
      "│    │    └─ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-0.8882, -0.4690,  0.4174],\n",
      "        [-0.8579, -0.1566,  0.2275],\n",
      "        [-0.6484,  0.3228, -0.0583],\n",
      "        [-0.8608, -0.1914,  0.2487],\n",
      "        [-0.8528, -0.1381,  0.2163]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-0.8882, -0.4690,  0.4174],\n",
      "        [-0.8579, -0.1566,  0.2275],\n",
      "        [-0.6484,  0.3228, -0.0583],\n",
      "        [-0.8608, -0.1914,  0.2487],\n",
      "        [-0.8528, -0.1381,  0.2163]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            15\n",
      "├─LayerNorm: 1-3                         8\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCNConvBlock: 2-1                 --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCNConv: 3-2                 30\n",
      "│    └─GCNConvBlock: 2-2                 --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCNConv: 3-4                 30\n",
      "│    └─GCNConvBlock: 2-3                 --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCNConv: 3-6                 24\n",
      "│    └─GCNConvBlock: 2-4                 --\n",
      "│    │    └─LayerNorm: 3-7               8\n",
      "│    │    └─GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[0.3969, 1.0275, 0.3226],\n",
      "        [0.4003, 1.0301, 0.3258],\n",
      "        [0.4061, 1.0337, 0.3306],\n",
      "        [0.4141, 1.0369, 0.3358],\n",
      "        [0.4149, 1.0371, 0.3362]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[0.3969, 1.0275, 0.3226],\n",
      "        [0.4003, 1.0301, 0.3258],\n",
      "        [0.4061, 1.0337, 0.3306],\n",
      "        [0.4141, 1.0369, 0.3358],\n",
      "        [0.4149, 1.0371, 0.3362]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            18\n",
      "├─LayerNorm: 1-3                         10\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCN2ConvBlock: 2-1                --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCN2Conv: 3-2                25\n",
      "│    └─GCN2ConvBlock: 2-2                --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCN2Conv: 3-4                25\n",
      "│    └─GCN2ConvBlock: 2-3                --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCN2Conv: 3-6                25\n",
      "│    └─GCN2ConvBlock: 2-4                --\n",
      "│    │    └─LayerNorm: 3-7               10\n",
      "│    │    └─GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-0.5356, -0.7017, -0.2938],\n",
      "        [-0.5356, -0.7016, -0.2942],\n",
      "        [-0.5359, -0.7014, -0.2956],\n",
      "        [-0.5362, -0.7010, -0.2981],\n",
      "        [-0.5358, -0.7015, -0.2951]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-0.5356, -0.7017, -0.2938],\n",
      "        [-0.5356, -0.7016, -0.2942],\n",
      "        [-0.5359, -0.7014, -0.2956],\n",
      "        [-0.5362, -0.7010, -0.2981],\n",
      "        [-0.5358, -0.7015, -0.2951]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT Encoder\")\n",
    "constr_params = gat_enc.serialize_constructor_params()\n",
    "state_dict = gat_enc.state_dict()\n",
    "print(constr_params)\n",
    "gat_enc2 = RevGATConvEncoder.from_constructor_params(constr_params)\n",
    "gat_enc2.load_state_dict(state_dict)\n",
    "print(gat_enc2)\n",
    "print(torchinfo.summary(gat_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gat_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "constr_params = sage_enc.serialize_constructor_params()\n",
    "state_dict = sage_enc.state_dict()\n",
    "print(constr_params)\n",
    "sage_enc2 = RevSAGEConvEncoder.from_constructor_params(constr_params)\n",
    "sage_enc2.load_state_dict(state_dict)\n",
    "print(sage_enc2)\n",
    "print(torchinfo.summary(sage_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(sage_enc2(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN Encoder\")\n",
    "constr_params = gcn_enc.serialize_constructor_params()\n",
    "state_dict = gcn_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn_enc2 = SimpleGCNEncoder.from_constructor_params(constr_params)\n",
    "gcn_enc2.load_state_dict(state_dict)\n",
    "print(gcn_enc2)\n",
    "print(torchinfo.summary(gcn_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 Encoder\")\n",
    "constr_params = gcn2_enc.serialize_constructor_params()\n",
    "state_dict = gcn2_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn2_enc2 = ResGCN2ConvEncoder.from_constructor_params(constr_params)\n",
    "gcn2_enc2.load_state_dict(state_dict)\n",
    "print(gcn2_enc2)\n",
    "print(torchinfo.summary(gcn2_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn2_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate and test GAEv2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevGATConvEncoder: 1-1                                     --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 268\n",
      "│    │    └─GroupAddRev: 3-2                                 268\n",
      "│    │    └─GroupAddRev: 3-3                                 268\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.7103, 0.7205, 0.7103, 0.7493, 0.7205, 0.7493, 0.7542, 0.7535, 0.7542,\n",
      "        0.7535], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6869, 0.7103, 0.7205, 0.7154, 0.7142],\n",
      "        [0.7103, 0.7386, 0.7493, 0.7431, 0.7426],\n",
      "        [0.7205, 0.7493, 0.7604, 0.7542, 0.7535],\n",
      "        [0.7154, 0.7431, 0.7542, 0.7482, 0.7473],\n",
      "        [0.7142, 0.7426, 0.7535, 0.7473, 0.7466]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.2903,  0.8375, -0.0025],\n",
      "        [-0.3478,  0.9509,  0.1168],\n",
      "        [-0.3982,  0.9929,  0.1032],\n",
      "        [-0.3869,  0.9667,  0.0715],\n",
      "        [-0.3687,  0.9661,  0.1067]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.7103, 0.7205, 0.7103, 0.7493, 0.7205, 0.7493, 0.7542, 0.7535, 0.7542,\n",
      "        0.7535], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.6249, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.68, 0.8142857142857143)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevSAGEConvEncoder: 1-1                                    --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 40\n",
      "│    │    └─GroupAddRev: 3-2                                 40\n",
      "│    │    └─GroupAddRev: 3-3                                 40\n",
      "│    │    └─GroupAddRev: 3-4                                 40\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.5130, 0.5170, 0.5130, 0.5125, 0.5170, 0.5125, 0.5128, 0.5159, 0.5128,\n",
      "        0.5159], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.5160, 0.5130, 0.5170, 0.5132, 0.5152],\n",
      "        [0.5130, 0.5140, 0.5125, 0.5140, 0.5131],\n",
      "        [0.5170, 0.5125, 0.5187, 0.5128, 0.5159],\n",
      "        [0.5132, 0.5140, 0.5128, 0.5140, 0.5132],\n",
      "        [0.5152, 0.5131, 0.5159, 0.5132, 0.5146]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.0668,  0.2156, -0.1150],\n",
      "        [ 0.0168,  0.2351, -0.0228],\n",
      "        [-0.0865,  0.2038, -0.1601],\n",
      "        [ 0.0104,  0.2346, -0.0267],\n",
      "        [-0.0343,  0.2154, -0.1042]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5130, 0.5170, 0.5130, 0.5125, 0.5170, 0.5125, 0.5128, 0.5159, 0.5128,\n",
      "        0.5159], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.3861, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.4, 0.6638888888888889)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─SimpleGCNEncoder: 1-1                       --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            15\n",
      "│    └─LayerNorm: 2-3                         8\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCNConvBlock: 3-1                 40\n",
      "│    │    └─GCNConvBlock: 3-2                 40\n",
      "│    │    └─GCNConvBlock: 3-3                 34\n",
      "│    │    └─GCNConvBlock: 3-4                 28\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.7956, 0.7942, 0.7956, 0.7938, 0.7942, 0.7938, 0.7910, 0.7889, 0.7910,\n",
      "        0.7889], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.7959, 0.7956, 0.7942, 0.7927, 0.7906],\n",
      "        [0.7956, 0.7953, 0.7938, 0.7924, 0.7903],\n",
      "        [0.7942, 0.7938, 0.7924, 0.7910, 0.7889],\n",
      "        [0.7927, 0.7924, 0.7910, 0.7896, 0.7875],\n",
      "        [0.7906, 0.7903, 0.7889, 0.7875, 0.7854]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.2510, -0.2572, -1.1099],\n",
      "        [-0.2500, -0.2562, -1.1086],\n",
      "        [-0.2454, -0.2517, -1.1027],\n",
      "        [-0.2409, -0.2473, -1.0969],\n",
      "        [-0.2343, -0.2408, -1.0884]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.7956, 0.7942, 0.7956, 0.7938, 0.7942, 0.7938, 0.7910, 0.7889, 0.7910,\n",
      "        0.7889], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.7964, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.76, 0.8444444444444443)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─ResGCN2ConvEncoder: 1-1                     --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            18\n",
      "│    └─LayerNorm: 2-3                         10\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCN2ConvBlock: 3-1                35\n",
      "│    │    └─GCN2ConvBlock: 3-2                35\n",
      "│    │    └─GCN2ConvBlock: 3-3                35\n",
      "│    │    └─GCN2ConvBlock: 3-4                35\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.8055, 0.8026, 0.8055, 0.8018, 0.8026, 0.8018, 0.7902, 0.8009, 0.7902,\n",
      "        0.8009], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.8063, 0.8055, 0.8026, 0.7938, 0.8046],\n",
      "        [0.8055, 0.8048, 0.8018, 0.7931, 0.8038],\n",
      "        [0.8026, 0.8018, 0.7989, 0.7902, 0.8009],\n",
      "        [0.7938, 0.7931, 0.7902, 0.7817, 0.7921],\n",
      "        [0.8046, 0.8038, 0.8009, 0.7921, 0.8029]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.8730,  0.1715, -0.7966],\n",
      "        [-0.8712,  0.1686, -0.7931],\n",
      "        [-0.8634,  0.1576, -0.7806],\n",
      "        [-0.8390,  0.1262, -0.7454],\n",
      "        [-0.8694,  0.1647, -0.7883]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.8055, 0.8026, 0.8055, 0.8018, 0.8026, 0.8018, 0.7902, 0.8009, 0.7902,\n",
      "        0.8009], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.8202, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.56, 0.6533333333333333)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test serialization for GAE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2325,  0.0062,  0.2586, -0.1427, -0.2812,  0.0527],\n",
      "        [-0.1823,  0.2179,  0.2643,  0.2845, -0.2952, -0.0728],\n",
      "        [-0.0282,  0.2282,  0.2309, -0.1633,  0.3095, -0.0712],\n",
      "        [ 0.2602,  0.3798,  0.3059,  0.2436,  0.1001, -0.3629]])), ('lin1.bias', tensor([-0.3369,  0.1305,  0.1654, -0.2465])), ('lin2.weight', tensor([[ 0.3199,  0.3288, -0.2284,  0.3137],\n",
      "        [-0.1276,  0.2141,  0.2200,  0.1632],\n",
      "        [-0.1096,  0.1098,  0.4757, -0.2267]])), ('lin2.bias', tensor([ 0.4975, -0.3851,  0.1256])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[ 0.3385,  0.6159],\n",
      "         [-0.1033, -0.2066],\n",
      "         [ 0.2152, -0.6009],\n",
      "         [ 0.5628,  0.7044],\n",
      "         [-0.0260, -0.5942],\n",
      "         [ 0.1920,  0.4970],\n",
      "         [-0.0321,  0.6451],\n",
      "         [ 0.4608,  0.6885]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.4427, -0.5164],\n",
      "        [ 0.1295, -0.1631],\n",
      "        [ 0.0221,  0.4073],\n",
      "        [ 0.5230,  0.5257],\n",
      "        [ 0.0423, -0.1572],\n",
      "        [ 0.2604,  0.1614],\n",
      "        [-0.0657,  0.2972],\n",
      "        [-0.3310, -0.4781],\n",
      "        [ 0.1123,  0.4613],\n",
      "        [-0.4847, -0.0755],\n",
      "        [ 0.4040,  0.4526],\n",
      "        [ 0.2239, -0.4693],\n",
      "        [ 0.3135,  0.2705],\n",
      "        [ 0.1079,  0.4033],\n",
      "        [ 0.2171,  0.1717],\n",
      "        [-0.0945,  0.1937]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.0916, -0.0741, -0.2589, -0.6670, -0.4121, -0.2575, -0.4884, -0.4090,\n",
      "        -0.1366,  0.0728,  0.6894,  0.4195,  0.6391, -0.1982, -0.1610, -0.1259])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.2723, -0.2408],\n",
      "        [ 0.3113, -0.3874],\n",
      "        [-0.2049,  0.1717],\n",
      "        [-0.4333, -0.0233],\n",
      "        [-0.0225, -0.2152],\n",
      "        [ 0.2165, -0.2541],\n",
      "        [-0.1199,  0.2281],\n",
      "        [-0.0524, -0.3702],\n",
      "        [ 0.5644, -0.2660],\n",
      "        [-0.5529, -0.2624],\n",
      "        [ 0.5413,  0.1334],\n",
      "        [-0.5245,  0.0484],\n",
      "        [ 0.0912,  0.3245],\n",
      "        [-0.0455,  0.3808],\n",
      "        [ 0.4126,  0.3460],\n",
      "        [ 0.4070, -0.1770]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([-0.1089,  0.0282, -0.2687, -0.3794, -0.6392,  0.2376,  0.7065,  0.6444,\n",
      "         0.6435, -0.1107,  0.1123,  0.5421, -0.0626, -0.0843, -0.3093, -0.2923])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.3755],\n",
      "        [-0.3477],\n",
      "        [ 0.5497],\n",
      "        [ 0.4589],\n",
      "        [ 0.4366],\n",
      "        [ 0.1445],\n",
      "        [-0.3951],\n",
      "        [-0.0958],\n",
      "        [-0.2929],\n",
      "        [-0.5146],\n",
      "        [-0.3031],\n",
      "        [ 0.2515],\n",
      "        [ 0.1666],\n",
      "        [-0.2527],\n",
      "        [ 0.0672],\n",
      "        [-0.4910]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.4569, -0.5142],\n",
      "         [ 0.4266, -0.0568],\n",
      "         [ 0.2536,  0.5843],\n",
      "         [ 0.2271,  0.3320],\n",
      "         [-0.5644,  0.4916],\n",
      "         [ 0.2385,  0.3216],\n",
      "         [ 0.5594, -0.0619],\n",
      "         [-0.7515,  0.1000]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.1699, -0.3425],\n",
      "        [-0.4952,  0.2090],\n",
      "        [ 0.1638,  0.3983],\n",
      "        [-0.2213,  0.4033],\n",
      "        [-0.5176, -0.1025],\n",
      "        [ 0.0638,  0.2000],\n",
      "        [-0.1860,  0.1995],\n",
      "        [-0.5606, -0.0694],\n",
      "        [ 0.2671, -0.3864],\n",
      "        [ 0.4590,  0.3585],\n",
      "        [ 0.3965,  0.2156],\n",
      "        [-0.0899,  0.4713],\n",
      "        [-0.0393, -0.3870],\n",
      "        [-0.1465,  0.5445],\n",
      "        [ 0.3074, -0.5433],\n",
      "        [-0.5279,  0.1498]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.0046, -0.0788, -0.6517,  0.4866, -0.3816,  0.2018, -0.0803,  0.7010,\n",
      "         0.3540, -0.4177, -0.4953, -0.3712, -0.1910,  0.3345, -0.2356,  0.6867])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.4104, -0.1616],\n",
      "        [-0.2061, -0.1064],\n",
      "        [ 0.1259, -0.2376],\n",
      "        [-0.1081, -0.1111],\n",
      "        [ 0.0304, -0.2869],\n",
      "        [ 0.5190,  0.3742],\n",
      "        [ 0.5676, -0.5406],\n",
      "        [ 0.3119,  0.4491],\n",
      "        [-0.3146, -0.0629],\n",
      "        [-0.0315,  0.1110],\n",
      "        [-0.5620, -0.4640],\n",
      "        [-0.0048, -0.4049],\n",
      "        [-0.4339,  0.3317],\n",
      "        [ 0.2759,  0.2819],\n",
      "        [-0.2522, -0.5695],\n",
      "        [ 0.2766, -0.2899]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.3799, -0.5526, -0.0476, -0.1361, -0.5362, -0.3905,  0.2358,  0.2396,\n",
      "         0.3287,  0.1662,  0.0956,  0.4180,  0.0705, -0.2526, -0.3094,  0.4105])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.4656],\n",
      "        [-0.1053],\n",
      "        [ 0.1694],\n",
      "        [-0.3336],\n",
      "        [ 0.5469],\n",
      "        [ 0.5197],\n",
      "        [ 0.5472],\n",
      "        [ 0.5880],\n",
      "        [-0.1771],\n",
      "        [ 0.1105],\n",
      "        [ 0.3627],\n",
      "        [ 0.1521],\n",
      "        [-0.4888],\n",
      "        [-0.2273],\n",
      "        [ 0.0537],\n",
      "        [-0.5108]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[ 0.0364,  0.2078],\n",
      "         [ 0.1421, -0.1446],\n",
      "         [ 0.2367, -0.1506],\n",
      "         [-0.0264, -0.6805],\n",
      "         [-0.7696,  0.5709],\n",
      "         [ 0.1828,  0.0553],\n",
      "         [-0.5277, -0.3751],\n",
      "         [-0.5604,  0.5391]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.5591, -0.3020],\n",
      "        [ 0.1735,  0.0463],\n",
      "        [-0.4791,  0.4285],\n",
      "        [ 0.0722, -0.4620],\n",
      "        [ 0.4141, -0.2285],\n",
      "        [-0.5758,  0.2954],\n",
      "        [ 0.1146,  0.2655],\n",
      "        [-0.2928,  0.0346],\n",
      "        [-0.5316,  0.4463],\n",
      "        [ 0.3498, -0.0255],\n",
      "        [-0.1422,  0.1248],\n",
      "        [-0.1848, -0.2530],\n",
      "        [-0.2629,  0.0263],\n",
      "        [-0.1580, -0.0667],\n",
      "        [-0.3472,  0.3313],\n",
      "        [-0.5051, -0.4478]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.3644, -0.3812,  0.6827,  0.6598, -0.6500,  0.0219, -0.3364,  0.7025,\n",
      "        -0.0613, -0.6470, -0.3216,  0.6064,  0.6227, -0.3182, -0.6829, -0.3786])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4843,  0.3683],\n",
      "        [ 0.2315, -0.3057],\n",
      "        [ 0.4165,  0.2363],\n",
      "        [ 0.4250,  0.1073],\n",
      "        [-0.3092, -0.5240],\n",
      "        [ 0.2804, -0.1176],\n",
      "        [-0.0318, -0.3243],\n",
      "        [ 0.2932,  0.5334],\n",
      "        [-0.5670, -0.3326],\n",
      "        [-0.1003, -0.0052],\n",
      "        [-0.0421, -0.2846],\n",
      "        [-0.0878, -0.2956],\n",
      "        [-0.1566, -0.3067],\n",
      "        [-0.1276, -0.5438],\n",
      "        [-0.0364, -0.3874],\n",
      "        [-0.0583, -0.3349]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([ 0.6937, -0.5914,  0.3506, -0.4247, -0.6396, -0.1510, -0.2144, -0.6983,\n",
      "         0.0740, -0.1416, -0.2508,  0.1674, -0.1573, -0.4746,  0.1824, -0.2127])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.1551],\n",
      "        [-0.5254],\n",
      "        [ 0.1254],\n",
      "        [ 0.5315],\n",
      "        [ 0.4666],\n",
      "        [-0.2966],\n",
      "        [-0.0462],\n",
      "        [-0.2125],\n",
      "        [ 0.1933],\n",
      "        [ 0.2632],\n",
      "        [-0.0956],\n",
      "        [ 0.4789],\n",
      "        [-0.3839],\n",
      "        [-0.4248],\n",
      "        [-0.2878],\n",
      "        [-0.1829]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[ 0.1664,  0.1209],\n",
      "         [-0.1102,  0.4641],\n",
      "         [-0.1353,  0.6987],\n",
      "         [-0.2233, -0.2290],\n",
      "         [ 0.4637,  0.5879],\n",
      "         [-0.4432, -0.7435],\n",
      "         [ 0.0448, -0.4867],\n",
      "         [-0.1147,  0.5516]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 2.6705e-01,  1.3837e-01],\n",
      "        [ 3.5897e-01, -4.9804e-01],\n",
      "        [-2.1275e-01,  1.8418e-01],\n",
      "        [ 3.1110e-01, -3.3597e-01],\n",
      "        [-3.6253e-01,  5.7487e-01],\n",
      "        [-2.2867e-01,  1.6474e-01],\n",
      "        [-2.9697e-01, -5.1864e-01],\n",
      "        [ 9.6864e-02,  3.6356e-01],\n",
      "        [ 1.6779e-04, -2.3982e-01],\n",
      "        [ 3.5375e-01, -3.4257e-01],\n",
      "        [ 1.4245e-01,  1.3799e-01],\n",
      "        [-1.7230e-01, -3.0457e-01],\n",
      "        [-5.5255e-01, -2.3032e-01],\n",
      "        [-4.4898e-01, -2.5755e-01],\n",
      "        [ 2.0507e-01,  2.3945e-01],\n",
      "        [ 4.3717e-01,  7.7904e-02]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.4911, -0.4601,  0.0847, -0.1399, -0.0782,  0.1258,  0.2234,  0.5962,\n",
      "        -0.6544,  0.1687, -0.4287,  0.4695, -0.4409, -0.2530, -0.1393,  0.5314])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.2049, -0.5738],\n",
      "        [-0.2760, -0.3373],\n",
      "        [ 0.4342,  0.3741],\n",
      "        [-0.1925, -0.1798],\n",
      "        [ 0.5244,  0.1562],\n",
      "        [ 0.2665,  0.0164],\n",
      "        [ 0.3908,  0.3595],\n",
      "        [ 0.1497,  0.3408],\n",
      "        [-0.3322, -0.1269],\n",
      "        [-0.5500, -0.4481],\n",
      "        [-0.4309, -0.1638],\n",
      "        [-0.2111,  0.1237],\n",
      "        [ 0.2579, -0.4561],\n",
      "        [ 0.1316,  0.5274],\n",
      "        [ 0.0154,  0.5201],\n",
      "        [ 0.5469,  0.4034]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([ 0.4103, -0.3425,  0.1665,  0.1855,  0.5803, -0.0891, -0.4670,  0.6755,\n",
      "         0.5077, -0.4810, -0.5462,  0.3947,  0.1696, -0.6777, -0.5205, -0.5429])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[ 0.5424],\n",
      "        [ 0.4485],\n",
      "        [-0.5494],\n",
      "        [ 0.4883],\n",
      "        [-0.3991],\n",
      "        [-0.4729],\n",
      "        [ 0.2225],\n",
      "        [ 0.4693],\n",
      "        [-0.4817],\n",
      "        [-0.2965],\n",
      "        [ 0.1357],\n",
      "        [ 0.0176],\n",
      "        [-0.4814],\n",
      "        [-0.3794],\n",
      "        [-0.0875],\n",
      "        [-0.3882]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[-0.5264, -0.4926],\n",
      "         [-0.3588, -0.3621],\n",
      "         [ 0.6811, -0.2423],\n",
      "         [ 0.6226,  0.4842],\n",
      "         [ 0.2671, -0.0117],\n",
      "         [-0.0599,  0.2740],\n",
      "         [-0.3136, -0.0162],\n",
      "         [-0.0888, -0.4437]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.4076,  0.0012],\n",
      "        [-0.1179,  0.0217],\n",
      "        [ 0.5265,  0.2009],\n",
      "        [ 0.4715, -0.3664],\n",
      "        [-0.1326,  0.0161],\n",
      "        [-0.3261,  0.1874],\n",
      "        [-0.1395,  0.3130],\n",
      "        [-0.0270,  0.4820],\n",
      "        [-0.5652, -0.0039],\n",
      "        [ 0.0673,  0.2428],\n",
      "        [ 0.5363, -0.0573],\n",
      "        [ 0.1972,  0.1875],\n",
      "        [-0.4001, -0.4961],\n",
      "        [-0.0723,  0.1952],\n",
      "        [ 0.1064, -0.5467],\n",
      "        [-0.4506,  0.0527]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.4439,  0.0933, -0.6449,  0.1643, -0.5909, -0.2140, -0.4119, -0.2058,\n",
      "         0.3424, -0.0757,  0.1109,  0.3667,  0.4201, -0.6829, -0.5139, -0.4114])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.4266, -0.1334],\n",
      "        [ 0.2066,  0.1939],\n",
      "        [-0.3874, -0.1729],\n",
      "        [ 0.2305, -0.2040],\n",
      "        [-0.4756,  0.1493],\n",
      "        [-0.4247,  0.0308],\n",
      "        [-0.0810,  0.1104],\n",
      "        [-0.3212,  0.4626],\n",
      "        [ 0.4038,  0.4239],\n",
      "        [ 0.2706, -0.1211],\n",
      "        [-0.2907,  0.1007],\n",
      "        [ 0.0324, -0.4435],\n",
      "        [ 0.0178,  0.4114],\n",
      "        [-0.0563,  0.0944],\n",
      "        [-0.4588,  0.5228],\n",
      "        [ 0.3268,  0.4617]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([-0.4241, -0.4114,  0.3952,  0.0378,  0.5961,  0.3374,  0.2352, -0.1069,\n",
      "        -0.4913,  0.4916,  0.1694,  0.1716,  0.4821, -0.0053,  0.4383, -0.0559])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.1885],\n",
      "        [ 0.3956],\n",
      "        [ 0.1663],\n",
      "        [ 0.5430],\n",
      "        [-0.4896],\n",
      "        [ 0.2961],\n",
      "        [-0.0922],\n",
      "        [-0.4012],\n",
      "        [-0.2314],\n",
      "        [-0.2845],\n",
      "        [ 0.2332],\n",
      "        [ 0.2507],\n",
      "        [-0.0555],\n",
      "        [-0.5660],\n",
      "        [ 0.1983],\n",
      "        [ 0.4466]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[-0.7263, -0.6950],\n",
      "         [ 0.3130, -0.1502],\n",
      "         [ 0.1886, -0.0751],\n",
      "         [ 0.0140,  0.0700],\n",
      "         [-0.4858,  0.6658],\n",
      "         [ 0.0646, -0.0635],\n",
      "         [ 0.1574,  0.5263],\n",
      "         [ 0.6245, -0.3281]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.1954,  0.1154],\n",
      "        [ 0.4530, -0.3088],\n",
      "        [-0.5747,  0.4966],\n",
      "        [-0.1014,  0.1693],\n",
      "        [ 0.0341,  0.0100],\n",
      "        [ 0.4030,  0.0018],\n",
      "        [-0.3265, -0.2739],\n",
      "        [ 0.2490, -0.0739],\n",
      "        [ 0.3893,  0.5685],\n",
      "        [ 0.5419,  0.0153],\n",
      "        [ 0.0665,  0.0966],\n",
      "        [ 0.2716,  0.4948],\n",
      "        [ 0.3732,  0.2824],\n",
      "        [ 0.4871,  0.3259],\n",
      "        [ 0.1376, -0.2948],\n",
      "        [ 0.2877, -0.0447]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.2310,  0.4835,  0.5630,  0.3091,  0.1223,  0.3612,  0.4087, -0.0288,\n",
      "        -0.3413, -0.5163, -0.5455,  0.3547,  0.2234, -0.3500,  0.0684, -0.0362])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.2370,  0.4882],\n",
      "        [-0.2194, -0.2370],\n",
      "        [-0.4644,  0.0472],\n",
      "        [ 0.5222, -0.0158],\n",
      "        [ 0.2191, -0.2867],\n",
      "        [-0.4287, -0.2547],\n",
      "        [ 0.4536, -0.3394],\n",
      "        [-0.4043,  0.4596],\n",
      "        [ 0.0821,  0.2763],\n",
      "        [ 0.4536, -0.5434],\n",
      "        [ 0.3737,  0.2799],\n",
      "        [-0.1117, -0.0245],\n",
      "        [ 0.5202,  0.5746],\n",
      "        [ 0.2904, -0.4555],\n",
      "        [-0.0768,  0.5137],\n",
      "        [ 0.2003, -0.1130]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([-0.0535,  0.1463, -0.3230, -0.4612,  0.0495,  0.0487, -0.1135,  0.5573,\n",
      "         0.4922,  0.2745, -0.0844, -0.5792, -0.5638,  0.4648, -0.4992, -0.0923])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[ 0.3731],\n",
      "        [-0.0325],\n",
      "        [ 0.2760],\n",
      "        [-0.4483],\n",
      "        [-0.0832],\n",
      "        [ 0.2020],\n",
      "        [-0.3479],\n",
      "        [-0.5281],\n",
      "        [-0.2917],\n",
      "        [-0.5426],\n",
      "        [ 0.3907],\n",
      "        [-0.0465],\n",
      "        [-0.5703],\n",
      "        [-0.5543],\n",
      "        [ 0.0811],\n",
      "        [ 0.5745]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevGATConvEncoder: 1-1                                     --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 268\n",
      "│    │    └─GroupAddRev: 3-2                                 268\n",
      "│    │    └─GroupAddRev: 3-3                                 268\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.7253, 0.7153, 0.7253, 0.6963, 0.7153, 0.6963, 0.7074, 0.6631, 0.7074,\n",
      "        0.6631], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.7253, 0.7153, 0.7253, 0.6963, 0.7153, 0.6963, 0.7074, 0.6631, 0.7074,\n",
      "        0.6631], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7475, 0.7253, 0.7153, 0.7391, 0.6822],\n",
      "        [0.7253, 0.7053, 0.6963, 0.7176, 0.6669],\n",
      "        [0.7153, 0.6963, 0.6887, 0.7074, 0.6631],\n",
      "        [0.7391, 0.7176, 0.7074, 0.7311, 0.6747],\n",
      "        [0.6822, 0.6669, 0.6631, 0.6747, 0.6474]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.7475, 0.7253, 0.7153, 0.7391, 0.6822],\n",
      "        [0.7253, 0.7053, 0.6963, 0.7176, 0.6669],\n",
      "        [0.7153, 0.6963, 0.6887, 0.7074, 0.6631],\n",
      "        [0.7391, 0.7176, 0.7074, 0.7311, 0.6747],\n",
      "        [0.6822, 0.6669, 0.6631, 0.6747, 0.6474]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 1.0134, -0.1124, -0.2135],\n",
      "        [ 0.9119, -0.1420, -0.1451],\n",
      "        [ 0.8826, -0.0983, -0.0737],\n",
      "        [ 0.9668, -0.1409, -0.2137],\n",
      "        [ 0.7706, -0.0489,  0.1059]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 1.0134, -0.1124, -0.2135],\n",
      "        [ 0.9119, -0.1420, -0.1451],\n",
      "        [ 0.8826, -0.0983, -0.0737],\n",
      "        [ 0.9668, -0.1409, -0.2137],\n",
      "        [ 0.7706, -0.0489,  0.1059]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.7253, 0.7153, 0.7253, 0.6963, 0.7153, 0.6963, 0.7074, 0.6631, 0.7074,\n",
      "        0.6631], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.7253, 0.7153, 0.7253, 0.6963, 0.7153, 0.6963, 0.7074, 0.6631, 0.7074,\n",
      "        0.6631], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.5504, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.5504, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.52, 0.5533333333333332)\n",
      "AUC and precision metric test deserialized\n",
      "(0.52, 0.5533333333333332)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.3061, -0.0916, -0.3863,  0.1137,  0.0526, -0.0209],\n",
      "        [ 0.3796,  0.0430,  0.3648,  0.1281, -0.1514,  0.0425],\n",
      "        [-0.2874,  0.1836, -0.0867, -0.3741,  0.0914, -0.3016],\n",
      "        [ 0.2212,  0.2738,  0.1175, -0.3322,  0.0852,  0.0191]])), ('lin1.bias', tensor([-0.2943, -0.0346, -0.0745,  0.2656])), ('lin2.weight', tensor([[-0.3814,  0.4206, -0.3504, -0.4777],\n",
      "        [ 0.1438, -0.2389, -0.2906,  0.4342],\n",
      "        [-0.1001, -0.4034, -0.0838, -0.2328]])), ('lin2.bias', tensor([ 0.4056, -0.2393,  0.0950])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.1418, -0.5907],\n",
      "        [-0.6217,  0.3399]])), ('convs.0.convs.0.conv.lin.bias', tensor([0.0524, 0.0476])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.5959, -0.4944],\n",
      "        [-0.7069, -0.3567]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([0.2384, 0.2057])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[-0.2423, -0.4318],\n",
      "        [ 0.5759, -0.3338]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.4343, -0.3748],\n",
      "        [-0.2128,  0.2577]])), ('convs.0.convs.1.conv.lin.bias', tensor([ 0.5314, -0.4251])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.0633,  0.6248],\n",
      "        [-0.5139, -0.3116]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.6218, -0.1155])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.4470, -0.5280],\n",
      "        [-0.1803, -0.2558]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[ 0.6055,  0.1639],\n",
      "        [-0.1515, -0.0562]])), ('convs.1.convs.0.conv.lin.bias', tensor([-0.5977, -0.5086])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.4265,  0.0257],\n",
      "        [ 0.1264,  0.4032]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.2314,  0.3375])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.0950,  0.0019],\n",
      "        [ 0.6828, -0.6250]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[0.5905, 0.0432],\n",
      "        [0.1410, 0.0306]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.0599, -0.0365])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.4454,  0.6099],\n",
      "        [ 0.6803, -0.3128]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([0.4546, 0.2943])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[0.3759, 0.5776],\n",
      "        [0.4568, 0.4301]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[ 0.2008, -0.4588],\n",
      "        [-0.3512, -0.0546]])), ('convs.2.convs.0.conv.lin.bias', tensor([ 0.4834, -0.3564])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.2631,  0.0940],\n",
      "        [ 0.2321, -0.6840]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.6949,  0.0353])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2937, -0.3069],\n",
      "        [ 0.6796, -0.3522]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[-0.5105,  0.2188],\n",
      "        [ 0.3889, -0.6352]])), ('convs.2.convs.1.conv.lin.bias', tensor([-0.0475, -0.3307])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.6908, -0.5282],\n",
      "        [-0.0535, -0.6759]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.1144, -0.3387])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.4315,  0.6182],\n",
      "        [ 0.2376, -0.4833]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[-0.6741, -0.6847],\n",
      "        [ 0.6554, -0.0780]])), ('convs.3.convs.0.conv.lin.bias', tensor([ 0.3394, -0.5374])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.6506, -0.1170],\n",
      "        [ 0.0050, -0.5756]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([ 0.3204, -0.1429])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.0565, -0.6745],\n",
      "        [-0.1355, -0.3966]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[ 0.5989, -0.5347],\n",
      "        [ 0.4242,  0.3273]])), ('convs.3.convs.1.conv.lin.bias', tensor([ 0.0503, -0.0841])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[0.6860, 0.3764],\n",
      "        [0.5832, 0.4715]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([0.2480, 0.5914])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[ 0.4260, -0.5283],\n",
      "        [ 0.1761,  0.2253]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevSAGEConvEncoder: 1-1                                    --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 40\n",
      "│    │    └─GroupAddRev: 3-2                                 40\n",
      "│    │    └─GroupAddRev: 3-3                                 40\n",
      "│    │    └─GroupAddRev: 3-4                                 40\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.5355, 0.5379, 0.5355, 0.5478, 0.5379, 0.5478, 0.5388, 0.5450, 0.5388,\n",
      "        0.5450], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.5355, 0.5379, 0.5355, 0.5478, 0.5379, 0.5478, 0.5388, 0.5450, 0.5388,\n",
      "        0.5450], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.5316, 0.5355, 0.5379, 0.5338, 0.5393],\n",
      "        [0.5355, 0.5586, 0.5478, 0.5322, 0.5366],\n",
      "        [0.5379, 0.5478, 0.5469, 0.5388, 0.5450],\n",
      "        [0.5338, 0.5322, 0.5388, 0.5377, 0.5441],\n",
      "        [0.5393, 0.5366, 0.5450, 0.5441, 0.5517]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.5316, 0.5355, 0.5379, 0.5338, 0.5393],\n",
      "        [0.5355, 0.5586, 0.5478, 0.5322, 0.5366],\n",
      "        [0.5379, 0.5478, 0.5469, 0.5388, 0.5450],\n",
      "        [0.5338, 0.5322, 0.5388, 0.5377, 0.5441],\n",
      "        [0.5393, 0.5366, 0.5450, 0.5441, 0.5517]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.2569, -0.1971, -0.1478],\n",
      "        [-0.1471, -0.4506, -0.1045],\n",
      "        [-0.2780, -0.3019, -0.1404],\n",
      "        [-0.3155, -0.1423, -0.1766],\n",
      "        [-0.3796, -0.1560, -0.1976]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.2569, -0.1971, -0.1478],\n",
      "        [-0.1471, -0.4506, -0.1045],\n",
      "        [-0.2780, -0.3019, -0.1404],\n",
      "        [-0.3155, -0.1423, -0.1766],\n",
      "        [-0.3796, -0.1560, -0.1976]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.5355, 0.5379, 0.5355, 0.5478, 0.5379, 0.5478, 0.5388, 0.5450, 0.5388,\n",
      "        0.5450], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.5355, 0.5379, 0.5355, 0.5478, 0.5379, 0.5478, 0.5388, 0.5450, 0.5388,\n",
      "        0.5450], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.3849, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.3849, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.72, 0.7783333333333333)\n",
      "AUC and precision metric test deserialized\n",
      "(0.72, 0.7783333333333333)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2253, -0.3490,  0.0263,  0.0143, -0.0473,  0.0640],\n",
      "        [-0.2225,  0.2643,  0.1371,  0.3303,  0.2850,  0.1560],\n",
      "        [-0.3384, -0.1804,  0.2390, -0.2218,  0.1817,  0.2627],\n",
      "        [-0.3503,  0.0651,  0.0370, -0.1522,  0.1062, -0.3729],\n",
      "        [ 0.3183,  0.3846,  0.0765, -0.2724, -0.3007, -0.3592]])), ('lin1.bias', tensor([-0.0399,  0.3552,  0.3902,  0.0148, -0.2714])), ('lin2.weight', tensor([[ 0.1511, -0.1411,  0.4007, -0.1471],\n",
      "        [-0.3093,  0.3394,  0.4173,  0.2401],\n",
      "        [ 0.3915,  0.0782, -0.4220,  0.2512]])), ('lin2.bias', tensor([0.2393, 0.2834, 0.2053])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[-0.3042, -0.0975,  0.0432, -0.6923, -0.5514],\n",
      "        [-0.7114, -0.2606, -0.5761, -0.0174, -0.2678],\n",
      "        [ 0.5488, -0.0596, -0.3402, -0.3834,  0.6864],\n",
      "        [ 0.5987, -0.4499,  0.5867,  0.2816,  0.7333],\n",
      "        [-0.2048, -0.3207, -0.6171, -0.3620, -0.4466]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.3275,  0.3027, -0.1353,  0.5603, -0.7456],\n",
      "        [ 0.7394,  0.5957, -0.0133,  0.0616, -0.2663],\n",
      "        [-0.3335, -0.4806,  0.4445, -0.4093, -0.7639],\n",
      "        [-0.5916,  0.5131,  0.2177,  0.4392,  0.6935],\n",
      "        [-0.0264,  0.3292, -0.6720, -0.4464, -0.6496]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[-0.7173, -0.6604, -0.4845, -0.1228, -0.0801],\n",
      "        [-0.4913,  0.1225,  0.3304,  0.0952, -0.7704],\n",
      "        [ 0.4488,  0.0470, -0.5147,  0.6177,  0.2593],\n",
      "        [ 0.1911,  0.4819,  0.4887, -0.5599, -0.3910]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[-0.7658, -0.0293, -0.7233, -0.1707],\n",
      "        [ 0.1989,  0.7898, -0.6332,  0.0176],\n",
      "        [ 0.0482, -0.6805,  0.1784,  0.4366],\n",
      "        [-0.5726, -0.3393,  0.6482, -0.5642]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─SimpleGCNEncoder: 1-1                       --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            15\n",
      "│    └─LayerNorm: 2-3                         8\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCNConvBlock: 3-1                 40\n",
      "│    │    └─GCNConvBlock: 3-2                 40\n",
      "│    │    └─GCNConvBlock: 3-3                 34\n",
      "│    │    └─GCNConvBlock: 3-4                 28\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.7918, 0.7998, 0.7918, 0.8042, 0.7998, 0.8042, 0.8168, 0.8298, 0.8168,\n",
      "        0.8298], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.7918, 0.7998, 0.7918, 0.8042, 0.7998, 0.8042, 0.8168, 0.8298, 0.8168,\n",
      "        0.8298], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7877, 0.7918, 0.7998, 0.8033, 0.8150],\n",
      "        [0.7918, 0.7959, 0.8042, 0.8078, 0.8199],\n",
      "        [0.7998, 0.8042, 0.8130, 0.8168, 0.8298],\n",
      "        [0.8033, 0.8078, 0.8168, 0.8207, 0.8341],\n",
      "        [0.8150, 0.8199, 0.8298, 0.8341, 0.8488]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.7877, 0.7918, 0.7998, 0.8033, 0.8150],\n",
      "        [0.7918, 0.7959, 0.8042, 0.8078, 0.8199],\n",
      "        [0.7998, 0.8042, 0.8130, 0.8168, 0.8298],\n",
      "        [0.8033, 0.8078, 0.8168, 0.8207, 0.8341],\n",
      "        [0.8150, 0.8199, 0.8298, 0.8341, 0.8488]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.5612,  0.9807, -0.1861],\n",
      "        [ 0.5848,  0.9876, -0.2084],\n",
      "        [ 0.6361,  0.9997, -0.2564],\n",
      "        [ 0.6600,  1.0039, -0.2786],\n",
      "        [ 0.7564,  1.0094, -0.3664]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 0.5612,  0.9807, -0.1861],\n",
      "        [ 0.5848,  0.9876, -0.2084],\n",
      "        [ 0.6361,  0.9997, -0.2564],\n",
      "        [ 0.6600,  1.0039, -0.2786],\n",
      "        [ 0.7564,  1.0094, -0.3664]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.7918, 0.7998, 0.7918, 0.8042, 0.7998, 0.8042, 0.8168, 0.8298, 0.8168,\n",
      "        0.8298], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.7918, 0.7998, 0.7918, 0.8042, 0.7998, 0.8042, 0.8168, 0.8298, 0.8168,\n",
      "        0.8298], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.9072, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.9072, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.32000000000000006, 0.4746031746031746)\n",
      "AUC and precision metric test deserialized\n",
      "(0.32000000000000006, 0.4746031746031746)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2918,  0.2324, -0.1292, -0.1406,  0.0455, -0.0835],\n",
      "        [-0.3140,  0.1812,  0.1103,  0.2869,  0.1533,  0.3444],\n",
      "        [ 0.1299, -0.3773,  0.3862, -0.3439,  0.3632, -0.0181],\n",
      "        [-0.3070,  0.1200, -0.2800,  0.1436,  0.2080,  0.3050],\n",
      "        [-0.3340, -0.2577, -0.2397, -0.0455, -0.2547,  0.3886]])), ('lin1.bias', tensor([-0.4043, -0.1106, -0.2125,  0.3038,  0.1027])), ('lin2.weight', tensor([[ 0.3565,  0.0279, -0.0419,  0.1174, -0.2747],\n",
      "        [-0.0931,  0.1905, -0.0569,  0.0154, -0.0655],\n",
      "        [-0.4377,  0.2700, -0.1876, -0.4281, -0.4328]])), ('lin2.bias', tensor([ 0.3099, -0.4444,  0.2108])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[-0.0976,  0.4145,  0.5544, -0.7245, -0.3617],\n",
      "        [-0.1413,  0.4427,  0.1413,  0.2546, -0.3521],\n",
      "        [-0.3629, -0.6947,  0.7284, -0.4215, -0.4936],\n",
      "        [-0.5737, -0.2989, -0.1075,  0.4776,  0.1957],\n",
      "        [ 0.4743,  0.0038, -0.4942,  0.2256, -0.6462]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.4081,  0.7531,  0.2521,  0.1421, -0.3422],\n",
      "        [-0.1833, -0.3538,  0.1115, -0.0055,  0.0478],\n",
      "        [-0.2438,  0.2495, -0.5396, -0.7011, -0.4153],\n",
      "        [ 0.3387,  0.6728,  0.3934,  0.7564,  0.3402],\n",
      "        [-0.1130, -0.6723,  0.2167,  0.0286, -0.2044]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[-0.5632, -0.1361, -0.7589,  0.4048,  0.5803],\n",
      "        [ 0.1086, -0.0531, -0.4124, -0.4173,  0.5479],\n",
      "        [ 0.0494,  0.2837,  0.7502,  0.6945,  0.3450],\n",
      "        [ 0.0695,  0.4700, -0.2179, -0.4706, -0.4546],\n",
      "        [ 0.6606, -0.1322, -0.0999, -0.6772,  0.3437]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[ 0.1716,  0.5560,  0.3331,  0.3660,  0.3015],\n",
      "        [-0.4623,  0.4955, -0.2108,  0.7093,  0.6055],\n",
      "        [-0.5418,  0.0705,  0.0324,  0.1047, -0.2521],\n",
      "        [ 0.5069, -0.1551,  0.1866,  0.0922, -0.6895],\n",
      "        [ 0.1413, -0.1305, -0.2030,  0.3476,  0.2818]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─ResGCN2ConvEncoder: 1-1                     --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            18\n",
      "│    └─LayerNorm: 2-3                         10\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCN2ConvBlock: 3-1                35\n",
      "│    │    └─GCN2ConvBlock: 3-2                35\n",
      "│    │    └─GCN2ConvBlock: 3-3                35\n",
      "│    │    └─GCN2ConvBlock: 3-4                35\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.6298, 0.6253, 0.6298, 0.6233, 0.6253, 0.6233, 0.5963, 0.6319, 0.5963,\n",
      "        0.6319], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.6298, 0.6253, 0.6298, 0.6233, 0.6253, 0.6233, 0.5963, 0.6319, 0.5963,\n",
      "        0.6319], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6320, 0.6298, 0.6253, 0.6009, 0.6389],\n",
      "        [0.6298, 0.6277, 0.6233, 0.5994, 0.6366],\n",
      "        [0.6253, 0.6233, 0.6191, 0.5963, 0.6319],\n",
      "        [0.6009, 0.5994, 0.5963, 0.5792, 0.6061],\n",
      "        [0.6389, 0.6366, 0.6319, 0.6061, 0.6462]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.6320, 0.6298, 0.6253, 0.6009, 0.6389],\n",
      "        [0.6298, 0.6277, 0.6233, 0.5994, 0.6366],\n",
      "        [0.6253, 0.6233, 0.6191, 0.5963, 0.6319],\n",
      "        [0.6009, 0.5994, 0.5963, 0.5792, 0.6061],\n",
      "        [0.6389, 0.6366, 0.6319, 0.6061, 0.6462]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.1172, -0.4412, -0.5765],\n",
      "        [ 0.1195, -0.4364, -0.5635],\n",
      "        [ 0.1317, -0.4250, -0.5364],\n",
      "        [ 0.1627, -0.3760, -0.3893],\n",
      "        [ 0.1225, -0.4538, -0.6175]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 0.1172, -0.4412, -0.5765],\n",
      "        [ 0.1195, -0.4364, -0.5635],\n",
      "        [ 0.1317, -0.4250, -0.5364],\n",
      "        [ 0.1627, -0.3760, -0.3893],\n",
      "        [ 0.1225, -0.4538, -0.6175]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6298, 0.6253, 0.6298, 0.6233, 0.6253, 0.6233, 0.5963, 0.6319, 0.5963,\n",
      "        0.6319], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.6298, 0.6253, 0.6298, 0.6233, 0.6253, 0.6233, 0.5963, 0.6319, 0.5963,\n",
      "        0.6319], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4353, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.4353, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.48, 0.52)\n",
      "AUC and precision metric test deserialized\n",
      "(0.48, 0.52)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevGATConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevSAGEConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, SimpleGCNEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate VGAEv2 and test it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevGATConvEncoder: 2-1                                     --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       804\n",
      "│    └─RevGATConvEncoder: 2-2                                     --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       804\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.3255, 0.8788, 0.3255, 0.2387, 0.8788, 0.2387, 0.9994, 0.2784, 0.9994,\n",
      "        0.2784], grad_fn=<SigmoidBackward0>), tensor([[-0.6200,  0.4121,  0.2798],\n",
      "        [ 0.0832,  0.2554, -0.7061],\n",
      "        [-0.0084,  0.2508, -0.5432],\n",
      "        [-0.4448,  0.3857,  0.0168],\n",
      "        [-0.1278,  0.3354, -0.4555]], grad_fn=<AddmmBackward0>), tensor([[ 0.0777,  0.0385, -0.5747],\n",
      "        [ 0.0316, -0.0045, -0.5995],\n",
      "        [ 0.0848,  0.0514, -0.6114],\n",
      "        [ 0.0755,  0.0319, -0.5270],\n",
      "        [ 0.0040, -0.0072, -0.6281]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9990, 0.1164, 0.7609, 0.9824, 0.1266],\n",
      "        [0.1164, 1.0000, 0.0204, 0.3076, 0.9987],\n",
      "        [0.7609, 0.0204, 0.7531, 0.6450, 0.1285],\n",
      "        [0.9824, 0.3076, 0.6450, 0.9596, 0.2944],\n",
      "        [0.1266, 0.9987, 0.1285, 0.2944, 0.9646]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-1.6498,  0.6064, -0.1209],\n",
      "        [ 0.0486,  1.0148, -0.8565],\n",
      "        [-0.7616, -0.4700,  0.0503],\n",
      "        [-0.4543, -0.2503, -0.4211],\n",
      "        [ 0.7626, -0.2975,  0.5847]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.6200,  0.4121,  0.2798],\n",
      "        [ 0.0832,  0.2554, -0.7061],\n",
      "        [-0.0084,  0.2508, -0.5432],\n",
      "        [-0.4448,  0.3857,  0.0168],\n",
      "        [-0.1278,  0.3354, -0.4555]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[ 0.0777,  0.0385, -0.5747],\n",
      "        [ 0.0316, -0.0045, -0.5995],\n",
      "        [ 0.0848,  0.0514, -0.6114],\n",
      "        [ 0.0755,  0.0319, -0.5270],\n",
      "        [ 0.0040, -0.0072, -0.6281]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6545, 0.7242, 0.6545, 0.3642, 0.7242, 0.3642, 0.6088, 0.3985, 0.6088,\n",
      "        0.3985], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.2054, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.7200000000000001, 0.7416666666666667)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevSAGEConvEncoder: 2-1                                    --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       160\n",
      "│    └─RevSAGEConvEncoder: 2-2                                    --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       160\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.3763, 0.3427, 0.3763, 0.5777, 0.3427, 0.5777, 0.7027, 0.2836, 0.7027,\n",
      "        0.2836], grad_fn=<SigmoidBackward0>), tensor([[ 0.4073, -0.1972, -0.1108],\n",
      "        [ 0.2965, -0.1860, -0.1311],\n",
      "        [ 0.1821, -0.2199, -0.1258],\n",
      "        [ 0.3141, -0.2068, -0.1161],\n",
      "        [ 0.1450, -0.2199, -0.1286]], grad_fn=<AddmmBackward0>), tensor([[ 0.3060, -0.6896, -0.1070],\n",
      "        [ 0.3011, -0.6864, -0.1115],\n",
      "        [ 0.3028, -0.6875, -0.1100],\n",
      "        [ 0.3037, -0.6881, -0.1091],\n",
      "        [ 0.2888, -0.6784, -0.1229]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9717, 0.0478, 0.1406, 0.9981, 0.7710],\n",
      "        [0.0478, 0.9485, 0.7968, 0.0023, 0.2004],\n",
      "        [0.1406, 0.7968, 0.7792, 0.0410, 0.3540],\n",
      "        [0.9981, 0.0023, 0.0410, 1.0000, 0.9526],\n",
      "        [0.7710, 0.2004, 0.3540, 0.9526, 0.6940]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-1.2012, -0.3095,  0.5556],\n",
      "        [ 1.4395, -0.7006,  1.8378],\n",
      "        [-1.0072, -0.5135,  0.8319],\n",
      "        [-1.7439, -0.3248, -0.2945],\n",
      "        [ 0.4791, -0.4936,  0.0077]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[ 0.4073, -0.1972, -0.1108],\n",
      "        [ 0.2965, -0.1860, -0.1311],\n",
      "        [ 0.1821, -0.2199, -0.1258],\n",
      "        [ 0.3141, -0.2068, -0.1161],\n",
      "        [ 0.1450, -0.2199, -0.1286]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[ 0.3060, -0.6896, -0.1070],\n",
      "        [ 0.3011, -0.6864, -0.1115],\n",
      "        [ 0.3028, -0.6875, -0.1100],\n",
      "        [ 0.3037, -0.6881, -0.1091],\n",
      "        [ 0.2888, -0.6784, -0.1229]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.3796, 0.8619, 0.3796, 0.6079, 0.8619, 0.6079, 0.8427, 0.4445, 0.8427,\n",
      "        0.4445], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4151, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.64, 0.6116666666666666)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "├─VGEncoder: 1-1                                        --\n",
      "│    └─SimpleGCNEncoder: 2-1                            --\n",
      "│    │    └─Linear: 3-1                                 35\n",
      "│    │    └─Linear: 3-2                                 15\n",
      "│    │    └─LayerNorm: 3-3                              8\n",
      "│    │    └─ModuleList: 3-4                             142\n",
      "│    └─SimpleGCNEncoder: 2-2                            --\n",
      "│    │    └─Linear: 3-5                                 35\n",
      "│    │    └─Linear: 3-6                                 15\n",
      "│    │    └─LayerNorm: 3-7                              8\n",
      "│    │    └─ModuleList: 3-8                             142\n",
      "├─InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.5188, 0.4987, 0.5188, 0.5054, 0.4987, 0.5054, 0.4642, 0.4486, 0.4642,\n",
      "        0.4486], grad_fn=<SigmoidBackward0>), tensor([[-0.3892,  0.2894, -0.3402],\n",
      "        [-0.3948,  0.2908, -0.3402],\n",
      "        [-0.4034,  0.3085, -0.3395],\n",
      "        [-0.4054,  0.3126, -0.3393],\n",
      "        [-0.4055,  0.3128, -0.3393]], grad_fn=<AddmmBackward0>), tensor([[-0.5396, -0.5664, -0.5697],\n",
      "        [-0.5396, -0.5664, -0.5697],\n",
      "        [-0.5397, -0.5664, -0.5697],\n",
      "        [-0.5396, -0.5664, -0.5697],\n",
      "        [-0.5397, -0.5664, -0.5698]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6340, 0.7382, 0.6121, 0.4458, 0.8143],\n",
      "        [0.7382, 0.9174, 0.5198, 0.2750, 0.9067],\n",
      "        [0.6121, 0.5198, 0.8496, 0.6875, 0.8924],\n",
      "        [0.4458, 0.2750, 0.6875, 0.7235, 0.4781],\n",
      "        [0.8143, 0.9067, 0.8924, 0.4781, 0.9907]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-1.5786, -0.1173, -0.7406],\n",
      "        [-0.2551,  0.6941, -0.4033],\n",
      "        [-0.8568, -0.1473,  0.5910],\n",
      "        [-1.4802,  0.5300,  0.2368],\n",
      "        [-0.3556,  0.6813,  0.0406]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.3892,  0.2894, -0.3402],\n",
      "        [-0.3948,  0.2908, -0.3402],\n",
      "        [-0.4034,  0.3085, -0.3395],\n",
      "        [-0.4054,  0.3126, -0.3393],\n",
      "        [-0.4055,  0.3128, -0.3393]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.5396, -0.5664, -0.5697],\n",
      "        [-0.5396, -0.5664, -0.5697],\n",
      "        [-0.5397, -0.5664, -0.5697],\n",
      "        [-0.5396, -0.5664, -0.5697],\n",
      "        [-0.5397, -0.5664, -0.5698]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6502, 0.7175, 0.6502, 0.4695, 0.7175, 0.4695, 0.7909, 0.5568, 0.7909,\n",
      "        0.5568], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.7620, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.4, 0.5222222222222221)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "├─VGEncoder: 1-1                                   --\n",
      "│    └─ResGCN2ConvEncoder: 2-1                     --\n",
      "│    │    └─Linear: 3-1                            35\n",
      "│    │    └─Linear: 3-2                            18\n",
      "│    │    └─LayerNorm: 3-3                         10\n",
      "│    │    └─ModuleList: 3-4                        140\n",
      "│    └─ResGCN2ConvEncoder: 2-2                     --\n",
      "│    │    └─Linear: 3-5                            35\n",
      "│    │    └─Linear: 3-6                            18\n",
      "│    │    └─LayerNorm: 3-7                         10\n",
      "│    │    └─ModuleList: 3-8                        140\n",
      "├─InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.0696, 0.0820, 0.0696, 0.9615, 0.0820, 0.9615, 0.3909, 0.7197, 0.3909,\n",
      "        0.7197], grad_fn=<SigmoidBackward0>), tensor([[ 0.4310, -0.9576, -0.1323],\n",
      "        [ 0.4313, -0.9577, -0.1324],\n",
      "        [ 0.4382, -0.9591, -0.1319],\n",
      "        [ 0.4479, -0.9598, -0.1303],\n",
      "        [ 0.4440, -0.9592, -0.1307]], grad_fn=<AddmmBackward0>), tensor([[-0.3273,  0.2983, -0.2594],\n",
      "        [-0.3152,  0.2826, -0.2458],\n",
      "        [ 0.4541,  0.3557,  0.7139],\n",
      "        [ 0.8031,  0.1478,  0.5164],\n",
      "        [ 0.6611,  0.4162,  1.0287]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9110, 0.8488, 0.7246, 0.9872, 0.4925],\n",
      "        [0.8488, 0.7879, 0.5230, 0.9482, 0.5290],\n",
      "        [0.7246, 0.5230, 1.0000, 0.9997, 0.0337],\n",
      "        [0.9872, 0.9482, 0.9997, 1.0000, 0.0576],\n",
      "        [0.4925, 0.5290, 0.0337, 0.0576, 0.9431]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.3061, -1.9321,  0.2773],\n",
      "        [-0.5523, -2.4608, -0.2446],\n",
      "        [-0.3108, -1.2301,  1.6311],\n",
      "        [-0.8356, -2.7962,  1.3736],\n",
      "        [-0.8114, -2.4391, -4.9789]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[ 0.4310, -0.9576, -0.1323],\n",
      "        [ 0.4313, -0.9577, -0.1324],\n",
      "        [ 0.4382, -0.9591, -0.1319],\n",
      "        [ 0.4479, -0.9598, -0.1303],\n",
      "        [ 0.4440, -0.9592, -0.1307]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.3273,  0.2983, -0.2594],\n",
      "        [-0.3152,  0.2826, -0.2458],\n",
      "        [ 0.4541,  0.3557,  0.7139],\n",
      "        [ 0.8031,  0.1478,  0.5164],\n",
      "        [ 0.6611,  0.4162,  1.0287]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.9892, 0.9390, 0.9892, 0.9427, 0.9390, 0.9427, 0.9974, 0.0076, 0.9974,\n",
      "        0.0076], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(5.8847, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.27999999999999997, 0.43238095238095237)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gat_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test VGAE serialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[ 0.0962, -0.1348,  0.1793, -0.1560, -0.3142, -0.2339],\n",
      "        [ 0.0866,  0.0050, -0.0477,  0.3456, -0.2976,  0.2538],\n",
      "        [-0.3441,  0.2846,  0.1308, -0.3383, -0.2968,  0.2946],\n",
      "        [ 0.2715,  0.0784, -0.2882,  0.0782,  0.0857, -0.2990]])), ('_encoder_mu.lin1.bias', tensor([-0.1896,  0.2323, -0.3134, -0.1182])), ('_encoder_mu.lin2.weight', tensor([[-0.2749, -0.4188, -0.2833,  0.0854],\n",
      "        [-0.2929, -0.0733,  0.3743, -0.3357],\n",
      "        [-0.0296, -0.0197, -0.2996,  0.0232]])), ('_encoder_mu.lin2.bias', tensor([ 0.4005,  0.2851, -0.2788])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.att', tensor([[[-3.4238e-01,  2.8958e-01],\n",
      "         [ 5.2643e-01, -2.7400e-01],\n",
      "         [-2.6762e-01,  2.7315e-01],\n",
      "         [-8.0058e-02,  3.8834e-02],\n",
      "         [ 5.5048e-01,  6.7781e-02],\n",
      "         [ 2.7357e-01, -1.4131e-01],\n",
      "         [-3.3712e-04, -5.8338e-01],\n",
      "         [ 2.4376e-01, -1.4445e-01]]])), ('_encoder_mu.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.weight', tensor([[-0.1900,  0.0393],\n",
      "        [-0.0749,  0.4178],\n",
      "        [-0.1371, -0.2647],\n",
      "        [ 0.2189, -0.1550],\n",
      "        [-0.1785,  0.0311],\n",
      "        [ 0.3450,  0.2842],\n",
      "        [-0.1268, -0.2797],\n",
      "        [ 0.4148, -0.1463],\n",
      "        [ 0.2784,  0.1165],\n",
      "        [-0.5521,  0.2204],\n",
      "        [ 0.4689, -0.1925],\n",
      "        [-0.4464,  0.3213],\n",
      "        [ 0.2330, -0.3144],\n",
      "        [ 0.0187,  0.4084],\n",
      "        [ 0.5768,  0.2885],\n",
      "        [ 0.5298, -0.3355]])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.bias', tensor([-0.4181,  0.0443,  0.1522, -0.2526,  0.2008,  0.4242, -0.1270,  0.4928,\n",
      "        -0.1201, -0.2292, -0.4214,  0.0013,  0.0323, -0.0737,  0.0366, -0.4422])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.2628,  0.5666],\n",
      "        [ 0.1617, -0.4781],\n",
      "        [ 0.2172, -0.4891],\n",
      "        [ 0.4243, -0.0241],\n",
      "        [ 0.3028, -0.0752],\n",
      "        [-0.2578,  0.2639],\n",
      "        [ 0.2728,  0.0752],\n",
      "        [-0.3660,  0.4146],\n",
      "        [-0.4338,  0.0221],\n",
      "        [-0.1151,  0.1528],\n",
      "        [ 0.1144, -0.1441],\n",
      "        [-0.1164,  0.2248],\n",
      "        [-0.1373,  0.4894],\n",
      "        [-0.5288, -0.0581],\n",
      "        [-0.3809, -0.3683],\n",
      "        [-0.3552, -0.2045]])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.bias', tensor([-0.6663, -0.4929, -0.2866,  0.5540,  0.5628,  0.5490, -0.6351,  0.3254,\n",
      "        -0.1699, -0.6905, -0.2206, -0.2066, -0.2265,  0.4376, -0.4635,  0.3277])), ('_encoder_mu.convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.3881],\n",
      "        [ 0.2029],\n",
      "        [-0.5714],\n",
      "        [-0.3604],\n",
      "        [-0.3717],\n",
      "        [-0.4305],\n",
      "        [ 0.0908],\n",
      "        [ 0.3534],\n",
      "        [-0.5845],\n",
      "        [-0.0039],\n",
      "        [-0.5291],\n",
      "        [-0.2506],\n",
      "        [-0.3754],\n",
      "        [ 0.0824],\n",
      "        [ 0.0309],\n",
      "        [-0.3816]])), ('_encoder_mu.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.att', tensor([[[ 0.5646,  0.1100],\n",
      "         [-0.5045, -0.3103],\n",
      "         [ 0.5726, -0.0980],\n",
      "         [-0.5478, -0.3231],\n",
      "         [-0.2765,  0.5434],\n",
      "         [ 0.2521,  0.6112],\n",
      "         [-0.1284,  0.0928],\n",
      "         [-0.7428, -0.0236]]])), ('_encoder_mu.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.1917,  0.2641],\n",
      "        [-0.1402, -0.0544],\n",
      "        [ 0.5272, -0.4336],\n",
      "        [-0.0410,  0.3629],\n",
      "        [ 0.4368, -0.0481],\n",
      "        [-0.3744,  0.2164],\n",
      "        [ 0.0597,  0.5143],\n",
      "        [ 0.2509,  0.2470],\n",
      "        [ 0.5540,  0.2297],\n",
      "        [-0.0391,  0.0535],\n",
      "        [-0.2208, -0.4064],\n",
      "        [-0.0485,  0.3331],\n",
      "        [ 0.1115, -0.5494],\n",
      "        [-0.0943,  0.5268],\n",
      "        [-0.1984, -0.0803],\n",
      "        [ 0.1053,  0.0649]])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.bias', tensor([ 0.2059,  0.1253,  0.0315,  0.0596,  0.5381, -0.5882,  0.3116, -0.0708,\n",
      "         0.2269, -0.4673,  0.6826, -0.5463, -0.5032,  0.4859, -0.3067,  0.6831])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.weight', tensor([[-1.2699e-01, -3.1461e-01],\n",
      "        [-3.1360e-01, -1.3173e-04],\n",
      "        [ 2.1655e-01,  2.1863e-01],\n",
      "        [ 3.8130e-01, -2.4450e-01],\n",
      "        [ 1.2965e-01, -2.8516e-01],\n",
      "        [ 3.8717e-01, -2.1732e-01],\n",
      "        [ 4.2387e-01, -1.8188e-02],\n",
      "        [ 4.9326e-01,  3.4241e-01],\n",
      "        [-3.8873e-01,  2.8919e-01],\n",
      "        [ 2.8431e-01, -2.9064e-01],\n",
      "        [-2.1373e-01,  3.4536e-01],\n",
      "        [ 1.5027e-01,  5.0957e-01],\n",
      "        [-3.5081e-01,  5.2084e-01],\n",
      "        [-5.6469e-01, -2.8150e-01],\n",
      "        [ 2.9317e-01, -3.3366e-02],\n",
      "        [ 4.9529e-01,  5.1256e-02]])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.bias', tensor([ 0.2268, -0.4083,  0.5207, -0.4405, -0.6650, -0.0869, -0.5436, -0.6513,\n",
      "         0.4319, -0.2924,  0.4914, -0.0444, -0.1375,  0.6614,  0.0861,  0.1232])), ('_encoder_mu.convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.4607],\n",
      "        [ 0.5313],\n",
      "        [ 0.5867],\n",
      "        [ 0.5404],\n",
      "        [-0.3134],\n",
      "        [ 0.2076],\n",
      "        [-0.2656],\n",
      "        [ 0.1115],\n",
      "        [-0.4675],\n",
      "        [-0.5120],\n",
      "        [ 0.0539],\n",
      "        [-0.2786],\n",
      "        [-0.1498],\n",
      "        [-0.1429],\n",
      "        [ 0.2983],\n",
      "        [ 0.2541]])), ('_encoder_mu.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.att', tensor([[[ 4.5946e-01, -2.3483e-02],\n",
      "         [ 3.2731e-02,  2.5095e-01],\n",
      "         [-1.3004e-01, -4.7712e-01],\n",
      "         [ 6.7240e-01, -5.5914e-01],\n",
      "         [-6.7776e-01, -2.3716e-01],\n",
      "         [-1.3234e-01,  1.4741e-01],\n",
      "         [-2.8951e-02, -4.2677e-04],\n",
      "         [ 1.3326e-01,  4.4650e-01]]])), ('_encoder_mu.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.0783,  0.0913],\n",
      "        [ 0.2108, -0.3950],\n",
      "        [ 0.5569,  0.1387],\n",
      "        [ 0.3233,  0.4085],\n",
      "        [ 0.4147,  0.1215],\n",
      "        [ 0.4975,  0.0212],\n",
      "        [ 0.0596, -0.3108],\n",
      "        [ 0.0019, -0.1720],\n",
      "        [-0.5728,  0.0432],\n",
      "        [ 0.1389, -0.2742],\n",
      "        [-0.3531,  0.4315],\n",
      "        [-0.5761, -0.0233],\n",
      "        [ 0.5205,  0.1973],\n",
      "        [-0.5742,  0.1821],\n",
      "        [-0.1233, -0.1099],\n",
      "        [ 0.5573, -0.0600]])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.bias', tensor([-0.4576, -0.3875, -0.5912,  0.0101,  0.2881, -0.2755, -0.5262, -0.0263,\n",
      "        -0.1557, -0.3790, -0.6251, -0.3706, -0.2302,  0.2263,  0.6531,  0.2982])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.1701, -0.2507],\n",
      "        [-0.5335, -0.0091],\n",
      "        [ 0.5347,  0.3057],\n",
      "        [ 0.3285,  0.2562],\n",
      "        [-0.2304, -0.4790],\n",
      "        [-0.1011, -0.0846],\n",
      "        [-0.4103,  0.4707],\n",
      "        [ 0.0691, -0.3031],\n",
      "        [-0.5095, -0.2741],\n",
      "        [ 0.2854, -0.3140],\n",
      "        [-0.5539, -0.4625],\n",
      "        [-0.0600,  0.1052],\n",
      "        [ 0.0557, -0.4836],\n",
      "        [-0.5554,  0.4267],\n",
      "        [-0.4799, -0.4318],\n",
      "        [-0.5382, -0.3562]])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.bias', tensor([-0.5502, -0.6859, -0.2647,  0.3773, -0.6476, -0.0546, -0.3433,  0.1162,\n",
      "        -0.1195, -0.5426,  0.3825, -0.1100,  0.2852, -0.3144,  0.0040, -0.5219])), ('_encoder_mu.convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.3222],\n",
      "        [-0.2725],\n",
      "        [-0.0611],\n",
      "        [-0.2818],\n",
      "        [-0.0610],\n",
      "        [-0.0556],\n",
      "        [ 0.4371],\n",
      "        [ 0.1219],\n",
      "        [ 0.0163],\n",
      "        [ 0.2907],\n",
      "        [-0.2852],\n",
      "        [-0.2747],\n",
      "        [-0.5493],\n",
      "        [-0.0902],\n",
      "        [ 0.3718],\n",
      "        [ 0.3419]])), ('_encoder_mu.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.att', tensor([[[-0.3537,  0.5243],\n",
      "         [ 0.7056,  0.3017],\n",
      "         [-0.4531,  0.3949],\n",
      "         [ 0.1746,  0.5427],\n",
      "         [ 0.5505, -0.5520],\n",
      "         [-0.7161,  0.4853],\n",
      "         [-0.7657,  0.1920],\n",
      "         [-0.3134, -0.0636]]])), ('_encoder_mu.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.3141, -0.1569],\n",
      "        [ 0.3294, -0.2164],\n",
      "        [-0.4745,  0.2960],\n",
      "        [ 0.2002,  0.0040],\n",
      "        [-0.1934, -0.0049],\n",
      "        [ 0.3590,  0.5054],\n",
      "        [-0.5677,  0.5470],\n",
      "        [ 0.2756, -0.0488],\n",
      "        [-0.3613,  0.1361],\n",
      "        [-0.0342, -0.5643],\n",
      "        [-0.2473, -0.2329],\n",
      "        [-0.0990,  0.4481],\n",
      "        [ 0.1364, -0.1893],\n",
      "        [ 0.1323,  0.1430],\n",
      "        [ 0.2628, -0.1028],\n",
      "        [-0.2015,  0.5637]])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.bias', tensor([-0.3249, -0.1200, -0.2167, -0.2431,  0.3960,  0.5418, -0.6855, -0.4393,\n",
      "         0.0094, -0.4458, -0.3695, -0.0864,  0.1205, -0.0426, -0.4212,  0.5990])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.2246,  0.1887],\n",
      "        [-0.2578,  0.0310],\n",
      "        [-0.3210, -0.2450],\n",
      "        [ 0.4232,  0.5135],\n",
      "        [-0.5542, -0.0535],\n",
      "        [-0.1559,  0.3327],\n",
      "        [ 0.1431,  0.3927],\n",
      "        [-0.4734, -0.3007],\n",
      "        [-0.4256, -0.1530],\n",
      "        [ 0.0886,  0.0778],\n",
      "        [-0.4253,  0.5710],\n",
      "        [-0.2359,  0.5309],\n",
      "        [ 0.0442, -0.0532],\n",
      "        [-0.2954, -0.4056],\n",
      "        [-0.1733, -0.0949],\n",
      "        [-0.2727,  0.3374]])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.bias', tensor([-0.0407,  0.5546,  0.2249,  0.1777, -0.2259,  0.2476,  0.4941,  0.2142,\n",
      "        -0.4328, -0.2712,  0.4483, -0.2431,  0.5025, -0.3632,  0.6014, -0.2844])), ('_encoder_mu.convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.5091],\n",
      "        [-0.3197],\n",
      "        [ 0.4034],\n",
      "        [ 0.4179],\n",
      "        [ 0.1639],\n",
      "        [ 0.0429],\n",
      "        [ 0.4409],\n",
      "        [-0.5456],\n",
      "        [-0.0717],\n",
      "        [ 0.4308],\n",
      "        [ 0.3751],\n",
      "        [ 0.5359],\n",
      "        [-0.0295],\n",
      "        [-0.2893],\n",
      "        [ 0.2657],\n",
      "        [-0.0819]])), ('_encoder_mu.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.att', tensor([[[ 6.9295e-01, -1.5411e-01],\n",
      "         [ 2.8488e-01, -2.1591e-01],\n",
      "         [-5.1622e-01, -2.6930e-01],\n",
      "         [-2.4301e-04, -1.1426e-01],\n",
      "         [-4.0171e-01,  5.0467e-01],\n",
      "         [-7.2803e-01,  6.9647e-01],\n",
      "         [ 3.8645e-01, -9.1029e-02],\n",
      "         [-4.9967e-01, -7.1161e-01]]])), ('_encoder_mu.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.4687, -0.5175],\n",
      "        [ 0.4625, -0.5405],\n",
      "        [-0.4413,  0.2499],\n",
      "        [-0.1314, -0.1390],\n",
      "        [-0.3200, -0.5388],\n",
      "        [-0.2490, -0.4586],\n",
      "        [ 0.1083,  0.2903],\n",
      "        [ 0.3102,  0.0495],\n",
      "        [-0.3419,  0.1732],\n",
      "        [ 0.2627,  0.0141],\n",
      "        [ 0.3190,  0.4147],\n",
      "        [ 0.2108,  0.4731],\n",
      "        [-0.1252, -0.4937],\n",
      "        [-0.3665, -0.5125],\n",
      "        [-0.4485,  0.5174],\n",
      "        [-0.5242,  0.1132]])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.bias', tensor([ 0.3321,  0.4367,  0.1248, -0.6020,  0.0064,  0.2095, -0.6965,  0.4542,\n",
      "        -0.0560,  0.5762,  0.3801, -0.5648, -0.5101, -0.3582,  0.2124,  0.0799])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.4637,  0.4687],\n",
      "        [-0.1779, -0.3284],\n",
      "        [ 0.1951, -0.0910],\n",
      "        [ 0.4780, -0.3469],\n",
      "        [ 0.2600,  0.2847],\n",
      "        [-0.2010, -0.2761],\n",
      "        [ 0.1851, -0.0100],\n",
      "        [-0.2214, -0.4596],\n",
      "        [-0.1148,  0.1589],\n",
      "        [ 0.4658,  0.4939],\n",
      "        [-0.5035,  0.3258],\n",
      "        [ 0.0753,  0.4515],\n",
      "        [ 0.1962,  0.3686],\n",
      "        [ 0.0849,  0.2974],\n",
      "        [ 0.2600,  0.1673],\n",
      "        [-0.0647, -0.4355]])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.bias', tensor([-0.2122,  0.3632, -0.0826,  0.4502,  0.2897, -0.0015, -0.6458,  0.6717,\n",
      "         0.5047,  0.3587, -0.5740, -0.4083,  0.5977,  0.4801, -0.1409,  0.0583])), ('_encoder_mu.convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.4225],\n",
      "        [ 0.4351],\n",
      "        [ 0.0283],\n",
      "        [ 0.0128],\n",
      "        [-0.0749],\n",
      "        [ 0.1019],\n",
      "        [ 0.0256],\n",
      "        [-0.3641],\n",
      "        [-0.5091],\n",
      "        [ 0.4265],\n",
      "        [ 0.1027],\n",
      "        [-0.1958],\n",
      "        [ 0.0850],\n",
      "        [ 0.2262],\n",
      "        [ 0.3520],\n",
      "        [-0.1913]])), ('_encoder_mu.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.att', tensor([[[ 0.1713,  0.2020],\n",
      "         [ 0.2356,  0.0780],\n",
      "         [-0.2860,  0.7374],\n",
      "         [ 0.3403, -0.5126],\n",
      "         [-0.1782,  0.1615],\n",
      "         [-0.7555,  0.4883],\n",
      "         [ 0.6667, -0.0013],\n",
      "         [ 0.6317,  0.3701]]])), ('_encoder_mu.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1427, -0.4320],\n",
      "        [-0.3164, -0.3545],\n",
      "        [-0.1375, -0.4361],\n",
      "        [-0.0396, -0.2927],\n",
      "        [ 0.0768,  0.1552],\n",
      "        [ 0.3255, -0.4965],\n",
      "        [ 0.2710,  0.0602],\n",
      "        [-0.3954,  0.0727],\n",
      "        [ 0.4404,  0.0551],\n",
      "        [-0.0681,  0.0348],\n",
      "        [-0.2576, -0.2842],\n",
      "        [-0.1256, -0.5694],\n",
      "        [-0.0181,  0.3436],\n",
      "        [ 0.2114, -0.5557],\n",
      "        [ 0.1699,  0.0819],\n",
      "        [-0.5505, -0.4527]])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.bias', tensor([-0.5638,  0.3888,  0.2432, -0.6003,  0.0629, -0.6677,  0.0038, -0.6586,\n",
      "         0.6276, -0.2497, -0.0437, -0.6547,  0.3455, -0.1290, -0.6557, -0.6977])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.5546, -0.1655],\n",
      "        [ 0.4896,  0.3543],\n",
      "        [-0.2288, -0.3989],\n",
      "        [ 0.2956,  0.2756],\n",
      "        [ 0.4532,  0.0542],\n",
      "        [-0.5341, -0.1827],\n",
      "        [ 0.2959, -0.4163],\n",
      "        [ 0.0666, -0.1090],\n",
      "        [ 0.2517,  0.5752],\n",
      "        [-0.1193,  0.0451],\n",
      "        [-0.0212, -0.2739],\n",
      "        [-0.0039, -0.0629],\n",
      "        [ 0.0043, -0.3804],\n",
      "        [-0.3514, -0.4511],\n",
      "        [ 0.4787,  0.2241],\n",
      "        [-0.2239, -0.2446]])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.bias', tensor([-0.5989,  0.0840,  0.3946,  0.4625, -0.0731,  0.0305,  0.1156, -0.0435,\n",
      "         0.1639, -0.5680, -0.1206, -0.0897, -0.2685,  0.6941, -0.3498,  0.6029])), ('_encoder_mu.convs.2.convs.1.conv.lin_edge.weight', tensor([[ 0.0403],\n",
      "        [-0.5601],\n",
      "        [ 0.2938],\n",
      "        [ 0.1133],\n",
      "        [-0.4244],\n",
      "        [-0.4711],\n",
      "        [-0.3120],\n",
      "        [-0.5582],\n",
      "        [ 0.2650],\n",
      "        [ 0.4250],\n",
      "        [-0.1594],\n",
      "        [-0.1698],\n",
      "        [ 0.4909],\n",
      "        [ 0.3064],\n",
      "        [-0.2360],\n",
      "        [ 0.5806]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.0028, -0.0845,  0.2900, -0.1665,  0.2322, -0.3199],\n",
      "        [ 0.3812,  0.0713, -0.3023,  0.2543, -0.3736, -0.3267],\n",
      "        [ 0.1741,  0.2729, -0.1541,  0.1395,  0.3208, -0.1860],\n",
      "        [ 0.3763,  0.1320,  0.2706,  0.0398,  0.3295,  0.3084]])), ('_encoder_logstd.lin1.bias', tensor([ 0.3837, -0.1088,  0.0095,  0.1377])), ('_encoder_logstd.lin2.weight', tensor([[-0.3418,  0.0053,  0.1200, -0.2190],\n",
      "        [ 0.3371,  0.2213, -0.2973, -0.1818],\n",
      "        [-0.0100, -0.1618, -0.3337,  0.3513]])), ('_encoder_logstd.lin2.bias', tensor([ 0.2059, -0.2910,  0.3085])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.att', tensor([[[-0.3266,  0.0552],\n",
      "         [ 0.3343, -0.0098],\n",
      "         [ 0.5863,  0.1110],\n",
      "         [ 0.4504, -0.0470],\n",
      "         [-0.3069,  0.1066],\n",
      "         [-0.4336,  0.0345],\n",
      "         [ 0.1470, -0.0833],\n",
      "         [ 0.6647, -0.3895]]])), ('_encoder_logstd.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.5745,  0.4522],\n",
      "        [-0.2354,  0.3124],\n",
      "        [-0.1172, -0.3256],\n",
      "        [-0.3198, -0.2741],\n",
      "        [-0.3764,  0.3906],\n",
      "        [-0.5396,  0.3942],\n",
      "        [ 0.2950,  0.5287],\n",
      "        [ 0.2425,  0.5630],\n",
      "        [ 0.0353,  0.4198],\n",
      "        [ 0.3834, -0.5772],\n",
      "        [ 0.0188, -0.3181],\n",
      "        [ 0.1167, -0.4605],\n",
      "        [-0.3832, -0.1803],\n",
      "        [ 0.3924, -0.0069],\n",
      "        [-0.4788,  0.0942],\n",
      "        [ 0.2131, -0.0297]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.bias', tensor([ 0.0504,  0.0579, -0.3396,  0.6294,  0.3727, -0.0077, -0.2262,  0.5556,\n",
      "        -0.4944, -0.1082, -0.4712, -0.6939,  0.1508, -0.0295,  0.2139, -0.1450])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.0266, -0.4714],\n",
      "        [ 0.1496,  0.5533],\n",
      "        [ 0.2981, -0.1429],\n",
      "        [-0.4035,  0.0446],\n",
      "        [-0.0039,  0.2523],\n",
      "        [-0.1475, -0.2690],\n",
      "        [ 0.0458, -0.0540],\n",
      "        [ 0.1998, -0.1243],\n",
      "        [-0.4959,  0.3874],\n",
      "        [-0.2407, -0.0875],\n",
      "        [ 0.5734,  0.0178],\n",
      "        [ 0.4443, -0.1050],\n",
      "        [-0.4452,  0.4468],\n",
      "        [-0.0019,  0.4950],\n",
      "        [-0.2385,  0.5565],\n",
      "        [ 0.4351, -0.4718]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.bias', tensor([ 0.5144,  0.0282, -0.0653, -0.5058, -0.0799, -0.0588,  0.2711,  0.3709,\n",
      "        -0.2471, -0.4565, -0.6886, -0.2819, -0.0158, -0.5740,  0.0562, -0.2146])), ('_encoder_logstd.convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.3540],\n",
      "        [ 0.3041],\n",
      "        [ 0.2496],\n",
      "        [ 0.4182],\n",
      "        [-0.5445],\n",
      "        [ 0.4780],\n",
      "        [ 0.4646],\n",
      "        [ 0.0347],\n",
      "        [-0.4972],\n",
      "        [ 0.4706],\n",
      "        [-0.0739],\n",
      "        [-0.1228],\n",
      "        [-0.1755],\n",
      "        [-0.0558],\n",
      "        [ 0.3888],\n",
      "        [-0.5571]])), ('_encoder_logstd.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.att', tensor([[[ 0.2511, -0.4360],\n",
      "         [ 0.3803,  0.2588],\n",
      "         [ 0.6839, -0.6552],\n",
      "         [-0.2688, -0.3706],\n",
      "         [-0.1731, -0.4165],\n",
      "         [-0.1857,  0.3800],\n",
      "         [ 0.6236,  0.7160],\n",
      "         [ 0.4274, -0.6979]]])), ('_encoder_logstd.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.1116,  0.5211],\n",
      "        [ 0.2924, -0.4598],\n",
      "        [ 0.1018, -0.5581],\n",
      "        [-0.4888, -0.2847],\n",
      "        [ 0.5355,  0.3981],\n",
      "        [ 0.2539,  0.5746],\n",
      "        [ 0.4150, -0.5501],\n",
      "        [ 0.0750,  0.0389],\n",
      "        [ 0.0540,  0.1096],\n",
      "        [-0.1343,  0.2729],\n",
      "        [-0.0990, -0.3795],\n",
      "        [ 0.0603, -0.2046],\n",
      "        [ 0.1643,  0.0190],\n",
      "        [-0.1362,  0.1843],\n",
      "        [ 0.0008, -0.4844],\n",
      "        [-0.0129, -0.1332]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.bias', tensor([-0.2833, -0.1571, -0.0530, -0.0959, -0.6194, -0.6883,  0.1610,  0.3746,\n",
      "         0.3902, -0.2908, -0.2880,  0.3211,  0.1541,  0.0654,  0.2824, -0.5864])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.0152, -0.2536],\n",
      "        [-0.2358,  0.4747],\n",
      "        [-0.4716,  0.1977],\n",
      "        [ 0.0110,  0.5191],\n",
      "        [ 0.2393, -0.0012],\n",
      "        [ 0.3903,  0.2677],\n",
      "        [ 0.3840,  0.5589],\n",
      "        [ 0.3153, -0.2954],\n",
      "        [-0.0793,  0.5726],\n",
      "        [ 0.1911, -0.1408],\n",
      "        [-0.4619, -0.1165],\n",
      "        [-0.2755,  0.5406],\n",
      "        [ 0.2217,  0.1662],\n",
      "        [-0.2156, -0.5734],\n",
      "        [-0.5273, -0.0268],\n",
      "        [ 0.2894, -0.3825]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.bias', tensor([ 0.6248,  0.3042,  0.7053, -0.6171, -0.4113, -0.1576,  0.6221, -0.3738,\n",
      "        -0.2806,  0.0353, -0.2506,  0.6417,  0.0604, -0.3229,  0.0709, -0.0113])), ('_encoder_logstd.convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.5748],\n",
      "        [-0.5354],\n",
      "        [ 0.0090],\n",
      "        [ 0.0691],\n",
      "        [ 0.4608],\n",
      "        [ 0.1826],\n",
      "        [-0.4800],\n",
      "        [-0.1505],\n",
      "        [ 0.4470],\n",
      "        [ 0.3836],\n",
      "        [ 0.3629],\n",
      "        [-0.0364],\n",
      "        [ 0.0564],\n",
      "        [ 0.1807],\n",
      "        [-0.3281],\n",
      "        [-0.5023]])), ('_encoder_logstd.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.att', tensor([[[-0.3102, -0.4579],\n",
      "         [-0.2455,  0.5229],\n",
      "         [-0.5051, -0.2869],\n",
      "         [ 0.7480,  0.7156],\n",
      "         [ 0.5171,  0.2875],\n",
      "         [ 0.3865,  0.4839],\n",
      "         [-0.6196, -0.2719],\n",
      "         [-0.0131,  0.1105]]])), ('_encoder_logstd.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.0183, -0.2406],\n",
      "        [ 0.5356,  0.3862],\n",
      "        [ 0.3908,  0.3362],\n",
      "        [ 0.4963, -0.2247],\n",
      "        [ 0.0880,  0.1726],\n",
      "        [ 0.3102,  0.4190],\n",
      "        [ 0.1632,  0.3903],\n",
      "        [-0.3721, -0.3329],\n",
      "        [-0.3889, -0.0012],\n",
      "        [ 0.3808,  0.3032],\n",
      "        [-0.3684,  0.2786],\n",
      "        [ 0.0867, -0.0886],\n",
      "        [-0.0351, -0.1452],\n",
      "        [-0.4477, -0.4709],\n",
      "        [-0.2434,  0.1956],\n",
      "        [-0.2176, -0.3953]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.bias', tensor([-0.3139,  0.5775, -0.3716, -0.5425,  0.5860,  0.0024, -0.1699, -0.4264,\n",
      "        -0.6108,  0.1031,  0.1665, -0.0349,  0.4108,  0.6438,  0.0268,  0.4250])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.3847,  0.0988],\n",
      "        [ 0.4858,  0.1078],\n",
      "        [-0.1006, -0.3833],\n",
      "        [-0.4826, -0.2862],\n",
      "        [-0.5358, -0.1693],\n",
      "        [ 0.5610,  0.3556],\n",
      "        [ 0.1333,  0.3481],\n",
      "        [ 0.4251,  0.3692],\n",
      "        [-0.0239, -0.4849],\n",
      "        [-0.4858,  0.3590],\n",
      "        [ 0.4063, -0.4463],\n",
      "        [ 0.2768, -0.3921],\n",
      "        [ 0.2122, -0.4795],\n",
      "        [ 0.1288, -0.2663],\n",
      "        [-0.4363,  0.5111],\n",
      "        [ 0.3991, -0.0474]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.bias', tensor([ 0.2665, -0.1462, -0.5823, -0.0399,  0.3688,  0.0760,  0.5891,  0.0523,\n",
      "        -0.5239,  0.1597,  0.5793, -0.2423,  0.5411,  0.0951, -0.5015,  0.6468])), ('_encoder_logstd.convs.1.convs.0.conv.lin_edge.weight', tensor([[ 0.4968],\n",
      "        [-0.2574],\n",
      "        [ 0.0331],\n",
      "        [ 0.4433],\n",
      "        [-0.3393],\n",
      "        [ 0.0017],\n",
      "        [-0.1661],\n",
      "        [-0.1574],\n",
      "        [ 0.3118],\n",
      "        [ 0.2844],\n",
      "        [-0.2321],\n",
      "        [ 0.4238],\n",
      "        [-0.2241],\n",
      "        [ 0.4655],\n",
      "        [ 0.0032],\n",
      "        [-0.1618]])), ('_encoder_logstd.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.att', tensor([[[ 0.2084,  0.1102],\n",
      "         [ 0.3941, -0.1469],\n",
      "         [ 0.1633, -0.2764],\n",
      "         [ 0.4976, -0.6031],\n",
      "         [-0.5807, -0.5448],\n",
      "         [ 0.2878, -0.0197],\n",
      "         [ 0.7174,  0.1291],\n",
      "         [-0.1776, -0.3672]]])), ('_encoder_logstd.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.weight', tensor([[-0.0436, -0.4792],\n",
      "        [ 0.0350,  0.0152],\n",
      "        [ 0.3097,  0.5321],\n",
      "        [-0.2620, -0.0150],\n",
      "        [ 0.5522, -0.3044],\n",
      "        [-0.4135,  0.0919],\n",
      "        [-0.5693,  0.3586],\n",
      "        [ 0.2924,  0.0865],\n",
      "        [-0.1662, -0.2273],\n",
      "        [ 0.2025,  0.1489],\n",
      "        [-0.2297, -0.0707],\n",
      "        [ 0.3351,  0.4590],\n",
      "        [-0.1235, -0.0161],\n",
      "        [ 0.0148,  0.0532],\n",
      "        [-0.2359,  0.4374],\n",
      "        [ 0.0198,  0.1432]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.bias', tensor([ 0.0444, -0.2847, -0.6319, -0.6534, -0.1823,  0.2989, -0.6431, -0.4057,\n",
      "        -0.3389,  0.4699,  0.4288,  0.4233, -0.3704, -0.5796,  0.6680, -0.3507])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.2989,  0.2765],\n",
      "        [-0.0140, -0.2878],\n",
      "        [ 0.5494,  0.5077],\n",
      "        [-0.0783, -0.1414],\n",
      "        [ 0.4631, -0.2818],\n",
      "        [ 0.3650, -0.1718],\n",
      "        [ 0.4126, -0.2990],\n",
      "        [-0.0802,  0.2324],\n",
      "        [-0.0355, -0.2330],\n",
      "        [ 0.5683, -0.4572],\n",
      "        [-0.3957,  0.4513],\n",
      "        [-0.0314, -0.1065],\n",
      "        [ 0.0006, -0.3555],\n",
      "        [-0.3489,  0.1068],\n",
      "        [ 0.1577, -0.4012],\n",
      "        [ 0.0823,  0.1229]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.bias', tensor([-0.5656, -0.0773,  0.0036, -0.3290,  0.6766,  0.2781, -0.2419, -0.4689,\n",
      "         0.4185, -0.1191,  0.6000,  0.2718,  0.5133,  0.2966, -0.2709, -0.5507])), ('_encoder_logstd.convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.0826],\n",
      "        [-0.5630],\n",
      "        [-0.2474],\n",
      "        [ 0.1771],\n",
      "        [-0.0463],\n",
      "        [-0.1313],\n",
      "        [-0.0630],\n",
      "        [-0.2947],\n",
      "        [-0.0988],\n",
      "        [ 0.1432],\n",
      "        [ 0.0925],\n",
      "        [ 0.0234],\n",
      "        [-0.4211],\n",
      "        [ 0.5583],\n",
      "        [ 0.2942],\n",
      "        [ 0.3404]])), ('_encoder_logstd.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.att', tensor([[[-0.1619, -0.1685],\n",
      "         [-0.1725,  0.0112],\n",
      "         [ 0.1983,  0.4262],\n",
      "         [ 0.3825,  0.3685],\n",
      "         [ 0.3692, -0.2570],\n",
      "         [-0.7614, -0.5590],\n",
      "         [ 0.1670,  0.1974],\n",
      "         [ 0.0891,  0.2273]]])), ('_encoder_logstd.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.1726,  0.1925],\n",
      "        [-0.0153, -0.2064],\n",
      "        [ 0.1197, -0.4407],\n",
      "        [ 0.5736, -0.2310],\n",
      "        [-0.0728, -0.2743],\n",
      "        [ 0.1779, -0.2372],\n",
      "        [-0.0319,  0.4116],\n",
      "        [-0.1622,  0.2904],\n",
      "        [-0.4763, -0.4994],\n",
      "        [ 0.3680, -0.1726],\n",
      "        [ 0.3288,  0.1974],\n",
      "        [-0.5047, -0.2499],\n",
      "        [-0.4092, -0.2490],\n",
      "        [ 0.1393, -0.0698],\n",
      "        [-0.0902, -0.1149],\n",
      "        [ 0.3369, -0.4384]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.bias', tensor([ 0.7038,  0.4990,  0.2159, -0.1997, -0.0295, -0.0487, -0.5997,  0.3646,\n",
      "         0.5232, -0.0639,  0.0564,  0.2476,  0.4226, -0.0559, -0.1700, -0.3408])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2202, -0.0430],\n",
      "        [-0.3958,  0.3157],\n",
      "        [ 0.0038,  0.1811],\n",
      "        [-0.2241, -0.2987],\n",
      "        [ 0.0674, -0.5420],\n",
      "        [ 0.0584, -0.0975],\n",
      "        [ 0.1151, -0.2258],\n",
      "        [-0.5433, -0.2533],\n",
      "        [ 0.3678,  0.4400],\n",
      "        [-0.4593,  0.5492],\n",
      "        [-0.5103, -0.4068],\n",
      "        [-0.5671, -0.4100],\n",
      "        [ 0.2637, -0.0465],\n",
      "        [-0.0148,  0.4424],\n",
      "        [ 0.5179,  0.0341],\n",
      "        [ 0.3142, -0.1288]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.bias', tensor([-0.6638,  0.0912,  0.0068,  0.1485,  0.0680, -0.6902,  0.4374, -0.2155,\n",
      "        -0.0650,  0.2332,  0.3256, -0.1791, -0.1682, -0.3591,  0.3469, -0.1182])), ('_encoder_logstd.convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.0033],\n",
      "        [-0.1346],\n",
      "        [-0.1649],\n",
      "        [ 0.1552],\n",
      "        [ 0.4546],\n",
      "        [-0.2931],\n",
      "        [ 0.4511],\n",
      "        [ 0.5140],\n",
      "        [-0.4366],\n",
      "        [ 0.0716],\n",
      "        [ 0.3180],\n",
      "        [ 0.4443],\n",
      "        [-0.0629],\n",
      "        [-0.3926],\n",
      "        [ 0.2223],\n",
      "        [-0.1698]])), ('_encoder_logstd.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.att', tensor([[[ 0.6645, -0.2398],\n",
      "         [ 0.6274, -0.7389],\n",
      "         [-0.3525, -0.0488],\n",
      "         [ 0.4625, -0.0862],\n",
      "         [-0.0684,  0.2226],\n",
      "         [-0.7192,  0.1847],\n",
      "         [ 0.6216, -0.3183],\n",
      "         [-0.2329, -0.5788]]])), ('_encoder_logstd.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1954, -0.0764],\n",
      "        [-0.2749, -0.3020],\n",
      "        [-0.2798,  0.0282],\n",
      "        [ 0.4160, -0.1590],\n",
      "        [-0.0496,  0.3354],\n",
      "        [-0.2258, -0.4643],\n",
      "        [ 0.2296, -0.5317],\n",
      "        [ 0.3733, -0.3875],\n",
      "        [-0.0661,  0.1770],\n",
      "        [-0.3759, -0.4406],\n",
      "        [-0.1068, -0.0606],\n",
      "        [-0.3481,  0.5047],\n",
      "        [ 0.0358,  0.2526],\n",
      "        [ 0.0546,  0.2253],\n",
      "        [ 0.0069,  0.2678],\n",
      "        [-0.4073, -0.1292]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.bias', tensor([-0.6093, -0.3422, -0.2994, -0.4663,  0.3117,  0.5822, -0.0933,  0.3005,\n",
      "         0.6761,  0.2808,  0.3645, -0.4327,  0.1076,  0.1355, -0.6023, -0.3652])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.2435, -0.5345],\n",
      "        [ 0.4667, -0.5249],\n",
      "        [ 0.4260,  0.4584],\n",
      "        [ 0.1970, -0.5035],\n",
      "        [-0.3005,  0.4894],\n",
      "        [ 0.1877,  0.0185],\n",
      "        [-0.2146,  0.3242],\n",
      "        [-0.3503,  0.3968],\n",
      "        [-0.5284,  0.1724],\n",
      "        [ 0.4704,  0.3010],\n",
      "        [ 0.1262,  0.4628],\n",
      "        [ 0.2692, -0.2614],\n",
      "        [-0.2065,  0.4742],\n",
      "        [ 0.2051, -0.3904],\n",
      "        [-0.4518, -0.4299],\n",
      "        [-0.5418,  0.3235]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.bias', tensor([ 0.6687, -0.5475,  0.6786, -0.0195,  0.0877,  0.3513, -0.0989,  0.6206,\n",
      "        -0.1825,  0.5894, -0.5321,  0.4378, -0.6800,  0.2099, -0.0644,  0.6375])), ('_encoder_logstd.convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.1956],\n",
      "        [ 0.5775],\n",
      "        [ 0.4857],\n",
      "        [-0.4989],\n",
      "        [-0.3139],\n",
      "        [ 0.1621],\n",
      "        [ 0.2045],\n",
      "        [ 0.1746],\n",
      "        [-0.5614],\n",
      "        [ 0.1691],\n",
      "        [-0.0240],\n",
      "        [-0.3288],\n",
      "        [-0.2946],\n",
      "        [ 0.4061],\n",
      "        [-0.0301],\n",
      "        [-0.1587]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0028, -0.0845,  0.2900, -0.1665,  0.2322, -0.3199],\n",
      "        [ 0.3812,  0.0713, -0.3023,  0.2543, -0.3736, -0.3267],\n",
      "        [ 0.1741,  0.2729, -0.1541,  0.1395,  0.3208, -0.1860],\n",
      "        [ 0.3763,  0.1320,  0.2706,  0.0398,  0.3295,  0.3084]])), ('lin1.bias', tensor([ 0.3837, -0.1088,  0.0095,  0.1377])), ('lin2.weight', tensor([[-0.3418,  0.0053,  0.1200, -0.2190],\n",
      "        [ 0.3371,  0.2213, -0.2973, -0.1818],\n",
      "        [-0.0100, -0.1618, -0.3337,  0.3513]])), ('lin2.bias', tensor([ 0.2059, -0.2910,  0.3085])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[-0.3266,  0.0552],\n",
      "         [ 0.3343, -0.0098],\n",
      "         [ 0.5863,  0.1110],\n",
      "         [ 0.4504, -0.0470],\n",
      "         [-0.3069,  0.1066],\n",
      "         [-0.4336,  0.0345],\n",
      "         [ 0.1470, -0.0833],\n",
      "         [ 0.6647, -0.3895]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.5745,  0.4522],\n",
      "        [-0.2354,  0.3124],\n",
      "        [-0.1172, -0.3256],\n",
      "        [-0.3198, -0.2741],\n",
      "        [-0.3764,  0.3906],\n",
      "        [-0.5396,  0.3942],\n",
      "        [ 0.2950,  0.5287],\n",
      "        [ 0.2425,  0.5630],\n",
      "        [ 0.0353,  0.4198],\n",
      "        [ 0.3834, -0.5772],\n",
      "        [ 0.0188, -0.3181],\n",
      "        [ 0.1167, -0.4605],\n",
      "        [-0.3832, -0.1803],\n",
      "        [ 0.3924, -0.0069],\n",
      "        [-0.4788,  0.0942],\n",
      "        [ 0.2131, -0.0297]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([ 0.0504,  0.0579, -0.3396,  0.6294,  0.3727, -0.0077, -0.2262,  0.5556,\n",
      "        -0.4944, -0.1082, -0.4712, -0.6939,  0.1508, -0.0295,  0.2139, -0.1450])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.0266, -0.4714],\n",
      "        [ 0.1496,  0.5533],\n",
      "        [ 0.2981, -0.1429],\n",
      "        [-0.4035,  0.0446],\n",
      "        [-0.0039,  0.2523],\n",
      "        [-0.1475, -0.2690],\n",
      "        [ 0.0458, -0.0540],\n",
      "        [ 0.1998, -0.1243],\n",
      "        [-0.4959,  0.3874],\n",
      "        [-0.2407, -0.0875],\n",
      "        [ 0.5734,  0.0178],\n",
      "        [ 0.4443, -0.1050],\n",
      "        [-0.4452,  0.4468],\n",
      "        [-0.0019,  0.4950],\n",
      "        [-0.2385,  0.5565],\n",
      "        [ 0.4351, -0.4718]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([ 0.5144,  0.0282, -0.0653, -0.5058, -0.0799, -0.0588,  0.2711,  0.3709,\n",
      "        -0.2471, -0.4565, -0.6886, -0.2819, -0.0158, -0.5740,  0.0562, -0.2146])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.3540],\n",
      "        [ 0.3041],\n",
      "        [ 0.2496],\n",
      "        [ 0.4182],\n",
      "        [-0.5445],\n",
      "        [ 0.4780],\n",
      "        [ 0.4646],\n",
      "        [ 0.0347],\n",
      "        [-0.4972],\n",
      "        [ 0.4706],\n",
      "        [-0.0739],\n",
      "        [-0.1228],\n",
      "        [-0.1755],\n",
      "        [-0.0558],\n",
      "        [ 0.3888],\n",
      "        [-0.5571]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.2511, -0.4360],\n",
      "         [ 0.3803,  0.2588],\n",
      "         [ 0.6839, -0.6552],\n",
      "         [-0.2688, -0.3706],\n",
      "         [-0.1731, -0.4165],\n",
      "         [-0.1857,  0.3800],\n",
      "         [ 0.6236,  0.7160],\n",
      "         [ 0.4274, -0.6979]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.1116,  0.5211],\n",
      "        [ 0.2924, -0.4598],\n",
      "        [ 0.1018, -0.5581],\n",
      "        [-0.4888, -0.2847],\n",
      "        [ 0.5355,  0.3981],\n",
      "        [ 0.2539,  0.5746],\n",
      "        [ 0.4150, -0.5501],\n",
      "        [ 0.0750,  0.0389],\n",
      "        [ 0.0540,  0.1096],\n",
      "        [-0.1343,  0.2729],\n",
      "        [-0.0990, -0.3795],\n",
      "        [ 0.0603, -0.2046],\n",
      "        [ 0.1643,  0.0190],\n",
      "        [-0.1362,  0.1843],\n",
      "        [ 0.0008, -0.4844],\n",
      "        [-0.0129, -0.1332]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.2833, -0.1571, -0.0530, -0.0959, -0.6194, -0.6883,  0.1610,  0.3746,\n",
      "         0.3902, -0.2908, -0.2880,  0.3211,  0.1541,  0.0654,  0.2824, -0.5864])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.0152, -0.2536],\n",
      "        [-0.2358,  0.4747],\n",
      "        [-0.4716,  0.1977],\n",
      "        [ 0.0110,  0.5191],\n",
      "        [ 0.2393, -0.0012],\n",
      "        [ 0.3903,  0.2677],\n",
      "        [ 0.3840,  0.5589],\n",
      "        [ 0.3153, -0.2954],\n",
      "        [-0.0793,  0.5726],\n",
      "        [ 0.1911, -0.1408],\n",
      "        [-0.4619, -0.1165],\n",
      "        [-0.2755,  0.5406],\n",
      "        [ 0.2217,  0.1662],\n",
      "        [-0.2156, -0.5734],\n",
      "        [-0.5273, -0.0268],\n",
      "        [ 0.2894, -0.3825]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.6248,  0.3042,  0.7053, -0.6171, -0.4113, -0.1576,  0.6221, -0.3738,\n",
      "        -0.2806,  0.0353, -0.2506,  0.6417,  0.0604, -0.3229,  0.0709, -0.0113])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.5748],\n",
      "        [-0.5354],\n",
      "        [ 0.0090],\n",
      "        [ 0.0691],\n",
      "        [ 0.4608],\n",
      "        [ 0.1826],\n",
      "        [-0.4800],\n",
      "        [-0.1505],\n",
      "        [ 0.4470],\n",
      "        [ 0.3836],\n",
      "        [ 0.3629],\n",
      "        [-0.0364],\n",
      "        [ 0.0564],\n",
      "        [ 0.1807],\n",
      "        [-0.3281],\n",
      "        [-0.5023]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[-0.3102, -0.4579],\n",
      "         [-0.2455,  0.5229],\n",
      "         [-0.5051, -0.2869],\n",
      "         [ 0.7480,  0.7156],\n",
      "         [ 0.5171,  0.2875],\n",
      "         [ 0.3865,  0.4839],\n",
      "         [-0.6196, -0.2719],\n",
      "         [-0.0131,  0.1105]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.0183, -0.2406],\n",
      "        [ 0.5356,  0.3862],\n",
      "        [ 0.3908,  0.3362],\n",
      "        [ 0.4963, -0.2247],\n",
      "        [ 0.0880,  0.1726],\n",
      "        [ 0.3102,  0.4190],\n",
      "        [ 0.1632,  0.3903],\n",
      "        [-0.3721, -0.3329],\n",
      "        [-0.3889, -0.0012],\n",
      "        [ 0.3808,  0.3032],\n",
      "        [-0.3684,  0.2786],\n",
      "        [ 0.0867, -0.0886],\n",
      "        [-0.0351, -0.1452],\n",
      "        [-0.4477, -0.4709],\n",
      "        [-0.2434,  0.1956],\n",
      "        [-0.2176, -0.3953]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.3139,  0.5775, -0.3716, -0.5425,  0.5860,  0.0024, -0.1699, -0.4264,\n",
      "        -0.6108,  0.1031,  0.1665, -0.0349,  0.4108,  0.6438,  0.0268,  0.4250])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.3847,  0.0988],\n",
      "        [ 0.4858,  0.1078],\n",
      "        [-0.1006, -0.3833],\n",
      "        [-0.4826, -0.2862],\n",
      "        [-0.5358, -0.1693],\n",
      "        [ 0.5610,  0.3556],\n",
      "        [ 0.1333,  0.3481],\n",
      "        [ 0.4251,  0.3692],\n",
      "        [-0.0239, -0.4849],\n",
      "        [-0.4858,  0.3590],\n",
      "        [ 0.4063, -0.4463],\n",
      "        [ 0.2768, -0.3921],\n",
      "        [ 0.2122, -0.4795],\n",
      "        [ 0.1288, -0.2663],\n",
      "        [-0.4363,  0.5111],\n",
      "        [ 0.3991, -0.0474]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([ 0.2665, -0.1462, -0.5823, -0.0399,  0.3688,  0.0760,  0.5891,  0.0523,\n",
      "        -0.5239,  0.1597,  0.5793, -0.2423,  0.5411,  0.0951, -0.5015,  0.6468])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[ 0.4968],\n",
      "        [-0.2574],\n",
      "        [ 0.0331],\n",
      "        [ 0.4433],\n",
      "        [-0.3393],\n",
      "        [ 0.0017],\n",
      "        [-0.1661],\n",
      "        [-0.1574],\n",
      "        [ 0.3118],\n",
      "        [ 0.2844],\n",
      "        [-0.2321],\n",
      "        [ 0.4238],\n",
      "        [-0.2241],\n",
      "        [ 0.4655],\n",
      "        [ 0.0032],\n",
      "        [-0.1618]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[ 0.2084,  0.1102],\n",
      "         [ 0.3941, -0.1469],\n",
      "         [ 0.1633, -0.2764],\n",
      "         [ 0.4976, -0.6031],\n",
      "         [-0.5807, -0.5448],\n",
      "         [ 0.2878, -0.0197],\n",
      "         [ 0.7174,  0.1291],\n",
      "         [-0.1776, -0.3672]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.0436, -0.4792],\n",
      "        [ 0.0350,  0.0152],\n",
      "        [ 0.3097,  0.5321],\n",
      "        [-0.2620, -0.0150],\n",
      "        [ 0.5522, -0.3044],\n",
      "        [-0.4135,  0.0919],\n",
      "        [-0.5693,  0.3586],\n",
      "        [ 0.2924,  0.0865],\n",
      "        [-0.1662, -0.2273],\n",
      "        [ 0.2025,  0.1489],\n",
      "        [-0.2297, -0.0707],\n",
      "        [ 0.3351,  0.4590],\n",
      "        [-0.1235, -0.0161],\n",
      "        [ 0.0148,  0.0532],\n",
      "        [-0.2359,  0.4374],\n",
      "        [ 0.0198,  0.1432]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([ 0.0444, -0.2847, -0.6319, -0.6534, -0.1823,  0.2989, -0.6431, -0.4057,\n",
      "        -0.3389,  0.4699,  0.4288,  0.4233, -0.3704, -0.5796,  0.6680, -0.3507])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.2989,  0.2765],\n",
      "        [-0.0140, -0.2878],\n",
      "        [ 0.5494,  0.5077],\n",
      "        [-0.0783, -0.1414],\n",
      "        [ 0.4631, -0.2818],\n",
      "        [ 0.3650, -0.1718],\n",
      "        [ 0.4126, -0.2990],\n",
      "        [-0.0802,  0.2324],\n",
      "        [-0.0355, -0.2330],\n",
      "        [ 0.5683, -0.4572],\n",
      "        [-0.3957,  0.4513],\n",
      "        [-0.0314, -0.1065],\n",
      "        [ 0.0006, -0.3555],\n",
      "        [-0.3489,  0.1068],\n",
      "        [ 0.1577, -0.4012],\n",
      "        [ 0.0823,  0.1229]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([-0.5656, -0.0773,  0.0036, -0.3290,  0.6766,  0.2781, -0.2419, -0.4689,\n",
      "         0.4185, -0.1191,  0.6000,  0.2718,  0.5133,  0.2966, -0.2709, -0.5507])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.0826],\n",
      "        [-0.5630],\n",
      "        [-0.2474],\n",
      "        [ 0.1771],\n",
      "        [-0.0463],\n",
      "        [-0.1313],\n",
      "        [-0.0630],\n",
      "        [-0.2947],\n",
      "        [-0.0988],\n",
      "        [ 0.1432],\n",
      "        [ 0.0925],\n",
      "        [ 0.0234],\n",
      "        [-0.4211],\n",
      "        [ 0.5583],\n",
      "        [ 0.2942],\n",
      "        [ 0.3404]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[-0.1619, -0.1685],\n",
      "         [-0.1725,  0.0112],\n",
      "         [ 0.1983,  0.4262],\n",
      "         [ 0.3825,  0.3685],\n",
      "         [ 0.3692, -0.2570],\n",
      "         [-0.7614, -0.5590],\n",
      "         [ 0.1670,  0.1974],\n",
      "         [ 0.0891,  0.2273]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.1726,  0.1925],\n",
      "        [-0.0153, -0.2064],\n",
      "        [ 0.1197, -0.4407],\n",
      "        [ 0.5736, -0.2310],\n",
      "        [-0.0728, -0.2743],\n",
      "        [ 0.1779, -0.2372],\n",
      "        [-0.0319,  0.4116],\n",
      "        [-0.1622,  0.2904],\n",
      "        [-0.4763, -0.4994],\n",
      "        [ 0.3680, -0.1726],\n",
      "        [ 0.3288,  0.1974],\n",
      "        [-0.5047, -0.2499],\n",
      "        [-0.4092, -0.2490],\n",
      "        [ 0.1393, -0.0698],\n",
      "        [-0.0902, -0.1149],\n",
      "        [ 0.3369, -0.4384]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.7038,  0.4990,  0.2159, -0.1997, -0.0295, -0.0487, -0.5997,  0.3646,\n",
      "         0.5232, -0.0639,  0.0564,  0.2476,  0.4226, -0.0559, -0.1700, -0.3408])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2202, -0.0430],\n",
      "        [-0.3958,  0.3157],\n",
      "        [ 0.0038,  0.1811],\n",
      "        [-0.2241, -0.2987],\n",
      "        [ 0.0674, -0.5420],\n",
      "        [ 0.0584, -0.0975],\n",
      "        [ 0.1151, -0.2258],\n",
      "        [-0.5433, -0.2533],\n",
      "        [ 0.3678,  0.4400],\n",
      "        [-0.4593,  0.5492],\n",
      "        [-0.5103, -0.4068],\n",
      "        [-0.5671, -0.4100],\n",
      "        [ 0.2637, -0.0465],\n",
      "        [-0.0148,  0.4424],\n",
      "        [ 0.5179,  0.0341],\n",
      "        [ 0.3142, -0.1288]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([-0.6638,  0.0912,  0.0068,  0.1485,  0.0680, -0.6902,  0.4374, -0.2155,\n",
      "        -0.0650,  0.2332,  0.3256, -0.1791, -0.1682, -0.3591,  0.3469, -0.1182])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.0033],\n",
      "        [-0.1346],\n",
      "        [-0.1649],\n",
      "        [ 0.1552],\n",
      "        [ 0.4546],\n",
      "        [-0.2931],\n",
      "        [ 0.4511],\n",
      "        [ 0.5140],\n",
      "        [-0.4366],\n",
      "        [ 0.0716],\n",
      "        [ 0.3180],\n",
      "        [ 0.4443],\n",
      "        [-0.0629],\n",
      "        [-0.3926],\n",
      "        [ 0.2223],\n",
      "        [-0.1698]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[ 0.6645, -0.2398],\n",
      "         [ 0.6274, -0.7389],\n",
      "         [-0.3525, -0.0488],\n",
      "         [ 0.4625, -0.0862],\n",
      "         [-0.0684,  0.2226],\n",
      "         [-0.7192,  0.1847],\n",
      "         [ 0.6216, -0.3183],\n",
      "         [-0.2329, -0.5788]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1954, -0.0764],\n",
      "        [-0.2749, -0.3020],\n",
      "        [-0.2798,  0.0282],\n",
      "        [ 0.4160, -0.1590],\n",
      "        [-0.0496,  0.3354],\n",
      "        [-0.2258, -0.4643],\n",
      "        [ 0.2296, -0.5317],\n",
      "        [ 0.3733, -0.3875],\n",
      "        [-0.0661,  0.1770],\n",
      "        [-0.3759, -0.4406],\n",
      "        [-0.1068, -0.0606],\n",
      "        [-0.3481,  0.5047],\n",
      "        [ 0.0358,  0.2526],\n",
      "        [ 0.0546,  0.2253],\n",
      "        [ 0.0069,  0.2678],\n",
      "        [-0.4073, -0.1292]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.6093, -0.3422, -0.2994, -0.4663,  0.3117,  0.5822, -0.0933,  0.3005,\n",
      "         0.6761,  0.2808,  0.3645, -0.4327,  0.1076,  0.1355, -0.6023, -0.3652])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.2435, -0.5345],\n",
      "        [ 0.4667, -0.5249],\n",
      "        [ 0.4260,  0.4584],\n",
      "        [ 0.1970, -0.5035],\n",
      "        [-0.3005,  0.4894],\n",
      "        [ 0.1877,  0.0185],\n",
      "        [-0.2146,  0.3242],\n",
      "        [-0.3503,  0.3968],\n",
      "        [-0.5284,  0.1724],\n",
      "        [ 0.4704,  0.3010],\n",
      "        [ 0.1262,  0.4628],\n",
      "        [ 0.2692, -0.2614],\n",
      "        [-0.2065,  0.4742],\n",
      "        [ 0.2051, -0.3904],\n",
      "        [-0.4518, -0.4299],\n",
      "        [-0.5418,  0.3235]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([ 0.6687, -0.5475,  0.6786, -0.0195,  0.0877,  0.3513, -0.0989,  0.6206,\n",
      "        -0.1825,  0.5894, -0.5321,  0.4378, -0.6800,  0.2099, -0.0644,  0.6375])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.1956],\n",
      "        [ 0.5775],\n",
      "        [ 0.4857],\n",
      "        [-0.4989],\n",
      "        [-0.3139],\n",
      "        [ 0.1621],\n",
      "        [ 0.2045],\n",
      "        [ 0.1746],\n",
      "        [-0.5614],\n",
      "        [ 0.1691],\n",
      "        [-0.0240],\n",
      "        [-0.3288],\n",
      "        [-0.2946],\n",
      "        [ 0.4061],\n",
      "        [-0.0301],\n",
      "        [-0.1587]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0962, -0.1348,  0.1793, -0.1560, -0.3142, -0.2339],\n",
      "        [ 0.0866,  0.0050, -0.0477,  0.3456, -0.2976,  0.2538],\n",
      "        [-0.3441,  0.2846,  0.1308, -0.3383, -0.2968,  0.2946],\n",
      "        [ 0.2715,  0.0784, -0.2882,  0.0782,  0.0857, -0.2990]])), ('lin1.bias', tensor([-0.1896,  0.2323, -0.3134, -0.1182])), ('lin2.weight', tensor([[-0.2749, -0.4188, -0.2833,  0.0854],\n",
      "        [-0.2929, -0.0733,  0.3743, -0.3357],\n",
      "        [-0.0296, -0.0197, -0.2996,  0.0232]])), ('lin2.bias', tensor([ 0.4005,  0.2851, -0.2788])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[-3.4238e-01,  2.8958e-01],\n",
      "         [ 5.2643e-01, -2.7400e-01],\n",
      "         [-2.6762e-01,  2.7315e-01],\n",
      "         [-8.0058e-02,  3.8834e-02],\n",
      "         [ 5.5048e-01,  6.7781e-02],\n",
      "         [ 2.7357e-01, -1.4131e-01],\n",
      "         [-3.3712e-04, -5.8338e-01],\n",
      "         [ 2.4376e-01, -1.4445e-01]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.1900,  0.0393],\n",
      "        [-0.0749,  0.4178],\n",
      "        [-0.1371, -0.2647],\n",
      "        [ 0.2189, -0.1550],\n",
      "        [-0.1785,  0.0311],\n",
      "        [ 0.3450,  0.2842],\n",
      "        [-0.1268, -0.2797],\n",
      "        [ 0.4148, -0.1463],\n",
      "        [ 0.2784,  0.1165],\n",
      "        [-0.5521,  0.2204],\n",
      "        [ 0.4689, -0.1925],\n",
      "        [-0.4464,  0.3213],\n",
      "        [ 0.2330, -0.3144],\n",
      "        [ 0.0187,  0.4084],\n",
      "        [ 0.5768,  0.2885],\n",
      "        [ 0.5298, -0.3355]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.4181,  0.0443,  0.1522, -0.2526,  0.2008,  0.4242, -0.1270,  0.4928,\n",
      "        -0.1201, -0.2292, -0.4214,  0.0013,  0.0323, -0.0737,  0.0366, -0.4422])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.2628,  0.5666],\n",
      "        [ 0.1617, -0.4781],\n",
      "        [ 0.2172, -0.4891],\n",
      "        [ 0.4243, -0.0241],\n",
      "        [ 0.3028, -0.0752],\n",
      "        [-0.2578,  0.2639],\n",
      "        [ 0.2728,  0.0752],\n",
      "        [-0.3660,  0.4146],\n",
      "        [-0.4338,  0.0221],\n",
      "        [-0.1151,  0.1528],\n",
      "        [ 0.1144, -0.1441],\n",
      "        [-0.1164,  0.2248],\n",
      "        [-0.1373,  0.4894],\n",
      "        [-0.5288, -0.0581],\n",
      "        [-0.3809, -0.3683],\n",
      "        [-0.3552, -0.2045]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([-0.6663, -0.4929, -0.2866,  0.5540,  0.5628,  0.5490, -0.6351,  0.3254,\n",
      "        -0.1699, -0.6905, -0.2206, -0.2066, -0.2265,  0.4376, -0.4635,  0.3277])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.3881],\n",
      "        [ 0.2029],\n",
      "        [-0.5714],\n",
      "        [-0.3604],\n",
      "        [-0.3717],\n",
      "        [-0.4305],\n",
      "        [ 0.0908],\n",
      "        [ 0.3534],\n",
      "        [-0.5845],\n",
      "        [-0.0039],\n",
      "        [-0.5291],\n",
      "        [-0.2506],\n",
      "        [-0.3754],\n",
      "        [ 0.0824],\n",
      "        [ 0.0309],\n",
      "        [-0.3816]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.5646,  0.1100],\n",
      "         [-0.5045, -0.3103],\n",
      "         [ 0.5726, -0.0980],\n",
      "         [-0.5478, -0.3231],\n",
      "         [-0.2765,  0.5434],\n",
      "         [ 0.2521,  0.6112],\n",
      "         [-0.1284,  0.0928],\n",
      "         [-0.7428, -0.0236]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.1917,  0.2641],\n",
      "        [-0.1402, -0.0544],\n",
      "        [ 0.5272, -0.4336],\n",
      "        [-0.0410,  0.3629],\n",
      "        [ 0.4368, -0.0481],\n",
      "        [-0.3744,  0.2164],\n",
      "        [ 0.0597,  0.5143],\n",
      "        [ 0.2509,  0.2470],\n",
      "        [ 0.5540,  0.2297],\n",
      "        [-0.0391,  0.0535],\n",
      "        [-0.2208, -0.4064],\n",
      "        [-0.0485,  0.3331],\n",
      "        [ 0.1115, -0.5494],\n",
      "        [-0.0943,  0.5268],\n",
      "        [-0.1984, -0.0803],\n",
      "        [ 0.1053,  0.0649]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.2059,  0.1253,  0.0315,  0.0596,  0.5381, -0.5882,  0.3116, -0.0708,\n",
      "         0.2269, -0.4673,  0.6826, -0.5463, -0.5032,  0.4859, -0.3067,  0.6831])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-1.2699e-01, -3.1461e-01],\n",
      "        [-3.1360e-01, -1.3173e-04],\n",
      "        [ 2.1655e-01,  2.1863e-01],\n",
      "        [ 3.8130e-01, -2.4450e-01],\n",
      "        [ 1.2965e-01, -2.8516e-01],\n",
      "        [ 3.8717e-01, -2.1732e-01],\n",
      "        [ 4.2387e-01, -1.8188e-02],\n",
      "        [ 4.9326e-01,  3.4241e-01],\n",
      "        [-3.8873e-01,  2.8919e-01],\n",
      "        [ 2.8431e-01, -2.9064e-01],\n",
      "        [-2.1373e-01,  3.4536e-01],\n",
      "        [ 1.5027e-01,  5.0957e-01],\n",
      "        [-3.5081e-01,  5.2084e-01],\n",
      "        [-5.6469e-01, -2.8150e-01],\n",
      "        [ 2.9317e-01, -3.3366e-02],\n",
      "        [ 4.9529e-01,  5.1256e-02]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.2268, -0.4083,  0.5207, -0.4405, -0.6650, -0.0869, -0.5436, -0.6513,\n",
      "         0.4319, -0.2924,  0.4914, -0.0444, -0.1375,  0.6614,  0.0861,  0.1232])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.4607],\n",
      "        [ 0.5313],\n",
      "        [ 0.5867],\n",
      "        [ 0.5404],\n",
      "        [-0.3134],\n",
      "        [ 0.2076],\n",
      "        [-0.2656],\n",
      "        [ 0.1115],\n",
      "        [-0.4675],\n",
      "        [-0.5120],\n",
      "        [ 0.0539],\n",
      "        [-0.2786],\n",
      "        [-0.1498],\n",
      "        [-0.1429],\n",
      "        [ 0.2983],\n",
      "        [ 0.2541]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[ 4.5946e-01, -2.3483e-02],\n",
      "         [ 3.2731e-02,  2.5095e-01],\n",
      "         [-1.3004e-01, -4.7712e-01],\n",
      "         [ 6.7240e-01, -5.5914e-01],\n",
      "         [-6.7776e-01, -2.3716e-01],\n",
      "         [-1.3234e-01,  1.4741e-01],\n",
      "         [-2.8951e-02, -4.2677e-04],\n",
      "         [ 1.3326e-01,  4.4650e-01]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.0783,  0.0913],\n",
      "        [ 0.2108, -0.3950],\n",
      "        [ 0.5569,  0.1387],\n",
      "        [ 0.3233,  0.4085],\n",
      "        [ 0.4147,  0.1215],\n",
      "        [ 0.4975,  0.0212],\n",
      "        [ 0.0596, -0.3108],\n",
      "        [ 0.0019, -0.1720],\n",
      "        [-0.5728,  0.0432],\n",
      "        [ 0.1389, -0.2742],\n",
      "        [-0.3531,  0.4315],\n",
      "        [-0.5761, -0.0233],\n",
      "        [ 0.5205,  0.1973],\n",
      "        [-0.5742,  0.1821],\n",
      "        [-0.1233, -0.1099],\n",
      "        [ 0.5573, -0.0600]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.4576, -0.3875, -0.5912,  0.0101,  0.2881, -0.2755, -0.5262, -0.0263,\n",
      "        -0.1557, -0.3790, -0.6251, -0.3706, -0.2302,  0.2263,  0.6531,  0.2982])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.1701, -0.2507],\n",
      "        [-0.5335, -0.0091],\n",
      "        [ 0.5347,  0.3057],\n",
      "        [ 0.3285,  0.2562],\n",
      "        [-0.2304, -0.4790],\n",
      "        [-0.1011, -0.0846],\n",
      "        [-0.4103,  0.4707],\n",
      "        [ 0.0691, -0.3031],\n",
      "        [-0.5095, -0.2741],\n",
      "        [ 0.2854, -0.3140],\n",
      "        [-0.5539, -0.4625],\n",
      "        [-0.0600,  0.1052],\n",
      "        [ 0.0557, -0.4836],\n",
      "        [-0.5554,  0.4267],\n",
      "        [-0.4799, -0.4318],\n",
      "        [-0.5382, -0.3562]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([-0.5502, -0.6859, -0.2647,  0.3773, -0.6476, -0.0546, -0.3433,  0.1162,\n",
      "        -0.1195, -0.5426,  0.3825, -0.1100,  0.2852, -0.3144,  0.0040, -0.5219])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.3222],\n",
      "        [-0.2725],\n",
      "        [-0.0611],\n",
      "        [-0.2818],\n",
      "        [-0.0610],\n",
      "        [-0.0556],\n",
      "        [ 0.4371],\n",
      "        [ 0.1219],\n",
      "        [ 0.0163],\n",
      "        [ 0.2907],\n",
      "        [-0.2852],\n",
      "        [-0.2747],\n",
      "        [-0.5493],\n",
      "        [-0.0902],\n",
      "        [ 0.3718],\n",
      "        [ 0.3419]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[-0.3537,  0.5243],\n",
      "         [ 0.7056,  0.3017],\n",
      "         [-0.4531,  0.3949],\n",
      "         [ 0.1746,  0.5427],\n",
      "         [ 0.5505, -0.5520],\n",
      "         [-0.7161,  0.4853],\n",
      "         [-0.7657,  0.1920],\n",
      "         [-0.3134, -0.0636]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.3141, -0.1569],\n",
      "        [ 0.3294, -0.2164],\n",
      "        [-0.4745,  0.2960],\n",
      "        [ 0.2002,  0.0040],\n",
      "        [-0.1934, -0.0049],\n",
      "        [ 0.3590,  0.5054],\n",
      "        [-0.5677,  0.5470],\n",
      "        [ 0.2756, -0.0488],\n",
      "        [-0.3613,  0.1361],\n",
      "        [-0.0342, -0.5643],\n",
      "        [-0.2473, -0.2329],\n",
      "        [-0.0990,  0.4481],\n",
      "        [ 0.1364, -0.1893],\n",
      "        [ 0.1323,  0.1430],\n",
      "        [ 0.2628, -0.1028],\n",
      "        [-0.2015,  0.5637]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.3249, -0.1200, -0.2167, -0.2431,  0.3960,  0.5418, -0.6855, -0.4393,\n",
      "         0.0094, -0.4458, -0.3695, -0.0864,  0.1205, -0.0426, -0.4212,  0.5990])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.2246,  0.1887],\n",
      "        [-0.2578,  0.0310],\n",
      "        [-0.3210, -0.2450],\n",
      "        [ 0.4232,  0.5135],\n",
      "        [-0.5542, -0.0535],\n",
      "        [-0.1559,  0.3327],\n",
      "        [ 0.1431,  0.3927],\n",
      "        [-0.4734, -0.3007],\n",
      "        [-0.4256, -0.1530],\n",
      "        [ 0.0886,  0.0778],\n",
      "        [-0.4253,  0.5710],\n",
      "        [-0.2359,  0.5309],\n",
      "        [ 0.0442, -0.0532],\n",
      "        [-0.2954, -0.4056],\n",
      "        [-0.1733, -0.0949],\n",
      "        [-0.2727,  0.3374]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([-0.0407,  0.5546,  0.2249,  0.1777, -0.2259,  0.2476,  0.4941,  0.2142,\n",
      "        -0.4328, -0.2712,  0.4483, -0.2431,  0.5025, -0.3632,  0.6014, -0.2844])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.5091],\n",
      "        [-0.3197],\n",
      "        [ 0.4034],\n",
      "        [ 0.4179],\n",
      "        [ 0.1639],\n",
      "        [ 0.0429],\n",
      "        [ 0.4409],\n",
      "        [-0.5456],\n",
      "        [-0.0717],\n",
      "        [ 0.4308],\n",
      "        [ 0.3751],\n",
      "        [ 0.5359],\n",
      "        [-0.0295],\n",
      "        [-0.2893],\n",
      "        [ 0.2657],\n",
      "        [-0.0819]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[ 6.9295e-01, -1.5411e-01],\n",
      "         [ 2.8488e-01, -2.1591e-01],\n",
      "         [-5.1622e-01, -2.6930e-01],\n",
      "         [-2.4301e-04, -1.1426e-01],\n",
      "         [-4.0171e-01,  5.0467e-01],\n",
      "         [-7.2803e-01,  6.9647e-01],\n",
      "         [ 3.8645e-01, -9.1029e-02],\n",
      "         [-4.9967e-01, -7.1161e-01]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.4687, -0.5175],\n",
      "        [ 0.4625, -0.5405],\n",
      "        [-0.4413,  0.2499],\n",
      "        [-0.1314, -0.1390],\n",
      "        [-0.3200, -0.5388],\n",
      "        [-0.2490, -0.4586],\n",
      "        [ 0.1083,  0.2903],\n",
      "        [ 0.3102,  0.0495],\n",
      "        [-0.3419,  0.1732],\n",
      "        [ 0.2627,  0.0141],\n",
      "        [ 0.3190,  0.4147],\n",
      "        [ 0.2108,  0.4731],\n",
      "        [-0.1252, -0.4937],\n",
      "        [-0.3665, -0.5125],\n",
      "        [-0.4485,  0.5174],\n",
      "        [-0.5242,  0.1132]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.3321,  0.4367,  0.1248, -0.6020,  0.0064,  0.2095, -0.6965,  0.4542,\n",
      "        -0.0560,  0.5762,  0.3801, -0.5648, -0.5101, -0.3582,  0.2124,  0.0799])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.4637,  0.4687],\n",
      "        [-0.1779, -0.3284],\n",
      "        [ 0.1951, -0.0910],\n",
      "        [ 0.4780, -0.3469],\n",
      "        [ 0.2600,  0.2847],\n",
      "        [-0.2010, -0.2761],\n",
      "        [ 0.1851, -0.0100],\n",
      "        [-0.2214, -0.4596],\n",
      "        [-0.1148,  0.1589],\n",
      "        [ 0.4658,  0.4939],\n",
      "        [-0.5035,  0.3258],\n",
      "        [ 0.0753,  0.4515],\n",
      "        [ 0.1962,  0.3686],\n",
      "        [ 0.0849,  0.2974],\n",
      "        [ 0.2600,  0.1673],\n",
      "        [-0.0647, -0.4355]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([-0.2122,  0.3632, -0.0826,  0.4502,  0.2897, -0.0015, -0.6458,  0.6717,\n",
      "         0.5047,  0.3587, -0.5740, -0.4083,  0.5977,  0.4801, -0.1409,  0.0583])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.4225],\n",
      "        [ 0.4351],\n",
      "        [ 0.0283],\n",
      "        [ 0.0128],\n",
      "        [-0.0749],\n",
      "        [ 0.1019],\n",
      "        [ 0.0256],\n",
      "        [-0.3641],\n",
      "        [-0.5091],\n",
      "        [ 0.4265],\n",
      "        [ 0.1027],\n",
      "        [-0.1958],\n",
      "        [ 0.0850],\n",
      "        [ 0.2262],\n",
      "        [ 0.3520],\n",
      "        [-0.1913]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[ 0.1713,  0.2020],\n",
      "         [ 0.2356,  0.0780],\n",
      "         [-0.2860,  0.7374],\n",
      "         [ 0.3403, -0.5126],\n",
      "         [-0.1782,  0.1615],\n",
      "         [-0.7555,  0.4883],\n",
      "         [ 0.6667, -0.0013],\n",
      "         [ 0.6317,  0.3701]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1427, -0.4320],\n",
      "        [-0.3164, -0.3545],\n",
      "        [-0.1375, -0.4361],\n",
      "        [-0.0396, -0.2927],\n",
      "        [ 0.0768,  0.1552],\n",
      "        [ 0.3255, -0.4965],\n",
      "        [ 0.2710,  0.0602],\n",
      "        [-0.3954,  0.0727],\n",
      "        [ 0.4404,  0.0551],\n",
      "        [-0.0681,  0.0348],\n",
      "        [-0.2576, -0.2842],\n",
      "        [-0.1256, -0.5694],\n",
      "        [-0.0181,  0.3436],\n",
      "        [ 0.2114, -0.5557],\n",
      "        [ 0.1699,  0.0819],\n",
      "        [-0.5505, -0.4527]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.5638,  0.3888,  0.2432, -0.6003,  0.0629, -0.6677,  0.0038, -0.6586,\n",
      "         0.6276, -0.2497, -0.0437, -0.6547,  0.3455, -0.1290, -0.6557, -0.6977])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.5546, -0.1655],\n",
      "        [ 0.4896,  0.3543],\n",
      "        [-0.2288, -0.3989],\n",
      "        [ 0.2956,  0.2756],\n",
      "        [ 0.4532,  0.0542],\n",
      "        [-0.5341, -0.1827],\n",
      "        [ 0.2959, -0.4163],\n",
      "        [ 0.0666, -0.1090],\n",
      "        [ 0.2517,  0.5752],\n",
      "        [-0.1193,  0.0451],\n",
      "        [-0.0212, -0.2739],\n",
      "        [-0.0039, -0.0629],\n",
      "        [ 0.0043, -0.3804],\n",
      "        [-0.3514, -0.4511],\n",
      "        [ 0.4787,  0.2241],\n",
      "        [-0.2239, -0.2446]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([-0.5989,  0.0840,  0.3946,  0.4625, -0.0731,  0.0305,  0.1156, -0.0435,\n",
      "         0.1639, -0.5680, -0.1206, -0.0897, -0.2685,  0.6941, -0.3498,  0.6029])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[ 0.0403],\n",
      "        [-0.5601],\n",
      "        [ 0.2938],\n",
      "        [ 0.1133],\n",
      "        [-0.4244],\n",
      "        [-0.4711],\n",
      "        [-0.3120],\n",
      "        [-0.5582],\n",
      "        [ 0.2650],\n",
      "        [ 0.4250],\n",
      "        [-0.1594],\n",
      "        [-0.1698],\n",
      "        [ 0.4909],\n",
      "        [ 0.3064],\n",
      "        [-0.2360],\n",
      "        [ 0.5806]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevGATConvEncoder: 2-1                                     --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       804\n",
      "│    └─RevGATConvEncoder: 2-2                                     --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       804\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.2133, 0.9937, 0.2133, 0.2123, 0.9937, 0.2123, 0.0025, 0.9836, 0.0025,\n",
      "        0.9836], grad_fn=<SigmoidBackward0>), tensor([[-0.2675,  0.1682, -0.3101],\n",
      "        [-0.1905,  0.0848, -0.3012],\n",
      "        [-0.2223,  0.1762, -0.3080],\n",
      "        [-0.3082,  0.1611, -0.3120],\n",
      "        [-0.0095, -0.0534, -0.2834]], grad_fn=<AddmmBackward0>), tensor([[-0.3319, -0.1399,  0.6339],\n",
      "        [ 0.3282, -0.7130, -0.0764],\n",
      "        [-0.0804, -0.2985,  0.2984],\n",
      "        [-0.1228, -0.5119,  0.7887],\n",
      "        [-0.0179, -0.5355,  0.4690]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.9929, 0.4919, 0.9929, 0.8392, 0.4919, 0.8392, 0.9462, 0.7954, 0.9462,\n",
      "        0.7954], grad_fn=<SigmoidBackward0>), tensor([[-0.2675,  0.1682, -0.3101],\n",
      "        [-0.1905,  0.0848, -0.3012],\n",
      "        [-0.2223,  0.1762, -0.3080],\n",
      "        [-0.3082,  0.1611, -0.3120],\n",
      "        [-0.0095, -0.0534, -0.2834]], grad_fn=<AddmmBackward0>), tensor([[-0.3319, -0.1399,  0.6339],\n",
      "        [ 0.3282, -0.7130, -0.0764],\n",
      "        [-0.0804, -0.2985,  0.2984],\n",
      "        [-0.1228, -0.5119,  0.7887],\n",
      "        [-0.0179, -0.5355,  0.4690]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[1.0000e+00, 3.6267e-03, 9.0476e-01, 9.8824e-04, 9.9616e-01],\n",
      "        [3.6267e-03, 9.9626e-01, 1.4632e-02, 9.9176e-01, 6.5614e-02],\n",
      "        [9.0476e-01, 1.4632e-02, 9.7272e-01, 3.7281e-02, 8.0215e-01],\n",
      "        [9.8824e-04, 9.9176e-01, 3.7281e-02, 9.9075e-01, 5.9800e-02],\n",
      "        [9.9616e-01, 6.5614e-02, 8.0215e-01, 5.9800e-02, 8.9849e-01]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.8441, 0.3786, 0.1444, 0.7441, 0.5105],\n",
      "        [0.3786, 0.8288, 0.8644, 0.4072, 0.9898],\n",
      "        [0.1444, 0.8644, 0.9701, 0.2461, 0.9845],\n",
      "        [0.7441, 0.4072, 0.2461, 0.6654, 0.4540],\n",
      "        [0.5105, 0.9898, 0.9845, 0.4540, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-2.4000,  0.3191, -1.6082],\n",
      "        [-1.5650, -0.2727,  0.0450],\n",
      "        [ 0.5876,  0.8603,  0.0131],\n",
      "        [-0.4467,  0.4672, -1.4501],\n",
      "        [-0.3721, -0.1318, -1.0339]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-1.1820,  0.7598, -0.8868],\n",
      "        [-0.5035,  0.5384, -1.6157],\n",
      "        [-0.1214, -0.1714, -0.3198],\n",
      "        [-1.4256, -0.1222,  0.8158],\n",
      "        [-1.3815,  0.2359, -3.2804]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.2675,  0.1682, -0.3101],\n",
      "        [-0.1905,  0.0848, -0.3012],\n",
      "        [-0.2223,  0.1762, -0.3080],\n",
      "        [-0.3082,  0.1611, -0.3120],\n",
      "        [-0.0095, -0.0534, -0.2834]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.3319, -0.1399,  0.6339],\n",
      "        [ 0.3282, -0.7130, -0.0764],\n",
      "        [-0.0804, -0.2985,  0.2984],\n",
      "        [-0.1228, -0.5119,  0.7887],\n",
      "        [-0.0179, -0.5355,  0.4690]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.2675,  0.1682, -0.3101],\n",
      "        [-0.1905,  0.0848, -0.3012],\n",
      "        [-0.2223,  0.1762, -0.3080],\n",
      "        [-0.3082,  0.1611, -0.3120],\n",
      "        [-0.0095, -0.0534, -0.2834]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.3319, -0.1399,  0.6339],\n",
      "        [ 0.3282, -0.7130, -0.0764],\n",
      "        [-0.0804, -0.2985,  0.2984],\n",
      "        [-0.1228, -0.5119,  0.7887],\n",
      "        [-0.0179, -0.5355,  0.4690]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6755, 0.4303, 0.6755, 0.0463, 0.4303, 0.0463, 0.0076, 0.7909, 0.0076,\n",
      "        0.7909], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.4542, 0.6219, 0.4542, 0.5068, 0.6219, 0.5068, 0.6841, 0.9303, 0.6841,\n",
      "        0.9303], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(3.8927, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(3.4776, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.44, 0.4859523809523809)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.48, 0.6053968253968254)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[ 0.0961, -0.3475,  0.0481, -0.2351,  0.2224,  0.3230],\n",
      "        [-0.0299,  0.3335,  0.2014, -0.2524, -0.0975,  0.2529],\n",
      "        [ 0.2598,  0.0416, -0.1509, -0.2893,  0.1630,  0.3604],\n",
      "        [ 0.3136, -0.0242,  0.3095, -0.1155, -0.1693,  0.3425]])), ('_encoder_mu.lin1.bias', tensor([ 0.0988,  0.2405, -0.0565, -0.2610])), ('_encoder_mu.lin2.weight', tensor([[ 0.2768, -0.3172,  0.3424,  0.2743],\n",
      "        [ 0.4947, -0.1300, -0.3605, -0.0873],\n",
      "        [ 0.4749,  0.2449, -0.1508,  0.2413]])), ('_encoder_mu.lin2.bias', tensor([ 0.3846, -0.1328,  0.4032])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.lin.weight', tensor([[ 0.1059, -0.2984],\n",
      "        [-0.0103,  0.6887]])), ('_encoder_mu.convs.0.convs.0.conv.lin.bias', tensor([-0.3307,  0.3064])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.4426,  0.3865],\n",
      "        [-0.3857,  0.3351]])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.bias', tensor([-0.0849, -0.5644])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.weight', tensor([[-0.4293,  0.5178],\n",
      "        [-0.3877, -0.6426]])), ('_encoder_mu.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.lin.weight', tensor([[-0.0081, -0.3740],\n",
      "        [ 0.0518,  0.3812]])), ('_encoder_mu.convs.0.convs.1.conv.lin.bias', tensor([-0.6905,  0.4683])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.0247, -0.5157],\n",
      "        [ 0.4008,  0.2122]])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.bias', tensor([0.3139, 0.1478])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.weight', tensor([[-0.4036,  0.0545],\n",
      "        [-0.3974, -0.2575]])), ('_encoder_mu.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.lin.weight', tensor([[-0.2349,  0.5254],\n",
      "        [ 0.1923,  0.4767]])), ('_encoder_mu.convs.1.convs.0.conv.lin.bias', tensor([-0.0634,  0.2480])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.0103,  0.0965],\n",
      "        [-0.3431, -0.5667]])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.bias', tensor([ 0.5312, -0.6150])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.2772,  0.2404],\n",
      "        [ 0.1574,  0.6577]])), ('_encoder_mu.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.lin.weight', tensor([[ 0.0278, -0.5499],\n",
      "        [-0.6585,  0.2122]])), ('_encoder_mu.convs.1.convs.1.conv.lin.bias', tensor([0.6013, 0.5702])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.weight', tensor([[-0.2206, -0.0330],\n",
      "        [ 0.0460, -0.5695]])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.bias', tensor([0.1851, 0.3740])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.3967,  0.2626],\n",
      "        [-0.5399, -0.3304]])), ('_encoder_mu.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.lin.weight', tensor([[-0.0285,  0.5948],\n",
      "        [-0.4908, -0.4544]])), ('_encoder_mu.convs.2.convs.0.conv.lin.bias', tensor([-0.5057, -0.3903])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.weight', tensor([[-0.4594, -0.0173],\n",
      "        [-0.4500, -0.6072]])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.bias', tensor([-0.5149, -0.3660])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.weight', tensor([[0.1320, 0.6346],\n",
      "        [0.3719, 0.1384]])), ('_encoder_mu.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.lin.weight', tensor([[-0.1064, -0.5040],\n",
      "        [ 0.6106, -0.2328]])), ('_encoder_mu.convs.2.convs.1.conv.lin.bias', tensor([-0.0338,  0.1213])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.6212,  0.1592],\n",
      "        [ 0.4074, -0.3097]])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.bias', tensor([-0.5755, -0.5869])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.0191, -0.2403],\n",
      "        [-0.5659, -0.3639]])), ('_encoder_mu.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.0.conv.lin.weight', tensor([[ 0.0143, -0.2407],\n",
      "        [ 0.1099, -0.4794]])), ('_encoder_mu.convs.3.convs.0.conv.lin.bias', tensor([-0.0139, -0.6221])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.weight', tensor([[-0.6894, -0.0998],\n",
      "        [ 0.5114,  0.5674]])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.bias', tensor([0.3657, 0.1325])), ('_encoder_mu.convs.3.convs.0.conv.lin_r.weight', tensor([[-0.1209,  0.3730],\n",
      "        [-0.2537,  0.1113]])), ('_encoder_mu.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.1.conv.lin.weight', tensor([[ 0.1290, -0.1248],\n",
      "        [ 0.4876, -0.5488]])), ('_encoder_mu.convs.3.convs.1.conv.lin.bias', tensor([-0.0222, -0.6827])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.2803,  0.3929],\n",
      "        [-0.1263, -0.2657]])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.bias', tensor([-0.6682,  0.6194])), ('_encoder_mu.convs.3.convs.1.conv.lin_r.weight', tensor([[-0.3597, -0.1051],\n",
      "        [-0.4572,  0.4047]])), ('_encoder_logstd.lin1.weight', tensor([[-0.2064, -0.0152, -0.3466, -0.0073, -0.0195, -0.3463],\n",
      "        [ 0.2796,  0.3107,  0.1150, -0.4011, -0.2226,  0.2202],\n",
      "        [ 0.0618, -0.3417, -0.2732, -0.1984, -0.2666,  0.1451],\n",
      "        [-0.3685,  0.1657,  0.3524, -0.1803, -0.0204, -0.3330]])), ('_encoder_logstd.lin1.bias', tensor([-0.1885,  0.3339, -0.2230, -0.0719])), ('_encoder_logstd.lin2.weight', tensor([[-0.3159,  0.0006,  0.0283, -0.1149],\n",
      "        [ 0.4685,  0.3544, -0.0576, -0.1038],\n",
      "        [-0.4155, -0.0366, -0.2399,  0.3846]])), ('_encoder_logstd.lin2.bias', tensor([-0.0919, -0.4610,  0.3244])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.lin.weight', tensor([[ 0.1137, -0.3323],\n",
      "        [ 0.1609,  0.1345]])), ('_encoder_logstd.convs.0.convs.0.conv.lin.bias', tensor([-0.2045, -0.0138])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.weight', tensor([[-0.6867,  0.2401],\n",
      "        [ 0.2365,  0.4193]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.bias', tensor([0.5664, 0.5548])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.weight', tensor([[-0.0656, -0.6188],\n",
      "        [ 0.0513,  0.3386]])), ('_encoder_logstd.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.lin.weight', tensor([[ 0.4755, -0.3143],\n",
      "        [-0.2805,  0.4540]])), ('_encoder_logstd.convs.0.convs.1.conv.lin.bias', tensor([0.3443, 0.2212])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.5776, -0.1624],\n",
      "        [-0.5055,  0.1761]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.bias', tensor([ 0.0836, -0.4924])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.weight', tensor([[-0.0869,  0.5183],\n",
      "        [-0.4547, -0.0175]])), ('_encoder_logstd.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.lin.weight', tensor([[-0.5102,  0.3971],\n",
      "        [-0.1005, -0.6982]])), ('_encoder_logstd.convs.1.convs.0.conv.lin.bias', tensor([-0.6180,  0.0377])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.4195,  0.6934],\n",
      "        [ 0.6883, -0.6304]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.bias', tensor([ 0.6966, -0.3919])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4630,  0.1331],\n",
      "        [ 0.3730, -0.6951]])), ('_encoder_logstd.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.lin.weight', tensor([[ 0.4980,  0.4284],\n",
      "        [-0.6051,  0.2151]])), ('_encoder_logstd.convs.1.convs.1.conv.lin.bias', tensor([-0.0741,  0.3161])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.5927,  0.4712],\n",
      "        [-0.4738, -0.1408]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.bias', tensor([-0.5895,  0.2147])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.6624, -0.1128],\n",
      "        [-0.0513,  0.2339]])), ('_encoder_logstd.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.lin.weight', tensor([[0.1010, 0.5439],\n",
      "        [0.6491, 0.0779]])), ('_encoder_logstd.convs.2.convs.0.conv.lin.bias', tensor([0.6594, 0.0270])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.weight', tensor([[-0.6194, -0.1769],\n",
      "        [ 0.6443,  0.6912]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.bias', tensor([ 0.1230, -0.5087])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.2084, -0.0789],\n",
      "        [-0.2733, -0.4182]])), ('_encoder_logstd.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.lin.weight', tensor([[ 0.2411, -0.0487],\n",
      "        [-0.2701,  0.5302]])), ('_encoder_logstd.convs.2.convs.1.conv.lin.bias', tensor([-0.3433,  0.5171])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.4182,  0.3963],\n",
      "        [-0.2721,  0.2790]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.bias', tensor([0.2548, 0.6145])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.1909,  0.1310],\n",
      "        [ 0.3908, -0.6605]])), ('_encoder_logstd.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.0.conv.lin.weight', tensor([[-0.1933, -0.4305],\n",
      "        [-0.6245,  0.1015]])), ('_encoder_logstd.convs.3.convs.0.conv.lin.bias', tensor([ 0.5321, -0.5729])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.weight', tensor([[ 0.6354,  0.0597],\n",
      "        [-0.3979, -0.7028]])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.bias', tensor([0.5506, 0.3577])), ('_encoder_logstd.convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.5890,  0.0660],\n",
      "        [-0.1839,  0.5094]])), ('_encoder_logstd.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.1.conv.lin.weight', tensor([[ 0.5686, -0.0325],\n",
      "        [ 0.2038,  0.6831]])), ('_encoder_logstd.convs.3.convs.1.conv.lin.bias', tensor([0.0387, 0.3305])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.weight', tensor([[-0.5177,  0.5049],\n",
      "        [ 0.1198,  0.0147]])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.bias', tensor([-0.6795, -0.4744])), ('_encoder_logstd.convs.3.convs.1.conv.lin_r.weight', tensor([[0.3762, 0.3179],\n",
      "        [0.0029, 0.0088]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2064, -0.0152, -0.3466, -0.0073, -0.0195, -0.3463],\n",
      "        [ 0.2796,  0.3107,  0.1150, -0.4011, -0.2226,  0.2202],\n",
      "        [ 0.0618, -0.3417, -0.2732, -0.1984, -0.2666,  0.1451],\n",
      "        [-0.3685,  0.1657,  0.3524, -0.1803, -0.0204, -0.3330]])), ('lin1.bias', tensor([-0.1885,  0.3339, -0.2230, -0.0719])), ('lin2.weight', tensor([[-0.3159,  0.0006,  0.0283, -0.1149],\n",
      "        [ 0.4685,  0.3544, -0.0576, -0.1038],\n",
      "        [-0.4155, -0.0366, -0.2399,  0.3846]])), ('lin2.bias', tensor([-0.0919, -0.4610,  0.3244])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[ 0.1137, -0.3323],\n",
      "        [ 0.1609,  0.1345]])), ('convs.0.convs.0.conv.lin.bias', tensor([-0.2045, -0.0138])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.6867,  0.2401],\n",
      "        [ 0.2365,  0.4193]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([0.5664, 0.5548])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[-0.0656, -0.6188],\n",
      "        [ 0.0513,  0.3386]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[ 0.4755, -0.3143],\n",
      "        [-0.2805,  0.4540]])), ('convs.0.convs.1.conv.lin.bias', tensor([0.3443, 0.2212])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.5776, -0.1624],\n",
      "        [-0.5055,  0.1761]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.0836, -0.4924])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.0869,  0.5183],\n",
      "        [-0.4547, -0.0175]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.5102,  0.3971],\n",
      "        [-0.1005, -0.6982]])), ('convs.1.convs.0.conv.lin.bias', tensor([-0.6180,  0.0377])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.4195,  0.6934],\n",
      "        [ 0.6883, -0.6304]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.6966, -0.3919])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4630,  0.1331],\n",
      "        [ 0.3730, -0.6951]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[ 0.4980,  0.4284],\n",
      "        [-0.6051,  0.2151]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.0741,  0.3161])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.5927,  0.4712],\n",
      "        [-0.4738, -0.1408]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.5895,  0.2147])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.6624, -0.1128],\n",
      "        [-0.0513,  0.2339]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[0.1010, 0.5439],\n",
      "        [0.6491, 0.0779]])), ('convs.2.convs.0.conv.lin.bias', tensor([0.6594, 0.0270])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.6194, -0.1769],\n",
      "        [ 0.6443,  0.6912]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.1230, -0.5087])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.2084, -0.0789],\n",
      "        [-0.2733, -0.4182]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.2411, -0.0487],\n",
      "        [-0.2701,  0.5302]])), ('convs.2.convs.1.conv.lin.bias', tensor([-0.3433,  0.5171])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.4182,  0.3963],\n",
      "        [-0.2721,  0.2790]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([0.2548, 0.6145])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.1909,  0.1310],\n",
      "        [ 0.3908, -0.6605]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[-0.1933, -0.4305],\n",
      "        [-0.6245,  0.1015]])), ('convs.3.convs.0.conv.lin.bias', tensor([ 0.5321, -0.5729])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[ 0.6354,  0.0597],\n",
      "        [-0.3979, -0.7028]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([0.5506, 0.3577])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.5890,  0.0660],\n",
      "        [-0.1839,  0.5094]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[ 0.5686, -0.0325],\n",
      "        [ 0.2038,  0.6831]])), ('convs.3.convs.1.conv.lin.bias', tensor([0.0387, 0.3305])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[-0.5177,  0.5049],\n",
      "        [ 0.1198,  0.0147]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([-0.6795, -0.4744])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[0.3762, 0.3179],\n",
      "        [0.0029, 0.0088]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0961, -0.3475,  0.0481, -0.2351,  0.2224,  0.3230],\n",
      "        [-0.0299,  0.3335,  0.2014, -0.2524, -0.0975,  0.2529],\n",
      "        [ 0.2598,  0.0416, -0.1509, -0.2893,  0.1630,  0.3604],\n",
      "        [ 0.3136, -0.0242,  0.3095, -0.1155, -0.1693,  0.3425]])), ('lin1.bias', tensor([ 0.0988,  0.2405, -0.0565, -0.2610])), ('lin2.weight', tensor([[ 0.2768, -0.3172,  0.3424,  0.2743],\n",
      "        [ 0.4947, -0.1300, -0.3605, -0.0873],\n",
      "        [ 0.4749,  0.2449, -0.1508,  0.2413]])), ('lin2.bias', tensor([ 0.3846, -0.1328,  0.4032])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[ 0.1059, -0.2984],\n",
      "        [-0.0103,  0.6887]])), ('convs.0.convs.0.conv.lin.bias', tensor([-0.3307,  0.3064])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.4426,  0.3865],\n",
      "        [-0.3857,  0.3351]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.0849, -0.5644])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[-0.4293,  0.5178],\n",
      "        [-0.3877, -0.6426]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.0081, -0.3740],\n",
      "        [ 0.0518,  0.3812]])), ('convs.0.convs.1.conv.lin.bias', tensor([-0.6905,  0.4683])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.0247, -0.5157],\n",
      "        [ 0.4008,  0.2122]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([0.3139, 0.1478])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.4036,  0.0545],\n",
      "        [-0.3974, -0.2575]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.2349,  0.5254],\n",
      "        [ 0.1923,  0.4767]])), ('convs.1.convs.0.conv.lin.bias', tensor([-0.0634,  0.2480])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.0103,  0.0965],\n",
      "        [-0.3431, -0.5667]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.5312, -0.6150])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.2772,  0.2404],\n",
      "        [ 0.1574,  0.6577]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[ 0.0278, -0.5499],\n",
      "        [-0.6585,  0.2122]])), ('convs.1.convs.1.conv.lin.bias', tensor([0.6013, 0.5702])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.2206, -0.0330],\n",
      "        [ 0.0460, -0.5695]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([0.1851, 0.3740])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.3967,  0.2626],\n",
      "        [-0.5399, -0.3304]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[-0.0285,  0.5948],\n",
      "        [-0.4908, -0.4544]])), ('convs.2.convs.0.conv.lin.bias', tensor([-0.5057, -0.3903])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.4594, -0.0173],\n",
      "        [-0.4500, -0.6072]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.5149, -0.3660])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[0.1320, 0.6346],\n",
      "        [0.3719, 0.1384]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[-0.1064, -0.5040],\n",
      "        [ 0.6106, -0.2328]])), ('convs.2.convs.1.conv.lin.bias', tensor([-0.0338,  0.1213])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.6212,  0.1592],\n",
      "        [ 0.4074, -0.3097]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.5755, -0.5869])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.0191, -0.2403],\n",
      "        [-0.5659, -0.3639]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.0143, -0.2407],\n",
      "        [ 0.1099, -0.4794]])), ('convs.3.convs.0.conv.lin.bias', tensor([-0.0139, -0.6221])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.6894, -0.0998],\n",
      "        [ 0.5114,  0.5674]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([0.3657, 0.1325])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[-0.1209,  0.3730],\n",
      "        [-0.2537,  0.1113]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[ 0.1290, -0.1248],\n",
      "        [ 0.4876, -0.5488]])), ('convs.3.convs.1.conv.lin.bias', tensor([-0.0222, -0.6827])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.2803,  0.3929],\n",
      "        [-0.1263, -0.2657]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([-0.6682,  0.6194])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[-0.3597, -0.1051],\n",
      "        [-0.4572,  0.4047]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevSAGEConvEncoder: 2-1                                    --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       160\n",
      "│    └─RevSAGEConvEncoder: 2-2                                    --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       160\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.9436, 0.0635, 0.9436, 0.1774, 0.0635, 0.1774, 0.8269, 0.6343, 0.8269,\n",
      "        0.6343], grad_fn=<SigmoidBackward0>), tensor([[0.8404, 0.6818, 1.1852],\n",
      "        [0.8520, 0.7025, 1.2051],\n",
      "        [0.8530, 0.7044, 1.2069],\n",
      "        [0.8363, 0.6744, 1.1781],\n",
      "        [0.8555, 0.7089, 1.2112]], grad_fn=<AddmmBackward0>), tensor([[-0.0817,  0.0139,  0.1942],\n",
      "        [-0.2757,  0.2074,  0.0408],\n",
      "        [-0.0902,  0.0426,  0.2656],\n",
      "        [-0.0909,  0.1132,  0.2651],\n",
      "        [-0.0909,  0.1018,  0.2662]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.9587, 0.9983, 0.9587, 0.9998, 0.9983, 0.9998, 0.9999, 0.9998, 0.9999,\n",
      "        0.9998], grad_fn=<SigmoidBackward0>), tensor([[0.8404, 0.6818, 1.1852],\n",
      "        [0.8520, 0.7025, 1.2051],\n",
      "        [0.8530, 0.7044, 1.2069],\n",
      "        [0.8363, 0.6744, 1.1781],\n",
      "        [0.8555, 0.7089, 1.2112]], grad_fn=<AddmmBackward0>), tensor([[-0.0817,  0.0139,  0.1942],\n",
      "        [-0.2757,  0.2074,  0.0408],\n",
      "        [-0.0902,  0.0426,  0.2656],\n",
      "        [-0.0909,  0.1132,  0.2651],\n",
      "        [-0.0909,  0.1018,  0.2662]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.9999, 0.9999, 0.4645, 0.9998, 0.9999],\n",
      "        [0.9999, 1.0000, 0.9798, 0.9951, 1.0000],\n",
      "        [0.4645, 0.9798, 0.7959, 0.2329, 0.8752],\n",
      "        [0.9998, 0.9951, 0.2329, 0.9999, 0.9989],\n",
      "        [0.9999, 1.0000, 0.8752, 0.9989, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.7914, 0.5108, 0.4642, 0.1470, 0.5389],\n",
      "        [0.5108, 0.8406, 0.6473, 0.9161, 0.9546],\n",
      "        [0.4642, 0.6473, 0.6818, 0.9093, 0.8732],\n",
      "        [0.1470, 0.9161, 0.9093, 0.9998, 0.9980],\n",
      "        [0.5389, 0.9546, 0.8732, 0.9980, 0.9990]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 1.2420,  2.4063,  2.8813],\n",
      "        [ 0.8247, -1.1019,  4.0038],\n",
      "        [ 0.2360,  0.8149,  2.9991],\n",
      "        [-0.4605,  1.3337,  4.0604],\n",
      "        [ 1.8100,  0.2335,  0.5915]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[ 3.9269,  1.6910,  2.4208],\n",
      "        [ 0.7247,  1.1353,  2.0205],\n",
      "        [ 3.2006,  0.9804,  3.0216],\n",
      "        [ 0.6354, -0.4305,  0.1734],\n",
      "        [ 2.0262,  0.2878,  1.3134]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[0.8404, 0.6818, 1.1852],\n",
      "        [0.8520, 0.7025, 1.2051],\n",
      "        [0.8530, 0.7044, 1.2069],\n",
      "        [0.8363, 0.6744, 1.1781],\n",
      "        [0.8555, 0.7089, 1.2112]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.0817,  0.0139,  0.1942],\n",
      "        [-0.2757,  0.2074,  0.0408],\n",
      "        [-0.0902,  0.0426,  0.2656],\n",
      "        [-0.0909,  0.1132,  0.2651],\n",
      "        [-0.0909,  0.1018,  0.2662]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[0.8404, 0.6818, 1.1852],\n",
      "        [0.8520, 0.7025, 1.2051],\n",
      "        [0.8530, 0.7044, 1.2069],\n",
      "        [0.8363, 0.6744, 1.1781],\n",
      "        [0.8555, 0.7089, 1.2112]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.0817,  0.0139,  0.1942],\n",
      "        [-0.2757,  0.2074,  0.0408],\n",
      "        [-0.0902,  0.0426,  0.2656],\n",
      "        [-0.0909,  0.1132,  0.2651],\n",
      "        [-0.0909,  0.1018,  0.2662]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.9995, 0.8242, 0.9995, 0.9017, 0.8242, 0.9017, 0.3902, 0.8829, 0.3902,\n",
      "        0.8829], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.6111, 0.8126, 0.6111, 0.2718, 0.8126, 0.2718, 0.4888, 0.8214, 0.4888,\n",
      "        0.8214], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.4381, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(1.4425, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.6000000000000001, 0.75)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.64, 0.5961904761904762)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[ 0.2134,  0.2511, -0.1088,  0.0070, -0.1618, -0.1873],\n",
      "        [-0.2123,  0.1154,  0.3710,  0.2183, -0.1081,  0.2522],\n",
      "        [-0.0538, -0.2526, -0.3971, -0.1454, -0.0331, -0.2611],\n",
      "        [-0.2690,  0.2631, -0.0424, -0.1592, -0.1478,  0.0875],\n",
      "        [ 0.3497, -0.1067, -0.1013, -0.0394,  0.1004, -0.2596]])), ('_encoder_mu.lin1.bias', tensor([-0.3769, -0.3029, -0.3036, -0.1008,  0.1807])), ('_encoder_mu.lin2.weight', tensor([[-0.4429,  0.3741, -0.1014, -0.1821],\n",
      "        [-0.2764,  0.1459,  0.0526, -0.3324],\n",
      "        [ 0.1267, -0.0470, -0.2539, -0.3860]])), ('_encoder_mu.lin2.bias', tensor([ 0.4996, -0.3791,  0.3086])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.lin.weight', tensor([[-0.0538, -0.5792, -0.1443, -0.5732, -0.4177],\n",
      "        [-0.4765, -0.1098,  0.1820, -0.5147, -0.3871],\n",
      "        [-0.5787, -0.2012, -0.2679,  0.2060,  0.0993],\n",
      "        [ 0.0560,  0.6154,  0.5186, -0.6473, -0.1852],\n",
      "        [-0.2204, -0.4336, -0.0738, -0.3989, -0.5930]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.lin.weight', tensor([[-0.0273,  0.4183,  0.4320,  0.3273,  0.3612],\n",
      "        [ 0.5663,  0.0680,  0.4194,  0.6117, -0.5514],\n",
      "        [-0.6122, -0.7296, -0.4993, -0.4289, -0.1705],\n",
      "        [ 0.5457,  0.3864,  0.6160,  0.1315,  0.6211],\n",
      "        [-0.2957, -0.4652, -0.0050,  0.2741, -0.3695]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.lin.weight', tensor([[ 0.7373, -0.6066, -0.3376, -0.4457,  0.0721],\n",
      "        [-0.5706,  0.1312,  0.7078,  0.6126,  0.2166],\n",
      "        [ 0.1058,  0.1981,  0.7965, -0.3261, -0.3891],\n",
      "        [-0.0014,  0.0737, -0.5679, -0.4504, -0.7483]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.lin.weight', tensor([[ 0.4932, -0.8104,  0.6516,  0.5813],\n",
      "        [ 0.2983,  0.8281,  0.2827,  0.5154],\n",
      "        [ 0.1507, -0.1363,  0.1343, -0.4136],\n",
      "        [ 0.7996, -0.1480, -0.8028, -0.3226]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.0985, -0.2620, -0.1784,  0.1831,  0.3663, -0.1482],\n",
      "        [ 0.0225,  0.3941, -0.2823, -0.1789, -0.1331,  0.3684],\n",
      "        [ 0.2670, -0.2596,  0.1517, -0.2085,  0.4034, -0.0319],\n",
      "        [ 0.2380, -0.0924,  0.1969,  0.3337, -0.0611, -0.1646],\n",
      "        [-0.1346,  0.2257, -0.2144, -0.3522,  0.0157, -0.1989]])), ('_encoder_logstd.lin1.bias', tensor([-0.3104, -0.2826,  0.2667, -0.0627, -0.1897])), ('_encoder_logstd.lin2.weight', tensor([[-0.4318, -0.2242, -0.3963,  0.2746],\n",
      "        [ 0.0288,  0.3426, -0.3614, -0.4482],\n",
      "        [-0.4737, -0.4619, -0.0331, -0.4771]])), ('_encoder_logstd.lin2.bias', tensor([ 0.1393,  0.2045, -0.2452])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.lin.weight', tensor([[ 0.5081, -0.0446,  0.1675,  0.0401,  0.0446],\n",
      "        [-0.7313, -0.4380,  0.6604, -0.7669,  0.3988],\n",
      "        [-0.4391, -0.3161, -0.5929, -0.0074,  0.7288],\n",
      "        [ 0.4810,  0.4623,  0.4130, -0.7715, -0.2083],\n",
      "        [-0.4623,  0.3715, -0.4105,  0.4256, -0.1032]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.lin.weight', tensor([[-0.6584,  0.7618, -0.7240, -0.5268,  0.1388],\n",
      "        [-0.4438,  0.4194,  0.1345, -0.4511, -0.3141],\n",
      "        [-0.7184,  0.4046,  0.0367, -0.0047,  0.5727],\n",
      "        [ 0.1791, -0.5003,  0.5882, -0.1681,  0.5408],\n",
      "        [-0.5100,  0.0857, -0.4178, -0.7488,  0.3836]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.lin.weight', tensor([[-0.7131,  0.2532,  0.6095, -0.0123, -0.2182],\n",
      "        [ 0.6705, -0.6172, -0.3405,  0.7694,  0.3763],\n",
      "        [-0.3038,  0.5094,  0.3006,  0.1948, -0.6252],\n",
      "        [ 0.3909, -0.0105, -0.2379, -0.5648, -0.0319]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.lin.weight', tensor([[ 0.6468, -0.5951, -0.3569,  0.4199],\n",
      "        [ 0.6541,  0.3346, -0.3280,  0.5690],\n",
      "        [ 0.2063,  0.0203,  0.8161,  0.4542],\n",
      "        [-0.0789,  0.1436, -0.5875, -0.5366]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0985, -0.2620, -0.1784,  0.1831,  0.3663, -0.1482],\n",
      "        [ 0.0225,  0.3941, -0.2823, -0.1789, -0.1331,  0.3684],\n",
      "        [ 0.2670, -0.2596,  0.1517, -0.2085,  0.4034, -0.0319],\n",
      "        [ 0.2380, -0.0924,  0.1969,  0.3337, -0.0611, -0.1646],\n",
      "        [-0.1346,  0.2257, -0.2144, -0.3522,  0.0157, -0.1989]])), ('lin1.bias', tensor([-0.3104, -0.2826,  0.2667, -0.0627, -0.1897])), ('lin2.weight', tensor([[-0.4318, -0.2242, -0.3963,  0.2746],\n",
      "        [ 0.0288,  0.3426, -0.3614, -0.4482],\n",
      "        [-0.4737, -0.4619, -0.0331, -0.4771]])), ('lin2.bias', tensor([ 0.1393,  0.2045, -0.2452])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[ 0.5081, -0.0446,  0.1675,  0.0401,  0.0446],\n",
      "        [-0.7313, -0.4380,  0.6604, -0.7669,  0.3988],\n",
      "        [-0.4391, -0.3161, -0.5929, -0.0074,  0.7288],\n",
      "        [ 0.4810,  0.4623,  0.4130, -0.7715, -0.2083],\n",
      "        [-0.4623,  0.3715, -0.4105,  0.4256, -0.1032]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[-0.6584,  0.7618, -0.7240, -0.5268,  0.1388],\n",
      "        [-0.4438,  0.4194,  0.1345, -0.4511, -0.3141],\n",
      "        [-0.7184,  0.4046,  0.0367, -0.0047,  0.5727],\n",
      "        [ 0.1791, -0.5003,  0.5882, -0.1681,  0.5408],\n",
      "        [-0.5100,  0.0857, -0.4178, -0.7488,  0.3836]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[-0.7131,  0.2532,  0.6095, -0.0123, -0.2182],\n",
      "        [ 0.6705, -0.6172, -0.3405,  0.7694,  0.3763],\n",
      "        [-0.3038,  0.5094,  0.3006,  0.1948, -0.6252],\n",
      "        [ 0.3909, -0.0105, -0.2379, -0.5648, -0.0319]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 0.6468, -0.5951, -0.3569,  0.4199],\n",
      "        [ 0.6541,  0.3346, -0.3280,  0.5690],\n",
      "        [ 0.2063,  0.0203,  0.8161,  0.4542],\n",
      "        [-0.0789,  0.1436, -0.5875, -0.5366]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2134,  0.2511, -0.1088,  0.0070, -0.1618, -0.1873],\n",
      "        [-0.2123,  0.1154,  0.3710,  0.2183, -0.1081,  0.2522],\n",
      "        [-0.0538, -0.2526, -0.3971, -0.1454, -0.0331, -0.2611],\n",
      "        [-0.2690,  0.2631, -0.0424, -0.1592, -0.1478,  0.0875],\n",
      "        [ 0.3497, -0.1067, -0.1013, -0.0394,  0.1004, -0.2596]])), ('lin1.bias', tensor([-0.3769, -0.3029, -0.3036, -0.1008,  0.1807])), ('lin2.weight', tensor([[-0.4429,  0.3741, -0.1014, -0.1821],\n",
      "        [-0.2764,  0.1459,  0.0526, -0.3324],\n",
      "        [ 0.1267, -0.0470, -0.2539, -0.3860]])), ('lin2.bias', tensor([ 0.4996, -0.3791,  0.3086])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[-0.0538, -0.5792, -0.1443, -0.5732, -0.4177],\n",
      "        [-0.4765, -0.1098,  0.1820, -0.5147, -0.3871],\n",
      "        [-0.5787, -0.2012, -0.2679,  0.2060,  0.0993],\n",
      "        [ 0.0560,  0.6154,  0.5186, -0.6473, -0.1852],\n",
      "        [-0.2204, -0.4336, -0.0738, -0.3989, -0.5930]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[-0.0273,  0.4183,  0.4320,  0.3273,  0.3612],\n",
      "        [ 0.5663,  0.0680,  0.4194,  0.6117, -0.5514],\n",
      "        [-0.6122, -0.7296, -0.4993, -0.4289, -0.1705],\n",
      "        [ 0.5457,  0.3864,  0.6160,  0.1315,  0.6211],\n",
      "        [-0.2957, -0.4652, -0.0050,  0.2741, -0.3695]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.7373, -0.6066, -0.3376, -0.4457,  0.0721],\n",
      "        [-0.5706,  0.1312,  0.7078,  0.6126,  0.2166],\n",
      "        [ 0.1058,  0.1981,  0.7965, -0.3261, -0.3891],\n",
      "        [-0.0014,  0.0737, -0.5679, -0.4504, -0.7483]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 0.4932, -0.8104,  0.6516,  0.5813],\n",
      "        [ 0.2983,  0.8281,  0.2827,  0.5154],\n",
      "        [ 0.1507, -0.1363,  0.1343, -0.4136],\n",
      "        [ 0.7996, -0.1480, -0.8028, -0.3226]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "├─VGEncoder: 1-1                                        --\n",
      "│    └─SimpleGCNEncoder: 2-1                            --\n",
      "│    │    └─Linear: 3-1                                 35\n",
      "│    │    └─Linear: 3-2                                 15\n",
      "│    │    └─LayerNorm: 3-3                              8\n",
      "│    │    └─ModuleList: 3-4                             142\n",
      "│    └─SimpleGCNEncoder: 2-2                            --\n",
      "│    │    └─Linear: 3-5                                 35\n",
      "│    │    └─Linear: 3-6                                 15\n",
      "│    │    └─LayerNorm: 3-7                              8\n",
      "│    │    └─ModuleList: 3-8                             142\n",
      "├─InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "forward() original\n",
      "(tensor([0.4892, 0.4431, 0.4892, 0.7548, 0.4431, 0.7548, 0.8589, 0.9135, 0.8589,\n",
      "        0.9135], grad_fn=<SigmoidBackward0>), tensor([[ 1.1051, -0.1429,  0.2325],\n",
      "        [ 1.1064, -0.1424,  0.2324],\n",
      "        [ 1.1077, -0.1419,  0.2322],\n",
      "        [ 1.0729, -0.1554,  0.2366],\n",
      "        [ 1.1183, -0.1377,  0.2309]], grad_fn=<AddmmBackward0>), tensor([[-0.2245,  0.1946, -0.7792],\n",
      "        [-0.2188,  0.1974, -0.7847],\n",
      "        [-0.2409,  0.1989, -0.7671],\n",
      "        [-0.1378,  0.2368, -0.8579],\n",
      "        [-0.3853,  0.1461, -0.6293]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.5874, 0.7469, 0.5874, 0.5951, 0.7469, 0.5951, 0.8200, 0.8850, 0.8200,\n",
      "        0.8850], grad_fn=<SigmoidBackward0>), tensor([[ 1.1051, -0.1429,  0.2325],\n",
      "        [ 1.1064, -0.1424,  0.2324],\n",
      "        [ 1.1077, -0.1419,  0.2322],\n",
      "        [ 1.0729, -0.1554,  0.2366],\n",
      "        [ 1.1183, -0.1377,  0.2309]], grad_fn=<AddmmBackward0>), tensor([[-0.2245,  0.1946, -0.7792],\n",
      "        [-0.2188,  0.1974, -0.7847],\n",
      "        [-0.2409,  0.1989, -0.7671],\n",
      "        [-0.1378,  0.2368, -0.8579],\n",
      "        [-0.3853,  0.1461, -0.6293]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.9984, 0.9905, 0.8567, 0.8027, 0.9621],\n",
      "        [0.9905, 0.9776, 0.6295, 0.7369, 0.9536],\n",
      "        [0.8567, 0.6295, 0.8641, 0.6023, 0.3651],\n",
      "        [0.8027, 0.7369, 0.6023, 0.6017, 0.5760],\n",
      "        [0.9621, 0.9536, 0.3651, 0.5760, 0.9885]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.9995, 0.9970, 0.5327, 0.0451, 0.5937],\n",
      "        [0.9970, 0.9956, 0.7386, 0.5132, 0.7936],\n",
      "        [0.5327, 0.7386, 0.9224, 0.9879, 0.8974],\n",
      "        [0.0451, 0.5132, 0.9879, 1.0000, 0.9826],\n",
      "        [0.5937, 0.7936, 0.8974, 0.9826, 0.8812]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 1.3674, -0.5300,  0.7296],\n",
      "        [ 0.9951,  0.0724, -0.0246],\n",
      "        [ 1.5197, -1.6409,  0.4494],\n",
      "        [ 1.1151, -0.7936,  1.1640],\n",
      "        [ 0.3386, -0.4498,  0.1919]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[ 1.2960,  1.5486,  0.1651],\n",
      "        [ 0.7779, -0.6192,  0.7975],\n",
      "        [ 1.3694,  0.2694,  0.6717],\n",
      "        [ 0.9495, -0.3977,  0.0527],\n",
      "        [ 2.1214, -2.0171,  0.3458]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[ 1.1051, -0.1429,  0.2325],\n",
      "        [ 1.1064, -0.1424,  0.2324],\n",
      "        [ 1.1077, -0.1419,  0.2322],\n",
      "        [ 1.0729, -0.1554,  0.2366],\n",
      "        [ 1.1183, -0.1377,  0.2309]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.2245,  0.1946, -0.7792],\n",
      "        [-0.2188,  0.1974, -0.7847],\n",
      "        [-0.2409,  0.1989, -0.7671],\n",
      "        [-0.1378,  0.2368, -0.8579],\n",
      "        [-0.3853,  0.1461, -0.6293]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[ 1.1051, -0.1429,  0.2325],\n",
      "        [ 1.1064, -0.1424,  0.2324],\n",
      "        [ 1.1077, -0.1419,  0.2322],\n",
      "        [ 1.0729, -0.1554,  0.2366],\n",
      "        [ 1.1183, -0.1377,  0.2309]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.2245,  0.1946, -0.7792],\n",
      "        [-0.2188,  0.1974, -0.7847],\n",
      "        [-0.2409,  0.1989, -0.7671],\n",
      "        [-0.1378,  0.2368, -0.8579],\n",
      "        [-0.3853,  0.1461, -0.6293]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.9910, 0.8117, 0.9910, 0.7670, 0.8117, 0.7670, 0.2704, 0.8665, 0.2704,\n",
      "        0.8665], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.6845, 0.6070, 0.6845, 0.7244, 0.6070, 0.7244, 0.5522, 0.8161, 0.5522,\n",
      "        0.8161], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.9394, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(2.2955, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.6, 0.5628571428571428)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.52, 0.5392857142857144)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.2498, -0.3727, -0.0521, -0.2652,  0.3801,  0.1810],\n",
      "        [ 0.2137,  0.2384,  0.2637, -0.0871,  0.3914,  0.2833],\n",
      "        [-0.1809, -0.3772, -0.1703,  0.1915, -0.2402, -0.0408],\n",
      "        [ 0.3684,  0.3265,  0.1959, -0.1942, -0.0219,  0.3832],\n",
      "        [-0.1271, -0.0772, -0.2850, -0.2873,  0.1291,  0.2939]])), ('_encoder_mu.lin1.bias', tensor([-0.2401,  0.1502,  0.1065,  0.2726,  0.1772])), ('_encoder_mu.lin2.weight', tensor([[-0.2694, -0.1904, -0.0744, -0.2744, -0.4160],\n",
      "        [ 0.0616, -0.0629,  0.2553, -0.0236,  0.3399],\n",
      "        [-0.2057, -0.1383,  0.4274,  0.3915,  0.3410]])), ('_encoder_mu.lin2.bias', tensor([ 0.2010,  0.3538, -0.1848])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.weight1', tensor([[ 0.2524, -0.6038, -0.1760, -0.3907,  0.4449],\n",
      "        [ 0.2633, -0.3902,  0.5580, -0.2447,  0.1539],\n",
      "        [ 0.6149,  0.1795,  0.6590,  0.2070, -0.6407],\n",
      "        [ 0.2064, -0.1601, -0.0336,  0.2629,  0.4220],\n",
      "        [-0.1579,  0.5551,  0.3993,  0.6139,  0.0934]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.weight1', tensor([[ 0.3493,  0.6807,  0.0621, -0.1697, -0.4632],\n",
      "        [-0.0646,  0.0836,  0.0610, -0.0675, -0.4373],\n",
      "        [ 0.0035,  0.7239, -0.3841, -0.3553,  0.3331],\n",
      "        [-0.2978,  0.4082, -0.3497,  0.0599,  0.4280],\n",
      "        [ 0.6083,  0.6634, -0.1176,  0.3593, -0.6336]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.weight1', tensor([[ 0.2477, -0.4069, -0.4618, -0.6398,  0.4359],\n",
      "        [-0.3292,  0.0928,  0.5982, -0.7006, -0.0015],\n",
      "        [-0.6199, -0.6762, -0.1099,  0.4213, -0.1905],\n",
      "        [-0.0011,  0.3202,  0.2096, -0.4853,  0.5635],\n",
      "        [-0.6906, -0.4477,  0.0457, -0.7714, -0.2864]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.weight1', tensor([[-0.5041, -0.2744,  0.5977, -0.7675, -0.3197],\n",
      "        [ 0.6035, -0.4735,  0.4216,  0.4802,  0.4587],\n",
      "        [ 0.6710, -0.0656, -0.0442, -0.6194,  0.1826],\n",
      "        [-0.1094,  0.2434,  0.4760, -0.4150,  0.1783],\n",
      "        [-0.3013, -0.1161,  0.1401,  0.7280,  0.1127]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.0167,  0.0495,  0.1248, -0.2766, -0.1956,  0.3693],\n",
      "        [ 0.0603, -0.0074,  0.3718, -0.0124, -0.3895,  0.2349],\n",
      "        [-0.2043, -0.1615,  0.2416, -0.0417, -0.3064, -0.0334],\n",
      "        [-0.3404, -0.2736, -0.2401,  0.3292,  0.0909,  0.2431],\n",
      "        [-0.1064,  0.0722, -0.2696, -0.0485,  0.2609,  0.1365]])), ('_encoder_logstd.lin1.bias', tensor([ 0.0137,  0.3528, -0.1882, -0.3423, -0.0968])), ('_encoder_logstd.lin2.weight', tensor([[ 0.2705,  0.2480, -0.3769,  0.1914, -0.0948],\n",
      "        [-0.3550, -0.0266,  0.4398, -0.2831, -0.1129],\n",
      "        [ 0.1424,  0.4368,  0.4210, -0.3293,  0.3807]])), ('_encoder_logstd.lin2.bias', tensor([-0.3107,  0.0132,  0.1613])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.weight1', tensor([[-0.7539, -0.7674, -0.7507,  0.7422, -0.7589],\n",
      "        [ 0.3826,  0.1120, -0.1593, -0.4645,  0.3520],\n",
      "        [ 0.4622,  0.7208, -0.6637,  0.7349, -0.3445],\n",
      "        [ 0.7059,  0.5226,  0.1628, -0.6899, -0.6686],\n",
      "        [-0.0587, -0.5328, -0.3414, -0.2333, -0.7101]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.weight1', tensor([[-0.5924,  0.0368, -0.3066,  0.4471,  0.0147],\n",
      "        [-0.2716,  0.1196, -0.3363, -0.2411,  0.6117],\n",
      "        [-0.5076, -0.1128,  0.6979, -0.1552, -0.0410],\n",
      "        [-0.4478,  0.2743,  0.3764,  0.4174,  0.2764],\n",
      "        [-0.4039, -0.6746,  0.3804, -0.1558, -0.5403]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.weight1', tensor([[ 0.3374,  0.6858, -0.6261,  0.3756,  0.0775],\n",
      "        [ 0.1190,  0.0424, -0.4888, -0.5590, -0.3909],\n",
      "        [ 0.2966, -0.1749, -0.7259,  0.2720,  0.4953],\n",
      "        [ 0.2631, -0.3700,  0.3664,  0.6617,  0.1692],\n",
      "        [-0.2506, -0.0698, -0.1939, -0.3147,  0.0274]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.weight1', tensor([[ 0.1369, -0.5117,  0.1192, -0.0420, -0.2067],\n",
      "        [-0.5073, -0.1995,  0.2576, -0.0253,  0.1967],\n",
      "        [ 0.4417, -0.4185, -0.6798, -0.5106, -0.4301],\n",
      "        [-0.7493,  0.7677, -0.6077, -0.5553, -0.2324],\n",
      "        [-0.3362,  0.6580, -0.4103, -0.6419,  0.1379]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0167,  0.0495,  0.1248, -0.2766, -0.1956,  0.3693],\n",
      "        [ 0.0603, -0.0074,  0.3718, -0.0124, -0.3895,  0.2349],\n",
      "        [-0.2043, -0.1615,  0.2416, -0.0417, -0.3064, -0.0334],\n",
      "        [-0.3404, -0.2736, -0.2401,  0.3292,  0.0909,  0.2431],\n",
      "        [-0.1064,  0.0722, -0.2696, -0.0485,  0.2609,  0.1365]])), ('lin1.bias', tensor([ 0.0137,  0.3528, -0.1882, -0.3423, -0.0968])), ('lin2.weight', tensor([[ 0.2705,  0.2480, -0.3769,  0.1914, -0.0948],\n",
      "        [-0.3550, -0.0266,  0.4398, -0.2831, -0.1129],\n",
      "        [ 0.1424,  0.4368,  0.4210, -0.3293,  0.3807]])), ('lin2.bias', tensor([-0.3107,  0.0132,  0.1613])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[-0.7539, -0.7674, -0.7507,  0.7422, -0.7589],\n",
      "        [ 0.3826,  0.1120, -0.1593, -0.4645,  0.3520],\n",
      "        [ 0.4622,  0.7208, -0.6637,  0.7349, -0.3445],\n",
      "        [ 0.7059,  0.5226,  0.1628, -0.6899, -0.6686],\n",
      "        [-0.0587, -0.5328, -0.3414, -0.2333, -0.7101]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.5924,  0.0368, -0.3066,  0.4471,  0.0147],\n",
      "        [-0.2716,  0.1196, -0.3363, -0.2411,  0.6117],\n",
      "        [-0.5076, -0.1128,  0.6979, -0.1552, -0.0410],\n",
      "        [-0.4478,  0.2743,  0.3764,  0.4174,  0.2764],\n",
      "        [-0.4039, -0.6746,  0.3804, -0.1558, -0.5403]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[ 0.3374,  0.6858, -0.6261,  0.3756,  0.0775],\n",
      "        [ 0.1190,  0.0424, -0.4888, -0.5590, -0.3909],\n",
      "        [ 0.2966, -0.1749, -0.7259,  0.2720,  0.4953],\n",
      "        [ 0.2631, -0.3700,  0.3664,  0.6617,  0.1692],\n",
      "        [-0.2506, -0.0698, -0.1939, -0.3147,  0.0274]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[ 0.1369, -0.5117,  0.1192, -0.0420, -0.2067],\n",
      "        [-0.5073, -0.1995,  0.2576, -0.0253,  0.1967],\n",
      "        [ 0.4417, -0.4185, -0.6798, -0.5106, -0.4301],\n",
      "        [-0.7493,  0.7677, -0.6077, -0.5553, -0.2324],\n",
      "        [-0.3362,  0.6580, -0.4103, -0.6419,  0.1379]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2498, -0.3727, -0.0521, -0.2652,  0.3801,  0.1810],\n",
      "        [ 0.2137,  0.2384,  0.2637, -0.0871,  0.3914,  0.2833],\n",
      "        [-0.1809, -0.3772, -0.1703,  0.1915, -0.2402, -0.0408],\n",
      "        [ 0.3684,  0.3265,  0.1959, -0.1942, -0.0219,  0.3832],\n",
      "        [-0.1271, -0.0772, -0.2850, -0.2873,  0.1291,  0.2939]])), ('lin1.bias', tensor([-0.2401,  0.1502,  0.1065,  0.2726,  0.1772])), ('lin2.weight', tensor([[-0.2694, -0.1904, -0.0744, -0.2744, -0.4160],\n",
      "        [ 0.0616, -0.0629,  0.2553, -0.0236,  0.3399],\n",
      "        [-0.2057, -0.1383,  0.4274,  0.3915,  0.3410]])), ('lin2.bias', tensor([ 0.2010,  0.3538, -0.1848])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[ 0.2524, -0.6038, -0.1760, -0.3907,  0.4449],\n",
      "        [ 0.2633, -0.3902,  0.5580, -0.2447,  0.1539],\n",
      "        [ 0.6149,  0.1795,  0.6590,  0.2070, -0.6407],\n",
      "        [ 0.2064, -0.1601, -0.0336,  0.2629,  0.4220],\n",
      "        [-0.1579,  0.5551,  0.3993,  0.6139,  0.0934]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[ 0.3493,  0.6807,  0.0621, -0.1697, -0.4632],\n",
      "        [-0.0646,  0.0836,  0.0610, -0.0675, -0.4373],\n",
      "        [ 0.0035,  0.7239, -0.3841, -0.3553,  0.3331],\n",
      "        [-0.2978,  0.4082, -0.3497,  0.0599,  0.4280],\n",
      "        [ 0.6083,  0.6634, -0.1176,  0.3593, -0.6336]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[ 0.2477, -0.4069, -0.4618, -0.6398,  0.4359],\n",
      "        [-0.3292,  0.0928,  0.5982, -0.7006, -0.0015],\n",
      "        [-0.6199, -0.6762, -0.1099,  0.4213, -0.1905],\n",
      "        [-0.0011,  0.3202,  0.2096, -0.4853,  0.5635],\n",
      "        [-0.6906, -0.4477,  0.0457, -0.7714, -0.2864]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.5041, -0.2744,  0.5977, -0.7675, -0.3197],\n",
      "        [ 0.6035, -0.4735,  0.4216,  0.4802,  0.4587],\n",
      "        [ 0.6710, -0.0656, -0.0442, -0.6194,  0.1826],\n",
      "        [-0.1094,  0.2434,  0.4760, -0.4150,  0.1783],\n",
      "        [-0.3013, -0.1161,  0.1401,  0.7280,  0.1127]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "├─VGEncoder: 1-1                                   --\n",
      "│    └─ResGCN2ConvEncoder: 2-1                     --\n",
      "│    │    └─Linear: 3-1                            35\n",
      "│    │    └─Linear: 3-2                            18\n",
      "│    │    └─LayerNorm: 3-3                         10\n",
      "│    │    └─ModuleList: 3-4                        140\n",
      "│    └─ResGCN2ConvEncoder: 2-2                     --\n",
      "│    │    └─Linear: 3-5                            35\n",
      "│    │    └─Linear: 3-6                            18\n",
      "│    │    └─LayerNorm: 3-7                         10\n",
      "│    │    └─ModuleList: 3-8                        140\n",
      "├─InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "forward() original\n",
      "(tensor([7.2987e-02, 9.1269e-02, 7.2987e-02, 9.0934e-01, 9.1269e-02, 9.0934e-01,\n",
      "        7.0027e-05, 3.0820e-01, 7.0027e-05, 3.0820e-01],\n",
      "       grad_fn=<SigmoidBackward0>), tensor([[-0.4181,  0.5963, -0.3861],\n",
      "        [-0.4156,  0.5956, -0.3845],\n",
      "        [-0.4139,  0.5922, -0.3653],\n",
      "        [-0.4249,  0.5874, -0.3285],\n",
      "        [-0.4357,  0.5807, -0.2879]], grad_fn=<AddmmBackward0>), tensor([[ 0.1591, -0.0383,  0.9937],\n",
      "        [ 0.1589, -0.0408,  1.0047],\n",
      "        [ 0.1535, -0.0467,  1.0240],\n",
      "        [ 0.1448, -0.0538,  1.0442],\n",
      "        [ 0.1452, -0.0535,  1.0436]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([6.5770e-02, 5.5847e-13, 6.5770e-02, 9.8923e-01, 5.5847e-13, 9.8923e-01,\n",
      "        6.8746e-01, 1.8870e-08, 6.8746e-01, 1.8870e-08],\n",
      "       grad_fn=<SigmoidBackward0>), tensor([[-0.4181,  0.5963, -0.3861],\n",
      "        [-0.4156,  0.5956, -0.3845],\n",
      "        [-0.4139,  0.5922, -0.3653],\n",
      "        [-0.4249,  0.5874, -0.3285],\n",
      "        [-0.4357,  0.5807, -0.2879]], grad_fn=<AddmmBackward0>), tensor([[ 0.1591, -0.0383,  0.9937],\n",
      "        [ 0.1589, -0.0408,  1.0047],\n",
      "        [ 0.1535, -0.0467,  1.0240],\n",
      "        [ 0.1448, -0.0538,  1.0442],\n",
      "        [ 0.1452, -0.0535,  1.0436]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[9.9995e-01, 9.8559e-01, 9.8915e-01, 9.9364e-01, 9.0445e-01],\n",
      "        [9.8559e-01, 9.9663e-01, 1.0654e-02, 6.6049e-01, 8.5436e-01],\n",
      "        [9.8915e-01, 1.0654e-02, 1.0000e+00, 9.9971e-01, 1.2328e-04],\n",
      "        [9.9364e-01, 6.6049e-01, 9.9971e-01, 9.9646e-01, 3.6912e-03],\n",
      "        [9.0445e-01, 8.5436e-01, 1.2328e-04, 3.6912e-03, 1.0000e+00]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[9.5483e-01, 9.9888e-01, 1.4210e-01, 8.5655e-01, 2.4287e-03],\n",
      "        [9.9888e-01, 1.0000e+00, 8.0929e-05, 9.9708e-01, 8.6378e-10],\n",
      "        [1.4210e-01, 8.0929e-05, 9.9924e-01, 2.8691e-02, 9.9999e-01],\n",
      "        [8.5655e-01, 9.9708e-01, 2.8691e-02, 9.8339e-01, 3.8162e-02],\n",
      "        [2.4287e-03, 8.6378e-10, 9.9999e-01, 3.8162e-02, 1.0000e+00]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 1.0366,  2.3403, -2.5767],\n",
      "        [ 0.1981,  0.1263, -4.6474],\n",
      "        [ 1.5600, -0.4749,  0.0581],\n",
      "        [ 0.0941,  0.6380, -3.3285],\n",
      "        [ 0.5441,  0.5760, -0.0188]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-1.2699e+00,  1.2515e+00, -1.1346e+00],\n",
      "        [-1.2089e-01,  1.5903e+00, -3.4784e+00],\n",
      "        [ 5.5585e-01, -2.7073e-01, -1.0539e+00],\n",
      "        [-1.0320e-01,  6.1034e-01,  6.1108e+00],\n",
      "        [-6.9997e-04,  1.2618e+00, -3.4400e-01]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.4181,  0.5963, -0.3861],\n",
      "        [-0.4156,  0.5956, -0.3845],\n",
      "        [-0.4139,  0.5922, -0.3653],\n",
      "        [-0.4249,  0.5874, -0.3285],\n",
      "        [-0.4357,  0.5807, -0.2879]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[ 0.1591, -0.0383,  0.9937],\n",
      "        [ 0.1589, -0.0408,  1.0047],\n",
      "        [ 0.1535, -0.0467,  1.0240],\n",
      "        [ 0.1448, -0.0538,  1.0442],\n",
      "        [ 0.1452, -0.0535,  1.0436]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.4181,  0.5963, -0.3861],\n",
      "        [-0.4156,  0.5956, -0.3845],\n",
      "        [-0.4139,  0.5922, -0.3653],\n",
      "        [-0.4249,  0.5874, -0.3285],\n",
      "        [-0.4357,  0.5807, -0.2879]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[ 0.1591, -0.0383,  0.9937],\n",
      "        [ 0.1589, -0.0408,  1.0047],\n",
      "        [ 0.1535, -0.0467,  1.0240],\n",
      "        [ 0.1448, -0.0538,  1.0442],\n",
      "        [ 0.1452, -0.0535,  1.0436]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.4458, 0.9904, 0.4458, 0.3846, 0.9904, 0.3846, 0.9987, 0.5862, 0.9987,\n",
      "        0.5862], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.2921, 0.0070, 0.2921, 0.7160, 0.0070, 0.7160, 0.9970, 0.9715, 0.9970,\n",
      "        0.9715], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.5748, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(3.7519, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.76, 0.8083333333333333)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.36000000000000004, 0.48)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gat_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, RevGATConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, RevSAGEConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, SimpleGCNEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, ResGCN2ConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate classifier and test it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevGAT encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MeanAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.5182, 0.4818]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevSAGE encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SumAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.8698, 0.1302]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "SimpleGCN encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.2437, 0.7563]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet LSTM aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): LSTMAggregation(3, 3)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.4975, 0.5025]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet softmax aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SoftmaxAggregation(learn=True)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.3205, 0.6795]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RevGAT encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gat_enc,\n",
    "    encoder_out_channels=gat_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='mean_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevSAGE encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=sage_enc,\n",
    "    encoder_out_channels=sage_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='add_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"SimpleGCN encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='max_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet LSTM aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='lstm'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet softmax aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='softmax'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test classifier serialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevGAT encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MeanAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.7825, 0.2175]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.8510, 0.1490]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevSAGE encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SumAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.3035, 0.6965]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.3684, 0.6316]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "SimpleGCN encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.6562, 0.3438]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.5182, 0.4818]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet LSTM aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): LSTMAggregation(3, 3)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.1731, 0.8269]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.1731, 0.8269]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet softmax aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SoftmaxAggregation(learn=True)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.4425, 0.5575]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.4425, 0.5575]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RevGAT encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gat_enc,\n",
    "    encoder_out_channels=gat_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='mean_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, RevGATConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevSAGE encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=sage_enc,\n",
    "    encoder_out_channels=sage_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='add_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, RevSAGEConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"SimpleGCN encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='max_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, SimpleGCNEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet LSTM aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='lstm'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet softmax aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='softmax'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8469545d",
   "language": "python",
   "display_name": "PyCharm (connectome-nn-generators)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}