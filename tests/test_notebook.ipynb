{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', 'config', 'ds', 'preprocessing', 'models', 'LICENSE', 'data', 'training', 'zinc250k.png', 'README.md', '.gitignore', 'prova.py', 'evaluation', 'tests', 'vgae_test0', '.idea']\n",
      "/home/prot_prj/PycharmProjects/protein-reconstruction\n",
      "['.git', 'config', 'ds', 'preprocessing', 'models', 'LICENSE', 'data', 'training', 'zinc250k.png', 'README.md', '.gitignore', 'prova.py', 'evaluation', 'tests', 'vgae_test0', '.idea']\n",
      "/home/prot_prj/PycharmProjects/protein-reconstruction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\".\"))\n",
    "print(os.getcwd())\n",
    "os.chdir(\"/home/prot_prj/PycharmProjects/protein-reconstruction\")\n",
    "print(os.listdir(\".\"))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torchinfo\n",
    "import torch_geometric.utils.convert as tgc\n",
    "import numpy as np\n",
    "from typing import final\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "from models.layers import GATConvBlock, SAGEConvBlock, GCN2ConvBlock, GCNConvBlock\n",
    "from models.pretraining.encoders import SimpleGCNEncoder, ResGCN2ConvEncoder, RevSAGEConvEncoder, RevGATConvEncoder, ResGCN2ConvEncoderV2\n",
    "from models.pretraining.gae import GAEv2\n",
    "from models.pretraining.vgae import VGAEv2, VGEncoder\n",
    "from models.classification.classifiers import ProtMoveNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from preprocessing.constants import PRETRAIN_CLEANED_TRAIN, PRETRAIN_CLEANED_VAL\n",
    "from preprocessing.dataset import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define graph and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {'x': [1.0, 0.0, 1.2, 1.1, 0.2, 0.1]}), (1, {'x': [0.0, 1.0, 0, 1.2, 1.1, 0.2]}), (2, {'x': [0.4, 1.0, 0.1, 0.2, 0.7, 0.3]}), (3, {'x': [1.0, 1.2, 0.9, 0.9, 0.5, 0.4]}), (4, {'x': [1.0, 1.3, 0.4, 0.3, 1.8, 0.45]})]\n",
      "[(0, 1, {'edge_weight': 1.0}), (0, 2, {'edge_weight': 1.0}), (1, 2, {'edge_weight': 2.0}), (2, 3, {'edge_weight': 1.0}), (2, 4, {'edge_weight': 1.0})]\n",
      "ciao\n"
     ]
    }
   ],
   "source": [
    "_POSITION_ATTRIBUTE: final = \"pos\"\n",
    "_X_MIN: final = 0\n",
    "_X_MAX: final = 2\n",
    "_Y_MIN: final = 0\n",
    "_Y_MAX: final = 2\n",
    "g = nx.Graph()\n",
    "g.add_node(0, x=[1., 0., 1.2, 1.1, 0.2, 0.1])\n",
    "g.add_node(1, x=[0., 1., 0, 1.2, 1.1, 0.2])\n",
    "g.add_node(2, x=[0.4, 1., 0.1, 0.2, 0.7, 0.3])\n",
    "g.add_node(3, x=[1., 1.2, 0.9, 0.9, 0.5, 0.4])\n",
    "g.add_node(4, x=[1., 1.3, 0.4, 0.3, 1.8, 0.45])\n",
    "g.add_edge(1, 0, edge_weight=1.0)\n",
    "g.add_edge(1, 2, edge_weight=2.)\n",
    "g.add_edge(2, 0, edge_weight=1.)\n",
    "g.add_edge(3, 2, edge_weight=1.)\n",
    "g.add_edge(4, 2, edge_weight=1.)\n",
    "\n",
    "print(g.nodes(data=True))\n",
    "print(g.edges(data=True))\n",
    "print(\"ciao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "#888",
          "width": 0.5
         },
         "mode": "lines",
         "x": [
          -3.3323173681284803,
          0.9245777881686816,
          null,
          -3.3323173681284803,
          -0.14507780443953738,
          null,
          0.9245777881686816,
          -0.14507780443953738,
          null,
          -0.14507780443953738,
          -2.6431292924506806,
          null,
          -0.14507780443953738,
          -1.8410399275698748,
          null
         ],
         "y": [
          -2.1998815394380435,
          -0.40277279313092723,
          null,
          -2.1998815394380435,
          4.26849554255249,
          null,
          -0.40277279313092723,
          4.26849554255249,
          null,
          4.26849554255249,
          0.9214160121200412,
          null,
          4.26849554255249,
          -1.1030431884994314,
          null
         ],
         "type": "scatter"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           2,
           2,
           4,
           1,
           1
          ],
          "colorbar": {
           "thickness": 15,
           "title": {
            "side": "right",
            "text": "Node Connections"
           },
           "xanchor": "left"
          },
          "colorscale": [
           [
            0.0,
            "rgb(255,255,217)"
           ],
           [
            0.125,
            "rgb(237,248,177)"
           ],
           [
            0.25,
            "rgb(199,233,180)"
           ],
           [
            0.375,
            "rgb(127,205,187)"
           ],
           [
            0.5,
            "rgb(65,182,196)"
           ],
           [
            0.625,
            "rgb(29,145,192)"
           ],
           [
            0.75,
            "rgb(34,94,168)"
           ],
           [
            0.875,
            "rgb(37,52,148)"
           ],
           [
            1.0,
            "rgb(8,29,88)"
           ]
          ],
          "line": {
           "width": 2
          },
          "reversescale": true,
          "showscale": true,
          "size": 10
         },
         "mode": "markers",
         "text": [
          "node 0, # of connections: 2",
          "node 1, # of connections: 2",
          "node 2, # of connections: 4",
          "node 3, # of connections: 1",
          "node 4, # of connections: 1"
         ],
         "x": [
          -3.3323173681284803,
          0.9245777881686816,
          -0.14507780443953738,
          -2.6431292924506806,
          -1.8410399275698748
         ],
         "y": [
          -2.1998815394380435,
          -0.40277279313092723,
          4.26849554255249,
          0.9214160121200412,
          -1.1030431884994314
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>",
          "x": 0.005,
          "xref": "paper",
          "y": -0.002,
          "yref": "paper"
         }
        ],
        "hovermode": "closest",
        "margin": {
         "b": 20,
         "l": 5,
         "r": 5,
         "t": 40
        },
        "showlegend": false,
        "title": {
         "font": {
          "size": 16
         },
         "text": "<br>Network graph made with Python"
        },
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"50667f29-32fb-4287-815e-e0fb9f5a9caa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"50667f29-32fb-4287-815e-e0fb9f5a9caa\")) {                    Plotly.newPlot(                        \"50667f29-32fb-4287-815e-e0fb9f5a9caa\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[-3.3323173681284803,0.9245777881686816,null,-3.3323173681284803,-0.14507780443953738,null,0.9245777881686816,-0.14507780443953738,null,-0.14507780443953738,-2.6431292924506806,null,-0.14507780443953738,-1.8410399275698748,null],\"y\":[-2.1998815394380435,-0.40277279313092723,null,-2.1998815394380435,4.26849554255249,null,-0.40277279313092723,4.26849554255249,null,4.26849554255249,0.9214160121200412,null,4.26849554255249,-1.1030431884994314,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[2,2,4,1,1],\"colorbar\":{\"thickness\":15,\"title\":{\"side\":\"right\",\"text\":\"Node Connections\"},\"xanchor\":\"left\"},\"colorscale\":[[0.0,\"rgb(255,255,217)\"],[0.125,\"rgb(237,248,177)\"],[0.25,\"rgb(199,233,180)\"],[0.375,\"rgb(127,205,187)\"],[0.5,\"rgb(65,182,196)\"],[0.625,\"rgb(29,145,192)\"],[0.75,\"rgb(34,94,168)\"],[0.875,\"rgb(37,52,148)\"],[1.0,\"rgb(8,29,88)\"]],\"line\":{\"width\":2},\"reversescale\":true,\"showscale\":true,\"size\":10},\"mode\":\"markers\",\"text\":[\"node 0, # of connections: 2\",\"node 1, # of connections: 2\",\"node 2, # of connections: 4\",\"node 3, # of connections: 1\",\"node 4, # of connections: 1\"],\"x\":[-3.3323173681284803,0.9245777881686816,-0.14507780443953738,-2.6431292924506806,-1.8410399275698748],\"y\":[-2.1998815394380435,-0.40277279313092723,4.26849554255249,0.9214160121200412,-1.1030431884994314],\"type\":\"scatter\"}],                        {\"annotations\":[{\"showarrow\":false,\"text\":\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\"x\":0.005,\"xref\":\"paper\",\"y\":-0.002,\"yref\":\"paper\"}],\"hovermode\":\"closest\",\"margin\":{\"b\":20,\"l\":5,\"r\":5,\"t\":40},\"showlegend\":false,\"title\":{\"font\":{\"size\":16},\"text\":\"<br>Network graph made with Python\"},\"xaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('50667f29-32fb-4287-815e-e0fb9f5a9caa');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(nx.get_node_attributes(g, \"pos\",)) == 0:\n",
    "    pos = {i: (random.gauss(_X_MIN, _X_MAX), random.gauss(_Y_MIN, _Y_MAX)) for i in g.nodes}\n",
    "    nx.set_node_attributes(g, pos, \"pos\")\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in g.edges():\n",
    "    x0, y0 = g.nodes[edge[0]]['pos']\n",
    "    x1, y1 = g.nodes[edge[1]]['pos']\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in g.nodes():\n",
    "    x, y = g.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(g.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append(f'node {node}, # of connections: ' + str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text\n",
    "\n",
    "# noinspection PyTypeChecker\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                layout=go.Layout(\n",
    "                    title='<br>Network graph made with Python',\n",
    "                    titlefont_size=16,\n",
    "                    showlegend=False,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=20,l=5,r=5,t=40),\n",
    "                    annotations=[ dict(\n",
    "                        text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "                        showarrow=False,\n",
    "                        xref=\"paper\", yref=\"paper\",\n",
    "                        x=0.005, y=-0.002 ) ],\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert graph in PyTorch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5, 6], edge_index=[2, 10], pos=[5, 2], edge_weight=[10])\n",
      "tensor([1., 1., 1., 2., 1., 2., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "pyg = tgc.from_networkx(g)\n",
    "print(pyg)\n",
    "print(pyg.edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate layers and test their serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=1)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=0.6931471805599453)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.5, beta=0.6931471805599453)\n",
      ")\n",
      "tensor([[ 0.3809, -0.5703, -0.1284],\n",
      "        [ 0.3843, -0.5267, -0.1488],\n",
      "        [ 0.2223, -0.6413, -0.1600],\n",
      "        [ 0.2505, -0.8689, -0.2123],\n",
      "        [ 0.0435, -0.6741, -0.2998]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.3872, -1.2415, -0.2718],\n",
      "        [-0.5002, -1.4190, -1.4073],\n",
      "        [-0.2477, -0.6669, -0.7920],\n",
      "        [-0.2740, -0.8775, -1.6071],\n",
      "        [ 0.1260, -0.3608, -0.6601]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.1447,  0.2851, -0.7833],\n",
      "        [ 0.2557,  0.3178, -0.8695],\n",
      "        [-0.0612,  0.3668, -0.6622],\n",
      "        [-0.2190,  0.4857, -0.7337],\n",
      "        [-0.2370,  0.1331, -0.5960]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.1289, -1.1502,  0.3484],\n",
      "        [ 0.4152, -0.5444,  0.1823],\n",
      "        [ 0.6613, -0.1844,  0.4888],\n",
      "        [-0.1244, -0.6513,  0.4343],\n",
      "        [ 0.7084, -0.5137,  0.3561]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.6704,  1.4964, -0.9161],\n",
      "        [ 2.9423,  2.5755, -2.0883],\n",
      "        [ 2.7208,  4.4357, -1.7193],\n",
      "        [ 0.7153,  0.5836, -0.7881],\n",
      "        [ 0.7153,  0.5836, -0.7881]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.1550,  0.1227, -0.4101],\n",
      "        [ 0.3271, -0.0153, -0.3220],\n",
      "        [ 0.4861,  0.0254, -0.5705],\n",
      "        [ 0.3530, -0.6113, -0.1497],\n",
      "        [ 0.8583,  0.0166, -0.1694]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.2260,  0.5088,  0.1261, -0.0558,  0.1064, -0.1793],\n",
      "        [-0.4641,  0.0528, -0.6426,  0.1321, -0.0592,  0.1286],\n",
      "        [-0.0572,  0.1909, -0.6596, -0.2274, -0.0121,  0.0487],\n",
      "        [ 0.3475,  0.4716, -0.4068, -0.3596, -0.1461,  0.1190],\n",
      "        [-0.0944,  0.1930, -0.9134, -0.4730,  0.3038, -0.2201]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.3033,  0.2531,  0.3438, -0.5605,  0.0622, -0.1560],\n",
      "        [-0.3011, -0.0939, -0.1112, -0.6689,  0.2876, -0.2608],\n",
      "        [-0.2534,  0.0232,  0.0209, -0.7831,  0.2876, -0.1367],\n",
      "        [-0.2147,  0.1420,  0.0383, -0.6929,  0.2341, -0.2299],\n",
      "        [-0.2867,  0.1430,  0.3143, -1.0784,  0.3077,  0.0898]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gat0 = GATConvBlock(6, 3, heads=2, edge_dim=1)\n",
    "gat1 = GATConvBlock(6, 3, heads=1, edge_dim=1, dropout=0.3, concat=True)\n",
    "\n",
    "sage0 = SAGEConvBlock(6, 3, project=True)\n",
    "sage1 = SAGEConvBlock(6, 3, project=False)\n",
    "\n",
    "gcn0 = GCNConvBlock(6, 3, normalize=False)\n",
    "gcn1 = GCNConvBlock(6, 3, normalize=True)\n",
    "\n",
    "gcn20 = GCN2ConvBlock(6, 0.6)\n",
    "gcn21 = GCN2ConvBlock(6, 0.5)\n",
    "\n",
    "print(gat0)\n",
    "print(gat1)\n",
    "print(sage0)\n",
    "print(sage1)\n",
    "print(gcn0)\n",
    "print(gcn1)\n",
    "print(gcn20)\n",
    "print(gcn21)\n",
    "\n",
    "print(gat0(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(gat1(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(sage0(pyg.x, edge_index=pyg.edge_index))\n",
    "print(sage1(pyg.x, edge_index=pyg.edge_index))\n",
    "print(gcn0(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn1(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn20(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn21(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=0.6931471805599453)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=0.6931471805599453)\n",
      ")\n",
      "tensor([[ 0.3809, -0.5703, -0.1284],\n",
      "        [ 0.3843, -0.5267, -0.1488],\n",
      "        [ 0.2223, -0.6413, -0.1600],\n",
      "        [ 0.2505, -0.8689, -0.2123],\n",
      "        [ 0.0435, -0.6741, -0.2998]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.3809, -0.5703, -0.1284],\n",
      "        [ 0.3843, -0.5267, -0.1488],\n",
      "        [ 0.2223, -0.6413, -0.1600],\n",
      "        [ 0.2505, -0.8689, -0.2123],\n",
      "        [ 0.0435, -0.6741, -0.2998]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.1447,  0.2851, -0.7833],\n",
      "        [ 0.2557,  0.3178, -0.8695],\n",
      "        [-0.0612,  0.3668, -0.6622],\n",
      "        [-0.2190,  0.4857, -0.7337],\n",
      "        [-0.2370,  0.1331, -0.5960]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.1447,  0.2851, -0.7833],\n",
      "        [ 0.2557,  0.3178, -0.8695],\n",
      "        [-0.0612,  0.3668, -0.6622],\n",
      "        [-0.2190,  0.4857, -0.7337],\n",
      "        [-0.2370,  0.1331, -0.5960]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.6704,  1.4964, -0.9161],\n",
      "        [ 2.9423,  2.5755, -2.0883],\n",
      "        [ 2.7208,  4.4357, -1.7193],\n",
      "        [ 0.7153,  0.5836, -0.7881],\n",
      "        [ 0.7153,  0.5836, -0.7881]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.6704,  1.4964, -0.9161],\n",
      "        [ 2.9423,  2.5755, -2.0883],\n",
      "        [ 2.7208,  4.4357, -1.7193],\n",
      "        [ 0.7153,  0.5836, -0.7881],\n",
      "        [ 0.7153,  0.5836, -0.7881]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.2260,  0.5088,  0.1261, -0.0558,  0.1064, -0.1793],\n",
      "        [-0.4641,  0.0528, -0.6426,  0.1321, -0.0592,  0.1286],\n",
      "        [-0.0572,  0.1909, -0.6596, -0.2274, -0.0121,  0.0487],\n",
      "        [ 0.3475,  0.4716, -0.4068, -0.3596, -0.1461,  0.1190],\n",
      "        [-0.0944,  0.1930, -0.9134, -0.4730,  0.3038, -0.2201]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.2260,  0.5088,  0.1261, -0.0558,  0.1064, -0.1793],\n",
      "        [-0.4641,  0.0528, -0.6426,  0.1321, -0.0592,  0.1286],\n",
      "        [-0.0572,  0.1909, -0.6596, -0.2274, -0.0121,  0.0487],\n",
      "        [ 0.3475,  0.4716, -0.4068, -0.3596, -0.1461,  0.1190],\n",
      "        [-0.0944,  0.1930, -0.9134, -0.4730,  0.3038, -0.2201]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "state_dict = gat0.state_dict()\n",
    "gat01 = GATConvBlock.from_constructor_params(gat0.serialize_constructor_params())\n",
    "gat01.load_state_dict(state_dict)\n",
    "\n",
    "state_dict = sage0.state_dict()\n",
    "sage01 = SAGEConvBlock.from_constructor_params(sage0.serialize_constructor_params())\n",
    "sage01.load_state_dict(state_dict)\n",
    "\n",
    "state_dict = gcn0.state_dict()\n",
    "gcn01 = GCNConvBlock.from_constructor_params(gcn0.serialize_constructor_params())\n",
    "gcn01.load_state_dict(state_dict)\n",
    "\n",
    "state_dict = gcn20.state_dict()\n",
    "gcn201 = GCN2ConvBlock.from_constructor_params(gcn20.serialize_constructor_params())\n",
    "gcn201.load_state_dict(state_dict)\n",
    "\n",
    "print(gat0)\n",
    "print(gat01)\n",
    "print(sage0)\n",
    "print(sage01)\n",
    "print(gcn0)\n",
    "print(gcn01)\n",
    "print(gcn20)\n",
    "print(gcn201)\n",
    "\n",
    "print(gat0(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(gat01(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(sage0(pyg.x, edge_index=pyg.edge_index))\n",
    "print(sage01(pyg.x, edge_index=pyg.edge_index))\n",
    "print(gcn0(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn01(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn20(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn201(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             268\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             268\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[ 0.6025,  0.4739, -0.8345],\n",
      "        [ 0.7199,  0.6000, -0.9026],\n",
      "        [ 0.6885,  0.5311, -0.8956],\n",
      "        [ 0.7057,  0.6363, -0.8787],\n",
      "        [ 0.5654,  0.2939, -0.8542]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             40\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             40\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             40\n",
      "    GroupAddRev: 2-4                                 --\n",
      "        ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[0.0427, 0.7804, 0.5054],\n",
      "        [0.0461, 0.7934, 0.5753],\n",
      "        [0.0571, 0.8309, 0.4868],\n",
      "        [0.0357, 0.7581, 0.4932],\n",
      "        [0.0245, 0.7223, 0.1883]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            15\n",
      "LayerNorm: 1-3                         8\n",
      "ModuleList: 1-4                        --\n",
      "    GCNConvBlock: 2-1                 --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCNConv: 3-2                 30\n",
      "    GCNConvBlock: 2-2                 --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCNConv: 3-4                 30\n",
      "    GCNConvBlock: 2-3                 --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCNConv: 3-6                 24\n",
      "    GCNConvBlock: 2-4                 --\n",
      "        LayerNorm: 3-7               8\n",
      "        GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[ 0.3083, -0.1587, -0.3774],\n",
      "        [ 0.3039, -0.1509, -0.3758],\n",
      "        [ 0.2859, -0.1181, -0.3688],\n",
      "        [ 0.2541, -0.0578, -0.3554],\n",
      "        [ 0.2532, -0.0563, -0.3550]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 Encoder\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[-0.9098, -0.4933,  0.7502],\n",
      "        [-0.9092, -0.4935,  0.7506],\n",
      "        [-0.9193, -0.4963,  0.7409],\n",
      "        [-0.9225, -0.4971,  0.7395],\n",
      "        [-0.9207, -0.4928,  0.7017]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 EncoderV2\n",
      "ResGCN2ConvEncoderV2(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.6931471805599453)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.4054651081081644)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.28768207245178085)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.22314355131420976)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoderV2                     --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[ 0.6958,  0.1079, -0.1163],\n",
      "        [ 0.6718,  0.0749, -0.1198],\n",
      "        [ 0.7441,  0.3909,  0.2283],\n",
      "        [ 0.7588,  0.4963,  0.3562],\n",
      "        [ 0.5927,  0.6745,  0.6513]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gat_enc = RevGATConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=3,\n",
    "    dropout=0.0,\n",
    "    version=\"v2\",\n",
    "    edge_dim=1,\n",
    "    heads=8,\n",
    "    num_groups=2,\n",
    "    concat=False,\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual GAT Encoder\")\n",
    "print(gat_enc)\n",
    "print(torchinfo.summary(gat_enc))\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "sage_enc = RevSAGEConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0,\n",
    "    project=True,\n",
    "    root_weight=True,\n",
    "    num_groups=2,\n",
    "    aggr='mean',\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "print(sage_enc)\n",
    "print(torchinfo.summary(sage_enc))\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn_enc = SimpleGCNEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    conv_dims=[5, 5, 4, 4],\n",
    "    dropout=0.0,\n",
    "    improved=True\n",
    ")\n",
    "print(\"Simple GCN Encoder\")\n",
    "print(gcn_enc)\n",
    "print(torchinfo.summary(gcn_enc))\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn2_enc = ResGCN2ConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    alpha=0.3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0\n",
    ")\n",
    "print(\"ResGCN2 Encoder\")\n",
    "print(gcn2_enc)\n",
    "print(torchinfo.summary(gcn2_enc))\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn22_enc = ResGCN2ConvEncoderV2(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    alpha=0.3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0\n",
    ")\n",
    "print(\"ResGCN2 EncoderV2\")\n",
    "print(gcn22_enc)\n",
    "print(torchinfo.summary(gcn22_enc))\n",
    "print(gcn22_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test encoders serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             268\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             268\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.6025,  0.4739, -0.8345],\n",
      "        [ 0.7199,  0.6000, -0.9026],\n",
      "        [ 0.6885,  0.5311, -0.8956],\n",
      "        [ 0.7057,  0.6363, -0.8787],\n",
      "        [ 0.5654,  0.2939, -0.8542]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.6025,  0.4739, -0.8345],\n",
      "        [ 0.7199,  0.6000, -0.9026],\n",
      "        [ 0.6885,  0.5311, -0.8956],\n",
      "        [ 0.7057,  0.6363, -0.8787],\n",
      "        [ 0.5654,  0.2939, -0.8542]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             40\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             40\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             40\n",
      "    GroupAddRev: 2-4                                 --\n",
      "        ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[0.0427, 0.7804, 0.5054],\n",
      "        [0.0461, 0.7934, 0.5753],\n",
      "        [0.0571, 0.8309, 0.4868],\n",
      "        [0.0357, 0.7581, 0.4932],\n",
      "        [0.0245, 0.7223, 0.1883]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[0.0427, 0.7804, 0.5054],\n",
      "        [0.0461, 0.7934, 0.5753],\n",
      "        [0.0571, 0.8309, 0.4868],\n",
      "        [0.0357, 0.7581, 0.4932],\n",
      "        [0.0245, 0.7223, 0.1883]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            15\n",
      "LayerNorm: 1-3                         8\n",
      "ModuleList: 1-4                        --\n",
      "    GCNConvBlock: 2-1                 --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCNConv: 3-2                 30\n",
      "    GCNConvBlock: 2-2                 --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCNConv: 3-4                 30\n",
      "    GCNConvBlock: 2-3                 --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCNConv: 3-6                 24\n",
      "    GCNConvBlock: 2-4                 --\n",
      "        LayerNorm: 3-7               8\n",
      "        GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.3083, -0.1587, -0.3774],\n",
      "        [ 0.3039, -0.1509, -0.3758],\n",
      "        [ 0.2859, -0.1181, -0.3688],\n",
      "        [ 0.2541, -0.0578, -0.3554],\n",
      "        [ 0.2532, -0.0563, -0.3550]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.3083, -0.1587, -0.3774],\n",
      "        [ 0.3039, -0.1509, -0.3758],\n",
      "        [ 0.2859, -0.1181, -0.3688],\n",
      "        [ 0.2541, -0.0578, -0.3554],\n",
      "        [ 0.2532, -0.0563, -0.3550]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-0.9141, -0.4950,  0.7485],\n",
      "        [-0.9146, -0.4954,  0.7476],\n",
      "        [-0.9193, -0.4961,  0.7392],\n",
      "        [-0.9231, -0.4971,  0.7379],\n",
      "        [-0.9235, -0.4931,  0.6890]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-0.9141, -0.4950,  0.7485],\n",
      "        [-0.9146, -0.4954,  0.7476],\n",
      "        [-0.9193, -0.4961,  0.7392],\n",
      "        [-0.9231, -0.4971,  0.7379],\n",
      "        [-0.9235, -0.4931,  0.6890]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 EncoderV2\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'theta': 1.0, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}\n",
      "ResGCN2ConvEncoderV2(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.6931471805599453)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.4054651081081644)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.28768207245178085)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.22314355131420976)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoderV2                     --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.6980,  0.1160, -0.1054],\n",
      "        [ 0.6820,  0.1028, -0.0918],\n",
      "        [ 0.7431,  0.3458,  0.1755],\n",
      "        [ 0.7588,  0.4925,  0.3520],\n",
      "        [ 0.5829,  0.6715,  0.6564]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.6980,  0.1160, -0.1054],\n",
      "        [ 0.6820,  0.1028, -0.0918],\n",
      "        [ 0.7431,  0.3458,  0.1755],\n",
      "        [ 0.7588,  0.4925,  0.3520],\n",
      "        [ 0.5829,  0.6715,  0.6564]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT Encoder\")\n",
    "constr_params = gat_enc.serialize_constructor_params()\n",
    "state_dict = gat_enc.state_dict()\n",
    "print(constr_params)\n",
    "gat_enc2 = RevGATConvEncoder.from_constructor_params(constr_params)\n",
    "gat_enc2.load_state_dict(state_dict)\n",
    "print(gat_enc2)\n",
    "print(torchinfo.summary(gat_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gat_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "constr_params = sage_enc.serialize_constructor_params()\n",
    "state_dict = sage_enc.state_dict()\n",
    "print(constr_params)\n",
    "sage_enc2 = RevSAGEConvEncoder.from_constructor_params(constr_params)\n",
    "sage_enc2.load_state_dict(state_dict)\n",
    "print(sage_enc2)\n",
    "print(torchinfo.summary(sage_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(sage_enc2(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN Encoder\")\n",
    "constr_params = gcn_enc.serialize_constructor_params()\n",
    "state_dict = gcn_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn_enc2 = SimpleGCNEncoder.from_constructor_params(constr_params)\n",
    "gcn_enc2.load_state_dict(state_dict)\n",
    "print(gcn_enc2)\n",
    "print(torchinfo.summary(gcn_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 Encoder\")\n",
    "constr_params = gcn2_enc.serialize_constructor_params()\n",
    "state_dict = gcn2_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn2_enc2 = ResGCN2ConvEncoder.from_constructor_params(constr_params)\n",
    "gcn2_enc2.load_state_dict(state_dict)\n",
    "print(gcn2_enc2)\n",
    "print(torchinfo.summary(gcn2_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn2_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 EncoderV2\")\n",
    "constr_params = gcn22_enc.serialize_constructor_params()\n",
    "state_dict = gcn22_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn22_enc2 = ResGCN2ConvEncoderV2.from_constructor_params(constr_params)\n",
    "gcn22_enc2.load_state_dict(state_dict)\n",
    "print(gcn22_enc2)\n",
    "print(torchinfo.summary(gcn22_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn22_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn22_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate and test GAEv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevGATConvEncoder: 1-1                                     --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 268\n",
      "        GroupAddRev: 3-2                                 268\n",
      "        GroupAddRev: 3-3                                 268\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.6768, 0.6653, 0.6768, 0.7002, 0.6653, 0.7002, 0.6589, 0.6786, 0.6589,\n",
      "        0.6786], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6462, 0.6768, 0.6653, 0.6412, 0.6569],\n",
      "        [0.6768, 0.7144, 0.7002, 0.6710, 0.6900],\n",
      "        [0.6653, 0.7002, 0.6889, 0.6589, 0.6786],\n",
      "        [0.6412, 0.6710, 0.6589, 0.6367, 0.6511],\n",
      "        [0.6569, 0.6900, 0.6786, 0.6511, 0.6691]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.3310,  0.6482,  0.2696],\n",
      "        [-0.3840,  0.8409,  0.2490],\n",
      "        [-0.4472,  0.7371,  0.2273],\n",
      "        [-0.2837,  0.6367,  0.2739],\n",
      "        [-0.3987,  0.6969,  0.2441]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6768, 0.6653, 0.6768, 0.7002, 0.6653, 0.7002, 0.6589, 0.6786, 0.6589,\n",
      "        0.6786], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4778, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.76, 0.7595238095238095)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevSAGEConvEncoder: 1-1                                    --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 40\n",
      "        GroupAddRev: 3-2                                 40\n",
      "        GroupAddRev: 3-3                                 40\n",
      "        GroupAddRev: 3-4                                 40\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.5468, 0.5288, 0.5468, 0.5663, 0.5288, 0.5663, 0.5256, 0.5384, 0.5256,\n",
      "        0.5384], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.5269, 0.5468, 0.5288, 0.5207, 0.5338],\n",
      "        [0.5468, 0.6705, 0.5663, 0.5541, 0.5723],\n",
      "        [0.5288, 0.5663, 0.5336, 0.5256, 0.5384],\n",
      "        [0.5207, 0.5541, 0.5256, 0.5216, 0.5277],\n",
      "        [0.5338, 0.5723, 0.5384, 0.5277, 0.5449]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.1061, -0.1570,  0.2683],\n",
      "        [ 0.7065,  0.0610,  0.4559],\n",
      "        [ 0.2086, -0.1178,  0.2778],\n",
      "        [ 0.2208, -0.1215,  0.1510],\n",
      "        [ 0.1904, -0.1200,  0.3596]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5468, 0.5288, 0.5468, 0.5663, 0.5288, 0.5663, 0.5256, 0.5384, 0.5256,\n",
      "        0.5384], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.3956, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.52, 0.5453968253968253)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "SimpleGCNEncoder: 1-1                       --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            15\n",
      "    LayerNorm: 2-3                         8\n",
      "    ModuleList: 2-4                        --\n",
      "        GCNConvBlock: 3-1                 40\n",
      "        GCNConvBlock: 3-2                 40\n",
      "        GCNConvBlock: 3-3                 34\n",
      "        GCNConvBlock: 3-4                 28\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.6562, 0.6562, 0.6562, 0.6563, 0.6562, 0.6563, 0.6557, 0.6570, 0.6557,\n",
      "        0.6570], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6560, 0.6562, 0.6562, 0.6556, 0.6568],\n",
      "        [0.6562, 0.6564, 0.6563, 0.6557, 0.6570],\n",
      "        [0.6562, 0.6563, 0.6563, 0.6557, 0.6570],\n",
      "        [0.6556, 0.6557, 0.6557, 0.6551, 0.6564],\n",
      "        [0.6568, 0.6570, 0.6570, 0.6564, 0.6577]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.5631,  0.3166, -0.4778],\n",
      "        [-0.5636,  0.3175, -0.4782],\n",
      "        [-0.5636,  0.3174, -0.4782],\n",
      "        [-0.5616,  0.3144, -0.4767],\n",
      "        [-0.5656,  0.3206, -0.4797]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6562, 0.6562, 0.6562, 0.6563, 0.6562, 0.6563, 0.6557, 0.6570, 0.6557,\n",
      "        0.6570], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4892, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.44, 0.5053968253968254)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "ResGCN2ConvEncoder: 1-1                     --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            18\n",
      "    LayerNorm: 2-3                         10\n",
      "    ModuleList: 2-4                        --\n",
      "        GCN2ConvBlock: 3-1                35\n",
      "        GCN2ConvBlock: 3-2                35\n",
      "        GCN2ConvBlock: 3-3                35\n",
      "        GCN2ConvBlock: 3-4                35\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.5778, 0.5779, 0.5778, 0.5779, 0.5779, 0.5779, 0.5779, 0.5779, 0.5779,\n",
      "        0.5779], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.5778, 0.5778, 0.5779, 0.5778, 0.5778],\n",
      "        [0.5778, 0.5779, 0.5779, 0.5778, 0.5779],\n",
      "        [0.5779, 0.5779, 0.5780, 0.5779, 0.5779],\n",
      "        [0.5778, 0.5778, 0.5779, 0.5778, 0.5778],\n",
      "        [0.5778, 0.5779, 0.5779, 0.5778, 0.5779]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.3122,  0.3491, -0.3072],\n",
      "        [-0.3162,  0.3484, -0.3047],\n",
      "        [-0.3158,  0.3460, -0.3082],\n",
      "        [-0.3092,  0.3478, -0.3115],\n",
      "        [-0.3096,  0.3447, -0.3154]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5778, 0.5779, 0.5778, 0.5779, 0.5779, 0.5779, 0.5779, 0.5779, 0.5779,\n",
      "        0.5779], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4107, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.8800000000000001, 0.8766666666666667)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test serialization for GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0346,  0.1452, -0.1357, -0.2467, -0.2633,  0.1168],\n",
      "        [ 0.3898,  0.2208,  0.3891,  0.2521,  0.4046, -0.4037],\n",
      "        [ 0.0969, -0.0171,  0.2289,  0.3636, -0.2057, -0.0205],\n",
      "        [-0.3246,  0.2733, -0.1963, -0.2073, -0.0734, -0.3725]])), ('lin1.bias', tensor([ 0.3550, -0.3670, -0.2185,  0.1859])), ('lin2.weight', tensor([[-0.0714, -0.4202, -0.2139,  0.4886],\n",
      "        [ 0.4204,  0.4997,  0.4052,  0.1737],\n",
      "        [-0.2925,  0.2611,  0.3000,  0.0612]])), ('lin2.bias', tensor([-0.1244,  0.1089,  0.1679])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[ 0.6677,  0.2422],\n",
      "         [-0.5130, -0.5829],\n",
      "         [ 0.7296,  0.7281],\n",
      "         [-0.2771,  0.4534],\n",
      "         [-0.5894, -0.6271],\n",
      "         [-0.6756, -0.2895],\n",
      "         [-0.1123,  0.4330],\n",
      "         [ 0.3803,  0.3350]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.0993, -0.2561],\n",
      "        [-0.3121,  0.2294],\n",
      "        [-0.5408, -0.2826],\n",
      "        [-0.0491,  0.4987],\n",
      "        [-0.1424,  0.1087],\n",
      "        [ 0.2431,  0.4903],\n",
      "        [-0.2676, -0.4585],\n",
      "        [-0.0410,  0.4348],\n",
      "        [-0.1792, -0.1745],\n",
      "        [-0.5321,  0.4633],\n",
      "        [ 0.4426,  0.5253],\n",
      "        [ 0.3585,  0.0327],\n",
      "        [ 0.2680, -0.2370],\n",
      "        [ 0.1849, -0.2932],\n",
      "        [ 0.3381, -0.5387],\n",
      "        [-0.5557,  0.0241]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.4523, -0.2946,  0.1158, -0.0302,  0.0730, -0.4222, -0.1886,  0.0074,\n",
      "        -0.4784,  0.6529, -0.6941, -0.4015, -0.3687, -0.0334,  0.2380,  0.0784])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.2385,  0.2119],\n",
      "        [-0.1750, -0.5330],\n",
      "        [-0.4577,  0.0722],\n",
      "        [-0.5633,  0.3626],\n",
      "        [-0.3397,  0.4409],\n",
      "        [-0.5513,  0.2589],\n",
      "        [ 0.4607, -0.1452],\n",
      "        [ 0.1914, -0.1197],\n",
      "        [ 0.4055, -0.2758],\n",
      "        [ 0.2626, -0.3209],\n",
      "        [-0.0809,  0.5285],\n",
      "        [-0.3557, -0.5248],\n",
      "        [ 0.0085, -0.2615],\n",
      "        [ 0.2660,  0.0714],\n",
      "        [ 0.0588,  0.3532],\n",
      "        [-0.0015, -0.0241]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([ 0.6809,  0.2729, -0.7050,  0.0360, -0.5808, -0.5334, -0.1961,  0.0522,\n",
      "        -0.3746, -0.6456, -0.2144,  0.0146,  0.4455, -0.5620, -0.5337, -0.6735])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.0436],\n",
      "        [-0.1721],\n",
      "        [-0.4805],\n",
      "        [-0.1865],\n",
      "        [ 0.2618],\n",
      "        [-0.4229],\n",
      "        [-0.3205],\n",
      "        [-0.2130],\n",
      "        [-0.2779],\n",
      "        [ 0.3732],\n",
      "        [ 0.1901],\n",
      "        [ 0.5069],\n",
      "        [-0.2415],\n",
      "        [-0.5843],\n",
      "        [ 0.0333],\n",
      "        [ 0.4219]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.7326,  0.1752],\n",
      "         [ 0.0420, -0.6874],\n",
      "         [-0.6378,  0.7560],\n",
      "         [-0.1549,  0.1117],\n",
      "         [-0.1255,  0.5425],\n",
      "         [-0.2471, -0.5753],\n",
      "         [-0.0970,  0.0832],\n",
      "         [ 0.1162,  0.6347]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.5679,  0.1481],\n",
      "        [ 0.0045,  0.1080],\n",
      "        [ 0.0776,  0.4734],\n",
      "        [-0.1083, -0.0771],\n",
      "        [-0.1001,  0.0045],\n",
      "        [ 0.5254, -0.4420],\n",
      "        [-0.2518, -0.0333],\n",
      "        [-0.1021,  0.5494],\n",
      "        [ 0.2767, -0.2547],\n",
      "        [ 0.3816,  0.1486],\n",
      "        [-0.2306, -0.4532],\n",
      "        [ 0.4865,  0.5653],\n",
      "        [ 0.0981, -0.0819],\n",
      "        [-0.3119,  0.4206],\n",
      "        [ 0.3757,  0.1394],\n",
      "        [ 0.1116, -0.5579]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.4335, -0.1707, -0.4018,  0.4307, -0.3506, -0.5264, -0.0786,  0.0498,\n",
      "         0.6912,  0.0338, -0.1871,  0.4150, -0.1502,  0.5737,  0.6156,  0.3435])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.3470,  0.1516],\n",
      "        [ 0.5405,  0.2778],\n",
      "        [ 0.3262,  0.2700],\n",
      "        [-0.2936,  0.3910],\n",
      "        [-0.2951,  0.1721],\n",
      "        [ 0.1825,  0.5382],\n",
      "        [ 0.5416, -0.5704],\n",
      "        [-0.0065,  0.1895],\n",
      "        [-0.3458,  0.2557],\n",
      "        [ 0.4880, -0.1696],\n",
      "        [-0.4144, -0.3773],\n",
      "        [ 0.2213, -0.2692],\n",
      "        [-0.4839,  0.0779],\n",
      "        [-0.4746, -0.0229],\n",
      "        [ 0.0388, -0.2308],\n",
      "        [ 0.2897,  0.1894]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([-0.6272,  0.3684,  0.4968,  0.0105, -0.5765, -0.5690,  0.1159,  0.1390,\n",
      "         0.5531,  0.3024, -0.0739, -0.3131, -0.6989,  0.4311,  0.4823,  0.6808])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.5113],\n",
      "        [ 0.3663],\n",
      "        [ 0.2370],\n",
      "        [-0.1254],\n",
      "        [ 0.2029],\n",
      "        [-0.0105],\n",
      "        [ 0.2512],\n",
      "        [ 0.5794],\n",
      "        [-0.4522],\n",
      "        [ 0.0767],\n",
      "        [ 0.1968],\n",
      "        [ 0.3430],\n",
      "        [-0.0189],\n",
      "        [ 0.1502],\n",
      "        [ 0.4377],\n",
      "        [ 0.5673]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[-0.0480, -0.5148],\n",
      "         [ 0.4746,  0.3292],\n",
      "         [-0.3003,  0.6867],\n",
      "         [ 0.6525, -0.0828],\n",
      "         [ 0.2253,  0.6398],\n",
      "         [ 0.4282, -0.2744],\n",
      "         [ 0.3250, -0.4597],\n",
      "         [ 0.6920,  0.5165]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.2486, -0.2346],\n",
      "        [ 0.0925,  0.4894],\n",
      "        [ 0.2501,  0.1043],\n",
      "        [-0.1094, -0.4672],\n",
      "        [ 0.0155,  0.4690],\n",
      "        [ 0.4205, -0.2814],\n",
      "        [-0.3029,  0.0834],\n",
      "        [-0.3167,  0.2733],\n",
      "        [-0.3390, -0.4627],\n",
      "        [-0.0800,  0.1845],\n",
      "        [-0.5288,  0.3789],\n",
      "        [-0.5308,  0.3867],\n",
      "        [-0.4168, -0.1618],\n",
      "        [-0.0323,  0.2795],\n",
      "        [ 0.2150, -0.3908],\n",
      "        [-0.3286,  0.0776]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.1360,  0.3971,  0.1362, -0.1756, -0.2659, -0.1126, -0.0035, -0.3108,\n",
      "         0.0221,  0.3772,  0.6792,  0.6108,  0.1209, -0.6064,  0.4130,  0.3839])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.1472, -0.5151],\n",
      "        [ 0.3277, -0.0266],\n",
      "        [-0.5351,  0.4177],\n",
      "        [-0.5437,  0.1675],\n",
      "        [-0.2686,  0.0333],\n",
      "        [ 0.1875,  0.4739],\n",
      "        [ 0.4172, -0.3905],\n",
      "        [ 0.3609, -0.0027],\n",
      "        [ 0.3289,  0.1307],\n",
      "        [ 0.0916,  0.2450],\n",
      "        [-0.3732,  0.1316],\n",
      "        [ 0.3183,  0.1045],\n",
      "        [ 0.1281,  0.5372],\n",
      "        [-0.4190,  0.2249],\n",
      "        [-0.3532,  0.0630],\n",
      "        [ 0.1436, -0.2281]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([ 0.0442,  0.0655,  0.2163, -0.0322,  0.3235, -0.4851, -0.3418, -0.4231,\n",
      "         0.0069, -0.3538,  0.4392,  0.0607,  0.0171, -0.1960, -0.0038, -0.3209])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.0241],\n",
      "        [-0.0910],\n",
      "        [-0.2656],\n",
      "        [ 0.5669],\n",
      "        [ 0.3177],\n",
      "        [-0.4797],\n",
      "        [-0.2074],\n",
      "        [ 0.0897],\n",
      "        [ 0.2306],\n",
      "        [-0.2655],\n",
      "        [-0.1841],\n",
      "        [-0.4405],\n",
      "        [-0.5658],\n",
      "        [ 0.1127],\n",
      "        [-0.1611],\n",
      "        [ 0.1951]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[ 4.7354e-01, -2.9298e-01],\n",
      "         [ 5.2522e-04, -5.8278e-03],\n",
      "         [-4.2183e-01, -5.0933e-01],\n",
      "         [ 7.3451e-01,  3.0016e-01],\n",
      "         [ 1.6412e-01, -5.7943e-01],\n",
      "         [ 7.2896e-02,  1.3789e-01],\n",
      "         [-3.8538e-01,  6.4843e-01],\n",
      "         [-2.5096e-01,  6.7083e-01]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.2446,  0.0559],\n",
      "        [ 0.4227,  0.0558],\n",
      "        [-0.5033,  0.0902],\n",
      "        [ 0.3980, -0.3831],\n",
      "        [-0.2323,  0.2452],\n",
      "        [ 0.3537,  0.0028],\n",
      "        [-0.2280, -0.5720],\n",
      "        [-0.4939, -0.1437],\n",
      "        [ 0.3004,  0.3584],\n",
      "        [ 0.0531,  0.5123],\n",
      "        [ 0.2711, -0.5024],\n",
      "        [-0.5588,  0.2256],\n",
      "        [ 0.4061, -0.5585],\n",
      "        [ 0.5129,  0.3896],\n",
      "        [ 0.1906, -0.5471],\n",
      "        [-0.0659,  0.4436]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.2434, -0.6330,  0.2775, -0.0065,  0.2135,  0.2757, -0.4266, -0.6347,\n",
      "        -0.6743, -0.6226, -0.4706, -0.0608, -0.3409, -0.2687,  0.3264, -0.5427])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-3.2187e-01, -3.8399e-01],\n",
      "        [ 4.6649e-01,  3.2864e-04],\n",
      "        [ 1.0897e-01, -9.4754e-02],\n",
      "        [ 2.3168e-01, -2.7446e-01],\n",
      "        [ 2.4068e-01,  3.0925e-01],\n",
      "        [ 2.1942e-01, -5.2281e-01],\n",
      "        [-3.5211e-01, -3.8951e-01],\n",
      "        [ 4.7949e-01, -1.5512e-01],\n",
      "        [ 7.6963e-02,  2.7519e-01],\n",
      "        [-2.5267e-01,  5.3849e-01],\n",
      "        [-1.3508e-01,  2.4869e-01],\n",
      "        [-1.9185e-01, -1.9741e-01],\n",
      "        [ 3.1022e-01,  4.5684e-01],\n",
      "        [ 1.6775e-01,  3.8240e-02],\n",
      "        [-4.2438e-01, -2.3507e-03],\n",
      "        [ 3.4209e-02,  4.4510e-01]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([-0.2605, -0.1634,  0.1112,  0.3066,  0.6435, -0.2278,  0.2043, -0.0213,\n",
      "         0.4669, -0.3582,  0.6425, -0.6997,  0.2760,  0.4959, -0.6588,  0.0707])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.2395],\n",
      "        [-0.0611],\n",
      "        [-0.4296],\n",
      "        [ 0.0082],\n",
      "        [ 0.5600],\n",
      "        [ 0.3527],\n",
      "        [ 0.3816],\n",
      "        [ 0.2796],\n",
      "        [-0.4631],\n",
      "        [ 0.0536],\n",
      "        [-0.3876],\n",
      "        [-0.5273],\n",
      "        [-0.1377],\n",
      "        [-0.3003],\n",
      "        [ 0.4833],\n",
      "        [ 0.0322]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[ 0.2551,  0.0414],\n",
      "         [-0.0427, -0.1205],\n",
      "         [-0.3388,  0.6316],\n",
      "         [-0.1587, -0.3607],\n",
      "         [-0.4928, -0.6490],\n",
      "         [ 0.6145, -0.5007],\n",
      "         [-0.2448, -0.6732],\n",
      "         [ 0.0364, -0.2424]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.2186,  0.2651],\n",
      "        [-0.4309,  0.4502],\n",
      "        [ 0.5639,  0.1997],\n",
      "        [ 0.5574, -0.5600],\n",
      "        [ 0.5627, -0.2763],\n",
      "        [-0.3150,  0.0294],\n",
      "        [-0.5724, -0.5228],\n",
      "        [-0.2088, -0.1644],\n",
      "        [-0.1928, -0.2791],\n",
      "        [-0.2383,  0.3937],\n",
      "        [-0.2622,  0.2978],\n",
      "        [ 0.2745, -0.1642],\n",
      "        [-0.5472,  0.3524],\n",
      "        [ 0.2916,  0.4302],\n",
      "        [ 0.5302,  0.4049],\n",
      "        [-0.1626,  0.5668]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.0333, -0.2567,  0.4607,  0.0487,  0.4771, -0.4127, -0.0525,  0.5643,\n",
      "        -0.2101,  0.4059, -0.1281, -0.2727,  0.3434,  0.4452,  0.0557,  0.6311])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.5205,  0.1966],\n",
      "        [-0.5359,  0.3960],\n",
      "        [-0.3546,  0.1732],\n",
      "        [-0.1045,  0.0708],\n",
      "        [ 0.1085, -0.4289],\n",
      "        [ 0.0674, -0.2229],\n",
      "        [-0.2234,  0.5682],\n",
      "        [-0.0311, -0.0752],\n",
      "        [-0.3957, -0.0197],\n",
      "        [-0.1342, -0.3090],\n",
      "        [-0.2855, -0.3744],\n",
      "        [-0.0441,  0.2284],\n",
      "        [ 0.5259,  0.2309],\n",
      "        [-0.0779,  0.3323],\n",
      "        [-0.3574, -0.2717],\n",
      "        [-0.2971, -0.0294]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([ 0.1180, -0.1731, -0.1151, -0.1910,  0.6641, -0.5083,  0.1145,  0.1371,\n",
      "         0.2802,  0.1874, -0.1922, -0.4828, -0.4848,  0.5501,  0.4218,  0.6104])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[ 0.1829],\n",
      "        [ 0.4891],\n",
      "        [-0.3984],\n",
      "        [ 0.5710],\n",
      "        [-0.4503],\n",
      "        [-0.5497],\n",
      "        [ 0.2306],\n",
      "        [ 0.5353],\n",
      "        [ 0.1077],\n",
      "        [ 0.4553],\n",
      "        [-0.1641],\n",
      "        [-0.5595],\n",
      "        [-0.1633],\n",
      "        [-0.0961],\n",
      "        [-0.0017],\n",
      "        [ 0.1100]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[-0.6240,  0.2975],\n",
      "         [ 0.6773, -0.1284],\n",
      "         [ 0.6978, -0.0667],\n",
      "         [ 0.7620, -0.1558],\n",
      "         [-0.6730, -0.6655],\n",
      "         [ 0.1401,  0.6403],\n",
      "         [-0.0401, -0.4811],\n",
      "         [ 0.5873, -0.7105]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.4502,  0.4962],\n",
      "        [-0.5615,  0.3171],\n",
      "        [ 0.0421,  0.3064],\n",
      "        [-0.2119, -0.0016],\n",
      "        [-0.2808,  0.5595],\n",
      "        [-0.3449,  0.1475],\n",
      "        [-0.0056,  0.0766],\n",
      "        [-0.2196, -0.4817],\n",
      "        [ 0.0379, -0.5402],\n",
      "        [ 0.0813, -0.2015],\n",
      "        [-0.0273,  0.1275],\n",
      "        [-0.0951,  0.0533],\n",
      "        [-0.0764, -0.4455],\n",
      "        [-0.5276, -0.2487],\n",
      "        [-0.3763, -0.2965],\n",
      "        [ 0.1439,  0.2282]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.4204, -0.2969, -0.5852,  0.2314, -0.2424,  0.3659, -0.1081,  0.0183,\n",
      "        -0.2134, -0.6137,  0.3836,  0.6575,  0.0646, -0.0553, -0.4134,  0.0072])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.3970, -0.5621],\n",
      "        [ 0.1456,  0.1780],\n",
      "        [-0.0720, -0.3228],\n",
      "        [ 0.2228,  0.3768],\n",
      "        [ 0.1694, -0.3860],\n",
      "        [ 0.4073, -0.0789],\n",
      "        [ 0.4485,  0.1521],\n",
      "        [-0.2084, -0.3655],\n",
      "        [-0.1190, -0.4153],\n",
      "        [-0.3278,  0.2384],\n",
      "        [-0.3783,  0.5721],\n",
      "        [ 0.1020, -0.0252],\n",
      "        [ 0.2826, -0.0405],\n",
      "        [-0.4181,  0.0822],\n",
      "        [-0.2556, -0.0297],\n",
      "        [-0.2648,  0.2486]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([-0.5708, -0.4893, -0.4614,  0.2376, -0.2909, -0.5010, -0.3361,  0.6934,\n",
      "         0.3148,  0.4779, -0.1611, -0.3915,  0.0984,  0.5271, -0.2921, -0.6393])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.4397],\n",
      "        [ 0.4797],\n",
      "        [-0.4534],\n",
      "        [-0.1395],\n",
      "        [-0.0515],\n",
      "        [ 0.5401],\n",
      "        [ 0.1158],\n",
      "        [ 0.4805],\n",
      "        [-0.1340],\n",
      "        [-0.3503],\n",
      "        [ 0.2087],\n",
      "        [-0.4046],\n",
      "        [-0.5459],\n",
      "        [ 0.1280],\n",
      "        [-0.4937],\n",
      "        [ 0.1292]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevGATConvEncoder: 1-1                                     --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 268\n",
      "        GroupAddRev: 3-2                                 268\n",
      "        GroupAddRev: 3-3                                 268\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.8166, 0.7506, 0.8166, 0.7368, 0.7506, 0.7368, 0.7516, 0.7491, 0.7516,\n",
      "        0.7491], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.8166, 0.7506, 0.8166, 0.7368, 0.7506, 0.7368, 0.7516, 0.7491, 0.7516,\n",
      "        0.7491], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.8330, 0.8166, 0.7506, 0.8338, 0.8309],\n",
      "        [0.8166, 0.8007, 0.7368, 0.8173, 0.8145],\n",
      "        [0.7506, 0.7368, 0.6868, 0.7516, 0.7491],\n",
      "        [0.8338, 0.8173, 0.7516, 0.8348, 0.8320],\n",
      "        [0.8309, 0.8145, 0.7491, 0.8320, 0.8291]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.8330, 0.8166, 0.7506, 0.8338, 0.8309],\n",
      "        [0.8166, 0.8007, 0.7368, 0.8173, 0.8145],\n",
      "        [0.7506, 0.7368, 0.6868, 0.7516, 0.7491],\n",
      "        [0.8338, 0.8173, 0.7516, 0.8348, 0.8320],\n",
      "        [0.8309, 0.8145, 0.7491, 0.8320, 0.8291]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.8126,  0.7694,  0.5954],\n",
      "        [-0.7238,  0.7398,  0.5651],\n",
      "        [-0.4817,  0.6634,  0.3361],\n",
      "        [-0.8387,  0.7764,  0.5604],\n",
      "        [-0.8204,  0.7690,  0.5609]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.8126,  0.7694,  0.5954],\n",
      "        [-0.7238,  0.7398,  0.5651],\n",
      "        [-0.4817,  0.6634,  0.3361],\n",
      "        [-0.8387,  0.7764,  0.5604],\n",
      "        [-0.8204,  0.7690,  0.5609]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.8166, 0.7506, 0.8166, 0.7368, 0.7506, 0.7368, 0.7516, 0.7491, 0.7516,\n",
      "        0.7491], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.8166, 0.7506, 0.8166, 0.7368, 0.7506, 0.7368, 0.7516, 0.7491, 0.7516,\n",
      "        0.7491], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.0219, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(2.0219, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.039999999999999994, 0.36103174603174604)\n",
      "AUC and precision metric test deserialized\n",
      "(0.039999999999999994, 0.36103174603174604)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.0041, -0.1318,  0.3216, -0.1281, -0.1909,  0.1141],\n",
      "        [ 0.0539,  0.1845, -0.2818,  0.1874,  0.2680,  0.1337],\n",
      "        [-0.1293,  0.0468,  0.2285, -0.2874,  0.2032,  0.1525],\n",
      "        [-0.0940,  0.0436, -0.0939, -0.0036, -0.0201,  0.1944]])), ('lin1.bias', tensor([ 0.0024,  0.3618,  0.3669, -0.1247])), ('lin2.weight', tensor([[ 0.1713,  0.1053,  0.3419, -0.2659],\n",
      "        [-0.2830,  0.3003,  0.1400, -0.0486],\n",
      "        [-0.0906, -0.4330, -0.3422, -0.0191]])), ('lin2.bias', tensor([ 0.4725, -0.4251,  0.4066])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.1504, -0.3936],\n",
      "        [ 0.2368,  0.6131]])), ('convs.0.convs.0.conv.lin.bias', tensor([0.7020, 0.1904])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[0.1284, 0.2581],\n",
      "        [0.0698, 0.1111]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.1424, -0.5258])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[0.5010, 0.1067],\n",
      "        [0.2675, 0.6180]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[ 0.1577,  0.2262],\n",
      "        [-0.0110,  0.2728]])), ('convs.0.convs.1.conv.lin.bias', tensor([-0.5609,  0.2761])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.2303, -0.4911],\n",
      "        [ 0.2354,  0.5281]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([0.6022, 0.6870])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.5968, -0.6358],\n",
      "        [ 0.3621, -0.5663]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[ 0.6597,  0.3870],\n",
      "        [-0.0135,  0.2478]])), ('convs.1.convs.0.conv.lin.bias', tensor([-0.3882, -0.1541])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.4458, -0.5230],\n",
      "        [ 0.6351, -0.4302]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.5013, -0.6344])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.4236,  0.5351],\n",
      "        [-0.1700,  0.2698]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[ 0.4438, -0.0457],\n",
      "        [ 0.4577,  0.1820]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.5977,  0.2350])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.1221, -0.2654],\n",
      "        [-0.1534, -0.5525]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([0.2495, 0.4814])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.0921, -0.0215],\n",
      "        [-0.6079,  0.6289]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[ 0.6036, -0.2969],\n",
      "        [-0.5134,  0.4346]])), ('convs.2.convs.0.conv.lin.bias', tensor([0.5926, 0.4873])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.2270,  0.4643],\n",
      "        [-0.6168, -0.1547]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.2485, -0.3807])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.1372, -0.5939],\n",
      "        [ 0.2909,  0.3306]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.5474,  0.6883],\n",
      "        [ 0.0945, -0.3007]])), ('convs.2.convs.1.conv.lin.bias', tensor([0.1735, 0.1127])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.5882, -0.6187],\n",
      "        [-0.3325,  0.4025]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.6606, -0.1893])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.6863,  0.3076],\n",
      "        [-0.4672, -0.5492]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.1386,  0.4822],\n",
      "        [-0.2536,  0.2334]])), ('convs.3.convs.0.conv.lin.bias', tensor([0.6171, 0.1488])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[0.0265, 0.4469],\n",
      "        [0.5893, 0.1375]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([-0.2552,  0.2149])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[-0.6218, -0.5195],\n",
      "        [ 0.2400,  0.4168]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-0.2647, -0.0222],\n",
      "        [-0.6996, -0.1319]])), ('convs.3.convs.1.conv.lin.bias', tensor([ 0.1504, -0.2735])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.0011, -0.2086],\n",
      "        [ 0.3923,  0.0315]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([ 0.1906, -0.5878])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[ 0.1556,  0.3079],\n",
      "        [-0.5762,  0.2056]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevSAGEConvEncoder: 1-1                                    --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 40\n",
      "        GroupAddRev: 3-2                                 40\n",
      "        GroupAddRev: 3-3                                 40\n",
      "        GroupAddRev: 3-4                                 40\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.5817, 0.5785, 0.5817, 0.5886, 0.5785, 0.5886, 0.5880, 0.5788, 0.5880,\n",
      "        0.5788], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.5817, 0.5785, 0.5817, 0.5886, 0.5785, 0.5886, 0.5880, 0.5788, 0.5880,\n",
      "        0.5788], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7115, 0.5817, 0.5785, 0.6557, 0.5775],\n",
      "        [0.5817, 0.6000, 0.5886, 0.5957, 0.5887],\n",
      "        [0.5785, 0.5886, 0.5788, 0.5880, 0.5788],\n",
      "        [0.6557, 0.5957, 0.5880, 0.6324, 0.5875],\n",
      "        [0.5775, 0.5887, 0.5788, 0.5875, 0.5788]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.7115, 0.5817, 0.5785, 0.6557, 0.5775],\n",
      "        [0.5817, 0.6000, 0.5886, 0.5957, 0.5887],\n",
      "        [0.5785, 0.5886, 0.5788, 0.5880, 0.5788],\n",
      "        [0.6557, 0.5957, 0.5880, 0.6324, 0.5875],\n",
      "        [0.5775, 0.5887, 0.5788, 0.5875, 0.5788]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.6967, -0.6171,  0.1911],\n",
      "        [ 0.5962,  0.0734, -0.2108],\n",
      "        [ 0.5364,  0.0403, -0.1682],\n",
      "        [ 0.6715, -0.2997, -0.0441],\n",
      "        [ 0.5353,  0.0448, -0.1715]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 0.6967, -0.6171,  0.1911],\n",
      "        [ 0.5962,  0.0734, -0.2108],\n",
      "        [ 0.5364,  0.0403, -0.1682],\n",
      "        [ 0.6715, -0.2997, -0.0441],\n",
      "        [ 0.5353,  0.0448, -0.1715]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.5817, 0.5785, 0.5817, 0.5886, 0.5785, 0.5886, 0.5880, 0.5788, 0.5880,\n",
      "        0.5788], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.5817, 0.5785, 0.5817, 0.5886, 0.5785, 0.5886, 0.5880, 0.5788, 0.5880,\n",
      "        0.5788], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4609, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.4609, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.27999999999999997, 0.42682539682539683)\n",
      "AUC and precision metric test deserialized\n",
      "(0.27999999999999997, 0.42682539682539683)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0244,  0.2860,  0.3264, -0.0949, -0.2837,  0.0647],\n",
      "        [-0.0428,  0.2794,  0.3078,  0.2268, -0.0672, -0.2024],\n",
      "        [ 0.1494,  0.1373, -0.0727,  0.1207, -0.3138, -0.3286],\n",
      "        [-0.3787,  0.2017,  0.3007,  0.1517, -0.3632,  0.2379],\n",
      "        [ 0.2437,  0.3138,  0.1790,  0.0819, -0.2714,  0.2976]])), ('lin1.bias', tensor([ 0.1187, -0.1457,  0.3845,  0.3106, -0.2369])), ('lin2.weight', tensor([[ 0.3516,  0.2106,  0.1233,  0.2989],\n",
      "        [-0.2226,  0.0934, -0.1127,  0.2527],\n",
      "        [-0.0320, -0.2535, -0.3043,  0.2502]])), ('lin2.bias', tensor([-0.0990,  0.0266, -0.0395])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[-0.4480,  0.3393,  0.7320,  0.6874,  0.3899],\n",
      "        [-0.3831,  0.1748,  0.7736, -0.4771, -0.5515],\n",
      "        [-0.3525,  0.0770, -0.4977,  0.2791, -0.4440],\n",
      "        [ 0.7244,  0.6723, -0.7146,  0.5387, -0.6696],\n",
      "        [-0.6915,  0.2968, -0.2616,  0.0560, -0.0140]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.5619,  0.4866,  0.2732,  0.2021, -0.3425],\n",
      "        [ 0.7137,  0.2044, -0.0457, -0.1838,  0.5620],\n",
      "        [-0.2410,  0.7113,  0.6254,  0.3399,  0.2148],\n",
      "        [ 0.3820,  0.4691,  0.6890, -0.6938, -0.5109],\n",
      "        [ 0.5260,  0.3891,  0.5678, -0.4044, -0.4313]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.1605,  0.7858,  0.4562, -0.5406, -0.4216],\n",
      "        [-0.3792, -0.5340, -0.7378, -0.3879, -0.7167],\n",
      "        [-0.0251,  0.1065, -0.5515, -0.3705,  0.7465],\n",
      "        [ 0.5482,  0.1923, -0.5523, -0.1267,  0.5022]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 0.8030, -0.7839, -0.3388,  0.8064],\n",
      "        [ 0.6347, -0.5664, -0.8566,  0.6735],\n",
      "        [ 0.2307, -0.0583,  0.8538, -0.8122],\n",
      "        [-0.0302, -0.1506,  0.0488, -0.6960]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "SimpleGCNEncoder: 1-1                       --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            15\n",
      "    LayerNorm: 2-3                         8\n",
      "    ModuleList: 2-4                        --\n",
      "        GCNConvBlock: 3-1                 40\n",
      "        GCNConvBlock: 3-2                 40\n",
      "        GCNConvBlock: 3-3                 34\n",
      "        GCNConvBlock: 3-4                 28\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5459, 0.5459, 0.5459,\n",
      "        0.5459], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5459, 0.5459, 0.5459,\n",
      "        0.5459], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.5462, 0.5461, 0.5461, 0.5459, 0.5459],\n",
      "        [0.5461, 0.5461, 0.5461, 0.5460, 0.5459],\n",
      "        [0.5461, 0.5461, 0.5460, 0.5459, 0.5459],\n",
      "        [0.5459, 0.5460, 0.5459, 0.5459, 0.5459],\n",
      "        [0.5459, 0.5459, 0.5459, 0.5459, 0.5458]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.5462, 0.5461, 0.5461, 0.5459, 0.5459],\n",
      "        [0.5461, 0.5461, 0.5461, 0.5460, 0.5459],\n",
      "        [0.5461, 0.5461, 0.5460, 0.5459, 0.5459],\n",
      "        [0.5459, 0.5460, 0.5459, 0.5459, 0.5459],\n",
      "        [0.5459, 0.5459, 0.5459, 0.5459, 0.5458]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.3358, -0.1745, -0.2048],\n",
      "        [ 0.3349, -0.1713, -0.2086],\n",
      "        [ 0.3328, -0.1645, -0.2163],\n",
      "        [ 0.3302, -0.1573, -0.2243],\n",
      "        [ 0.3287, -0.1535, -0.2286]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 0.3358, -0.1745, -0.2048],\n",
      "        [ 0.3349, -0.1713, -0.2086],\n",
      "        [ 0.3328, -0.1645, -0.2163],\n",
      "        [ 0.3302, -0.1573, -0.2243],\n",
      "        [ 0.3287, -0.1535, -0.2286]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5459, 0.5459, 0.5459,\n",
      "        0.5459], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5461, 0.5459, 0.5459, 0.5459,\n",
      "        0.5459], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.3946, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.3946, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.84, 0.8761904761904762)\n",
      "AUC and precision metric test deserialized\n",
      "(0.84, 0.8761904761904762)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.0375, -0.2570,  0.3198, -0.3337,  0.3404, -0.1353],\n",
      "        [-0.2967, -0.0307,  0.3505, -0.1274, -0.3431,  0.3086],\n",
      "        [-0.0130, -0.3939, -0.3769, -0.0849,  0.1958, -0.2614],\n",
      "        [ 0.0290,  0.2659,  0.3809, -0.3301,  0.2389,  0.0446],\n",
      "        [ 0.0938,  0.3882, -0.3828,  0.0182,  0.0219, -0.1899]])), ('lin1.bias', tensor([ 0.1391,  0.0664, -0.1943, -0.1344,  0.0945])), ('lin2.weight', tensor([[-0.3926, -0.0740, -0.2745,  0.1973, -0.0472],\n",
      "        [-0.2434,  0.1949,  0.4404, -0.1967, -0.3348],\n",
      "        [ 0.0791,  0.1928,  0.3893,  0.1837,  0.2337]])), ('lin2.bias', tensor([-0.0811, -0.1880,  0.4298])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[ 0.4758,  0.0622,  0.0205, -0.6393,  0.3768],\n",
      "        [-0.5892,  0.1956, -0.3234, -0.4106,  0.1039],\n",
      "        [-0.7507,  0.4892,  0.6061,  0.7012,  0.5829],\n",
      "        [ 0.0248,  0.6217,  0.4119, -0.2303,  0.3635],\n",
      "        [ 0.7630,  0.2430, -0.4403, -0.3948, -0.4330]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.0460,  0.7126,  0.5157, -0.2152, -0.0512],\n",
      "        [ 0.6672,  0.0674, -0.0388,  0.7269, -0.2074],\n",
      "        [ 0.6574, -0.3876, -0.5735,  0.1518, -0.4002],\n",
      "        [ 0.1565,  0.5655,  0.5768,  0.1513, -0.3402],\n",
      "        [ 0.3192,  0.3319,  0.3505, -0.5347,  0.1917]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[-0.0497,  0.0138, -0.0975,  0.1174,  0.2877],\n",
      "        [-0.0228,  0.2167,  0.1384,  0.1193,  0.6810],\n",
      "        [-0.2373,  0.4042,  0.6831,  0.4204, -0.3227],\n",
      "        [-0.3581,  0.1716,  0.2597, -0.2351, -0.1826],\n",
      "        [ 0.0477,  0.1648, -0.0727,  0.4279,  0.2411]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[ 0.1547, -0.3624, -0.6948, -0.3561,  0.7714],\n",
      "        [ 0.0628, -0.2589,  0.2055, -0.6403,  0.1820],\n",
      "        [-0.6306, -0.1620,  0.1833, -0.7283,  0.6300],\n",
      "        [-0.1702, -0.2871, -0.1985, -0.5185,  0.7530],\n",
      "        [ 0.4476,  0.4696, -0.0790, -0.0174, -0.5556]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "ResGCN2ConvEncoder: 1-1                     --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            18\n",
      "    LayerNorm: 2-3                         10\n",
      "    ModuleList: 2-4                        --\n",
      "        GCN2ConvBlock: 3-1                35\n",
      "        GCN2ConvBlock: 3-2                35\n",
      "        GCN2ConvBlock: 3-3                35\n",
      "        GCN2ConvBlock: 3-4                35\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.6684, 0.6679, 0.6684, 0.6682, 0.6679, 0.6682, 0.6679, 0.6671, 0.6679,\n",
      "        0.6671], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.6684, 0.6679, 0.6684, 0.6682, 0.6679, 0.6682, 0.6679, 0.6671, 0.6679,\n",
      "        0.6671], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6682, 0.6684, 0.6679, 0.6681, 0.6671],\n",
      "        [0.6684, 0.6687, 0.6682, 0.6683, 0.6674],\n",
      "        [0.6679, 0.6682, 0.6677, 0.6679, 0.6671],\n",
      "        [0.6681, 0.6683, 0.6679, 0.6681, 0.6672],\n",
      "        [0.6671, 0.6674, 0.6671, 0.6672, 0.6668]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.6682, 0.6684, 0.6679, 0.6681, 0.6671],\n",
      "        [0.6684, 0.6687, 0.6682, 0.6683, 0.6674],\n",
      "        [0.6679, 0.6682, 0.6677, 0.6679, 0.6671],\n",
      "        [0.6681, 0.6683, 0.6679, 0.6681, 0.6672],\n",
      "        [0.6671, 0.6674, 0.6671, 0.6672, 0.6668]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.3690,  0.0737,  0.7474],\n",
      "        [-0.3719,  0.0783,  0.7468],\n",
      "        [-0.3839,  0.0782,  0.7379],\n",
      "        [-0.3844,  0.0803,  0.7384],\n",
      "        [-0.4170,  0.0660,  0.7179]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.3690,  0.0737,  0.7474],\n",
      "        [-0.3719,  0.0783,  0.7468],\n",
      "        [-0.3839,  0.0782,  0.7379],\n",
      "        [-0.3844,  0.0803,  0.7384],\n",
      "        [-0.4170,  0.0660,  0.7179]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6684, 0.6679, 0.6684, 0.6682, 0.6679, 0.6682, 0.6679, 0.6671, 0.6679,\n",
      "        0.6671], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.6684, 0.6679, 0.6684, 0.6682, 0.6679, 0.6682, 0.6679, 0.6671, 0.6679,\n",
      "        0.6671], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.5052, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.5052, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.6, 0.6866666666666665)\n",
      "AUC and precision metric test deserialized\n",
      "(0.6, 0.6866666666666665)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevGATConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevSAGEConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, SimpleGCNEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate VGAEv2 and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevGATConvEncoder: 2-1                                     --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       804\n",
      "    RevGATConvEncoder: 2-2                                     --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       804\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.8097, 0.7806, 0.8097, 0.9074, 0.7806, 0.9074, 0.0498, 0.9910, 0.0498,\n",
      "        0.9910], grad_fn=<SigmoidBackward0>), tensor([[ 0.0303,  1.0508, -0.3838],\n",
      "        [ 0.1740,  0.1285, -0.2459],\n",
      "        [ 0.1598,  0.2780, -0.2551],\n",
      "        [ 0.1209,  0.4400, -0.2432],\n",
      "        [ 0.0238,  0.7571, -0.2593]], grad_fn=<AddmmBackward0>), tensor([[ 0.0211,  0.2329,  0.1603],\n",
      "        [ 0.1529, -0.0205, -0.0553],\n",
      "        [ 0.0534,  0.1527,  0.1027],\n",
      "        [-0.0396,  0.2091,  0.2010],\n",
      "        [ 0.0783,  0.0936,  0.0579]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9448, 0.9407, 0.2071, 0.8641, 0.5717],\n",
      "        [0.9407, 0.9838, 0.2227, 0.8442, 0.5458],\n",
      "        [0.2071, 0.2227, 0.8355, 0.0581, 0.5457],\n",
      "        [0.8641, 0.8442, 0.0581, 0.9925, 0.3944],\n",
      "        [0.5717, 0.5458, 0.5457, 0.3944, 0.5355]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-1.5777,  1.2506, -2.0409],\n",
      "        [ 1.5036,  0.7673,  0.0613],\n",
      "        [-1.3875,  2.3607, -0.8327],\n",
      "        [ 0.5884,  1.0212, -1.9403],\n",
      "        [-0.9998, -0.0622,  1.3851]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[ 0.0303,  1.0508, -0.3838],\n",
      "        [ 0.1740,  0.1285, -0.2459],\n",
      "        [ 0.1598,  0.2780, -0.2551],\n",
      "        [ 0.1209,  0.4400, -0.2432],\n",
      "        [ 0.0238,  0.7571, -0.2593]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[ 0.0211,  0.2329,  0.1603],\n",
      "        [ 0.1529, -0.0205, -0.0553],\n",
      "        [ 0.0534,  0.1527,  0.1027],\n",
      "        [-0.0396,  0.2091,  0.2010],\n",
      "        [ 0.0783,  0.0936,  0.0579]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.1769, 0.9989, 0.1769, 0.4192, 0.9989, 0.4192, 0.9612, 0.5217, 0.9612,\n",
      "        0.5217], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.9670, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.64, 0.6977777777777778)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevSAGEConvEncoder: 2-1                                    --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       160\n",
      "    RevSAGEConvEncoder: 2-2                                    --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       160\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.7008, 0.7332, 0.7008, 0.4524, 0.7332, 0.4524, 0.4753, 0.4758, 0.4753,\n",
      "        0.4758], grad_fn=<SigmoidBackward0>), tensor([[-1.9329e-01, -2.9472e-01,  1.0024e-01],\n",
      "        [-4.6928e-01, -3.6628e-01,  9.1240e-03],\n",
      "        [-2.2068e-01, -3.7293e-01,  1.3068e-01],\n",
      "        [-3.5844e-01, -2.7109e-01, -5.1503e-04],\n",
      "        [-5.5590e-01, -2.9792e-01, -8.5660e-02]], grad_fn=<AddmmBackward0>), tensor([[-0.1498, -0.4485,  0.0673],\n",
      "        [-0.1455, -0.4583,  0.0534],\n",
      "        [-0.1493, -0.4719,  0.0886],\n",
      "        [-0.1494, -0.4389,  0.0544],\n",
      "        [-0.1394, -0.4508,  0.0298]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.8729, 0.7588, 0.3663, 0.3302, 0.1851],\n",
      "        [0.7588, 0.8983, 0.2285, 0.4512, 0.3250],\n",
      "        [0.3663, 0.2285, 0.6660, 0.5164, 0.5994],\n",
      "        [0.3302, 0.4512, 0.5164, 0.5730, 0.6309],\n",
      "        [0.1851, 0.3250, 0.5994, 0.6309, 0.9169]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.7065, -0.4820,  0.5016],\n",
      "        [-1.3708, -1.7046,  1.6619],\n",
      "        [-0.6387, -0.3963,  2.2309],\n",
      "        [-0.8366, -0.1435,  1.4973],\n",
      "        [-0.1659, -0.4000,  0.3269]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-1.9329e-01, -2.9472e-01,  1.0024e-01],\n",
      "        [-4.6928e-01, -3.6628e-01,  9.1240e-03],\n",
      "        [-2.2068e-01, -3.7293e-01,  1.3068e-01],\n",
      "        [-3.5844e-01, -2.7109e-01, -5.1503e-04],\n",
      "        [-5.5590e-01, -2.9792e-01, -8.5660e-02]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.1498, -0.4485,  0.0673],\n",
      "        [-0.1455, -0.4583,  0.0534],\n",
      "        [-0.1493, -0.4719,  0.0886],\n",
      "        [-0.1494, -0.4389,  0.0544],\n",
      "        [-0.1394, -0.4508,  0.0298]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6652, 0.7024, 0.6652, 0.9948, 0.7024, 0.9948, 0.9808, 0.7298, 0.9808,\n",
      "        0.7298], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.8783, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.76, 0.7961904761904761)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "VGEncoder: 1-1                                        --\n",
      "    SimpleGCNEncoder: 2-1                            --\n",
      "        Linear: 3-1                                 35\n",
      "        Linear: 3-2                                 15\n",
      "        LayerNorm: 3-3                              8\n",
      "        ModuleList: 3-4                             142\n",
      "    SimpleGCNEncoder: 2-2                            --\n",
      "        Linear: 3-5                                 35\n",
      "        Linear: 3-6                                 15\n",
      "        LayerNorm: 3-7                              8\n",
      "        ModuleList: 3-8                             142\n",
      "InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.4789, 0.5117, 0.4789, 0.6059, 0.5117, 0.6059, 0.5626, 0.4158, 0.5626,\n",
      "        0.4158], grad_fn=<SigmoidBackward0>), tensor([[-0.0285,  0.0144,  0.4313],\n",
      "        [-0.0283,  0.0143,  0.4313],\n",
      "        [-0.0276,  0.0136,  0.4315],\n",
      "        [-0.0290,  0.0148,  0.4312],\n",
      "        [-0.0240,  0.0108,  0.4321]], grad_fn=<AddmmBackward0>), tensor([[-6.8051e-01, -4.5876e-01, -1.3972e-02],\n",
      "        [-6.8001e-01, -4.5921e-01, -1.1854e-02],\n",
      "        [-6.7844e-01, -4.6071e-01, -5.4105e-03],\n",
      "        [-6.7445e-01, -4.6498e-01,  9.2891e-03],\n",
      "        [-6.7707e-01, -4.6205e-01, -2.8016e-04]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.8437, 0.6209, 0.3109, 0.8752, 0.7263],\n",
      "        [0.6209, 0.7024, 0.3150, 0.8073, 0.5934],\n",
      "        [0.3109, 0.3150, 0.7414, 0.1638, 0.4792],\n",
      "        [0.8752, 0.8073, 0.1638, 0.9645, 0.7590],\n",
      "        [0.7263, 0.5934, 0.4792, 0.7590, 0.7921]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.0993, -1.4441, -0.7306],\n",
      "        [ 0.1362,  0.5263,  2.6677],\n",
      "        [-0.2929, -0.9751,  0.3916],\n",
      "        [ 0.4027, -0.4233,  0.3472],\n",
      "        [-0.2780,  0.5325, -1.7318]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.0285,  0.0144,  0.4313],\n",
      "        [-0.0283,  0.0143,  0.4313],\n",
      "        [-0.0276,  0.0136,  0.4315],\n",
      "        [-0.0290,  0.0148,  0.4312],\n",
      "        [-0.0240,  0.0108,  0.4321]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-6.8051e-01, -4.5876e-01, -1.3972e-02],\n",
      "        [-6.8001e-01, -4.5921e-01, -1.1854e-02],\n",
      "        [-6.7844e-01, -4.6071e-01, -5.4105e-03],\n",
      "        [-6.7445e-01, -4.6498e-01,  9.2891e-03],\n",
      "        [-6.7707e-01, -4.6205e-01, -2.8016e-04]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.0632, 0.7490, 0.0632, 0.6204, 0.7490, 0.6204, 0.6061, 0.2468, 0.6061,\n",
      "        0.2468], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.7558, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.5599999999999999, 0.6644444444444444)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "VGEncoder: 1-1                                   --\n",
      "    ResGCN2ConvEncoder: 2-1                     --\n",
      "        Linear: 3-1                            35\n",
      "        Linear: 3-2                            18\n",
      "        LayerNorm: 3-3                         10\n",
      "        ModuleList: 3-4                        140\n",
      "    ResGCN2ConvEncoder: 2-2                     --\n",
      "        Linear: 3-5                            35\n",
      "        Linear: 3-6                            18\n",
      "        LayerNorm: 3-7                         10\n",
      "        ModuleList: 3-8                        140\n",
      "InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.5662, 0.4018, 0.5662, 0.7563, 0.4018, 0.7563, 0.5192, 0.4722, 0.5192,\n",
      "        0.4722], grad_fn=<SigmoidBackward0>), tensor([[-0.2587,  0.1117,  0.0678],\n",
      "        [-0.2609,  0.1134,  0.0673],\n",
      "        [-0.2666,  0.1184,  0.0659],\n",
      "        [-0.2724,  0.1238,  0.0646],\n",
      "        [-0.2729,  0.1233,  0.0644]], grad_fn=<AddmmBackward0>), tensor([[ 0.2048, -0.1418,  0.2209],\n",
      "        [ 0.2056, -0.1376,  0.2191],\n",
      "        [ 0.2141, -0.1351,  0.2154],\n",
      "        [ 0.2212, -0.1122,  0.2050],\n",
      "        [ 0.2136, -0.1276,  0.2132]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9992, 0.9093, 0.0374, 0.1643, 0.7362],\n",
      "        [0.9093, 0.9214, 0.6483, 0.1745, 0.8472],\n",
      "        [0.0374, 0.6483, 0.9651, 0.4527, 0.4237],\n",
      "        [0.1643, 0.1745, 0.4527, 0.7321, 0.2002],\n",
      "        [0.7362, 0.8472, 0.4237, 0.2002, 0.9992]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 1.0820, -0.0243,  0.3236],\n",
      "        [-0.9675, -0.8333, -0.1155],\n",
      "        [-1.8121,  1.1378, -0.0112],\n",
      "        [ 0.2630,  1.2573, -0.2151],\n",
      "        [-0.3713,  0.8283,  0.3901]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.2587,  0.1117,  0.0678],\n",
      "        [-0.2609,  0.1134,  0.0673],\n",
      "        [-0.2666,  0.1184,  0.0659],\n",
      "        [-0.2724,  0.1238,  0.0646],\n",
      "        [-0.2729,  0.1233,  0.0644]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[ 0.2048, -0.1418,  0.2209],\n",
      "        [ 0.2056, -0.1376,  0.2191],\n",
      "        [ 0.2141, -0.1351,  0.2154],\n",
      "        [ 0.2212, -0.1122,  0.2050],\n",
      "        [ 0.2136, -0.1276,  0.2132]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.2566, 0.1201, 0.2566, 0.6913, 0.1201, 0.6913, 0.7224, 0.8335, 0.7224,\n",
      "        0.8335], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.5367, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.6000000000000001, 0.75)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gat_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test VGAE serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.norm.weight', tensor([1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0.])), ('_encoder_mu.conv.att', tensor([[[ 0.3579,  0.9866,  1.0575],\n",
      "         [ 0.2570, -0.8998, -1.0497]]])), ('_encoder_mu.conv.bias', tensor([0., 0., 0.])), ('_encoder_mu.conv.lin_l.weight', tensor([[ 0.0486, -0.1225, -0.5542],\n",
      "        [-0.4130,  0.7974, -0.0612],\n",
      "        [ 0.0086, -0.7460,  0.3276],\n",
      "        [ 0.0209, -0.6054, -0.1583],\n",
      "        [ 0.5776, -0.3417, -0.5212],\n",
      "        [-0.6380, -0.6325, -0.3136]])), ('_encoder_mu.conv.lin_l.bias', tensor([-0.0443, -0.1616,  0.3953,  0.4634, -0.4250,  0.1949])), ('_encoder_mu.conv.lin_r.weight', tensor([[-0.6274, -0.3435,  0.5300],\n",
      "        [-0.5172,  0.1107, -0.3396],\n",
      "        [ 0.4242,  0.6773,  0.0554],\n",
      "        [ 0.0848,  0.1916, -0.0869],\n",
      "        [ 0.8154, -0.2181,  0.1336],\n",
      "        [ 0.4835,  0.7259, -0.1814]])), ('_encoder_mu.conv.lin_r.bias', tensor([-0.5432,  0.5412,  0.3144,  0.3737, -0.2872, -0.2192])), ('_encoder_mu.conv.lin_edge.weight', tensor([[-0.9175],\n",
      "        [ 0.6308],\n",
      "        [ 0.2859],\n",
      "        [ 0.4841],\n",
      "        [ 0.4491],\n",
      "        [ 0.7673]])), ('_shared_encoder.lin1.weight', tensor([[-0.1229,  0.0242, -0.0708,  0.2928,  0.3686,  0.3391],\n",
      "        [ 0.3730, -0.2483,  0.2430, -0.1645, -0.3713,  0.0022],\n",
      "        [-0.2297,  0.1254,  0.3649,  0.2770, -0.1025,  0.0325],\n",
      "        [ 0.2206, -0.0203,  0.3517,  0.3367,  0.3543, -0.0250]])), ('_shared_encoder.lin1.bias', tensor([-0.2097,  0.3288, -0.2051,  0.3535])), ('_shared_encoder.lin2.weight', tensor([[-0.3879,  0.0286,  0.2166, -0.2984],\n",
      "        [ 0.3214, -0.0961,  0.1568, -0.1290],\n",
      "        [ 0.4660, -0.4091,  0.1612,  0.4720]])), ('_shared_encoder.lin2.bias', tensor([ 0.2505, -0.0449,  0.1876])), ('_shared_encoder.norm.weight', tensor([1., 1., 1., 1.])), ('_shared_encoder.norm.bias', tensor([0., 0., 0., 0.])), ('_shared_encoder.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.0.conv.att', tensor([[[-0.0526, -0.4608],\n",
      "         [ 0.5524,  0.2415],\n",
      "         [ 0.7230,  0.1697],\n",
      "         [ 0.6663,  0.0295],\n",
      "         [ 0.0182, -0.4623],\n",
      "         [-0.4694,  0.4187],\n",
      "         [-0.2698, -0.3603],\n",
      "         [-0.6316, -0.0326]]])), ('_shared_encoder.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.0209,  0.1445],\n",
      "        [-0.5222,  0.1348],\n",
      "        [-0.0740, -0.0641],\n",
      "        [ 0.4767,  0.4742],\n",
      "        [ 0.1503, -0.3387],\n",
      "        [-0.4849, -0.1534],\n",
      "        [-0.1195,  0.2328],\n",
      "        [-0.0732,  0.3560],\n",
      "        [ 0.4346, -0.4611],\n",
      "        [-0.5171, -0.4179],\n",
      "        [ 0.4488,  0.2638],\n",
      "        [-0.2887, -0.4350],\n",
      "        [ 0.1925,  0.5273],\n",
      "        [-0.1269,  0.2222],\n",
      "        [-0.0041, -0.3342],\n",
      "        [ 0.3436, -0.0606]])), ('_shared_encoder.convs.0.convs.0.conv.lin_l.bias', tensor([-0.0382,  0.0854, -0.0739,  0.5126,  0.0892, -0.5764,  0.0512,  0.2909,\n",
      "         0.4843, -0.5980, -0.5882, -0.3674,  0.2752,  0.4249,  0.6864, -0.5494])), ('_shared_encoder.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.4788,  0.4287],\n",
      "        [ 0.4935, -0.3287],\n",
      "        [-0.4627, -0.2848],\n",
      "        [ 0.0965, -0.1909],\n",
      "        [-0.4282,  0.2776],\n",
      "        [ 0.0808, -0.0360],\n",
      "        [ 0.5416, -0.5058],\n",
      "        [ 0.3431, -0.4738],\n",
      "        [ 0.5517, -0.2892],\n",
      "        [ 0.0381,  0.3748],\n",
      "        [ 0.3325,  0.0959],\n",
      "        [-0.0983,  0.0345],\n",
      "        [-0.2522,  0.2236],\n",
      "        [-0.5499, -0.5416],\n",
      "        [-0.3815,  0.3316],\n",
      "        [ 0.2626, -0.2268]])), ('_shared_encoder.convs.0.convs.0.conv.lin_r.bias', tensor([-0.1518, -0.6478, -0.4472, -0.2162, -0.1583,  0.2978,  0.4363, -0.6890,\n",
      "         0.0060,  0.4150,  0.6654,  0.1922,  0.1290, -0.6095,  0.0564, -0.3167])), ('_shared_encoder.convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.5185],\n",
      "        [ 0.4079],\n",
      "        [-0.2321],\n",
      "        [-0.2607],\n",
      "        [ 0.4309],\n",
      "        [ 0.5479],\n",
      "        [ 0.5536],\n",
      "        [-0.4012],\n",
      "        [ 0.4227],\n",
      "        [ 0.1418],\n",
      "        [ 0.3216],\n",
      "        [ 0.3654],\n",
      "        [-0.2669],\n",
      "        [-0.0417],\n",
      "        [-0.1841],\n",
      "        [ 0.3768]])), ('_shared_encoder.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.1.conv.att', tensor([[[ 0.4715, -0.0486],\n",
      "         [ 0.6121, -0.0638],\n",
      "         [-0.3718, -0.0557],\n",
      "         [ 0.2476, -0.3024],\n",
      "         [ 0.2086, -0.0973],\n",
      "         [-0.1421, -0.0321],\n",
      "         [ 0.0734, -0.5617],\n",
      "         [-0.7044,  0.2275]]])), ('_shared_encoder.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.1888, -0.0318],\n",
      "        [-0.4393,  0.0888],\n",
      "        [-0.5227, -0.5524],\n",
      "        [ 0.3518, -0.4875],\n",
      "        [ 0.5570,  0.2136],\n",
      "        [ 0.2519,  0.1257],\n",
      "        [ 0.4523,  0.4612],\n",
      "        [ 0.0998, -0.1023],\n",
      "        [ 0.4011,  0.2632],\n",
      "        [-0.3969, -0.4105],\n",
      "        [ 0.5685,  0.3244],\n",
      "        [ 0.4869,  0.2043],\n",
      "        [-0.3940, -0.4304],\n",
      "        [ 0.3024,  0.3014],\n",
      "        [-0.2437,  0.0784],\n",
      "        [ 0.4816,  0.1390]])), ('_shared_encoder.convs.0.convs.1.conv.lin_l.bias', tensor([ 0.7048, -0.6246, -0.3242,  0.4475, -0.6846, -0.5147,  0.4907, -0.1339,\n",
      "        -0.3347, -0.3032, -0.3169, -0.1835,  0.4131,  0.6452, -0.2877, -0.0150])), ('_shared_encoder.convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.2051, -0.0181],\n",
      "        [-0.3977,  0.2966],\n",
      "        [ 0.5374, -0.1855],\n",
      "        [-0.0859, -0.1999],\n",
      "        [-0.0276,  0.4561],\n",
      "        [ 0.3241,  0.5729],\n",
      "        [ 0.2533, -0.0015],\n",
      "        [-0.3080, -0.5559],\n",
      "        [-0.1357,  0.2570],\n",
      "        [-0.0193, -0.1268],\n",
      "        [ 0.0302, -0.1936],\n",
      "        [ 0.0597, -0.3874],\n",
      "        [ 0.2075, -0.2172],\n",
      "        [-0.5719, -0.5707],\n",
      "        [ 0.4549,  0.1512],\n",
      "        [-0.0911, -0.3558]])), ('_shared_encoder.convs.0.convs.1.conv.lin_r.bias', tensor([ 0.4422, -0.3488, -0.5428,  0.5915, -0.4314, -0.1861,  0.1925,  0.3985,\n",
      "         0.0519,  0.0832,  0.5050, -0.2167, -0.5534, -0.2006,  0.1760,  0.2697])), ('_shared_encoder.convs.0.convs.1.conv.lin_edge.weight', tensor([[ 0.1062],\n",
      "        [ 0.5117],\n",
      "        [ 0.0416],\n",
      "        [ 0.1086],\n",
      "        [-0.4398],\n",
      "        [-0.2659],\n",
      "        [ 0.0054],\n",
      "        [ 0.4455],\n",
      "        [-0.5545],\n",
      "        [-0.3959],\n",
      "        [ 0.3456],\n",
      "        [ 0.1898],\n",
      "        [ 0.0614],\n",
      "        [ 0.5044],\n",
      "        [-0.4056],\n",
      "        [-0.0173]])), ('_shared_encoder.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.0.conv.att', tensor([[[ 0.0146,  0.3986],\n",
      "         [ 0.1089,  0.6757],\n",
      "         [-0.0534,  0.4909],\n",
      "         [-0.7615, -0.1841],\n",
      "         [ 0.5854, -0.2991],\n",
      "         [-0.3876, -0.5855],\n",
      "         [-0.6520, -0.5870],\n",
      "         [ 0.5205, -0.2480]]])), ('_shared_encoder.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.2541,  0.3424],\n",
      "        [ 0.1895, -0.2790],\n",
      "        [-0.4701,  0.3681],\n",
      "        [ 0.2399, -0.1382],\n",
      "        [ 0.1796,  0.1940],\n",
      "        [ 0.2489,  0.1348],\n",
      "        [-0.2402,  0.0423],\n",
      "        [ 0.2965, -0.4857],\n",
      "        [ 0.3139,  0.0705],\n",
      "        [-0.1340,  0.4308],\n",
      "        [-0.4390,  0.5097],\n",
      "        [-0.3886, -0.5540],\n",
      "        [ 0.0389, -0.5455],\n",
      "        [ 0.2550,  0.2645],\n",
      "        [ 0.0506,  0.1864],\n",
      "        [ 0.5145, -0.1426]])), ('_shared_encoder.convs.1.convs.0.conv.lin_l.bias', tensor([ 0.4648, -0.2004,  0.5986,  0.4650, -0.2601, -0.6240,  0.0591,  0.4232,\n",
      "        -0.2570, -0.1897, -0.2637,  0.6381, -0.1111,  0.3423, -0.4815, -0.0286])), ('_shared_encoder.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.5066, -0.2770],\n",
      "        [ 0.4640, -0.3423],\n",
      "        [-0.1188, -0.3950],\n",
      "        [-0.2430,  0.0223],\n",
      "        [-0.5438, -0.4719],\n",
      "        [-0.0462,  0.4655],\n",
      "        [-0.0220,  0.4580],\n",
      "        [-0.4272,  0.0439],\n",
      "        [-0.2107,  0.1784],\n",
      "        [-0.0776, -0.3079],\n",
      "        [ 0.5083, -0.1315],\n",
      "        [-0.4783, -0.1462],\n",
      "        [ 0.1426,  0.3090],\n",
      "        [ 0.2877, -0.1598],\n",
      "        [ 0.0032, -0.4866],\n",
      "        [ 0.3665,  0.1784]])), ('_shared_encoder.convs.1.convs.0.conv.lin_r.bias', tensor([ 0.4743, -0.4914,  0.4852, -0.3146,  0.4249, -0.4677, -0.1213, -0.6146,\n",
      "         0.3038, -0.1509,  0.3335,  0.5000, -0.2478, -0.0360, -0.5166, -0.6002])), ('_shared_encoder.convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.0034],\n",
      "        [-0.2423],\n",
      "        [ 0.3647],\n",
      "        [ 0.4648],\n",
      "        [ 0.3310],\n",
      "        [-0.0105],\n",
      "        [ 0.5379],\n",
      "        [-0.3703],\n",
      "        [-0.2975],\n",
      "        [-0.5626],\n",
      "        [ 0.0515],\n",
      "        [-0.3218],\n",
      "        [-0.4455],\n",
      "        [-0.5665],\n",
      "        [ 0.0976],\n",
      "        [-0.1756]])), ('_shared_encoder.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.1.conv.att', tensor([[[ 0.6018, -0.4637],\n",
      "         [ 0.4091, -0.6711],\n",
      "         [-0.6989, -0.0598],\n",
      "         [ 0.2608, -0.4156],\n",
      "         [ 0.6517, -0.1296],\n",
      "         [-0.6321,  0.5264],\n",
      "         [ 0.4967,  0.5001],\n",
      "         [ 0.1707, -0.1403]]])), ('_shared_encoder.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.1.conv.lin_l.weight', tensor([[-0.4070,  0.5211],\n",
      "        [-0.1923, -0.2264],\n",
      "        [ 0.2889,  0.5062],\n",
      "        [-0.1966, -0.0111],\n",
      "        [-0.0271,  0.4266],\n",
      "        [ 0.2852,  0.4506],\n",
      "        [ 0.5569,  0.5448],\n",
      "        [ 0.0936,  0.2283],\n",
      "        [ 0.0803, -0.0240],\n",
      "        [ 0.1467, -0.2355],\n",
      "        [ 0.3641, -0.0937],\n",
      "        [ 0.5133,  0.0185],\n",
      "        [-0.5187,  0.2234],\n",
      "        [-0.5555, -0.3425],\n",
      "        [ 0.2227, -0.0492],\n",
      "        [-0.3522, -0.0956]])), ('_shared_encoder.convs.1.convs.1.conv.lin_l.bias', tensor([ 0.0329, -0.6274,  0.1581,  0.1442,  0.4750, -0.3952, -0.3723,  0.6143,\n",
      "        -0.0550, -0.1552, -0.1999,  0.3741,  0.1639,  0.4993,  0.0609, -0.1035])), ('_shared_encoder.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.2325, -0.3326],\n",
      "        [-0.2582, -0.2858],\n",
      "        [-0.0008, -0.3446],\n",
      "        [-0.4082, -0.5291],\n",
      "        [ 0.5165, -0.3226],\n",
      "        [-0.3276, -0.4814],\n",
      "        [ 0.2472,  0.2163],\n",
      "        [-0.2680, -0.2739],\n",
      "        [ 0.2282,  0.1764],\n",
      "        [-0.1752, -0.1188],\n",
      "        [ 0.2167,  0.2120],\n",
      "        [ 0.0710,  0.4955],\n",
      "        [ 0.0575,  0.2758],\n",
      "        [-0.0217, -0.4032],\n",
      "        [ 0.1448,  0.2744],\n",
      "        [ 0.0708,  0.2500]])), ('_shared_encoder.convs.1.convs.1.conv.lin_r.bias', tensor([ 0.3583, -0.0219,  0.4028, -0.3647, -0.1951,  0.7016, -0.4678,  0.2148,\n",
      "        -0.5423,  0.4102, -0.6334, -0.2064, -0.2386,  0.4787, -0.2437,  0.1338])), ('_shared_encoder.convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.3372],\n",
      "        [-0.1730],\n",
      "        [-0.0089],\n",
      "        [-0.2338],\n",
      "        [ 0.0547],\n",
      "        [ 0.0031],\n",
      "        [ 0.1237],\n",
      "        [ 0.3604],\n",
      "        [-0.0830],\n",
      "        [-0.0011],\n",
      "        [ 0.5018],\n",
      "        [ 0.1183],\n",
      "        [-0.3313],\n",
      "        [-0.4916],\n",
      "        [ 0.0696],\n",
      "        [-0.3054]])), ('_shared_encoder.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.0.conv.att', tensor([[[ 7.5174e-01,  5.6328e-01],\n",
      "         [-9.2673e-02,  7.6959e-01],\n",
      "         [-2.3509e-01,  4.3409e-04],\n",
      "         [ 5.4807e-01,  6.1053e-02],\n",
      "         [-6.9554e-01, -6.9958e-01],\n",
      "         [-5.2413e-01,  6.8906e-01],\n",
      "         [-2.9831e-01, -7.5061e-01],\n",
      "         [ 4.7598e-01,  6.6002e-01]]])), ('_shared_encoder.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.0.conv.lin_l.weight', tensor([[-0.2634,  0.0183],\n",
      "        [-0.2517, -0.4038],\n",
      "        [ 0.4726, -0.3440],\n",
      "        [ 0.0241, -0.0225],\n",
      "        [ 0.3139, -0.0332],\n",
      "        [-0.0868, -0.5364],\n",
      "        [-0.2328,  0.4025],\n",
      "        [-0.1124, -0.3376],\n",
      "        [ 0.1873,  0.0503],\n",
      "        [ 0.0768, -0.2066],\n",
      "        [ 0.0264, -0.4476],\n",
      "        [ 0.3595,  0.5647],\n",
      "        [-0.1378, -0.3666],\n",
      "        [-0.2139, -0.4455],\n",
      "        [-0.0763, -0.0022],\n",
      "        [ 0.2431, -0.0567]])), ('_shared_encoder.convs.2.convs.0.conv.lin_l.bias', tensor([-0.5053,  0.0353, -0.0974, -0.2851, -0.5872,  0.0978,  0.3604,  0.2450,\n",
      "        -0.4851, -0.5988, -0.2858, -0.4163,  0.3486,  0.5694,  0.1144,  0.0015])), ('_shared_encoder.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2863, -0.3670],\n",
      "        [ 0.2378, -0.2436],\n",
      "        [-0.3468,  0.3459],\n",
      "        [-0.5729,  0.2097],\n",
      "        [ 0.4999, -0.2180],\n",
      "        [ 0.2402, -0.2845],\n",
      "        [ 0.3957,  0.0396],\n",
      "        [-0.0395, -0.4436],\n",
      "        [-0.2586, -0.1648],\n",
      "        [ 0.4863, -0.3888],\n",
      "        [-0.4384,  0.5455],\n",
      "        [-0.0399,  0.3192],\n",
      "        [-0.5127, -0.0904],\n",
      "        [-0.0766,  0.4561],\n",
      "        [ 0.3857,  0.1796],\n",
      "        [ 0.0303, -0.0652]])), ('_shared_encoder.convs.2.convs.0.conv.lin_r.bias', tensor([-0.3217,  0.6151, -0.2282, -0.0952, -0.6683, -0.2182,  0.1551,  0.4919,\n",
      "        -0.6905,  0.4138, -0.1967,  0.6267, -0.1228,  0.2655, -0.4204, -0.2421])), ('_shared_encoder.convs.2.convs.0.conv.lin_edge.weight', tensor([[ 0.1125],\n",
      "        [-0.3755],\n",
      "        [ 0.0854],\n",
      "        [ 0.3299],\n",
      "        [ 0.0143],\n",
      "        [-0.5822],\n",
      "        [-0.2777],\n",
      "        [-0.3653],\n",
      "        [ 0.0234],\n",
      "        [-0.1771],\n",
      "        [-0.0209],\n",
      "        [ 0.3957],\n",
      "        [ 0.0312],\n",
      "        [ 0.3794],\n",
      "        [ 0.5769],\n",
      "        [-0.5729]])), ('_shared_encoder.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.1.conv.att', tensor([[[ 0.1596,  0.0882],\n",
      "         [ 0.0160, -0.5636],\n",
      "         [-0.5672,  0.5332],\n",
      "         [-0.2321,  0.3065],\n",
      "         [ 0.5208, -0.1428],\n",
      "         [-0.1829,  0.6031],\n",
      "         [-0.4831, -0.1096],\n",
      "         [-0.1750,  0.0589]]])), ('_shared_encoder.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.5548, -0.3558],\n",
      "        [-0.1687,  0.0871],\n",
      "        [ 0.0259, -0.3623],\n",
      "        [ 0.1342, -0.4634],\n",
      "        [ 0.0970, -0.4773],\n",
      "        [ 0.2677, -0.3384],\n",
      "        [ 0.4073,  0.2504],\n",
      "        [ 0.4713, -0.3562],\n",
      "        [ 0.2462,  0.3670],\n",
      "        [-0.1047, -0.4487],\n",
      "        [-0.2999,  0.4558],\n",
      "        [ 0.3771,  0.2933],\n",
      "        [-0.1683,  0.0696],\n",
      "        [-0.3058, -0.0371],\n",
      "        [ 0.2608,  0.5011],\n",
      "        [ 0.0655, -0.3378]])), ('_shared_encoder.convs.2.convs.1.conv.lin_l.bias', tensor([ 0.2120,  0.3991, -0.0772,  0.3591, -0.6162,  0.2788, -0.3939, -0.6961,\n",
      "        -0.4701,  0.1420, -0.3229,  0.6793,  0.1923,  0.0069,  0.0156, -0.2916])), ('_shared_encoder.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.4431, -0.0486],\n",
      "        [-0.2827,  0.4154],\n",
      "        [-0.4762, -0.5162],\n",
      "        [ 0.5548,  0.4362],\n",
      "        [-0.4022,  0.3413],\n",
      "        [-0.5088, -0.4630],\n",
      "        [ 0.1241,  0.4829],\n",
      "        [-0.4152, -0.4241],\n",
      "        [ 0.3985,  0.0199],\n",
      "        [ 0.1482, -0.3570],\n",
      "        [ 0.1436, -0.5135],\n",
      "        [ 0.3271,  0.4726],\n",
      "        [ 0.2392, -0.0335],\n",
      "        [-0.4079, -0.1655],\n",
      "        [-0.2689, -0.1437],\n",
      "        [ 0.4654, -0.3476]])), ('_shared_encoder.convs.2.convs.1.conv.lin_r.bias', tensor([-0.3257,  0.4544, -0.6005,  0.4539,  0.3172, -0.5747, -0.1419, -0.5257,\n",
      "        -0.6110,  0.4934,  0.0221, -0.0980,  0.5133, -0.4135,  0.6266, -0.3602])), ('_shared_encoder.convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.4676],\n",
      "        [ 0.5342],\n",
      "        [ 0.5560],\n",
      "        [-0.5940],\n",
      "        [ 0.5168],\n",
      "        [-0.1684],\n",
      "        [-0.0375],\n",
      "        [-0.0593],\n",
      "        [ 0.5937],\n",
      "        [-0.5441],\n",
      "        [-0.1911],\n",
      "        [-0.4026],\n",
      "        [-0.4515],\n",
      "        [ 0.1712],\n",
      "        [ 0.0565],\n",
      "        [ 0.2885]])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0.])), ('_encoder_logstd.conv.att', tensor([[[ 0.4829, -0.5467,  0.0723],\n",
      "         [-0.2368, -0.5401,  0.0317],\n",
      "         [ 0.7561, -0.0536, -0.7233]]])), ('_encoder_logstd.conv.bias', tensor([0., 0., 0.])), ('_encoder_logstd.conv.lin_l.weight', tensor([[-0.7016, -0.5648, -0.0229],\n",
      "        [ 0.1840, -0.1189, -0.1075],\n",
      "        [ 0.5961, -0.6962, -0.3744],\n",
      "        [ 0.1737,  0.3217,  0.2794],\n",
      "        [ 0.5923, -0.1841, -0.3021],\n",
      "        [-0.0030,  0.5695, -0.4629],\n",
      "        [-0.1808, -0.0403,  0.4527],\n",
      "        [-0.3316,  0.4183,  0.4101],\n",
      "        [-0.3225,  0.1936,  0.2987]])), ('_encoder_logstd.conv.lin_l.bias', tensor([-0.1781,  0.5734, -0.5221,  0.2609, -0.0366, -0.2316,  0.5376,  0.1384,\n",
      "        -0.3463])), ('_encoder_logstd.conv.lin_r.weight', tensor([[ 0.0795,  0.0075,  0.6932],\n",
      "        [ 0.1248,  0.6308, -0.1352],\n",
      "        [ 0.6527, -0.1106, -0.6831],\n",
      "        [ 0.5286, -0.1951, -0.6414],\n",
      "        [-0.0791,  0.3072, -0.3728],\n",
      "        [ 0.5945, -0.6692, -0.3504],\n",
      "        [-0.5513,  0.4622, -0.0891],\n",
      "        [ 0.5815,  0.2665,  0.2724],\n",
      "        [-0.5103,  0.2560, -0.5808]])), ('_encoder_logstd.conv.lin_r.bias', tensor([-0.5016,  0.2512, -0.3261,  0.3946, -0.1946,  0.4241, -0.5222, -0.1314,\n",
      "         0.3920])), ('_encoder_logstd.conv.lin_edge.weight', tensor([[-0.2367],\n",
      "        [ 0.2322],\n",
      "        [-0.1829],\n",
      "        [-0.1543],\n",
      "        [-0.4022],\n",
      "        [ 0.0816],\n",
      "        [ 0.1610],\n",
      "        [ 0.4121],\n",
      "        [-0.4876]]))]), 'constructor_params': {'encoder_logstd_given': True, 'shared_encoder_given': True, 'encoder_logstd': {'state_dict': OrderedDict([('norm.weight', tensor([1., 1., 1.])), ('norm.bias', tensor([0., 0., 0.])), ('conv.att', tensor([[[ 0.4829, -0.5467,  0.0723],\n",
      "         [-0.2368, -0.5401,  0.0317],\n",
      "         [ 0.7561, -0.0536, -0.7233]]])), ('conv.bias', tensor([0., 0., 0.])), ('conv.lin_l.weight', tensor([[-0.7016, -0.5648, -0.0229],\n",
      "        [ 0.1840, -0.1189, -0.1075],\n",
      "        [ 0.5961, -0.6962, -0.3744],\n",
      "        [ 0.1737,  0.3217,  0.2794],\n",
      "        [ 0.5923, -0.1841, -0.3021],\n",
      "        [-0.0030,  0.5695, -0.4629],\n",
      "        [-0.1808, -0.0403,  0.4527],\n",
      "        [-0.3316,  0.4183,  0.4101],\n",
      "        [-0.3225,  0.1936,  0.2987]])), ('conv.lin_l.bias', tensor([-0.1781,  0.5734, -0.5221,  0.2609, -0.0366, -0.2316,  0.5376,  0.1384,\n",
      "        -0.3463])), ('conv.lin_r.weight', tensor([[ 0.0795,  0.0075,  0.6932],\n",
      "        [ 0.1248,  0.6308, -0.1352],\n",
      "        [ 0.6527, -0.1106, -0.6831],\n",
      "        [ 0.5286, -0.1951, -0.6414],\n",
      "        [-0.0791,  0.3072, -0.3728],\n",
      "        [ 0.5945, -0.6692, -0.3504],\n",
      "        [-0.5513,  0.4622, -0.0891],\n",
      "        [ 0.5815,  0.2665,  0.2724],\n",
      "        [-0.5103,  0.2560, -0.5808]])), ('conv.lin_r.bias', tensor([-0.5016,  0.2512, -0.3261,  0.3946, -0.1946,  0.4241, -0.5222, -0.1314,\n",
      "         0.3920])), ('conv.lin_edge.weight', tensor([[-0.2367],\n",
      "        [ 0.2322],\n",
      "        [-0.1829],\n",
      "        [-0.1543],\n",
      "        [-0.4022],\n",
      "        [ 0.0816],\n",
      "        [ 0.1610],\n",
      "        [ 0.4121],\n",
      "        [-0.4876]]))]), 'constructor_params': {'in_channels': 3, 'out_channels': 3, 'version': 'v2', 'heads': 3, 'concat': False, 'dropout': 0.0, 'bias': True, 'add_self_loops': True, 'edge_dim': 1, 'fill_value': 'mean', 'project_multi_head': True}}, 'encoder_mu': {'state_dict': OrderedDict([('norm.weight', tensor([1., 1., 1.])), ('norm.bias', tensor([0., 0., 0.])), ('conv.att', tensor([[[ 0.3579,  0.9866,  1.0575],\n",
      "         [ 0.2570, -0.8998, -1.0497]]])), ('conv.bias', tensor([0., 0., 0.])), ('conv.lin_l.weight', tensor([[ 0.0486, -0.1225, -0.5542],\n",
      "        [-0.4130,  0.7974, -0.0612],\n",
      "        [ 0.0086, -0.7460,  0.3276],\n",
      "        [ 0.0209, -0.6054, -0.1583],\n",
      "        [ 0.5776, -0.3417, -0.5212],\n",
      "        [-0.6380, -0.6325, -0.3136]])), ('conv.lin_l.bias', tensor([-0.0443, -0.1616,  0.3953,  0.4634, -0.4250,  0.1949])), ('conv.lin_r.weight', tensor([[-0.6274, -0.3435,  0.5300],\n",
      "        [-0.5172,  0.1107, -0.3396],\n",
      "        [ 0.4242,  0.6773,  0.0554],\n",
      "        [ 0.0848,  0.1916, -0.0869],\n",
      "        [ 0.8154, -0.2181,  0.1336],\n",
      "        [ 0.4835,  0.7259, -0.1814]])), ('conv.lin_r.bias', tensor([-0.5432,  0.5412,  0.3144,  0.3737, -0.2872, -0.2192])), ('conv.lin_edge.weight', tensor([[-0.9175],\n",
      "        [ 0.6308],\n",
      "        [ 0.2859],\n",
      "        [ 0.4841],\n",
      "        [ 0.4491],\n",
      "        [ 0.7673]]))]), 'constructor_params': {'in_channels': 3, 'out_channels': 3, 'version': 'v2', 'heads': 2, 'concat': False, 'dropout': 0.0, 'bias': True, 'add_self_loops': True, 'edge_dim': 1, 'fill_value': 'mean', 'project_multi_head': True}}, 'shared_encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.1229,  0.0242, -0.0708,  0.2928,  0.3686,  0.3391],\n",
      "        [ 0.3730, -0.2483,  0.2430, -0.1645, -0.3713,  0.0022],\n",
      "        [-0.2297,  0.1254,  0.3649,  0.2770, -0.1025,  0.0325],\n",
      "        [ 0.2206, -0.0203,  0.3517,  0.3367,  0.3543, -0.0250]])), ('lin1.bias', tensor([-0.2097,  0.3288, -0.2051,  0.3535])), ('lin2.weight', tensor([[-0.3879,  0.0286,  0.2166, -0.2984],\n",
      "        [ 0.3214, -0.0961,  0.1568, -0.1290],\n",
      "        [ 0.4660, -0.4091,  0.1612,  0.4720]])), ('lin2.bias', tensor([ 0.2505, -0.0449,  0.1876])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[-0.0526, -0.4608],\n",
      "         [ 0.5524,  0.2415],\n",
      "         [ 0.7230,  0.1697],\n",
      "         [ 0.6663,  0.0295],\n",
      "         [ 0.0182, -0.4623],\n",
      "         [-0.4694,  0.4187],\n",
      "         [-0.2698, -0.3603],\n",
      "         [-0.6316, -0.0326]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.0209,  0.1445],\n",
      "        [-0.5222,  0.1348],\n",
      "        [-0.0740, -0.0641],\n",
      "        [ 0.4767,  0.4742],\n",
      "        [ 0.1503, -0.3387],\n",
      "        [-0.4849, -0.1534],\n",
      "        [-0.1195,  0.2328],\n",
      "        [-0.0732,  0.3560],\n",
      "        [ 0.4346, -0.4611],\n",
      "        [-0.5171, -0.4179],\n",
      "        [ 0.4488,  0.2638],\n",
      "        [-0.2887, -0.4350],\n",
      "        [ 0.1925,  0.5273],\n",
      "        [-0.1269,  0.2222],\n",
      "        [-0.0041, -0.3342],\n",
      "        [ 0.3436, -0.0606]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.0382,  0.0854, -0.0739,  0.5126,  0.0892, -0.5764,  0.0512,  0.2909,\n",
      "         0.4843, -0.5980, -0.5882, -0.3674,  0.2752,  0.4249,  0.6864, -0.5494])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.4788,  0.4287],\n",
      "        [ 0.4935, -0.3287],\n",
      "        [-0.4627, -0.2848],\n",
      "        [ 0.0965, -0.1909],\n",
      "        [-0.4282,  0.2776],\n",
      "        [ 0.0808, -0.0360],\n",
      "        [ 0.5416, -0.5058],\n",
      "        [ 0.3431, -0.4738],\n",
      "        [ 0.5517, -0.2892],\n",
      "        [ 0.0381,  0.3748],\n",
      "        [ 0.3325,  0.0959],\n",
      "        [-0.0983,  0.0345],\n",
      "        [-0.2522,  0.2236],\n",
      "        [-0.5499, -0.5416],\n",
      "        [-0.3815,  0.3316],\n",
      "        [ 0.2626, -0.2268]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([-0.1518, -0.6478, -0.4472, -0.2162, -0.1583,  0.2978,  0.4363, -0.6890,\n",
      "         0.0060,  0.4150,  0.6654,  0.1922,  0.1290, -0.6095,  0.0564, -0.3167])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.5185],\n",
      "        [ 0.4079],\n",
      "        [-0.2321],\n",
      "        [-0.2607],\n",
      "        [ 0.4309],\n",
      "        [ 0.5479],\n",
      "        [ 0.5536],\n",
      "        [-0.4012],\n",
      "        [ 0.4227],\n",
      "        [ 0.1418],\n",
      "        [ 0.3216],\n",
      "        [ 0.3654],\n",
      "        [-0.2669],\n",
      "        [-0.0417],\n",
      "        [-0.1841],\n",
      "        [ 0.3768]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.4715, -0.0486],\n",
      "         [ 0.6121, -0.0638],\n",
      "         [-0.3718, -0.0557],\n",
      "         [ 0.2476, -0.3024],\n",
      "         [ 0.2086, -0.0973],\n",
      "         [-0.1421, -0.0321],\n",
      "         [ 0.0734, -0.5617],\n",
      "         [-0.7044,  0.2275]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.1888, -0.0318],\n",
      "        [-0.4393,  0.0888],\n",
      "        [-0.5227, -0.5524],\n",
      "        [ 0.3518, -0.4875],\n",
      "        [ 0.5570,  0.2136],\n",
      "        [ 0.2519,  0.1257],\n",
      "        [ 0.4523,  0.4612],\n",
      "        [ 0.0998, -0.1023],\n",
      "        [ 0.4011,  0.2632],\n",
      "        [-0.3969, -0.4105],\n",
      "        [ 0.5685,  0.3244],\n",
      "        [ 0.4869,  0.2043],\n",
      "        [-0.3940, -0.4304],\n",
      "        [ 0.3024,  0.3014],\n",
      "        [-0.2437,  0.0784],\n",
      "        [ 0.4816,  0.1390]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.7048, -0.6246, -0.3242,  0.4475, -0.6846, -0.5147,  0.4907, -0.1339,\n",
      "        -0.3347, -0.3032, -0.3169, -0.1835,  0.4131,  0.6452, -0.2877, -0.0150])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.2051, -0.0181],\n",
      "        [-0.3977,  0.2966],\n",
      "        [ 0.5374, -0.1855],\n",
      "        [-0.0859, -0.1999],\n",
      "        [-0.0276,  0.4561],\n",
      "        [ 0.3241,  0.5729],\n",
      "        [ 0.2533, -0.0015],\n",
      "        [-0.3080, -0.5559],\n",
      "        [-0.1357,  0.2570],\n",
      "        [-0.0193, -0.1268],\n",
      "        [ 0.0302, -0.1936],\n",
      "        [ 0.0597, -0.3874],\n",
      "        [ 0.2075, -0.2172],\n",
      "        [-0.5719, -0.5707],\n",
      "        [ 0.4549,  0.1512],\n",
      "        [-0.0911, -0.3558]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.4422, -0.3488, -0.5428,  0.5915, -0.4314, -0.1861,  0.1925,  0.3985,\n",
      "         0.0519,  0.0832,  0.5050, -0.2167, -0.5534, -0.2006,  0.1760,  0.2697])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[ 0.1062],\n",
      "        [ 0.5117],\n",
      "        [ 0.0416],\n",
      "        [ 0.1086],\n",
      "        [-0.4398],\n",
      "        [-0.2659],\n",
      "        [ 0.0054],\n",
      "        [ 0.4455],\n",
      "        [-0.5545],\n",
      "        [-0.3959],\n",
      "        [ 0.3456],\n",
      "        [ 0.1898],\n",
      "        [ 0.0614],\n",
      "        [ 0.5044],\n",
      "        [-0.4056],\n",
      "        [-0.0173]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[ 0.0146,  0.3986],\n",
      "         [ 0.1089,  0.6757],\n",
      "         [-0.0534,  0.4909],\n",
      "         [-0.7615, -0.1841],\n",
      "         [ 0.5854, -0.2991],\n",
      "         [-0.3876, -0.5855],\n",
      "         [-0.6520, -0.5870],\n",
      "         [ 0.5205, -0.2480]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.2541,  0.3424],\n",
      "        [ 0.1895, -0.2790],\n",
      "        [-0.4701,  0.3681],\n",
      "        [ 0.2399, -0.1382],\n",
      "        [ 0.1796,  0.1940],\n",
      "        [ 0.2489,  0.1348],\n",
      "        [-0.2402,  0.0423],\n",
      "        [ 0.2965, -0.4857],\n",
      "        [ 0.3139,  0.0705],\n",
      "        [-0.1340,  0.4308],\n",
      "        [-0.4390,  0.5097],\n",
      "        [-0.3886, -0.5540],\n",
      "        [ 0.0389, -0.5455],\n",
      "        [ 0.2550,  0.2645],\n",
      "        [ 0.0506,  0.1864],\n",
      "        [ 0.5145, -0.1426]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.4648, -0.2004,  0.5986,  0.4650, -0.2601, -0.6240,  0.0591,  0.4232,\n",
      "        -0.2570, -0.1897, -0.2637,  0.6381, -0.1111,  0.3423, -0.4815, -0.0286])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.5066, -0.2770],\n",
      "        [ 0.4640, -0.3423],\n",
      "        [-0.1188, -0.3950],\n",
      "        [-0.2430,  0.0223],\n",
      "        [-0.5438, -0.4719],\n",
      "        [-0.0462,  0.4655],\n",
      "        [-0.0220,  0.4580],\n",
      "        [-0.4272,  0.0439],\n",
      "        [-0.2107,  0.1784],\n",
      "        [-0.0776, -0.3079],\n",
      "        [ 0.5083, -0.1315],\n",
      "        [-0.4783, -0.1462],\n",
      "        [ 0.1426,  0.3090],\n",
      "        [ 0.2877, -0.1598],\n",
      "        [ 0.0032, -0.4866],\n",
      "        [ 0.3665,  0.1784]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([ 0.4743, -0.4914,  0.4852, -0.3146,  0.4249, -0.4677, -0.1213, -0.6146,\n",
      "         0.3038, -0.1509,  0.3335,  0.5000, -0.2478, -0.0360, -0.5166, -0.6002])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.0034],\n",
      "        [-0.2423],\n",
      "        [ 0.3647],\n",
      "        [ 0.4648],\n",
      "        [ 0.3310],\n",
      "        [-0.0105],\n",
      "        [ 0.5379],\n",
      "        [-0.3703],\n",
      "        [-0.2975],\n",
      "        [-0.5626],\n",
      "        [ 0.0515],\n",
      "        [-0.3218],\n",
      "        [-0.4455],\n",
      "        [-0.5665],\n",
      "        [ 0.0976],\n",
      "        [-0.1756]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[ 0.6018, -0.4637],\n",
      "         [ 0.4091, -0.6711],\n",
      "         [-0.6989, -0.0598],\n",
      "         [ 0.2608, -0.4156],\n",
      "         [ 0.6517, -0.1296],\n",
      "         [-0.6321,  0.5264],\n",
      "         [ 0.4967,  0.5001],\n",
      "         [ 0.1707, -0.1403]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.4070,  0.5211],\n",
      "        [-0.1923, -0.2264],\n",
      "        [ 0.2889,  0.5062],\n",
      "        [-0.1966, -0.0111],\n",
      "        [-0.0271,  0.4266],\n",
      "        [ 0.2852,  0.4506],\n",
      "        [ 0.5569,  0.5448],\n",
      "        [ 0.0936,  0.2283],\n",
      "        [ 0.0803, -0.0240],\n",
      "        [ 0.1467, -0.2355],\n",
      "        [ 0.3641, -0.0937],\n",
      "        [ 0.5133,  0.0185],\n",
      "        [-0.5187,  0.2234],\n",
      "        [-0.5555, -0.3425],\n",
      "        [ 0.2227, -0.0492],\n",
      "        [-0.3522, -0.0956]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([ 0.0329, -0.6274,  0.1581,  0.1442,  0.4750, -0.3952, -0.3723,  0.6143,\n",
      "        -0.0550, -0.1552, -0.1999,  0.3741,  0.1639,  0.4993,  0.0609, -0.1035])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.2325, -0.3326],\n",
      "        [-0.2582, -0.2858],\n",
      "        [-0.0008, -0.3446],\n",
      "        [-0.4082, -0.5291],\n",
      "        [ 0.5165, -0.3226],\n",
      "        [-0.3276, -0.4814],\n",
      "        [ 0.2472,  0.2163],\n",
      "        [-0.2680, -0.2739],\n",
      "        [ 0.2282,  0.1764],\n",
      "        [-0.1752, -0.1188],\n",
      "        [ 0.2167,  0.2120],\n",
      "        [ 0.0710,  0.4955],\n",
      "        [ 0.0575,  0.2758],\n",
      "        [-0.0217, -0.4032],\n",
      "        [ 0.1448,  0.2744],\n",
      "        [ 0.0708,  0.2500]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([ 0.3583, -0.0219,  0.4028, -0.3647, -0.1951,  0.7016, -0.4678,  0.2148,\n",
      "        -0.5423,  0.4102, -0.6334, -0.2064, -0.2386,  0.4787, -0.2437,  0.1338])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.3372],\n",
      "        [-0.1730],\n",
      "        [-0.0089],\n",
      "        [-0.2338],\n",
      "        [ 0.0547],\n",
      "        [ 0.0031],\n",
      "        [ 0.1237],\n",
      "        [ 0.3604],\n",
      "        [-0.0830],\n",
      "        [-0.0011],\n",
      "        [ 0.5018],\n",
      "        [ 0.1183],\n",
      "        [-0.3313],\n",
      "        [-0.4916],\n",
      "        [ 0.0696],\n",
      "        [-0.3054]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[ 7.5174e-01,  5.6328e-01],\n",
      "         [-9.2673e-02,  7.6959e-01],\n",
      "         [-2.3509e-01,  4.3409e-04],\n",
      "         [ 5.4807e-01,  6.1053e-02],\n",
      "         [-6.9554e-01, -6.9958e-01],\n",
      "         [-5.2413e-01,  6.8906e-01],\n",
      "         [-2.9831e-01, -7.5061e-01],\n",
      "         [ 4.7598e-01,  6.6002e-01]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.2634,  0.0183],\n",
      "        [-0.2517, -0.4038],\n",
      "        [ 0.4726, -0.3440],\n",
      "        [ 0.0241, -0.0225],\n",
      "        [ 0.3139, -0.0332],\n",
      "        [-0.0868, -0.5364],\n",
      "        [-0.2328,  0.4025],\n",
      "        [-0.1124, -0.3376],\n",
      "        [ 0.1873,  0.0503],\n",
      "        [ 0.0768, -0.2066],\n",
      "        [ 0.0264, -0.4476],\n",
      "        [ 0.3595,  0.5647],\n",
      "        [-0.1378, -0.3666],\n",
      "        [-0.2139, -0.4455],\n",
      "        [-0.0763, -0.0022],\n",
      "        [ 0.2431, -0.0567]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.5053,  0.0353, -0.0974, -0.2851, -0.5872,  0.0978,  0.3604,  0.2450,\n",
      "        -0.4851, -0.5988, -0.2858, -0.4163,  0.3486,  0.5694,  0.1144,  0.0015])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2863, -0.3670],\n",
      "        [ 0.2378, -0.2436],\n",
      "        [-0.3468,  0.3459],\n",
      "        [-0.5729,  0.2097],\n",
      "        [ 0.4999, -0.2180],\n",
      "        [ 0.2402, -0.2845],\n",
      "        [ 0.3957,  0.0396],\n",
      "        [-0.0395, -0.4436],\n",
      "        [-0.2586, -0.1648],\n",
      "        [ 0.4863, -0.3888],\n",
      "        [-0.4384,  0.5455],\n",
      "        [-0.0399,  0.3192],\n",
      "        [-0.5127, -0.0904],\n",
      "        [-0.0766,  0.4561],\n",
      "        [ 0.3857,  0.1796],\n",
      "        [ 0.0303, -0.0652]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([-0.3217,  0.6151, -0.2282, -0.0952, -0.6683, -0.2182,  0.1551,  0.4919,\n",
      "        -0.6905,  0.4138, -0.1967,  0.6267, -0.1228,  0.2655, -0.4204, -0.2421])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[ 0.1125],\n",
      "        [-0.3755],\n",
      "        [ 0.0854],\n",
      "        [ 0.3299],\n",
      "        [ 0.0143],\n",
      "        [-0.5822],\n",
      "        [-0.2777],\n",
      "        [-0.3653],\n",
      "        [ 0.0234],\n",
      "        [-0.1771],\n",
      "        [-0.0209],\n",
      "        [ 0.3957],\n",
      "        [ 0.0312],\n",
      "        [ 0.3794],\n",
      "        [ 0.5769],\n",
      "        [-0.5729]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[ 0.1596,  0.0882],\n",
      "         [ 0.0160, -0.5636],\n",
      "         [-0.5672,  0.5332],\n",
      "         [-0.2321,  0.3065],\n",
      "         [ 0.5208, -0.1428],\n",
      "         [-0.1829,  0.6031],\n",
      "         [-0.4831, -0.1096],\n",
      "         [-0.1750,  0.0589]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.5548, -0.3558],\n",
      "        [-0.1687,  0.0871],\n",
      "        [ 0.0259, -0.3623],\n",
      "        [ 0.1342, -0.4634],\n",
      "        [ 0.0970, -0.4773],\n",
      "        [ 0.2677, -0.3384],\n",
      "        [ 0.4073,  0.2504],\n",
      "        [ 0.4713, -0.3562],\n",
      "        [ 0.2462,  0.3670],\n",
      "        [-0.1047, -0.4487],\n",
      "        [-0.2999,  0.4558],\n",
      "        [ 0.3771,  0.2933],\n",
      "        [-0.1683,  0.0696],\n",
      "        [-0.3058, -0.0371],\n",
      "        [ 0.2608,  0.5011],\n",
      "        [ 0.0655, -0.3378]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.2120,  0.3991, -0.0772,  0.3591, -0.6162,  0.2788, -0.3939, -0.6961,\n",
      "        -0.4701,  0.1420, -0.3229,  0.6793,  0.1923,  0.0069,  0.0156, -0.2916])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.4431, -0.0486],\n",
      "        [-0.2827,  0.4154],\n",
      "        [-0.4762, -0.5162],\n",
      "        [ 0.5548,  0.4362],\n",
      "        [-0.4022,  0.3413],\n",
      "        [-0.5088, -0.4630],\n",
      "        [ 0.1241,  0.4829],\n",
      "        [-0.4152, -0.4241],\n",
      "        [ 0.3985,  0.0199],\n",
      "        [ 0.1482, -0.3570],\n",
      "        [ 0.1436, -0.5135],\n",
      "        [ 0.3271,  0.4726],\n",
      "        [ 0.2392, -0.0335],\n",
      "        [-0.4079, -0.1655],\n",
      "        [-0.2689, -0.1437],\n",
      "        [ 0.4654, -0.3476]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([-0.3257,  0.4544, -0.6005,  0.4539,  0.3172, -0.5747, -0.1419, -0.5257,\n",
      "        -0.6110,  0.4934,  0.0221, -0.0980,  0.5133, -0.4135,  0.6266, -0.3602])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.4676],\n",
      "        [ 0.5342],\n",
      "        [ 0.5560],\n",
      "        [-0.5940],\n",
      "        [ 0.5168],\n",
      "        [-0.1684],\n",
      "        [-0.0375],\n",
      "        [-0.0593],\n",
      "        [ 0.5937],\n",
      "        [-0.5441],\n",
      "        [-0.1911],\n",
      "        [-0.4026],\n",
      "        [-0.4515],\n",
      "        [ 0.1712],\n",
      "        [ 0.0565],\n",
      "        [ 0.2885]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): GATConvBlock(\n",
      "      (norm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(3, 3, heads=2)\n",
      "    )\n",
      "    (_shared_encoder): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): GATConvBlock(\n",
      "      (norm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(3, 3, heads=3)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    GATConvBlock: 2-1                                          --\n",
      "        LayerNorm: 3-1                                        6\n",
      "        GATv2Conv: 3-2                                        63\n",
      "    RevGATConvEncoder: 2-2                                     --\n",
      "        Linear: 3-3                                           28\n",
      "        Linear: 3-4                                           15\n",
      "        LayerNorm: 3-5                                        8\n",
      "        ModuleList: 3-6                                       804\n",
      "    GATConvBlock: 2-3                                          --\n",
      "        LayerNorm: 3-7                                        6\n",
      "        GATv2Conv: 3-8                                        93\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,023\n",
      "Trainable params: 1,023\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([3.3713e-03, 1.0000e+00, 3.3713e-03, 1.1670e-03, 1.0000e+00, 1.1670e-03,\n",
      "        5.4648e-01, 3.1260e-04, 5.4648e-01, 3.1260e-04],\n",
      "       grad_fn=<SigmoidBackward0>), tensor([[-0.2928, -0.7039,  0.3050],\n",
      "        [-0.2930, -0.7038,  0.3052],\n",
      "        [-0.2929, -0.7042,  0.3049],\n",
      "        [-0.2937, -0.7047,  0.3050],\n",
      "        [-0.2939, -0.7048,  0.3050]], grad_fn=<AddBackward0>), tensor([[ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5403,  0.2253, -0.6199],\n",
      "        [ 0.5407,  0.2253, -0.6203],\n",
      "        [ 0.5409,  0.2253, -0.6204]], grad_fn=<AddBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.0533, 0.9980, 0.0533, 0.6276, 0.9980, 0.6276, 0.9717, 0.8758, 0.9717,\n",
      "        0.8758], grad_fn=<SigmoidBackward0>), tensor([[-0.2928, -0.7039,  0.3050],\n",
      "        [-0.2930, -0.7038,  0.3052],\n",
      "        [-0.2929, -0.7042,  0.3049],\n",
      "        [-0.2937, -0.7047,  0.3050],\n",
      "        [-0.2939, -0.7048,  0.3050]], grad_fn=<AddBackward0>), tensor([[ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5403,  0.2253, -0.6199],\n",
      "        [ 0.5407,  0.2253, -0.6203],\n",
      "        [ 0.5409,  0.2253, -0.6204]], grad_fn=<AddBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.9695, 0.9997, 0.9912, 0.4878, 0.9940],\n",
      "        [0.9997, 1.0000, 1.0000, 0.1125, 1.0000],\n",
      "        [0.9912, 1.0000, 0.9998, 0.0834, 0.9999],\n",
      "        [0.4878, 0.1125, 0.0834, 0.9246, 0.1205],\n",
      "        [0.9940, 1.0000, 0.9999, 0.1205, 0.9999]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.7009, 0.7436, 0.4080, 0.1229, 0.4098],\n",
      "        [0.7436, 0.9872, 0.6931, 0.1106, 0.6108],\n",
      "        [0.4080, 0.6931, 0.7429, 0.6366, 0.7311],\n",
      "        [0.1229, 0.1106, 0.6366, 0.9943, 0.5907],\n",
      "        [0.4098, 0.6108, 0.7311, 0.5907, 0.7339]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.4260, -3.2861,  0.5370],\n",
      "        [ 0.8009, -0.4880, -0.1971],\n",
      "        [ 1.2098, -0.6493,  0.4384],\n",
      "        [-3.8567,  0.3840,  0.9458],\n",
      "        [-0.2924, -0.9710,  0.3661]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-2.6386, -0.6378,  0.0627],\n",
      "        [-0.5852,  1.2076,  0.0062],\n",
      "        [ 0.3569, -2.3970, -0.1318],\n",
      "        [ 2.6212, -1.3735,  0.3916],\n",
      "        [-3.0344, -1.2066,  0.8044]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.2928, -0.7039,  0.3050],\n",
      "        [-0.2930, -0.7038,  0.3052],\n",
      "        [-0.2929, -0.7042,  0.3049],\n",
      "        [-0.2937, -0.7047,  0.3050],\n",
      "        [-0.2939, -0.7048,  0.3050]], grad_fn=<AddBackward0>)\n",
      "log(std) original\n",
      "tensor([[ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5403,  0.2253, -0.6199],\n",
      "        [ 0.5407,  0.2253, -0.6203],\n",
      "        [ 0.5409,  0.2253, -0.6204]], grad_fn=<AddBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.2928, -0.7039,  0.3050],\n",
      "        [-0.2930, -0.7038,  0.3052],\n",
      "        [-0.2929, -0.7042,  0.3049],\n",
      "        [-0.2937, -0.7047,  0.3050],\n",
      "        [-0.2939, -0.7048,  0.3050]], grad_fn=<AddBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5402,  0.2253, -0.6198],\n",
      "        [ 0.5403,  0.2253, -0.6199],\n",
      "        [ 0.5407,  0.2253, -0.6203],\n",
      "        [ 0.5409,  0.2253, -0.6204]], grad_fn=<AddBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.4197, 0.5756, 0.4197, 0.3439, 0.5756, 0.3439, 0.1104, 0.4768, 0.1104,\n",
      "        0.4768], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.8851, 0.0803, 0.8851, 0.2742, 0.0803, 0.2742, 0.0643, 0.8857, 0.0643,\n",
      "        0.8857], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(3.6769, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(2.2631, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.4, 0.5857142857142856)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.8, 0.71)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.1616, -0.0297, -0.2914, -0.1237,  0.0950, -0.3758],\n",
      "        [ 0.2269,  0.0857, -0.0738, -0.0268,  0.1446, -0.0932],\n",
      "        [-0.0878, -0.2951,  0.2103,  0.1879,  0.2232, -0.2305],\n",
      "        [ 0.2702, -0.2406,  0.1705,  0.1132, -0.2727, -0.1365]])), ('_encoder_mu.lin1.bias', tensor([0.0210, 0.2468, 0.3792, 0.0692])), ('_encoder_mu.lin2.weight', tensor([[ 0.2675, -0.2057,  0.0776, -0.2864],\n",
      "        [-0.3916, -0.0299, -0.3982,  0.3943],\n",
      "        [-0.0604, -0.4146, -0.2677,  0.4601]])), ('_encoder_mu.lin2.bias', tensor([-0.0860,  0.0098, -0.1651])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.lin.weight', tensor([[-0.7045, -0.2599],\n",
      "        [-0.3259, -0.2168]])), ('_encoder_mu.convs.0.convs.0.conv.lin.bias', tensor([0.2543, 0.5988])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.3785, -0.1994],\n",
      "        [-0.1810, -0.6404]])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.bias', tensor([-0.2436, -0.5161])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.3965, -0.3102],\n",
      "        [ 0.4904,  0.0417]])), ('_encoder_mu.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.lin.weight', tensor([[-0.0705,  0.7005],\n",
      "        [ 0.3096, -0.5207]])), ('_encoder_mu.convs.0.convs.1.conv.lin.bias', tensor([0.0097, 0.3023])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.2387, -0.0947],\n",
      "        [ 0.5299, -0.1722]])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.bias', tensor([ 0.6025, -0.1467])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.0924, -0.1549],\n",
      "        [ 0.2293,  0.5404]])), ('_encoder_mu.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.lin.weight', tensor([[-0.6955, -0.5473],\n",
      "        [ 0.6008,  0.6682]])), ('_encoder_mu.convs.1.convs.0.conv.lin.bias', tensor([ 0.4527, -0.5982])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.5404, -0.4298],\n",
      "        [-0.1697,  0.6836]])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.bias', tensor([-0.3193,  0.0610])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.5621,  0.5364],\n",
      "        [ 0.6895, -0.3135]])), ('_encoder_mu.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.lin.weight', tensor([[-0.1106,  0.6785],\n",
      "        [ 0.6105,  0.3062]])), ('_encoder_mu.convs.1.convs.1.conv.lin.bias', tensor([ 0.5755, -0.4523])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.weight', tensor([[-0.0242, -0.0461],\n",
      "        [-0.4484, -0.1332]])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.bias', tensor([0.5028, 0.3620])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.6482, -0.0105],\n",
      "        [ 0.3195, -0.3278]])), ('_encoder_mu.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.lin.weight', tensor([[ 0.0363,  0.0972],\n",
      "        [-0.1784, -0.0842]])), ('_encoder_mu.convs.2.convs.0.conv.lin.bias', tensor([ 0.2071, -0.6478])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.3762, -0.0462],\n",
      "        [ 0.5397, -0.6189]])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.bias', tensor([-0.0992,  0.2055])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2613, -0.4404],\n",
      "        [-0.2219,  0.5136]])), ('_encoder_mu.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.lin.weight', tensor([[ 0.5690, -0.5911],\n",
      "        [ 0.3155,  0.6758]])), ('_encoder_mu.convs.2.convs.1.conv.lin.bias', tensor([ 0.3869, -0.6231])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1737, -0.4102],\n",
      "        [-0.3854, -0.3855]])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.bias', tensor([ 0.0633, -0.4132])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.3125,  0.5653],\n",
      "        [ 0.2572, -0.5434]])), ('_encoder_mu.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.0.conv.lin.weight', tensor([[ 0.4668,  0.5607],\n",
      "        [-0.1073, -0.1392]])), ('_encoder_mu.convs.3.convs.0.conv.lin.bias', tensor([-0.4396,  0.3556])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.weight', tensor([[-0.4535,  0.1452],\n",
      "        [-0.0884, -0.5710]])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.bias', tensor([-0.4477,  0.2184])), ('_encoder_mu.convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.0798,  0.6763],\n",
      "        [ 0.3790, -0.4260]])), ('_encoder_mu.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.1.conv.lin.weight', tensor([[-0.2610, -0.4074],\n",
      "        [ 0.2613,  0.2277]])), ('_encoder_mu.convs.3.convs.1.conv.lin.bias', tensor([-0.4812,  0.0095])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.4666, -0.3612],\n",
      "        [ 0.5306, -0.3997]])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.bias', tensor([-0.2743,  0.3491])), ('_encoder_mu.convs.3.convs.1.conv.lin_r.weight', tensor([[-0.2932,  0.4886],\n",
      "        [ 0.4126, -0.5416]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.0006,  0.1065,  0.1892,  0.1909,  0.3812,  0.0358],\n",
      "        [-0.0507, -0.3731,  0.4031, -0.3557,  0.0696, -0.3143],\n",
      "        [ 0.3131, -0.2570, -0.0319,  0.3037, -0.2561, -0.3068],\n",
      "        [-0.1206, -0.2570,  0.1964, -0.3491,  0.0416,  0.1206]])), ('_encoder_logstd.lin1.bias', tensor([-0.3940,  0.1135, -0.3711, -0.3775])), ('_encoder_logstd.lin2.weight', tensor([[-0.2047,  0.4730, -0.2103,  0.3947],\n",
      "        [-0.0433, -0.2648, -0.0712, -0.2411],\n",
      "        [-0.4701,  0.3496, -0.3743,  0.0925]])), ('_encoder_logstd.lin2.bias', tensor([0.2972, 0.3786, 0.2994])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.lin.weight', tensor([[-0.6645,  0.6609],\n",
      "        [ 0.2586,  0.2209]])), ('_encoder_logstd.convs.0.convs.0.conv.lin.bias', tensor([ 0.0887, -0.2055])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.3708, -0.1533],\n",
      "        [ 0.6134,  0.0160]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.bias', tensor([0.5317, 0.0766])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.4696, -0.4367],\n",
      "        [-0.5889,  0.5827]])), ('_encoder_logstd.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.lin.weight', tensor([[ 0.4859,  0.6535],\n",
      "        [-0.6304,  0.0403]])), ('_encoder_logstd.convs.0.convs.1.conv.lin.bias', tensor([0.0865, 0.0040])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.6368, -0.4635],\n",
      "        [ 0.1639, -0.3047]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.bias', tensor([-0.1197,  0.2762])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.weight', tensor([[-0.4359,  0.0326],\n",
      "        [ 0.4245,  0.4930]])), ('_encoder_logstd.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.lin.weight', tensor([[0.6940, 0.6152],\n",
      "        [0.6146, 0.3299]])), ('_encoder_logstd.convs.1.convs.0.conv.lin.bias', tensor([ 0.2485, -0.1998])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.6355,  0.4466],\n",
      "        [ 0.4477, -0.2179]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.bias', tensor([0.3169, 0.1624])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4535,  0.5972],\n",
      "        [-0.1743, -0.1211]])), ('_encoder_logstd.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.lin.weight', tensor([[-0.3193, -0.6671],\n",
      "        [-0.2486,  0.3719]])), ('_encoder_logstd.convs.1.convs.1.conv.lin.bias', tensor([0.5384, 0.2680])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.weight', tensor([[0.6449, 0.2452],\n",
      "        [0.4373, 0.1137]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.bias', tensor([-0.6430, -0.6818])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.5420,  0.6524],\n",
      "        [-0.6849,  0.3167]])), ('_encoder_logstd.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.lin.weight', tensor([[ 0.3716,  0.6340],\n",
      "        [-0.5825, -0.5600]])), ('_encoder_logstd.convs.2.convs.0.conv.lin.bias', tensor([-0.4420, -0.2456])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.weight', tensor([[-0.5043,  0.5861],\n",
      "        [-0.6301,  0.6127]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.bias', tensor([0.6290, 0.2795])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.6640, -0.6100],\n",
      "        [ 0.2668, -0.5979]])), ('_encoder_logstd.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.lin.weight', tensor([[ 0.3802,  0.0214],\n",
      "        [-0.4074,  0.0957]])), ('_encoder_logstd.convs.2.convs.1.conv.lin.bias', tensor([-0.1669,  0.7050])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.0061,  0.5894],\n",
      "        [-0.3269, -0.5227]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.bias', tensor([-0.1823, -0.5924])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.3077,  0.5239],\n",
      "        [-0.2495, -0.6415]])), ('_encoder_logstd.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.0.conv.lin.weight', tensor([[ 0.6538, -0.2305],\n",
      "        [ 0.6581,  0.0014]])), ('_encoder_logstd.convs.3.convs.0.conv.lin.bias', tensor([0.1982, 0.6187])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.weight', tensor([[ 0.1079,  0.4582],\n",
      "        [ 0.5265, -0.3262]])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.bias', tensor([-0.0661, -0.2595])), ('_encoder_logstd.convs.3.convs.0.conv.lin_r.weight', tensor([[-0.3061,  0.1315],\n",
      "        [-0.4680, -0.0267]])), ('_encoder_logstd.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.1.conv.lin.weight', tensor([[-0.6318,  0.6856],\n",
      "        [ 0.1683,  0.6784]])), ('_encoder_logstd.convs.3.convs.1.conv.lin.bias', tensor([-0.7043,  0.5854])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.0060, -0.2142],\n",
      "        [-0.0162,  0.1575]])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.bias', tensor([-0.4986, -0.6850])), ('_encoder_logstd.convs.3.convs.1.conv.lin_r.weight', tensor([[-0.4613,  0.5829],\n",
      "        [ 0.3847,  0.2717]]))]), 'constructor_params': {'encoder_logstd_given': False, 'shared_encoder_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0006,  0.1065,  0.1892,  0.1909,  0.3812,  0.0358],\n",
      "        [-0.0507, -0.3731,  0.4031, -0.3557,  0.0696, -0.3143],\n",
      "        [ 0.3131, -0.2570, -0.0319,  0.3037, -0.2561, -0.3068],\n",
      "        [-0.1206, -0.2570,  0.1964, -0.3491,  0.0416,  0.1206]])), ('lin1.bias', tensor([-0.3940,  0.1135, -0.3711, -0.3775])), ('lin2.weight', tensor([[-0.2047,  0.4730, -0.2103,  0.3947],\n",
      "        [-0.0433, -0.2648, -0.0712, -0.2411],\n",
      "        [-0.4701,  0.3496, -0.3743,  0.0925]])), ('lin2.bias', tensor([0.2972, 0.3786, 0.2994])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.6645,  0.6609],\n",
      "        [ 0.2586,  0.2209]])), ('convs.0.convs.0.conv.lin.bias', tensor([ 0.0887, -0.2055])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.3708, -0.1533],\n",
      "        [ 0.6134,  0.0160]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([0.5317, 0.0766])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.4696, -0.4367],\n",
      "        [-0.5889,  0.5827]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[ 0.4859,  0.6535],\n",
      "        [-0.6304,  0.0403]])), ('convs.0.convs.1.conv.lin.bias', tensor([0.0865, 0.0040])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.6368, -0.4635],\n",
      "        [ 0.1639, -0.3047]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.1197,  0.2762])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.4359,  0.0326],\n",
      "        [ 0.4245,  0.4930]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[0.6940, 0.6152],\n",
      "        [0.6146, 0.3299]])), ('convs.1.convs.0.conv.lin.bias', tensor([ 0.2485, -0.1998])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.6355,  0.4466],\n",
      "        [ 0.4477, -0.2179]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([0.3169, 0.1624])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4535,  0.5972],\n",
      "        [-0.1743, -0.1211]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[-0.3193, -0.6671],\n",
      "        [-0.2486,  0.3719]])), ('convs.1.convs.1.conv.lin.bias', tensor([0.5384, 0.2680])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[0.6449, 0.2452],\n",
      "        [0.4373, 0.1137]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.6430, -0.6818])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.5420,  0.6524],\n",
      "        [-0.6849,  0.3167]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[ 0.3716,  0.6340],\n",
      "        [-0.5825, -0.5600]])), ('convs.2.convs.0.conv.lin.bias', tensor([-0.4420, -0.2456])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.5043,  0.5861],\n",
      "        [-0.6301,  0.6127]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([0.6290, 0.2795])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.6640, -0.6100],\n",
      "        [ 0.2668, -0.5979]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.3802,  0.0214],\n",
      "        [-0.4074,  0.0957]])), ('convs.2.convs.1.conv.lin.bias', tensor([-0.1669,  0.7050])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.0061,  0.5894],\n",
      "        [-0.3269, -0.5227]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.1823, -0.5924])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.3077,  0.5239],\n",
      "        [-0.2495, -0.6415]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.6538, -0.2305],\n",
      "        [ 0.6581,  0.0014]])), ('convs.3.convs.0.conv.lin.bias', tensor([0.1982, 0.6187])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[ 0.1079,  0.4582],\n",
      "        [ 0.5265, -0.3262]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([-0.0661, -0.2595])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[-0.3061,  0.1315],\n",
      "        [-0.4680, -0.0267]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-0.6318,  0.6856],\n",
      "        [ 0.1683,  0.6784]])), ('convs.3.convs.1.conv.lin.bias', tensor([-0.7043,  0.5854])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.0060, -0.2142],\n",
      "        [-0.0162,  0.1575]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([-0.4986, -0.6850])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[-0.4613,  0.5829],\n",
      "        [ 0.3847,  0.2717]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.1616, -0.0297, -0.2914, -0.1237,  0.0950, -0.3758],\n",
      "        [ 0.2269,  0.0857, -0.0738, -0.0268,  0.1446, -0.0932],\n",
      "        [-0.0878, -0.2951,  0.2103,  0.1879,  0.2232, -0.2305],\n",
      "        [ 0.2702, -0.2406,  0.1705,  0.1132, -0.2727, -0.1365]])), ('lin1.bias', tensor([0.0210, 0.2468, 0.3792, 0.0692])), ('lin2.weight', tensor([[ 0.2675, -0.2057,  0.0776, -0.2864],\n",
      "        [-0.3916, -0.0299, -0.3982,  0.3943],\n",
      "        [-0.0604, -0.4146, -0.2677,  0.4601]])), ('lin2.bias', tensor([-0.0860,  0.0098, -0.1651])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.7045, -0.2599],\n",
      "        [-0.3259, -0.2168]])), ('convs.0.convs.0.conv.lin.bias', tensor([0.2543, 0.5988])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.3785, -0.1994],\n",
      "        [-0.1810, -0.6404]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.2436, -0.5161])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.3965, -0.3102],\n",
      "        [ 0.4904,  0.0417]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.0705,  0.7005],\n",
      "        [ 0.3096, -0.5207]])), ('convs.0.convs.1.conv.lin.bias', tensor([0.0097, 0.3023])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.2387, -0.0947],\n",
      "        [ 0.5299, -0.1722]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.6025, -0.1467])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.0924, -0.1549],\n",
      "        [ 0.2293,  0.5404]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.6955, -0.5473],\n",
      "        [ 0.6008,  0.6682]])), ('convs.1.convs.0.conv.lin.bias', tensor([ 0.4527, -0.5982])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.5404, -0.4298],\n",
      "        [-0.1697,  0.6836]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.3193,  0.0610])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.5621,  0.5364],\n",
      "        [ 0.6895, -0.3135]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[-0.1106,  0.6785],\n",
      "        [ 0.6105,  0.3062]])), ('convs.1.convs.1.conv.lin.bias', tensor([ 0.5755, -0.4523])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.0242, -0.0461],\n",
      "        [-0.4484, -0.1332]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([0.5028, 0.3620])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.6482, -0.0105],\n",
      "        [ 0.3195, -0.3278]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[ 0.0363,  0.0972],\n",
      "        [-0.1784, -0.0842]])), ('convs.2.convs.0.conv.lin.bias', tensor([ 0.2071, -0.6478])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.3762, -0.0462],\n",
      "        [ 0.5397, -0.6189]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.0992,  0.2055])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2613, -0.4404],\n",
      "        [-0.2219,  0.5136]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.5690, -0.5911],\n",
      "        [ 0.3155,  0.6758]])), ('convs.2.convs.1.conv.lin.bias', tensor([ 0.3869, -0.6231])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1737, -0.4102],\n",
      "        [-0.3854, -0.3855]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.0633, -0.4132])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.3125,  0.5653],\n",
      "        [ 0.2572, -0.5434]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.4668,  0.5607],\n",
      "        [-0.1073, -0.1392]])), ('convs.3.convs.0.conv.lin.bias', tensor([-0.4396,  0.3556])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.4535,  0.1452],\n",
      "        [-0.0884, -0.5710]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([-0.4477,  0.2184])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.0798,  0.6763],\n",
      "        [ 0.3790, -0.4260]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-0.2610, -0.4074],\n",
      "        [ 0.2613,  0.2277]])), ('convs.3.convs.1.conv.lin.bias', tensor([-0.4812,  0.0095])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.4666, -0.3612],\n",
      "        [ 0.5306, -0.3997]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([-0.2743,  0.3491])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[-0.2932,  0.4886],\n",
      "        [ 0.4126, -0.5416]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevSAGEConvEncoder: 2-1                                    --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       160\n",
      "    RevSAGEConvEncoder: 2-2                                    --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       160\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.9463, 0.8265, 0.9463, 0.7676, 0.8265, 0.7676, 0.9537, 0.0070, 0.9537,\n",
      "        0.0070], grad_fn=<SigmoidBackward0>), tensor([[ 0.0217, -0.5808, -0.6471],\n",
      "        [-0.1565, -0.3782, -0.7486],\n",
      "        [-0.2426, -0.2807, -0.8282],\n",
      "        [-0.0333, -0.5322, -0.7049],\n",
      "        [-0.2112, -0.3178, -0.7947]], grad_fn=<AddmmBackward0>), tensor([[ 0.0386,  0.3309, -0.2778],\n",
      "        [-0.0344,  0.3586, -0.3603],\n",
      "        [ 0.1902,  0.2780, -0.0994],\n",
      "        [-0.0007,  0.3459, -0.3217],\n",
      "        [ 0.2512,  0.2558, -0.0292]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.8362, 0.8421, 0.8362, 0.9367, 0.8421, 0.9367, 0.9422, 0.6957, 0.9422,\n",
      "        0.6957], grad_fn=<SigmoidBackward0>), tensor([[ 0.0217, -0.5808, -0.6471],\n",
      "        [-0.1565, -0.3782, -0.7486],\n",
      "        [-0.2426, -0.2807, -0.8282],\n",
      "        [-0.0333, -0.5322, -0.7049],\n",
      "        [-0.2112, -0.3178, -0.7947]], grad_fn=<AddmmBackward0>), tensor([[ 0.0386,  0.3309, -0.2778],\n",
      "        [-0.0344,  0.3586, -0.3603],\n",
      "        [ 0.1902,  0.2780, -0.0994],\n",
      "        [-0.0007,  0.3459, -0.3217],\n",
      "        [ 0.2512,  0.2558, -0.0292]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[1.0000, 0.9678, 0.9356, 0.9953, 0.0395],\n",
      "        [0.9678, 0.9971, 0.0904, 0.7330, 0.5548],\n",
      "        [0.9356, 0.0904, 1.0000, 0.9996, 0.6016],\n",
      "        [0.9953, 0.7330, 0.9996, 0.9979, 0.3762],\n",
      "        [0.0395, 0.5548, 0.6016, 0.3762, 0.8081]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.8942, 0.9947, 0.0984, 0.9014, 0.8768],\n",
      "        [0.9947, 1.0000, 0.0200, 0.9970, 0.9897],\n",
      "        [0.0984, 0.0200, 0.9769, 0.4546, 0.0931],\n",
      "        [0.9014, 0.9970, 0.4546, 0.9993, 0.8430],\n",
      "        [0.8768, 0.9897, 0.0931, 0.8430, 0.8635]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.0530,  0.6442, -0.3057],\n",
      "        [-0.6909, -1.1539, -1.9754],\n",
      "        [-0.1127,  0.5095, -0.9332],\n",
      "        [-0.8270,  0.2692, -1.0242],\n",
      "        [-0.0862, -0.9248, -1.8476]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-0.6135,  0.7004,  0.1446],\n",
      "        [ 2.0828,  0.4054, -1.8591],\n",
      "        [-1.5276,  3.5569, -2.4061],\n",
      "        [-0.8325,  0.3508, -0.2412],\n",
      "        [ 1.4744, -2.5755, -0.9316]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[ 0.0217, -0.5808, -0.6471],\n",
      "        [-0.1565, -0.3782, -0.7486],\n",
      "        [-0.2426, -0.2807, -0.8282],\n",
      "        [-0.0333, -0.5322, -0.7049],\n",
      "        [-0.2112, -0.3178, -0.7947]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[ 0.0386,  0.3309, -0.2778],\n",
      "        [-0.0344,  0.3586, -0.3603],\n",
      "        [ 0.1902,  0.2780, -0.0994],\n",
      "        [-0.0007,  0.3459, -0.3217],\n",
      "        [ 0.2512,  0.2558, -0.0292]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[ 0.0217, -0.5808, -0.6471],\n",
      "        [-0.1565, -0.3782, -0.7486],\n",
      "        [-0.2426, -0.2807, -0.8282],\n",
      "        [-0.0333, -0.5322, -0.7049],\n",
      "        [-0.2112, -0.3178, -0.7947]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[ 0.0386,  0.3309, -0.2778],\n",
      "        [-0.0344,  0.3586, -0.3603],\n",
      "        [ 0.1902,  0.2780, -0.0994],\n",
      "        [-0.0007,  0.3459, -0.3217],\n",
      "        [ 0.2512,  0.2558, -0.0292]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.4391, 0.6383, 0.4391, 0.8653, 0.6383, 0.8653, 0.6789, 0.7669, 0.6789,\n",
      "        0.7669], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.6626, 0.1380, 0.6626, 0.3510, 0.1380, 0.3510, 0.2105, 0.4702, 0.2105,\n",
      "        0.4702], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.7199, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(2.6416, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.4, 0.5857142857142856)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.64, 0.7453968253968253)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[ 0.3142,  0.2760,  0.0094, -0.0630,  0.3681,  0.2995],\n",
      "        [ 0.1715,  0.0319,  0.1115, -0.0698, -0.3570, -0.0911],\n",
      "        [-0.1958,  0.0286, -0.0036,  0.0259, -0.3453, -0.3108],\n",
      "        [ 0.2468,  0.2419,  0.1855, -0.1068,  0.3353,  0.2833],\n",
      "        [ 0.0018, -0.2302, -0.0522,  0.0866,  0.3142, -0.3871]])), ('_encoder_mu.lin1.bias', tensor([-0.1801, -0.0721,  0.3093, -0.0487, -0.0372])), ('_encoder_mu.lin2.weight', tensor([[-0.0961, -0.3809, -0.4691,  0.4973],\n",
      "        [-0.1622, -0.4112, -0.2469,  0.1025],\n",
      "        [ 0.4168,  0.1020,  0.4167,  0.2519]])), ('_encoder_mu.lin2.bias', tensor([ 0.3896, -0.3803,  0.0154])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.lin.weight', tensor([[ 0.7564,  0.4922, -0.2655, -0.4942, -0.5699],\n",
      "        [ 0.5620, -0.0008,  0.4232, -0.5586, -0.3273],\n",
      "        [-0.0854,  0.3930, -0.4185,  0.0631, -0.2304],\n",
      "        [-0.4416,  0.5746, -0.4865,  0.5623,  0.1697],\n",
      "        [ 0.4651,  0.1806, -0.3298, -0.2760,  0.6452]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.lin.weight', tensor([[ 0.4930, -0.6003,  0.4032,  0.6310,  0.4407],\n",
      "        [ 0.5313,  0.1569, -0.5698, -0.7540,  0.0800],\n",
      "        [-0.0699,  0.7252, -0.6202,  0.0314, -0.6124],\n",
      "        [-0.1695,  0.0957,  0.6767, -0.2099,  0.3170],\n",
      "        [-0.2938,  0.7078,  0.6569, -0.4994, -0.5187]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.lin.weight', tensor([[ 0.6878,  0.0724,  0.3486,  0.4503, -0.5801],\n",
      "        [-0.4733, -0.3077, -0.3972, -0.7463,  0.4176],\n",
      "        [ 0.5712, -0.6648, -0.7041, -0.0144, -0.2888],\n",
      "        [ 0.7136,  0.5515, -0.3994,  0.4544, -0.3413]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.lin.weight', tensor([[ 0.6357, -0.4123,  0.7816, -0.2610],\n",
      "        [-0.4710,  0.0231, -0.0639, -0.1781],\n",
      "        [ 0.5039,  0.5401, -0.2360, -0.0743],\n",
      "        [ 0.0985,  0.1247, -0.1124,  0.0957]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.0418,  0.2155, -0.2894,  0.1664,  0.1093, -0.4017],\n",
      "        [ 0.1638, -0.3475,  0.2229, -0.3455,  0.2626, -0.0451],\n",
      "        [ 0.2215, -0.3398, -0.2418, -0.0975,  0.0014, -0.3216],\n",
      "        [-0.3635,  0.3070, -0.3034,  0.1655, -0.2382,  0.0607],\n",
      "        [-0.1632, -0.2058, -0.3026,  0.0964,  0.2678, -0.1258]])), ('_encoder_logstd.lin1.bias', tensor([ 0.3562, -0.1095, -0.2451, -0.1593, -0.3058])), ('_encoder_logstd.lin2.weight', tensor([[-0.0830,  0.2589, -0.1941, -0.0036],\n",
      "        [-0.1547, -0.2133,  0.3024, -0.3279],\n",
      "        [ 0.2522, -0.4585, -0.4188,  0.0612]])), ('_encoder_logstd.lin2.bias', tensor([ 0.0870, -0.3255, -0.3077])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.lin.weight', tensor([[ 0.1086, -0.3446, -0.4164, -0.3563, -0.6259],\n",
      "        [-0.0208,  0.4534, -0.7587,  0.0807,  0.0416],\n",
      "        [ 0.1186,  0.4302,  0.2241,  0.1731, -0.2257],\n",
      "        [ 0.4370, -0.4664, -0.6747, -0.5869, -0.0870],\n",
      "        [ 0.1540,  0.3702, -0.5755, -0.6107,  0.5049]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.lin.weight', tensor([[ 0.3223, -0.1458,  0.6132, -0.6644,  0.1618],\n",
      "        [ 0.3198,  0.3397, -0.4035,  0.5889, -0.1647],\n",
      "        [-0.3415, -0.4771, -0.2017, -0.5805, -0.3304],\n",
      "        [-0.1616, -0.0887,  0.6887,  0.3053, -0.7607],\n",
      "        [ 0.4627,  0.7578,  0.4376, -0.5557, -0.1618]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.lin.weight', tensor([[ 0.1191, -0.1524, -0.7371,  0.1575, -0.0669],\n",
      "        [-0.3200,  0.0745,  0.0802,  0.5812,  0.0588],\n",
      "        [-0.7549, -0.6215, -0.7951, -0.7854, -0.2681],\n",
      "        [-0.3468,  0.6369, -0.5233,  0.3277,  0.3674]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.lin.weight', tensor([[ 8.4100e-02,  6.3826e-01,  6.2542e-04, -7.3367e-01],\n",
      "        [ 2.4768e-01,  5.4385e-01,  8.5628e-03,  3.0154e-01],\n",
      "        [-3.8297e-01,  5.7754e-01,  1.5112e-01,  3.4899e-02],\n",
      "        [-2.2673e-01, -5.3535e-01,  6.6603e-01, -4.6742e-01]]))]), 'constructor_params': {'encoder_logstd_given': False, 'shared_encoder_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0418,  0.2155, -0.2894,  0.1664,  0.1093, -0.4017],\n",
      "        [ 0.1638, -0.3475,  0.2229, -0.3455,  0.2626, -0.0451],\n",
      "        [ 0.2215, -0.3398, -0.2418, -0.0975,  0.0014, -0.3216],\n",
      "        [-0.3635,  0.3070, -0.3034,  0.1655, -0.2382,  0.0607],\n",
      "        [-0.1632, -0.2058, -0.3026,  0.0964,  0.2678, -0.1258]])), ('lin1.bias', tensor([ 0.3562, -0.1095, -0.2451, -0.1593, -0.3058])), ('lin2.weight', tensor([[-0.0830,  0.2589, -0.1941, -0.0036],\n",
      "        [-0.1547, -0.2133,  0.3024, -0.3279],\n",
      "        [ 0.2522, -0.4585, -0.4188,  0.0612]])), ('lin2.bias', tensor([ 0.0870, -0.3255, -0.3077])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[ 0.1086, -0.3446, -0.4164, -0.3563, -0.6259],\n",
      "        [-0.0208,  0.4534, -0.7587,  0.0807,  0.0416],\n",
      "        [ 0.1186,  0.4302,  0.2241,  0.1731, -0.2257],\n",
      "        [ 0.4370, -0.4664, -0.6747, -0.5869, -0.0870],\n",
      "        [ 0.1540,  0.3702, -0.5755, -0.6107,  0.5049]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.3223, -0.1458,  0.6132, -0.6644,  0.1618],\n",
      "        [ 0.3198,  0.3397, -0.4035,  0.5889, -0.1647],\n",
      "        [-0.3415, -0.4771, -0.2017, -0.5805, -0.3304],\n",
      "        [-0.1616, -0.0887,  0.6887,  0.3053, -0.7607],\n",
      "        [ 0.4627,  0.7578,  0.4376, -0.5557, -0.1618]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.1191, -0.1524, -0.7371,  0.1575, -0.0669],\n",
      "        [-0.3200,  0.0745,  0.0802,  0.5812,  0.0588],\n",
      "        [-0.7549, -0.6215, -0.7951, -0.7854, -0.2681],\n",
      "        [-0.3468,  0.6369, -0.5233,  0.3277,  0.3674]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 8.4100e-02,  6.3826e-01,  6.2542e-04, -7.3367e-01],\n",
      "        [ 2.4768e-01,  5.4385e-01,  8.5628e-03,  3.0154e-01],\n",
      "        [-3.8297e-01,  5.7754e-01,  1.5112e-01,  3.4899e-02],\n",
      "        [-2.2673e-01, -5.3535e-01,  6.6603e-01, -4.6742e-01]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.3142,  0.2760,  0.0094, -0.0630,  0.3681,  0.2995],\n",
      "        [ 0.1715,  0.0319,  0.1115, -0.0698, -0.3570, -0.0911],\n",
      "        [-0.1958,  0.0286, -0.0036,  0.0259, -0.3453, -0.3108],\n",
      "        [ 0.2468,  0.2419,  0.1855, -0.1068,  0.3353,  0.2833],\n",
      "        [ 0.0018, -0.2302, -0.0522,  0.0866,  0.3142, -0.3871]])), ('lin1.bias', tensor([-0.1801, -0.0721,  0.3093, -0.0487, -0.0372])), ('lin2.weight', tensor([[-0.0961, -0.3809, -0.4691,  0.4973],\n",
      "        [-0.1622, -0.4112, -0.2469,  0.1025],\n",
      "        [ 0.4168,  0.1020,  0.4167,  0.2519]])), ('lin2.bias', tensor([ 0.3896, -0.3803,  0.0154])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[ 0.7564,  0.4922, -0.2655, -0.4942, -0.5699],\n",
      "        [ 0.5620, -0.0008,  0.4232, -0.5586, -0.3273],\n",
      "        [-0.0854,  0.3930, -0.4185,  0.0631, -0.2304],\n",
      "        [-0.4416,  0.5746, -0.4865,  0.5623,  0.1697],\n",
      "        [ 0.4651,  0.1806, -0.3298, -0.2760,  0.6452]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.4930, -0.6003,  0.4032,  0.6310,  0.4407],\n",
      "        [ 0.5313,  0.1569, -0.5698, -0.7540,  0.0800],\n",
      "        [-0.0699,  0.7252, -0.6202,  0.0314, -0.6124],\n",
      "        [-0.1695,  0.0957,  0.6767, -0.2099,  0.3170],\n",
      "        [-0.2938,  0.7078,  0.6569, -0.4994, -0.5187]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.6878,  0.0724,  0.3486,  0.4503, -0.5801],\n",
      "        [-0.4733, -0.3077, -0.3972, -0.7463,  0.4176],\n",
      "        [ 0.5712, -0.6648, -0.7041, -0.0144, -0.2888],\n",
      "        [ 0.7136,  0.5515, -0.3994,  0.4544, -0.3413]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 0.6357, -0.4123,  0.7816, -0.2610],\n",
      "        [-0.4710,  0.0231, -0.0639, -0.1781],\n",
      "        [ 0.5039,  0.5401, -0.2360, -0.0743],\n",
      "        [ 0.0985,  0.1247, -0.1124,  0.0957]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "VGEncoder: 1-1                                        --\n",
      "    SimpleGCNEncoder: 2-1                            --\n",
      "        Linear: 3-1                                 35\n",
      "        Linear: 3-2                                 15\n",
      "        LayerNorm: 3-3                              8\n",
      "        ModuleList: 3-4                             142\n",
      "    SimpleGCNEncoder: 2-2                            --\n",
      "        Linear: 3-5                                 35\n",
      "        Linear: 3-6                                 15\n",
      "        LayerNorm: 3-7                              8\n",
      "        ModuleList: 3-8                             142\n",
      "InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "forward() original\n",
      "(tensor([0.0275, 0.1384, 0.0275, 0.5472, 0.1384, 0.5472, 0.3076, 0.5660, 0.3076,\n",
      "        0.5660], grad_fn=<SigmoidBackward0>), tensor([[ 0.2056, -0.5737,  0.5444],\n",
      "        [ 0.2090, -0.5726,  0.5439],\n",
      "        [ 0.2191, -0.5691,  0.5418],\n",
      "        [ 0.2368, -0.5655,  0.5444],\n",
      "        [ 0.2318, -0.5613,  0.5319]], grad_fn=<AddmmBackward0>), tensor([[ 0.2464, -0.3058, -1.0410],\n",
      "        [ 0.2485, -0.3065, -1.0451],\n",
      "        [ 0.2529, -0.3079, -1.0533],\n",
      "        [ 0.2597, -0.3105, -1.0653],\n",
      "        [ 0.2576, -0.3097, -1.0617]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.6452, 0.5853, 0.6452, 0.0945, 0.5853, 0.0945, 0.8207, 0.9396, 0.8207,\n",
      "        0.9396], grad_fn=<SigmoidBackward0>), tensor([[ 0.2056, -0.5737,  0.5444],\n",
      "        [ 0.2090, -0.5726,  0.5439],\n",
      "        [ 0.2191, -0.5691,  0.5418],\n",
      "        [ 0.2368, -0.5655,  0.5444],\n",
      "        [ 0.2318, -0.5613,  0.5319]], grad_fn=<AddmmBackward0>), tensor([[ 0.2464, -0.3058, -1.0410],\n",
      "        [ 0.2485, -0.3065, -1.0451],\n",
      "        [ 0.2529, -0.3079, -1.0533],\n",
      "        [ 0.2597, -0.3105, -1.0653],\n",
      "        [ 0.2576, -0.3097, -1.0617]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.9252, 0.4369, 0.5629, 0.8324, 0.4342],\n",
      "        [0.4369, 0.6830, 0.5698, 0.7337, 0.6854],\n",
      "        [0.5629, 0.5698, 0.5395, 0.6583, 0.5648],\n",
      "        [0.8324, 0.7337, 0.6583, 0.9477, 0.7287],\n",
      "        [0.4342, 0.6854, 0.5648, 0.7287, 0.7057]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.9709, 0.7844, 0.6919, 0.5479, 0.4822],\n",
      "        [0.7844, 0.9295, 0.1679, 0.8855, 0.8310],\n",
      "        [0.6919, 0.1679, 0.9643, 0.2513, 0.2545],\n",
      "        [0.5479, 0.8855, 0.2513, 0.8969, 0.8458],\n",
      "        [0.4822, 0.8310, 0.2545, 0.8458, 0.7963]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-1.5545, -1.4821,  0.9195],\n",
      "        [-0.3127,  0.2035,  0.2409],\n",
      "        [-0.2979, -1.7131,  0.2520],\n",
      "        [-2.1386, -1.5734,  0.6208],\n",
      "        [ 0.9124, -0.2766,  0.8820]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-1.5041,  0.4774,  0.6002],\n",
      "        [ 0.9234,  0.1793,  0.2447],\n",
      "        [-0.0975, -0.6068,  0.8969],\n",
      "        [-1.6740, -1.4509,  0.4788],\n",
      "        [ 1.9232, -0.5006,  0.6800]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[ 0.2056, -0.5737,  0.5444],\n",
      "        [ 0.2090, -0.5726,  0.5439],\n",
      "        [ 0.2191, -0.5691,  0.5418],\n",
      "        [ 0.2368, -0.5655,  0.5444],\n",
      "        [ 0.2318, -0.5613,  0.5319]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[ 0.2464, -0.3058, -1.0410],\n",
      "        [ 0.2485, -0.3065, -1.0451],\n",
      "        [ 0.2529, -0.3079, -1.0533],\n",
      "        [ 0.2597, -0.3105, -1.0653],\n",
      "        [ 0.2576, -0.3097, -1.0617]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[ 0.2056, -0.5737,  0.5444],\n",
      "        [ 0.2090, -0.5726,  0.5439],\n",
      "        [ 0.2191, -0.5691,  0.5418],\n",
      "        [ 0.2368, -0.5655,  0.5444],\n",
      "        [ 0.2318, -0.5613,  0.5319]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[ 0.2464, -0.3058, -1.0410],\n",
      "        [ 0.2485, -0.3065, -1.0451],\n",
      "        [ 0.2529, -0.3079, -1.0533],\n",
      "        [ 0.2597, -0.3105, -1.0653],\n",
      "        [ 0.2576, -0.3097, -1.0617]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.1516, 0.8649, 0.1516, 0.3428, 0.8649, 0.3428, 0.3844, 0.5200, 0.3844,\n",
      "        0.5200], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.3941, 0.2406, 0.3941, 0.9046, 0.2406, 0.9046, 0.7289, 0.9372, 0.7289,\n",
      "        0.9372], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.3815, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(1.3564, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.6, 0.6944444444444444)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.15999999999999998, 0.3923809523809524)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.2516, -0.1645, -0.2592,  0.0240,  0.1025,  0.2756],\n",
      "        [-0.2989, -0.0847,  0.2901,  0.1627,  0.3336, -0.2555],\n",
      "        [ 0.3543, -0.0250,  0.2521, -0.3244, -0.0561,  0.1089],\n",
      "        [ 0.3748, -0.0446, -0.3135,  0.2894,  0.0999, -0.2270],\n",
      "        [-0.1788, -0.0763,  0.2884, -0.1308,  0.1603,  0.1906]])), ('_encoder_mu.lin1.bias', tensor([-1.6438e-01,  1.6703e-01,  3.6699e-01,  2.2486e-01, -2.8947e-04])), ('_encoder_mu.lin2.weight', tensor([[-0.1880,  0.1047,  0.4054,  0.1233,  0.1074],\n",
      "        [ 0.3237,  0.0813,  0.1580, -0.1758,  0.3511],\n",
      "        [ 0.4350, -0.3425,  0.3524,  0.0775, -0.0647]])), ('_encoder_mu.lin2.bias', tensor([-0.2126,  0.3009,  0.4003])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.weight1', tensor([[-0.6821, -0.3787, -0.1004,  0.4238, -0.3712],\n",
      "        [-0.4855,  0.2473,  0.0289, -0.3154,  0.6306],\n",
      "        [ 0.5619, -0.6216,  0.2040, -0.4208,  0.6562],\n",
      "        [-0.7046,  0.3143,  0.4771, -0.3719, -0.3534],\n",
      "        [ 0.0671,  0.5638, -0.0520,  0.6718,  0.0946]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.weight1', tensor([[-0.5771, -0.1979,  0.1111, -0.1402,  0.5065],\n",
      "        [ 0.7676, -0.1444, -0.4282,  0.3362, -0.3863],\n",
      "        [-0.6256, -0.3562,  0.1973, -0.5420,  0.2349],\n",
      "        [ 0.3128,  0.7643,  0.2024,  0.1272,  0.1601],\n",
      "        [-0.7364,  0.5952, -0.2973,  0.4369, -0.5802]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.weight1', tensor([[-0.2698,  0.2757, -0.4254, -0.0339, -0.5121],\n",
      "        [-0.1893, -0.2580, -0.1178, -0.6500,  0.0345],\n",
      "        [ 0.3912,  0.1840,  0.6772, -0.0065,  0.3192],\n",
      "        [ 0.1768,  0.6333,  0.6546, -0.1757,  0.2201],\n",
      "        [-0.6811,  0.7299, -0.2323, -0.6811,  0.2058]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.weight1', tensor([[-0.7035, -0.4449,  0.2996,  0.6927, -0.5951],\n",
      "        [ 0.5996,  0.5832, -0.5781, -0.4323,  0.1008],\n",
      "        [-0.0798, -0.0329,  0.1505,  0.6643, -0.4729],\n",
      "        [ 0.6537, -0.3205, -0.4560,  0.3768,  0.7308],\n",
      "        [ 0.5836,  0.2125,  0.0339, -0.5830,  0.4331]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.1396, -0.3351,  0.0378,  0.3725,  0.3057,  0.0937],\n",
      "        [-0.0762, -0.2693,  0.1834, -0.3382,  0.3846,  0.1749],\n",
      "        [-0.1908,  0.2765,  0.2673,  0.1382, -0.0222,  0.3161],\n",
      "        [ 0.1006,  0.1156, -0.2576, -0.3397,  0.0468, -0.0698],\n",
      "        [-0.2907,  0.0990,  0.1761,  0.1878,  0.2140, -0.2798]])), ('_encoder_logstd.lin1.bias', tensor([-0.0814, -0.2271,  0.0467, -0.1386,  0.3207])), ('_encoder_logstd.lin2.weight', tensor([[-0.3498,  0.1180,  0.3140, -0.0423, -0.2330],\n",
      "        [-0.3007,  0.0528,  0.4283, -0.3102,  0.1585],\n",
      "        [-0.3170,  0.0860,  0.2235,  0.1120, -0.0769]])), ('_encoder_logstd.lin2.bias', tensor([-0.3172, -0.3717, -0.1767])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.weight1', tensor([[-0.0770,  0.3180, -0.6170,  0.7317,  0.5734],\n",
      "        [-0.6646, -0.2133, -0.7020,  0.7623, -0.2234],\n",
      "        [-0.6840,  0.5075, -0.7086,  0.2071, -0.2334],\n",
      "        [ 0.1092,  0.6197, -0.1055,  0.1218,  0.7284],\n",
      "        [-0.0236,  0.4563, -0.7477,  0.0336,  0.1228]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.weight1', tensor([[-0.6274,  0.6747, -0.3140,  0.2784, -0.7428],\n",
      "        [-0.7701,  0.2807, -0.2807, -0.5486, -0.5418],\n",
      "        [-0.1886, -0.2866, -0.5720, -0.7041,  0.1269],\n",
      "        [-0.4169, -0.1180, -0.4764, -0.7662, -0.4630],\n",
      "        [ 0.5966,  0.1295, -0.7378, -0.1233, -0.4498]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.weight1', tensor([[ 0.0686,  0.1437, -0.2126, -0.2823,  0.4695],\n",
      "        [-0.2108,  0.6286,  0.2836,  0.3347, -0.0693],\n",
      "        [ 0.3600, -0.6539,  0.3391, -0.0760,  0.5443],\n",
      "        [-0.5141,  0.2608, -0.6016, -0.3208,  0.4732],\n",
      "        [-0.1298, -0.3779, -0.5667,  0.7738,  0.1737]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.weight1', tensor([[-0.0738,  0.7189,  0.0403,  0.5819,  0.3193],\n",
      "        [ 0.4333, -0.3289, -0.0958,  0.2523, -0.4917],\n",
      "        [ 0.0333, -0.5316, -0.2806,  0.6901, -0.5153],\n",
      "        [-0.4218, -0.3253,  0.3483, -0.5633,  0.5679],\n",
      "        [-0.5629,  0.0382,  0.3570,  0.0030,  0.1820]]))]), 'constructor_params': {'encoder_logstd_given': False, 'shared_encoder_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.1396, -0.3351,  0.0378,  0.3725,  0.3057,  0.0937],\n",
      "        [-0.0762, -0.2693,  0.1834, -0.3382,  0.3846,  0.1749],\n",
      "        [-0.1908,  0.2765,  0.2673,  0.1382, -0.0222,  0.3161],\n",
      "        [ 0.1006,  0.1156, -0.2576, -0.3397,  0.0468, -0.0698],\n",
      "        [-0.2907,  0.0990,  0.1761,  0.1878,  0.2140, -0.2798]])), ('lin1.bias', tensor([-0.0814, -0.2271,  0.0467, -0.1386,  0.3207])), ('lin2.weight', tensor([[-0.3498,  0.1180,  0.3140, -0.0423, -0.2330],\n",
      "        [-0.3007,  0.0528,  0.4283, -0.3102,  0.1585],\n",
      "        [-0.3170,  0.0860,  0.2235,  0.1120, -0.0769]])), ('lin2.bias', tensor([-0.3172, -0.3717, -0.1767])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[-0.0770,  0.3180, -0.6170,  0.7317,  0.5734],\n",
      "        [-0.6646, -0.2133, -0.7020,  0.7623, -0.2234],\n",
      "        [-0.6840,  0.5075, -0.7086,  0.2071, -0.2334],\n",
      "        [ 0.1092,  0.6197, -0.1055,  0.1218,  0.7284],\n",
      "        [-0.0236,  0.4563, -0.7477,  0.0336,  0.1228]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.6274,  0.6747, -0.3140,  0.2784, -0.7428],\n",
      "        [-0.7701,  0.2807, -0.2807, -0.5486, -0.5418],\n",
      "        [-0.1886, -0.2866, -0.5720, -0.7041,  0.1269],\n",
      "        [-0.4169, -0.1180, -0.4764, -0.7662, -0.4630],\n",
      "        [ 0.5966,  0.1295, -0.7378, -0.1233, -0.4498]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[ 0.0686,  0.1437, -0.2126, -0.2823,  0.4695],\n",
      "        [-0.2108,  0.6286,  0.2836,  0.3347, -0.0693],\n",
      "        [ 0.3600, -0.6539,  0.3391, -0.0760,  0.5443],\n",
      "        [-0.5141,  0.2608, -0.6016, -0.3208,  0.4732],\n",
      "        [-0.1298, -0.3779, -0.5667,  0.7738,  0.1737]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.0738,  0.7189,  0.0403,  0.5819,  0.3193],\n",
      "        [ 0.4333, -0.3289, -0.0958,  0.2523, -0.4917],\n",
      "        [ 0.0333, -0.5316, -0.2806,  0.6901, -0.5153],\n",
      "        [-0.4218, -0.3253,  0.3483, -0.5633,  0.5679],\n",
      "        [-0.5629,  0.0382,  0.3570,  0.0030,  0.1820]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2516, -0.1645, -0.2592,  0.0240,  0.1025,  0.2756],\n",
      "        [-0.2989, -0.0847,  0.2901,  0.1627,  0.3336, -0.2555],\n",
      "        [ 0.3543, -0.0250,  0.2521, -0.3244, -0.0561,  0.1089],\n",
      "        [ 0.3748, -0.0446, -0.3135,  0.2894,  0.0999, -0.2270],\n",
      "        [-0.1788, -0.0763,  0.2884, -0.1308,  0.1603,  0.1906]])), ('lin1.bias', tensor([-1.6438e-01,  1.6703e-01,  3.6699e-01,  2.2486e-01, -2.8947e-04])), ('lin2.weight', tensor([[-0.1880,  0.1047,  0.4054,  0.1233,  0.1074],\n",
      "        [ 0.3237,  0.0813,  0.1580, -0.1758,  0.3511],\n",
      "        [ 0.4350, -0.3425,  0.3524,  0.0775, -0.0647]])), ('lin2.bias', tensor([-0.2126,  0.3009,  0.4003])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[-0.6821, -0.3787, -0.1004,  0.4238, -0.3712],\n",
      "        [-0.4855,  0.2473,  0.0289, -0.3154,  0.6306],\n",
      "        [ 0.5619, -0.6216,  0.2040, -0.4208,  0.6562],\n",
      "        [-0.7046,  0.3143,  0.4771, -0.3719, -0.3534],\n",
      "        [ 0.0671,  0.5638, -0.0520,  0.6718,  0.0946]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.5771, -0.1979,  0.1111, -0.1402,  0.5065],\n",
      "        [ 0.7676, -0.1444, -0.4282,  0.3362, -0.3863],\n",
      "        [-0.6256, -0.3562,  0.1973, -0.5420,  0.2349],\n",
      "        [ 0.3128,  0.7643,  0.2024,  0.1272,  0.1601],\n",
      "        [-0.7364,  0.5952, -0.2973,  0.4369, -0.5802]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[-0.2698,  0.2757, -0.4254, -0.0339, -0.5121],\n",
      "        [-0.1893, -0.2580, -0.1178, -0.6500,  0.0345],\n",
      "        [ 0.3912,  0.1840,  0.6772, -0.0065,  0.3192],\n",
      "        [ 0.1768,  0.6333,  0.6546, -0.1757,  0.2201],\n",
      "        [-0.6811,  0.7299, -0.2323, -0.6811,  0.2058]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.7035, -0.4449,  0.2996,  0.6927, -0.5951],\n",
      "        [ 0.5996,  0.5832, -0.5781, -0.4323,  0.1008],\n",
      "        [-0.0798, -0.0329,  0.1505,  0.6643, -0.4729],\n",
      "        [ 0.6537, -0.3205, -0.4560,  0.3768,  0.7308],\n",
      "        [ 0.5836,  0.2125,  0.0339, -0.5830,  0.4331]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "VGEncoder: 1-1                                   --\n",
      "    ResGCN2ConvEncoder: 2-1                     --\n",
      "        Linear: 3-1                            35\n",
      "        Linear: 3-2                            18\n",
      "        LayerNorm: 3-3                         10\n",
      "        ModuleList: 3-4                        140\n",
      "    ResGCN2ConvEncoder: 2-2                     --\n",
      "        Linear: 3-5                            35\n",
      "        Linear: 3-6                            18\n",
      "        LayerNorm: 3-7                         10\n",
      "        ModuleList: 3-8                        140\n",
      "InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "forward() original\n",
      "(tensor([0.5614, 0.6035, 0.5614, 0.3900, 0.6035, 0.3900, 0.2641, 0.4899, 0.2641,\n",
      "        0.4899], grad_fn=<SigmoidBackward0>), tensor([[0.1742, 0.1199, 0.6880],\n",
      "        [0.1729, 0.1252, 0.6880],\n",
      "        [0.1679, 0.1489, 0.6937],\n",
      "        [0.1408, 0.2185, 0.7119],\n",
      "        [0.1771, 0.1508, 0.7061]], grad_fn=<AddmmBackward0>), tensor([[-0.6571, -1.0497, -0.3199],\n",
      "        [-0.6552, -1.0496, -0.3173],\n",
      "        [-0.6463, -1.0497, -0.3054],\n",
      "        [-0.6264, -1.0476, -0.2797],\n",
      "        [-0.6446, -1.0504, -0.3026]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.5711, 0.4978, 0.5711, 0.7089, 0.4978, 0.7089, 0.6574, 0.9118, 0.6574,\n",
      "        0.9118], grad_fn=<SigmoidBackward0>), tensor([[0.1742, 0.1199, 0.6880],\n",
      "        [0.1729, 0.1252, 0.6880],\n",
      "        [0.1679, 0.1489, 0.6937],\n",
      "        [0.1408, 0.2185, 0.7119],\n",
      "        [0.1771, 0.1508, 0.7061]], grad_fn=<AddmmBackward0>), tensor([[-0.6571, -1.0497, -0.3199],\n",
      "        [-0.6552, -1.0496, -0.3173],\n",
      "        [-0.6463, -1.0497, -0.3054],\n",
      "        [-0.6264, -1.0476, -0.2797],\n",
      "        [-0.6446, -1.0504, -0.3026]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7525, 0.6030, 0.5101, 0.6737, 0.4218],\n",
      "        [0.6030, 0.5904, 0.4222, 0.6032, 0.4304],\n",
      "        [0.5101, 0.4222, 0.7057, 0.5656, 0.4796],\n",
      "        [0.6737, 0.6032, 0.5656, 0.7677, 0.3210],\n",
      "        [0.4218, 0.4304, 0.4796, 0.3210, 0.6255]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.8366, 0.9170, 0.4268, 0.6981, 0.6184],\n",
      "        [0.9170, 0.9933, 0.2167, 0.9321, 0.9139],\n",
      "        [0.4268, 0.2167, 0.6499, 0.2718, 0.2717],\n",
      "        [0.6981, 0.9321, 0.2718, 0.8524, 0.8564],\n",
      "        [0.6184, 0.9139, 0.2717, 0.8564, 0.8868]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.1614,  0.4923, -0.7001],\n",
      "        [-0.1562,  0.2447, -0.8340],\n",
      "        [ 0.4852,  0.1296,  0.1582],\n",
      "        [-0.1812,  0.5652,  1.8170],\n",
      "        [ 0.9065,  0.5320,  1.3286]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[ 0.0418,  0.9124,  0.7123],\n",
      "        [ 0.5056,  0.2844, -0.1128],\n",
      "        [ 0.0883,  0.0412,  0.7838],\n",
      "        [ 0.0503, -0.1624,  1.3188],\n",
      "        [-0.2706, -0.1914,  0.8937]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[0.1742, 0.1199, 0.6880],\n",
      "        [0.1729, 0.1252, 0.6880],\n",
      "        [0.1679, 0.1489, 0.6937],\n",
      "        [0.1408, 0.2185, 0.7119],\n",
      "        [0.1771, 0.1508, 0.7061]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.6571, -1.0497, -0.3199],\n",
      "        [-0.6552, -1.0496, -0.3173],\n",
      "        [-0.6463, -1.0497, -0.3054],\n",
      "        [-0.6264, -1.0476, -0.2797],\n",
      "        [-0.6446, -1.0504, -0.3026]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[0.1742, 0.1199, 0.6880],\n",
      "        [0.1729, 0.1252, 0.6880],\n",
      "        [0.1679, 0.1489, 0.6937],\n",
      "        [0.1408, 0.2185, 0.7119],\n",
      "        [0.1771, 0.1508, 0.7061]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.6571, -1.0497, -0.3199],\n",
      "        [-0.6552, -1.0496, -0.3173],\n",
      "        [-0.6463, -1.0497, -0.3054],\n",
      "        [-0.6264, -1.0476, -0.2797],\n",
      "        [-0.6446, -1.0504, -0.3026]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.4004, 0.3960, 0.4004, 0.6031, 0.3960, 0.6031, 0.8754, 0.8422, 0.8754,\n",
      "        0.8422], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.5220, 0.7176, 0.5220, 0.5184, 0.7176, 0.5184, 0.6960, 0.8049, 0.6960,\n",
      "        0.8049], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4068, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(1.2319, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.12, 0.38769841269841265)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.76, 0.7683333333333333)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(shared_encoder=gat_enc, encoder_mu=GATConvBlock(in_channels=3, out_channels=3, heads=2, edge_dim=1), encoder_logstd=GATConvBlock(out_channels=3, in_channels=3, heads=3, edge_dim=1))\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, encoder_mu_constructor=GATConvBlock, shared_encoder_constructor=RevGATConvEncoder, encoder_logstd_constructor=GATConvBlock)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, RevSAGEConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, SimpleGCNEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, ResGCN2ConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate classifier and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevGAT encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MeanAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.4686, 0.5314]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevSAGE encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SumAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.5102, 0.4898]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "SimpleGCN encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.2793, 0.7207]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet LSTM aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): LSTMAggregation(3, 3)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.6780, 0.3220]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet softmax aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SoftmaxAggregation(learn=True)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.3955, 0.6045]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RevGAT encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gat_enc,\n",
    "    encoder_out_channels=gat_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='mean_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevSAGE encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=sage_enc,\n",
    "    encoder_out_channels=sage_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='add_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"SimpleGCN encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='max_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet LSTM aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='lstm'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet softmax aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='softmax'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classifier serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevGAT encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MeanAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.6518, 0.3482]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.6768, 0.3232]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevSAGE encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SumAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.3115, 0.6885]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.2497, 0.7503]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "SimpleGCN encoder protnet\n",
      "ProtMoveNet(\n",
      "  (_encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.5591, 0.4409]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.5146, 0.4854]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet LSTM aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): LSTMAggregation(3, 3)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.5296, 0.4704]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.5296, 0.4704]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet softmax aggregation\n",
      "ProtMoveNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SoftmaxAggregation(learn=True)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.4170, 0.5830]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.4170, 0.5830]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RevGAT encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gat_enc,\n",
    "    encoder_out_channels=gat_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='mean_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, RevGATConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevSAGE encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=sage_enc,\n",
    "    encoder_out_channels=sage_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='add_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, RevSAGEConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"SimpleGCN encoder protnet\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='max_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, SimpleGCNEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet LSTM aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='lstm'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet softmax aggregation\")\n",
    "protnet = ProtMoveNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='softmax'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMoveNet.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.4363,  0.2653,  1.9098,  ...,  1.3111,  0.2059, -0.1325],\n",
      "        [ 0.0431,  0.4697,  1.6860,  ...,  0.8487,  0.2626, -0.2183],\n",
      "        [-0.2741, -0.2785,  1.7406,  ...,  1.6063,  0.2670, -0.7520],\n",
      "        ...,\n",
      "        [-0.2805, -0.1890,  2.9499,  ...,  1.1430,  0.6847, -0.0286],\n",
      "        [-0.3335, -0.1602,  2.9652,  ...,  0.9711,  0.7076,  0.0332],\n",
      "        [-0.3646, -0.2827,  3.0414,  ...,  0.8908,  0.6895,  0.0691]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[ 1.5125e-01,  1.2289e-01,  8.5128e-02,  ..., -1.6853e-01,\n",
      "          1.0622e+00, -6.4612e-01],\n",
      "        [ 1.3586e-01,  2.2080e-01,  7.6670e-04,  ..., -1.3084e-01,\n",
      "          1.1202e+00, -6.6937e-01],\n",
      "        [-5.3260e-01,  3.4206e-01,  1.1395e-01,  ...,  1.7975e-01,\n",
      "          9.3618e-01, -8.2030e-01],\n",
      "        ...,\n",
      "        [-3.4503e-01,  2.3223e-01,  2.3209e-01,  ..., -2.3082e-01,\n",
      "          1.2660e+00, -4.7598e-01],\n",
      "        [-3.2718e-01,  2.3293e-01,  2.1378e-01,  ..., -2.4951e-01,\n",
      "          1.2628e+00, -4.5549e-01],\n",
      "        [-3.3010e-01,  2.5518e-01,  2.2584e-01,  ..., -2.5249e-01,\n",
      "          1.3257e+00, -5.2181e-01]], device='cuda:0', grad_fn=<AddmmBackward0>))\n",
      "(tensor([[ 0.4916,  0.8038,  0.0604,  ...,  0.4668,  0.1214, -0.1369],\n",
      "        [ 0.4667,  0.8448,  0.0657,  ...,  0.5732,  0.1596, -0.1858],\n",
      "        [ 0.5002,  0.9089,  0.0318,  ...,  0.4512,  0.1550, -0.1192],\n",
      "        ...,\n",
      "        [-0.2040,  2.1062,  0.2631,  ...,  0.0600,  0.6925, -0.2024],\n",
      "        [-0.2235,  2.0628,  0.1955,  ..., -0.0143,  0.6718, -0.2016],\n",
      "        [-0.1980,  1.9945,  0.1862,  ...,  0.0732,  0.6612, -0.2364]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[ 1.0965, -0.1144, -0.2287,  ..., -0.1691,  0.3645, -0.3040],\n",
      "        [ 1.1980, -0.1190, -0.2328,  ..., -0.1856,  0.4044, -0.2951],\n",
      "        [ 1.3829, -0.1419, -0.2734,  ..., -0.2374,  0.4049, -0.2767],\n",
      "        ...,\n",
      "        [ 0.7254, -0.0191, -0.3549,  ..., -0.6170,  0.1054,  0.9142],\n",
      "        [ 0.7242, -0.0212, -0.3655,  ..., -0.6100,  0.0798,  0.9036],\n",
      "        [ 0.7626, -0.0222, -0.3643,  ..., -0.6389,  0.0497,  0.9401]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>))\n",
      "(tensor([[-0.0863, -0.3214,  2.9515,  ...,  0.9609,  0.5592,  0.1402],\n",
      "        [-0.0363, -0.3019,  2.9436,  ...,  0.9828,  0.5502,  0.1582],\n",
      "        [ 0.0048, -0.2850,  2.9066,  ...,  0.9927,  0.5268,  0.1582],\n",
      "        ...,\n",
      "        [-0.2119,  1.8037,  0.7792,  ...,  0.1793,  0.7174, -0.1067],\n",
      "        [-0.2209,  1.8492,  0.7175,  ...,  0.1562,  0.7143, -0.1236],\n",
      "        [-0.2272,  1.9110,  0.6953,  ...,  0.1359,  0.7247, -0.1225]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-0.2623,  0.2010,  0.2172,  ..., -0.2573,  1.1789, -0.4920],\n",
      "        [-0.2198,  0.2326,  0.2357,  ..., -0.2734,  1.2843, -0.5524],\n",
      "        [-0.1882,  0.2426,  0.2413,  ..., -0.2822,  1.3384, -0.5967],\n",
      "        ...,\n",
      "        [ 0.5654,  0.0501, -0.2509,  ..., -0.5631,  0.3916,  0.6435],\n",
      "        [ 0.5766,  0.0388, -0.2630,  ..., -0.5700,  0.3653,  0.6679],\n",
      "        [ 0.6473,  0.0409, -0.2838,  ..., -0.6150,  0.3634,  0.7251]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>))\n",
      "(tensor([[-0.0065,  0.4213,  0.2206,  ...,  1.0072,  0.3484, -0.6184],\n",
      "        [-0.0697,  0.3273,  0.4073,  ...,  0.8140,  0.4128, -0.4687],\n",
      "        [-0.0453,  0.2804,  0.4085,  ...,  0.8428,  0.3932, -0.4741],\n",
      "        ...,\n",
      "        [-0.0656,  0.0520,  1.3343,  ...,  0.8182,  0.4527, -0.1687],\n",
      "        [-0.0650,  0.0353,  1.4317,  ...,  0.8165,  0.4737, -0.1352],\n",
      "        [-0.0729,  0.0219,  1.4056,  ...,  0.8193,  0.4528, -0.1601]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-0.5567,  0.3183,  0.2479,  ...,  0.1672, -0.2263, -0.0022],\n",
      "        [-0.6472,  0.3490,  0.1872,  ...,  0.1411, -0.1704, -0.1020],\n",
      "        [-0.6871,  0.3593,  0.1819,  ...,  0.1473, -0.1784, -0.1558],\n",
      "        ...,\n",
      "        [-0.2479,  0.2688,  0.1838,  ..., -0.0922,  0.7557, -0.3750],\n",
      "        [-0.2426,  0.2633,  0.1823,  ..., -0.0918,  0.7591, -0.3452],\n",
      "        [-0.2458,  0.2742,  0.1981,  ..., -0.0935,  0.8094, -0.3876]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>))\n",
      "(tensor([[ 1.1316,  0.3990,  1.4871,  ...,  1.0475, -0.0415,  0.2437],\n",
      "        [ 0.9544,  0.2903,  1.7739,  ...,  1.0801,  0.0653,  0.2361],\n",
      "        [ 0.9417,  0.2540,  1.8599,  ...,  1.3050,  0.0867,  0.1479],\n",
      "        ...,\n",
      "        [-0.0831,  0.2708,  0.4238,  ...,  0.7805,  0.3835, -0.4466],\n",
      "        [-0.1129,  0.2976,  0.4105,  ...,  0.7505,  0.4207, -0.4465],\n",
      "        [-0.0921,  0.2973,  0.4285,  ...,  0.8147,  0.4054, -0.4601]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[ 0.8823, -0.1020, -0.0188,  ..., -0.3413,  0.9163, -0.6396],\n",
      "        [ 0.8883, -0.0526,  0.0029,  ..., -0.3505,  1.1168, -0.7397],\n",
      "        [ 0.8747, -0.0319,  0.0331,  ..., -0.3370,  1.2176, -0.8057],\n",
      "        ...,\n",
      "        [-0.6054,  0.3290,  0.2213,  ...,  0.1498, -0.1244,  0.0077],\n",
      "        [-0.5924,  0.3262,  0.2252,  ...,  0.0987, -0.2167,  0.0352],\n",
      "        [-0.5723,  0.3476,  0.2360,  ...,  0.1333, -0.2096,  0.0192]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>))\n",
      "(tensor([[ 1.0965,  0.6900,  0.1488,  ...,  0.7803, -0.1523, -0.0051],\n",
      "        [ 1.2561,  0.7461,  0.0795,  ...,  1.0710, -0.1840, -0.0711],\n",
      "        [ 1.2234,  0.7357,  0.0219,  ...,  1.1467, -0.1863, -0.1459],\n",
      "        ...,\n",
      "        [ 1.6633,  0.7922,  0.1563,  ...,  0.8523, -0.3843,  0.2083],\n",
      "        [ 1.6751,  0.7492,  0.3187,  ...,  0.8858, -0.3906,  0.2347],\n",
      "        [ 1.5188,  0.7120,  0.5579,  ...,  1.0266, -0.2666,  0.1780]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[ 1.2302, -0.2288, -0.1919,  ..., -0.2074,  0.4061, -0.4794],\n",
      "        [ 1.3797, -0.2636, -0.1863,  ..., -0.2048,  0.4724, -0.5516],\n",
      "        [ 1.4097, -0.2575, -0.1825,  ..., -0.1751,  0.5019, -0.6028],\n",
      "        ...,\n",
      "        [ 1.4794, -0.3094, -0.2063,  ..., -0.3153,  0.4978, -0.5950],\n",
      "        [ 1.4034, -0.3084, -0.1899,  ..., -0.3190,  0.4916, -0.5773],\n",
      "        [ 1.4286, -0.2802, -0.1669,  ..., -0.3179,  0.6016, -0.6022]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>))\n",
      "(tensor([[ 0.1376,  0.4344,  0.2581,  ...,  0.5915,  0.2512, -0.2968],\n",
      "        [ 0.3187,  0.5156,  0.1969,  ...,  0.6350,  0.2126, -0.2274],\n",
      "        [ 0.3818,  0.5043,  0.1622,  ...,  0.9325,  0.1719, -0.3663],\n",
      "        ...,\n",
      "        [-0.0036,  0.2828,  0.4711,  ...,  0.9237,  0.3817, -0.5045],\n",
      "        [-0.0604,  0.0591,  0.8174,  ...,  1.0125,  0.2900, -0.4997],\n",
      "        [-0.0972,  0.0431,  1.0692,  ...,  0.8075,  0.4235, -0.2869]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[-0.3191,  0.2537,  0.1069,  ...,  0.0994, -0.1004, -0.0905],\n",
      "        [-0.0786,  0.1852,  0.0937,  ...,  0.0472, -0.0398, -0.1314],\n",
      "        [-0.1211,  0.1872,  0.1230,  ...,  0.1056,  0.0248, -0.2053],\n",
      "        ...,\n",
      "        [-0.5634,  0.2033,  0.1804,  ...,  0.0267, -0.0374, -0.0290],\n",
      "        [-0.5774,  0.3293,  0.1959,  ...,  0.1175,  0.3954, -0.4460],\n",
      "        [-0.4533,  0.3283,  0.0814,  ...,  0.0757,  0.4230, -0.4272]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.nn import Linear\n",
    "from models.layers import SerializableModule\n",
    "from torch.nn import ModuleList, LayerNorm\n",
    "from torch import Tensor\n",
    "from typing import Any, List, Optional\n",
    "from torch_geometric.nn.models import GroupAddRev\n",
    "import torch_geometric.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class RevResWrapper(SerializableModule):\n",
    "    def serialize_constructor_params(self, *args, **kwargs) -> dict:\n",
    "        pass\n",
    "\n",
    "    def __init__(self, rev_res_module: torch.nn.Module):\n",
    "        super().__init__()\n",
    "        self.rev_res_module_list_wrapper = ModuleList()\n",
    "\n",
    "        # This is the only fucking way to make it work, we are not sure why,\n",
    "        # but for some reason torch requires that the calls to rev res modules to be in a for loop, otherwise weird memory errors will be thrown on forward() call\n",
    "        for i in range(0, 1):\n",
    "            self.rev_res_module_list_wrapper.append(rev_res_module)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        for i  in range(0, 1):\n",
    "            output = None\n",
    "            for rev_res_module in self.rev_res_module_list_wrapper:\n",
    "                output = rev_res_module(*args, **kwargs)\n",
    "            return output\n",
    "\n",
    "\n",
    "class Giggino(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Giggino, self).__init__()\n",
    "        self.split_dim = -1\n",
    "        self.num_groups = 2\n",
    "        #self.convs = ModuleList([GATConvBlock(5, 5, heads=5), GATConvBlock(5, 5, heads=5)])\n",
    "        self.conv3 = GATConvBlock(10, 10, heads=5)\n",
    "        self.conv = VGEncoder(shared_encoder=RevGATConvEncoder(10, 10, 10, 2), encoder_mu=GATConvBlock(10, 10, heads=2), encoder_logstd=GATConvBlock(10, 10, heads=2))\n",
    "        self.conv2 = RevGATConvEncoder(10, 10, 10, 2)\n",
    "        self.conv5 = RevGATConvEncoder(10, 10, 10, 2)\n",
    "        self.conv3 = RevSAGEConvEncoder(10, 10, 10, 2)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        for i in range(0, 2):\n",
    "            self.convs.append(RevGATConvEncoder(10, 10, 10, 2))\n",
    "\n",
    "        self.conv4 = RevResWrapper(RevGATConvEncoder(10, 10, 10, 2))\n",
    "        self.ciao = nn.Linear(10, 10)\n",
    "        self.ciao4 = GCN2ConvBlock(10)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        ciao = x\n",
    "        ciao3 = ciao\n",
    "        # il prblema  creare due variabili\n",
    "        ciao = self.conv4(ciao, edge_index)\n",
    "        #yield ciao\n",
    "        a = self.ciao(ciao) + ciao\n",
    "        b = self.ciao4(ciao, x0=a, edge_index=edge_index)\n",
    "        #yield self.conv5(ciao, edge_index)\n",
    "        return a, b\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ds_train = load_dataset(PRETRAIN_CLEANED_TRAIN, dataset_type=\"pretrain\")\n",
    "ds_val = load_dataset(PRETRAIN_CLEANED_VAL, dataset_type=\"pretrain\")\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "count = 0\n",
    "g = Giggino()\n",
    "g.to(device)\n",
    "for el in iter(dl_train):\n",
    "    el.to(device)\n",
    "    print(g.forward(el.x, el.edge_index))\n",
    "    if count > 5:\n",
    "        break\n",
    "    count += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
