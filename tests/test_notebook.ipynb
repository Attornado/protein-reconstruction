{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\attor\\Desktop\\Python\\protein-reconstruction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "cwd = os.getcwd()\n",
    "if re.search(\"protein-reconstruction.+\", cwd):\n",
    "    os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torchinfo\n",
    "import torch_geometric.utils.convert as tgc\n",
    "import numpy as np\n",
    "from typing import final\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "from models.layers import GATConvBlock, SAGEConvBlock, GCN2ConvBlock, GCNConvBlock\n",
    "from models.pretraining.encoders import SimpleGCNEncoder, ResGCN2ConvEncoder, RevSAGEConvEncoder, RevGATConvEncoder, \\\n",
    "    ResGCN2ConvEncoderV2, RevGCNEncoder\n",
    "from models.pretraining.gae import GAEv2\n",
    "from models.pretraining.vgae import VGAEv2, VGEncoder\n",
    "from models.classification.classifiers import ProtMotionNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from preprocessing.constants import PRETRAIN_CLEANED_TRAIN, PRETRAIN_CLEANED_VAL\n",
    "from preprocessing.dataset import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define graph and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {'x': [1.0, 0.0, 1.2, 1.1, 0.2, 0.1]}), (1, {'x': [0.0, 1.0, 0, 1.2, 1.1, 0.2]}), (2, {'x': [0.4, 1.0, 0.1, 0.2, 0.7, 0.3]}), (3, {'x': [1.0, 1.2, 0.9, 0.9, 0.5, 0.4]}), (4, {'x': [1.0, 1.3, 0.4, 0.3, 1.8, 0.45]})]\n",
      "[(0, 1, {'edge_weight': 1.0}), (0, 2, {'edge_weight': 1.0}), (1, 2, {'edge_weight': 2.0}), (2, 3, {'edge_weight': 1.0}), (2, 4, {'edge_weight': 1.0})]\n",
      "ciao\n"
     ]
    }
   ],
   "source": [
    "_POSITION_ATTRIBUTE: final = \"pos\"\n",
    "_X_MIN: final = 0\n",
    "_X_MAX: final = 2\n",
    "_Y_MIN: final = 0\n",
    "_Y_MAX: final = 2\n",
    "g = nx.Graph()\n",
    "g.add_node(0, x=[1., 0., 1.2, 1.1, 0.2, 0.1])\n",
    "g.add_node(1, x=[0., 1., 0, 1.2, 1.1, 0.2])\n",
    "g.add_node(2, x=[0.4, 1., 0.1, 0.2, 0.7, 0.3])\n",
    "g.add_node(3, x=[1., 1.2, 0.9, 0.9, 0.5, 0.4])\n",
    "g.add_node(4, x=[1., 1.3, 0.4, 0.3, 1.8, 0.45])\n",
    "g.add_edge(1, 0, edge_weight=1.0)\n",
    "g.add_edge(1, 2, edge_weight=2.)\n",
    "g.add_edge(2, 0, edge_weight=1.)\n",
    "g.add_edge(3, 2, edge_weight=1.)\n",
    "g.add_edge(4, 2, edge_weight=1.)\n",
    "\n",
    "print(g.nodes(data=True))\n",
    "print(g.edges(data=True))\n",
    "print(\"ciao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "#888",
          "width": 0.5
         },
         "mode": "lines",
         "x": [
          2.3135880499128665,
          3.1116530355663974,
          null,
          2.3135880499128665,
          3.2006673357964393,
          null,
          3.1116530355663974,
          3.2006673357964393,
          null,
          3.2006673357964393,
          2.509953535303115,
          null,
          3.2006673357964393,
          2.431774011329024,
          null
         ],
         "y": [
          0.9416761721950196,
          -1.706130826736365,
          null,
          0.9416761721950196,
          -0.7630151821871428,
          null,
          -1.706130826736365,
          -0.7630151821871428,
          null,
          -0.7630151821871428,
          2.6725847675827286,
          null,
          -0.7630151821871428,
          0.7915270307446127,
          null
         ],
         "type": "scatter"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           2,
           2,
           4,
           1,
           1
          ],
          "colorbar": {
           "thickness": 15,
           "title": {
            "side": "right",
            "text": "Node Connections"
           },
           "xanchor": "left"
          },
          "colorscale": [
           [
            0.0,
            "rgb(255,255,217)"
           ],
           [
            0.125,
            "rgb(237,248,177)"
           ],
           [
            0.25,
            "rgb(199,233,180)"
           ],
           [
            0.375,
            "rgb(127,205,187)"
           ],
           [
            0.5,
            "rgb(65,182,196)"
           ],
           [
            0.625,
            "rgb(29,145,192)"
           ],
           [
            0.75,
            "rgb(34,94,168)"
           ],
           [
            0.875,
            "rgb(37,52,148)"
           ],
           [
            1.0,
            "rgb(8,29,88)"
           ]
          ],
          "line": {
           "width": 2
          },
          "reversescale": true,
          "showscale": true,
          "size": 10
         },
         "mode": "markers",
         "text": [
          "node 0, # of connections: 2",
          "node 1, # of connections: 2",
          "node 2, # of connections: 4",
          "node 3, # of connections: 1",
          "node 4, # of connections: 1"
         ],
         "x": [
          2.3135880499128665,
          3.1116530355663974,
          3.2006673357964393,
          2.509953535303115,
          2.431774011329024
         ],
         "y": [
          0.9416761721950196,
          -1.706130826736365,
          -0.7630151821871428,
          2.6725847675827286,
          0.7915270307446127
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>",
          "x": 0.005,
          "xref": "paper",
          "y": -0.002,
          "yref": "paper"
         }
        ],
        "hovermode": "closest",
        "margin": {
         "b": 20,
         "l": 5,
         "r": 5,
         "t": 40
        },
        "showlegend": false,
        "title": {
         "font": {
          "size": 16
         },
         "text": "<br>Network graph made with Python"
        },
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"bbd97076-098c-4a97-bae2-03f3fb1bf57b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bbd97076-098c-4a97-bae2-03f3fb1bf57b\")) {                    Plotly.newPlot(                        \"bbd97076-098c-4a97-bae2-03f3fb1bf57b\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[2.3135880499128665,3.1116530355663974,null,2.3135880499128665,3.2006673357964393,null,3.1116530355663974,3.2006673357964393,null,3.2006673357964393,2.509953535303115,null,3.2006673357964393,2.431774011329024,null],\"y\":[0.9416761721950196,-1.706130826736365,null,0.9416761721950196,-0.7630151821871428,null,-1.706130826736365,-0.7630151821871428,null,-0.7630151821871428,2.6725847675827286,null,-0.7630151821871428,0.7915270307446127,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[2,2,4,1,1],\"colorbar\":{\"thickness\":15,\"title\":{\"side\":\"right\",\"text\":\"Node Connections\"},\"xanchor\":\"left\"},\"colorscale\":[[0.0,\"rgb(255,255,217)\"],[0.125,\"rgb(237,248,177)\"],[0.25,\"rgb(199,233,180)\"],[0.375,\"rgb(127,205,187)\"],[0.5,\"rgb(65,182,196)\"],[0.625,\"rgb(29,145,192)\"],[0.75,\"rgb(34,94,168)\"],[0.875,\"rgb(37,52,148)\"],[1.0,\"rgb(8,29,88)\"]],\"line\":{\"width\":2},\"reversescale\":true,\"showscale\":true,\"size\":10},\"mode\":\"markers\",\"text\":[\"node 0, # of connections: 2\",\"node 1, # of connections: 2\",\"node 2, # of connections: 4\",\"node 3, # of connections: 1\",\"node 4, # of connections: 1\"],\"x\":[2.3135880499128665,3.1116530355663974,3.2006673357964393,2.509953535303115,2.431774011329024],\"y\":[0.9416761721950196,-1.706130826736365,-0.7630151821871428,2.6725847675827286,0.7915270307446127],\"type\":\"scatter\"}],                        {\"annotations\":[{\"showarrow\":false,\"text\":\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\"x\":0.005,\"xref\":\"paper\",\"y\":-0.002,\"yref\":\"paper\"}],\"hovermode\":\"closest\",\"margin\":{\"b\":20,\"l\":5,\"r\":5,\"t\":40},\"showlegend\":false,\"title\":{\"font\":{\"size\":16},\"text\":\"<br>Network graph made with Python\"},\"xaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('bbd97076-098c-4a97-bae2-03f3fb1bf57b');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(nx.get_node_attributes(g, \"pos\",)) == 0:\n",
    "    pos = {i: (random.gauss(_X_MIN, _X_MAX), random.gauss(_Y_MIN, _Y_MAX)) for i in g.nodes}\n",
    "    nx.set_node_attributes(g, pos, \"pos\")\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in g.edges():\n",
    "    x0, y0 = g.nodes[edge[0]]['pos']\n",
    "    x1, y1 = g.nodes[edge[1]]['pos']\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in g.nodes():\n",
    "    x, y = g.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(g.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append(f'node {node}, # of connections: ' + str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text\n",
    "\n",
    "# noinspection PyTypeChecker\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                layout=go.Layout(\n",
    "                    title='<br>Network graph made with Python',\n",
    "                    titlefont_size=16,\n",
    "                    showlegend=False,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=20,l=5,r=5,t=40),\n",
    "                    annotations=[ dict(\n",
    "                        text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "                        showarrow=False,\n",
    "                        xref=\"paper\", yref=\"paper\",\n",
    "                        x=0.005, y=-0.002 ) ],\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert graph in PyTorch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5, 6], edge_index=[2, 10], pos=[5, 2], edge_weight=[10])\n",
      "tensor([1., 1., 1., 2., 1., 2., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "pyg = tgc.from_networkx(g)\n",
    "print(pyg)\n",
    "print(pyg.edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate layers and test their serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=1)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=0.6931471805599453)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.5, beta=0.6931471805599453)\n",
      ")\n",
      "tensor([[ 0.3742,  0.1815,  0.1761],\n",
      "        [ 0.3373,  0.1259,  0.1758],\n",
      "        [ 0.3657,  0.1690,  0.2542],\n",
      "        [ 0.4000, -0.3091,  0.4359],\n",
      "        [ 0.2186,  0.1921,  0.3783]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.4007,  0.5990,  0.1977],\n",
      "        [-1.2051,  1.5155, -1.0427],\n",
      "        [-0.9983,  1.2199, -0.7839],\n",
      "        [-0.6960,  0.5533, -0.3640],\n",
      "        [-0.5635,  1.0282, -0.6551]], grad_fn=<AsStridedBackward0>)\n",
      "tensor([[-0.0896,  0.1296,  0.7979],\n",
      "        [ 0.4429,  0.4400,  0.8563],\n",
      "        [-0.4718,  0.2319,  0.6127],\n",
      "        [-0.6414,  0.0738,  0.5633],\n",
      "        [ 0.1992,  0.4853,  0.8070]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.2152, -0.5126, -0.2759],\n",
      "        [ 0.2131, -0.2652,  0.0975],\n",
      "        [ 0.7306, -0.3093,  0.3914],\n",
      "        [ 1.1563, -0.2052, -0.2920],\n",
      "        [ 1.0787,  0.5158, -0.5773]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 3.4632, -1.5718,  1.5736],\n",
      "        [ 2.7500, -0.0316,  2.4946],\n",
      "        [ 5.6534, -2.0935,  3.2373],\n",
      "        [ 1.5596, -0.3939,  1.0480],\n",
      "        [ 1.5596, -0.3939,  1.0480]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.3665, -0.3899,  0.4214],\n",
      "        [-0.3625, -0.3343,  0.5388],\n",
      "        [-0.4800, -0.2545,  0.6109],\n",
      "        [-0.2839,  0.0303,  0.4438],\n",
      "        [-0.1358,  0.2517,  0.3383]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.3954, -0.5106, -0.4130,  0.1340,  0.6035, -0.8588],\n",
      "        [-0.2726,  0.2051, -0.8479, -0.0767,  0.5095, -0.9283],\n",
      "        [-0.1745,  0.4489, -0.5836,  0.0149,  0.5014, -0.9577],\n",
      "        [ 0.1154,  0.1815, -0.4966,  0.1581,  0.6388, -1.1902],\n",
      "        [-0.2687,  0.7774, -0.6446, -0.0687,  0.5790, -1.0635]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.4708,  1.1637,  0.4148,  0.4665,  0.0575,  0.3252],\n",
      "        [ 0.3276,  1.3595, -0.0546,  0.4754, -0.3787, -0.0301],\n",
      "        [ 0.4591,  1.4687, -0.0716,  0.3873, -0.4112,  0.1515],\n",
      "        [ 0.4670,  1.6690, -0.1485,  0.2831, -0.4055,  0.5046],\n",
      "        [ 0.7130,  1.4410,  0.1363,  0.4809, -0.3502,  0.0420]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gat0 = GATConvBlock(6, 3, heads=2, edge_dim=1)\n",
    "gat1 = GATConvBlock(6, 3, heads=1, edge_dim=1, dropout=0.3, concat=True)\n",
    "\n",
    "sage0 = SAGEConvBlock(6, 3, project=True)\n",
    "sage1 = SAGEConvBlock(6, 3, project=False)\n",
    "\n",
    "gcn0 = GCNConvBlock(6, 3, normalize=False)\n",
    "gcn1 = GCNConvBlock(6, 3, normalize=True)\n",
    "\n",
    "gcn20 = GCN2ConvBlock(6, 0.6)\n",
    "gcn21 = GCN2ConvBlock(6, 0.5)\n",
    "\n",
    "print(gat0)\n",
    "print(gat1)\n",
    "print(sage0)\n",
    "print(sage1)\n",
    "print(gcn0)\n",
    "print(gcn1)\n",
    "print(gcn20)\n",
    "print(gcn21)\n",
    "\n",
    "print(gat0(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(gat1(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(sage0(pyg.x, edge_index=pyg.edge_index))\n",
    "print(sage1(pyg.x, edge_index=pyg.edge_index))\n",
    "print(gcn0(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn1(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn20(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn21(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=0.6931471805599453)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=0.6931471805599453)\n",
      ")\n",
      "tensor([[ 0.3742,  0.1815,  0.1761],\n",
      "        [ 0.3373,  0.1259,  0.1758],\n",
      "        [ 0.3657,  0.1690,  0.2542],\n",
      "        [ 0.4000, -0.3091,  0.4359],\n",
      "        [ 0.2186,  0.1921,  0.3783]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.3742,  0.1815,  0.1761],\n",
      "        [ 0.3373,  0.1259,  0.1758],\n",
      "        [ 0.3657,  0.1690,  0.2542],\n",
      "        [ 0.4000, -0.3091,  0.4359],\n",
      "        [ 0.2186,  0.1921,  0.3783]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.0896,  0.1296,  0.7979],\n",
      "        [ 0.4429,  0.4400,  0.8563],\n",
      "        [-0.4718,  0.2319,  0.6127],\n",
      "        [-0.6414,  0.0738,  0.5633],\n",
      "        [ 0.1992,  0.4853,  0.8070]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.0896,  0.1296,  0.7979],\n",
      "        [ 0.4429,  0.4400,  0.8563],\n",
      "        [-0.4718,  0.2319,  0.6127],\n",
      "        [-0.6414,  0.0738,  0.5633],\n",
      "        [ 0.1992,  0.4853,  0.8070]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 3.4632, -1.5718,  1.5736],\n",
      "        [ 2.7500, -0.0316,  2.4946],\n",
      "        [ 5.6534, -2.0935,  3.2373],\n",
      "        [ 1.5596, -0.3939,  1.0480],\n",
      "        [ 1.5596, -0.3939,  1.0480]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 3.4632, -1.5718,  1.5736],\n",
      "        [ 2.7500, -0.0316,  2.4946],\n",
      "        [ 5.6534, -2.0935,  3.2373],\n",
      "        [ 1.5596, -0.3939,  1.0480],\n",
      "        [ 1.5596, -0.3939,  1.0480]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.3954, -0.5106, -0.4130,  0.1340,  0.6035, -0.8588],\n",
      "        [-0.2726,  0.2051, -0.8479, -0.0767,  0.5095, -0.9283],\n",
      "        [-0.1745,  0.4489, -0.5836,  0.0149,  0.5014, -0.9577],\n",
      "        [ 0.1154,  0.1815, -0.4966,  0.1581,  0.6388, -1.1902],\n",
      "        [-0.2687,  0.7774, -0.6446, -0.0687,  0.5790, -1.0635]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.3954, -0.5106, -0.4130,  0.1340,  0.6035, -0.8588],\n",
      "        [-0.2726,  0.2051, -0.8479, -0.0767,  0.5095, -0.9283],\n",
      "        [-0.1745,  0.4489, -0.5836,  0.0149,  0.5014, -0.9577],\n",
      "        [ 0.1154,  0.1815, -0.4966,  0.1581,  0.6388, -1.1902],\n",
      "        [-0.2687,  0.7774, -0.6446, -0.0687,  0.5790, -1.0635]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "state_dict = gat0.state_dict()\n",
    "gat01 = GATConvBlock.from_constructor_params(gat0.serialize_constructor_params())\n",
    "gat01.load_state_dict(state_dict)\n",
    "\n",
    "state_dict = sage0.state_dict()\n",
    "sage01 = SAGEConvBlock.from_constructor_params(sage0.serialize_constructor_params())\n",
    "sage01.load_state_dict(state_dict)\n",
    "\n",
    "state_dict = gcn0.state_dict()\n",
    "gcn01 = GCNConvBlock.from_constructor_params(gcn0.serialize_constructor_params())\n",
    "gcn01.load_state_dict(state_dict)\n",
    "\n",
    "state_dict = gcn20.state_dict()\n",
    "gcn201 = GCN2ConvBlock.from_constructor_params(gcn20.serialize_constructor_params())\n",
    "gcn201.load_state_dict(state_dict)\n",
    "\n",
    "print(gat0)\n",
    "print(gat01)\n",
    "print(sage0)\n",
    "print(sage01)\n",
    "print(gcn0)\n",
    "print(gcn01)\n",
    "print(gcn20)\n",
    "print(gcn201)\n",
    "\n",
    "print(gat0(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(gat01(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(sage0(pyg.x, edge_index=pyg.edge_index))\n",
    "print(sage01(pyg.x, edge_index=pyg.edge_index))\n",
    "print(gcn0(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn01(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn20(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn201(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             268\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             268\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[ 0.4770,  0.0948, -0.5193],\n",
      "        [ 0.5850,  0.1986, -0.6551],\n",
      "        [ 0.4876,  0.1076, -0.5321],\n",
      "        [ 0.5346,  0.1514, -0.5903],\n",
      "        [ 0.4564,  0.1100, -0.5052]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             40\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             40\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             40\n",
      "    GroupAddRev: 2-4                                 --\n",
      "        ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[-0.0304, -0.5837,  0.6164],\n",
      "        [-0.0674, -0.5441,  0.5695],\n",
      "        [-0.2025, -0.6236,  0.5528],\n",
      "        [-0.2300, -0.6603,  0.5627],\n",
      "        [-0.1864, -0.5996,  0.5450]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            15\n",
      "LayerNorm: 1-3                         8\n",
      "ModuleList: 1-4                        --\n",
      "    GCNConvBlock: 2-1                 --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCNConv: 3-2                 30\n",
      "    GCNConvBlock: 2-2                 --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCNConv: 3-4                 30\n",
      "    GCNConvBlock: 2-3                 --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCNConv: 3-6                 24\n",
      "    GCNConvBlock: 2-4                 --\n",
      "        LayerNorm: 3-7               8\n",
      "        GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[-1.0128,  0.6126,  0.6191],\n",
      "        [-0.9885,  0.6055,  0.5954],\n",
      "        [-0.8711,  0.5683,  0.4801],\n",
      "        [-1.0248,  0.6161,  0.6307],\n",
      "        [ 0.1025,  0.0443, -0.1106]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 Encoder\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[ 0.2094, -0.3823,  0.1566],\n",
      "        [ 0.2099, -0.3830,  0.1563],\n",
      "        [ 0.2086, -0.3821,  0.1565],\n",
      "        [ 0.2048, -0.3790,  0.1577],\n",
      "        [ 0.2101, -0.3817,  0.1559]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 EncoderV2\n",
      "ResGCN2ConvEncoderV2(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.6931471805599453)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.4054651081081644)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.28768207245178085)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.22314355131420976)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoderV2                     --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[ 0.5159,  0.0849, -0.5270],\n",
      "        [ 0.4684,  0.1429, -0.5213],\n",
      "        [ 0.5021,  0.1057, -0.5300],\n",
      "        [ 0.5054,  0.1020, -0.5336],\n",
      "        [ 0.5088,  0.0974, -0.5375]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevGCN Encoder\n",
      "RevGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGCNEncoder                                           --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             20\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             20\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             20\n",
      "    GroupAddRev: 2-4                                 --\n",
      "        ModuleList: 3-4                             20\n",
      "================================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[-1.0128,  0.6126,  0.6191],\n",
      "        [-0.9885,  0.6055,  0.5954],\n",
      "        [-0.8711,  0.5683,  0.4801],\n",
      "        [-1.0248,  0.6161,  0.6307],\n",
      "        [ 0.1025,  0.0443, -0.1106]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gat_enc = RevGATConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=3,\n",
    "    dropout=0.0,\n",
    "    version=\"v2\",\n",
    "    edge_dim=1,\n",
    "    heads=8,\n",
    "    num_groups=2,\n",
    "    concat=False,\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual GAT Encoder\")\n",
    "print(gat_enc)\n",
    "print(torchinfo.summary(gat_enc))\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "sage_enc = RevSAGEConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0,\n",
    "    project=True,\n",
    "    root_weight=True,\n",
    "    num_groups=2,\n",
    "    aggr='mean',\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "print(sage_enc)\n",
    "print(torchinfo.summary(sage_enc))\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn_enc = SimpleGCNEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    conv_dims=[5, 5, 4, 4],\n",
    "    dropout=0.0,\n",
    "    improved=True\n",
    ")\n",
    "print(\"Simple GCN Encoder\")\n",
    "print(gcn_enc)\n",
    "print(torchinfo.summary(gcn_enc))\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn2_enc = ResGCN2ConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    alpha=0.3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0\n",
    ")\n",
    "print(\"ResGCN2 Encoder\")\n",
    "print(gcn2_enc)\n",
    "print(torchinfo.summary(gcn2_enc))\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn22_enc = ResGCN2ConvEncoderV2(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    alpha=0.3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0\n",
    ")\n",
    "print(\"ResGCN2 EncoderV2\")\n",
    "print(gcn22_enc)\n",
    "print(torchinfo.summary(gcn22_enc))\n",
    "print(gcn22_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn_rev_enc = RevGCNEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0,\n",
    "    improved=True\n",
    ")\n",
    "print(\"RevGCN Encoder\")\n",
    "print(gcn_rev_enc)\n",
    "print(torchinfo.summary(gcn_rev_enc))\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test encoders serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             268\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             268\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.4770,  0.0948, -0.5193],\n",
      "        [ 0.5850,  0.1986, -0.6551],\n",
      "        [ 0.4876,  0.1076, -0.5321],\n",
      "        [ 0.5346,  0.1514, -0.5903],\n",
      "        [ 0.4564,  0.1100, -0.5052]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.4770,  0.0948, -0.5193],\n",
      "        [ 0.5850,  0.1986, -0.6551],\n",
      "        [ 0.4876,  0.1076, -0.5321],\n",
      "        [ 0.5346,  0.1514, -0.5903],\n",
      "        [ 0.4564,  0.1100, -0.5052]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             40\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             40\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             40\n",
      "    GroupAddRev: 2-4                                 --\n",
      "        ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-0.0304, -0.5837,  0.6164],\n",
      "        [-0.0674, -0.5441,  0.5695],\n",
      "        [-0.2025, -0.6236,  0.5528],\n",
      "        [-0.2300, -0.6603,  0.5627],\n",
      "        [-0.1864, -0.5996,  0.5450]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-0.0304, -0.5837,  0.6164],\n",
      "        [-0.0674, -0.5441,  0.5695],\n",
      "        [-0.2025, -0.6236,  0.5528],\n",
      "        [-0.2300, -0.6603,  0.5627],\n",
      "        [-0.1864, -0.5996,  0.5450]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            15\n",
      "LayerNorm: 1-3                         8\n",
      "ModuleList: 1-4                        --\n",
      "    GCNConvBlock: 2-1                 --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCNConv: 3-2                 30\n",
      "    GCNConvBlock: 2-2                 --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCNConv: 3-4                 30\n",
      "    GCNConvBlock: 2-3                 --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCNConv: 3-6                 24\n",
      "    GCNConvBlock: 2-4                 --\n",
      "        LayerNorm: 3-7               8\n",
      "        GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-1.0128,  0.6126,  0.6191],\n",
      "        [-0.9885,  0.6055,  0.5954],\n",
      "        [-0.8711,  0.5683,  0.4801],\n",
      "        [-1.0248,  0.6161,  0.6307],\n",
      "        [ 0.1025,  0.0443, -0.1106]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-1.0128,  0.6126,  0.6191],\n",
      "        [-0.9885,  0.6055,  0.5954],\n",
      "        [-0.8711,  0.5683,  0.4801],\n",
      "        [-1.0248,  0.6161,  0.6307],\n",
      "        [ 0.1025,  0.0443, -0.1106]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.2090, -0.3818,  0.1567],\n",
      "        [ 0.2098, -0.3829,  0.1562],\n",
      "        [ 0.2085, -0.3820,  0.1565],\n",
      "        [ 0.2037, -0.3781,  0.1580],\n",
      "        [ 0.2093, -0.3810,  0.1561]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.2090, -0.3818,  0.1567],\n",
      "        [ 0.2098, -0.3829,  0.1562],\n",
      "        [ 0.2085, -0.3820,  0.1565],\n",
      "        [ 0.2037, -0.3781,  0.1580],\n",
      "        [ 0.2093, -0.3810,  0.1561]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 EncoderV2\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'theta': 1.0, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}\n",
      "ResGCN2ConvEncoderV2(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.6931471805599453)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.4054651081081644)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.28768207245178085)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=0.22314355131420976)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoderV2                     --\n",
      "Linear: 1-1                            35\n",
      "Linear: 1-2                            18\n",
      "LayerNorm: 1-3                         10\n",
      "ModuleList: 1-4                        --\n",
      "    GCN2ConvBlock: 2-1                --\n",
      "        LayerNorm: 3-1               10\n",
      "        GCN2Conv: 3-2                25\n",
      "    GCN2ConvBlock: 2-2                --\n",
      "        LayerNorm: 3-3               10\n",
      "        GCN2Conv: 3-4                25\n",
      "    GCN2ConvBlock: 2-3                --\n",
      "        LayerNorm: 3-5               10\n",
      "        GCN2Conv: 3-6                25\n",
      "    GCN2ConvBlock: 2-4                --\n",
      "        LayerNorm: 3-7               10\n",
      "        GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.5176,  0.0825, -0.5266],\n",
      "        [ 0.4691,  0.1421, -0.5214],\n",
      "        [ 0.5021,  0.1058, -0.5298],\n",
      "        [ 0.5055,  0.1017, -0.5337],\n",
      "        [ 0.5090,  0.0970, -0.5378]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.5176,  0.0825, -0.5266],\n",
      "        [ 0.4691,  0.1421, -0.5214],\n",
      "        [ 0.5021,  0.1058, -0.5298],\n",
      "        [ 0.5055,  0.1017, -0.5337],\n",
      "        [ 0.5090,  0.0970, -0.5378]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevGCN Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(GCNConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(2, 2)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGCNEncoder                                           --\n",
      "Linear: 1-1                                           28\n",
      "Linear: 1-2                                           15\n",
      "LayerNorm: 1-3                                        8\n",
      "ModuleList: 1-4                                       --\n",
      "    GroupAddRev: 2-1                                 --\n",
      "        ModuleList: 3-1                             20\n",
      "    GroupAddRev: 2-2                                 --\n",
      "        ModuleList: 3-2                             20\n",
      "    GroupAddRev: 2-3                                 --\n",
      "        ModuleList: 3-3                             20\n",
      "    GroupAddRev: 2-4                                 --\n",
      "        ModuleList: 3-4                             20\n",
      "================================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-0.4977, -0.4000, -0.0351],\n",
      "        [-0.1812, -0.2896, -0.4922],\n",
      "        [-0.2170, -0.3174, -0.4044],\n",
      "        [-0.3194, -0.3637, -0.2722],\n",
      "        [ 0.0287, -0.2798, -0.7208]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-0.4977, -0.4000, -0.0351],\n",
      "        [-0.1812, -0.2896, -0.4922],\n",
      "        [-0.2170, -0.3174, -0.4044],\n",
      "        [-0.3194, -0.3637, -0.2722],\n",
      "        [ 0.0287, -0.2798, -0.7208]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT Encoder\")\n",
    "constr_params = gat_enc.serialize_constructor_params()\n",
    "state_dict = gat_enc.state_dict()\n",
    "print(constr_params)\n",
    "gat_enc2 = RevGATConvEncoder.from_constructor_params(constr_params)\n",
    "gat_enc2.load_state_dict(state_dict)\n",
    "print(gat_enc2)\n",
    "print(torchinfo.summary(gat_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gat_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "constr_params = sage_enc.serialize_constructor_params()\n",
    "state_dict = sage_enc.state_dict()\n",
    "print(constr_params)\n",
    "sage_enc2 = RevSAGEConvEncoder.from_constructor_params(constr_params)\n",
    "sage_enc2.load_state_dict(state_dict)\n",
    "print(sage_enc2)\n",
    "print(torchinfo.summary(sage_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(sage_enc2(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN Encoder\")\n",
    "constr_params = gcn_enc.serialize_constructor_params()\n",
    "state_dict = gcn_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn_enc2 = SimpleGCNEncoder.from_constructor_params(constr_params)\n",
    "gcn_enc2.load_state_dict(state_dict)\n",
    "print(gcn_enc2)\n",
    "print(torchinfo.summary(gcn_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 Encoder\")\n",
    "constr_params = gcn2_enc.serialize_constructor_params()\n",
    "state_dict = gcn2_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn2_enc2 = ResGCN2ConvEncoder.from_constructor_params(constr_params)\n",
    "gcn2_enc2.load_state_dict(state_dict)\n",
    "print(gcn2_enc2)\n",
    "print(torchinfo.summary(gcn2_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn2_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 EncoderV2\")\n",
    "constr_params = gcn22_enc.serialize_constructor_params()\n",
    "state_dict = gcn22_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn22_enc2 = ResGCN2ConvEncoderV2.from_constructor_params(constr_params)\n",
    "gcn22_enc2.load_state_dict(state_dict)\n",
    "print(gcn22_enc2)\n",
    "print(torchinfo.summary(gcn22_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn22_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn22_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevGCN Encoder\")\n",
    "constr_params = gcn_rev_enc.serialize_constructor_params()\n",
    "state_dict = gcn_rev_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn_rev_enc2 = RevGCNEncoder.from_constructor_params(constr_params)\n",
    "gcn_rev_enc2.load_state_dict(state_dict)\n",
    "print(gcn_rev_enc2)\n",
    "print(torchinfo.summary(gcn_rev_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn_rev_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn_rev_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate and test GAEv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevGATConvEncoder: 1-1                                     --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 268\n",
      "        GroupAddRev: 3-2                                 268\n",
      "        GroupAddRev: 3-3                                 268\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.6774, 0.6684, 0.6774, 0.6774, 0.6684, 0.6774, 0.6570, 0.6746, 0.6570,\n",
      "        0.6746], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6726, 0.6774, 0.6684, 0.6527, 0.6657],\n",
      "        [0.6774, 0.6896, 0.6774, 0.6503, 0.6756],\n",
      "        [0.6684, 0.6774, 0.6721, 0.6570, 0.6746],\n",
      "        [0.6527, 0.6503, 0.6570, 0.6672, 0.6641],\n",
      "        [0.6657, 0.6756, 0.6746, 0.6641, 0.6811]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.4356, -0.7200,  0.1090],\n",
      "        [ 0.3495, -0.8219, -0.0214],\n",
      "        [ 0.2626, -0.7944,  0.1328],\n",
      "        [ 0.2378, -0.6653,  0.4430],\n",
      "        [ 0.1549, -0.8320,  0.2059]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6774, 0.6684, 0.6774, 0.6774, 0.6684, 0.6774, 0.6570, 0.6746, 0.6570,\n",
      "        0.6746], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4833, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.8, 0.8350000000000001)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevSAGEConvEncoder: 1-1                                    --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 40\n",
      "        GroupAddRev: 3-2                                 40\n",
      "        GroupAddRev: 3-3                                 40\n",
      "        GroupAddRev: 3-4                                 40\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.5600, 0.5610, 0.5600, 0.5608, 0.5610, 0.5608, 0.5611, 0.5605, 0.5611,\n",
      "        0.5605], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.5601, 0.5600, 0.5610, 0.5601, 0.5594],\n",
      "        [0.5600, 0.5600, 0.5608, 0.5600, 0.5594],\n",
      "        [0.5610, 0.5608, 0.5630, 0.5611, 0.5605],\n",
      "        [0.5601, 0.5600, 0.5611, 0.5601, 0.5594],\n",
      "        [0.5594, 0.5594, 0.5605, 0.5594, 0.5588]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.2767,  0.0256, -0.4054],\n",
      "        [ 0.2832,  0.0322, -0.4000],\n",
      "        [ 0.2258,  0.0169, -0.4497],\n",
      "        [ 0.2705,  0.0236, -0.4097],\n",
      "        [ 0.2646,  0.0317, -0.4065]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5600, 0.5610, 0.5600, 0.5608, 0.5610, 0.5608, 0.5611, 0.5605, 0.5611,\n",
      "        0.5605], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.3988, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.9600000000000001, 0.9666666666666666)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "SimpleGCNEncoder: 1-1                       --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            15\n",
      "    LayerNorm: 2-3                         8\n",
      "    ModuleList: 2-4                        --\n",
      "        GCNConvBlock: 3-1                 40\n",
      "        GCNConvBlock: 3-2                 40\n",
      "        GCNConvBlock: 3-3                 34\n",
      "        GCNConvBlock: 3-4                 28\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206,\n",
      "        0.5206], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.5206, 0.5206, 0.5206, 0.5206, 0.5206],\n",
      "        [0.5206, 0.5206, 0.5206, 0.5206, 0.5206],\n",
      "        [0.5206, 0.5206, 0.5206, 0.5206, 0.5206],\n",
      "        [0.5206, 0.5206, 0.5206, 0.5206, 0.5206],\n",
      "        [0.5206, 0.5206, 0.5206, 0.5206, 0.5206]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[0.0293, 0.1406, 0.2484],\n",
      "        [0.0293, 0.1406, 0.2484],\n",
      "        [0.0293, 0.1406, 0.2484],\n",
      "        [0.0293, 0.1406, 0.2484],\n",
      "        [0.0293, 0.1406, 0.2484]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206, 0.5206,\n",
      "        0.5206], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.3880, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.96, 0.9428571428571428)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "ResGCN2ConvEncoder: 1-1                     --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            18\n",
      "    LayerNorm: 2-3                         10\n",
      "    ModuleList: 2-4                        --\n",
      "        GCN2ConvBlock: 3-1                35\n",
      "        GCN2ConvBlock: 3-2                35\n",
      "        GCN2ConvBlock: 3-3                35\n",
      "        GCN2ConvBlock: 3-4                35\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.6185, 0.6190, 0.6185, 0.6194, 0.6190, 0.6194, 0.6157, 0.6250, 0.6157,\n",
      "        0.6250], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6183, 0.6185, 0.6190, 0.6161, 0.6224],\n",
      "        [0.6185, 0.6187, 0.6194, 0.6158, 0.6233],\n",
      "        [0.6190, 0.6194, 0.6202, 0.6157, 0.6250],\n",
      "        [0.6161, 0.6158, 0.6157, 0.6158, 0.6164],\n",
      "        [0.6224, 0.6233, 0.6250, 0.6164, 0.6334]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.5352, -0.2087,  0.3904],\n",
      "        [-0.5450, -0.2131,  0.3762],\n",
      "        [-0.5638, -0.2187,  0.3535],\n",
      "        [-0.4721, -0.1992,  0.4575],\n",
      "        [-0.6473, -0.2409,  0.2639]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6185, 0.6190, 0.6185, 0.6194, 0.6190, 0.6194, 0.6157, 0.6250, 0.6157,\n",
      "        0.6250], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4433, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.56, 0.6533333333333333)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Rev GCN GAE\n",
      "GAEv2(\n",
      "  (encoder): RevGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevGCNEncoder: 1-1                                         --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 20\n",
      "        GroupAddRev: 3-2                                 20\n",
      "        GroupAddRev: 3-3                                 20\n",
      "        GroupAddRev: 3-4                                 20\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.5442, 0.5530, 0.5442, 0.5446, 0.5530, 0.5446, 0.5649, 0.5760, 0.5649,\n",
      "        0.5760], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.5510, 0.5442, 0.5530, 0.5604, 0.5688],\n",
      "        [0.5442, 0.5428, 0.5446, 0.5461, 0.5464],\n",
      "        [0.5530, 0.5446, 0.5557, 0.5649, 0.5760],\n",
      "        [0.5604, 0.5461, 0.5649, 0.5805, 0.6003],\n",
      "        [0.5688, 0.5464, 0.5760, 0.6003, 0.6318]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.0555, -0.4463, -0.0474],\n",
      "        [ 0.1237, -0.3893,  0.0687],\n",
      "        [ 0.0354, -0.4635, -0.0876],\n",
      "        [-0.0420, -0.5261, -0.2157],\n",
      "        [-0.1413, -0.5947, -0.4080]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5442, 0.5530, 0.5442, 0.5446, 0.5530, 0.5446, 0.5649, 0.5760, 0.5649,\n",
      "        0.5760], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4183, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.36, 0.4888888888888888)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Rev GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_rev_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test serialization for GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0982,  0.2437, -0.4080, -0.1093, -0.3962,  0.1662],\n",
      "        [ 0.0552,  0.0723, -0.2609,  0.3955,  0.0599,  0.2873],\n",
      "        [-0.2237, -0.0228, -0.1366,  0.2851,  0.0460,  0.0314],\n",
      "        [ 0.3006, -0.1165, -0.1177,  0.1174, -0.3019, -0.2847]])), ('lin1.bias', tensor([ 0.1078,  0.0161,  0.2881, -0.1122])), ('lin2.weight', tensor([[-0.2132,  0.1202,  0.4042, -0.3074],\n",
      "        [-0.1146, -0.1745, -0.4527,  0.1278],\n",
      "        [-0.0321, -0.4272, -0.3950, -0.1019]])), ('lin2.bias', tensor([-0.4414, -0.4191,  0.3793])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[ 0.0029, -0.4917],\n",
      "         [-0.0739, -0.4109],\n",
      "         [ 0.6850, -0.1777],\n",
      "         [ 0.7178,  0.7318],\n",
      "         [-0.0716,  0.2772],\n",
      "         [-0.0826,  0.1818],\n",
      "         [ 0.1967, -0.1147],\n",
      "         [-0.2155,  0.7743]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.1583, -0.4882],\n",
      "        [-0.5410, -0.0949],\n",
      "        [-0.3576, -0.0215],\n",
      "        [ 0.3008, -0.4434],\n",
      "        [ 0.4240,  0.2653],\n",
      "        [ 0.3845,  0.2727],\n",
      "        [ 0.4686,  0.1438],\n",
      "        [-0.5205, -0.3176],\n",
      "        [-0.1731,  0.1439],\n",
      "        [-0.3964, -0.2361],\n",
      "        [ 0.2458,  0.0582],\n",
      "        [ 0.0028,  0.2721],\n",
      "        [-0.0879,  0.1938],\n",
      "        [ 0.1206,  0.1663],\n",
      "        [-0.3109, -0.1955],\n",
      "        [-0.1271, -0.5635]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.3765, -0.4957,  0.5918,  0.4809,  0.1080,  0.1220, -0.2823,  0.3007,\n",
      "         0.3102, -0.0187, -0.1181, -0.2557, -0.0530, -0.0379,  0.2915,  0.3197])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.5529, -0.2807],\n",
      "        [ 0.0761,  0.1082],\n",
      "        [-0.0721, -0.4904],\n",
      "        [ 0.4607, -0.0009],\n",
      "        [ 0.0293,  0.5538],\n",
      "        [ 0.0832, -0.0537],\n",
      "        [-0.0674,  0.2835],\n",
      "        [ 0.2361, -0.3006],\n",
      "        [-0.4947,  0.1751],\n",
      "        [ 0.2623, -0.0858],\n",
      "        [-0.3655, -0.0847],\n",
      "        [-0.2573, -0.3183],\n",
      "        [ 0.4030,  0.3898],\n",
      "        [ 0.4647,  0.2331],\n",
      "        [-0.3948, -0.0976],\n",
      "        [ 0.5738,  0.2216]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([ 0.0918,  0.1980,  0.3996, -0.1903, -0.1201,  0.3935,  0.5765, -0.5814,\n",
      "        -0.0186, -0.4051, -0.2024, -0.1575, -0.6593,  0.4704,  0.5051,  0.6611])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[ 0.3137],\n",
      "        [-0.0808],\n",
      "        [-0.0589],\n",
      "        [-0.4074],\n",
      "        [-0.0945],\n",
      "        [ 0.0274],\n",
      "        [-0.3001],\n",
      "        [ 0.4678],\n",
      "        [ 0.3227],\n",
      "        [ 0.2028],\n",
      "        [ 0.2190],\n",
      "        [-0.5795],\n",
      "        [ 0.4105],\n",
      "        [-0.0007],\n",
      "        [-0.1853],\n",
      "        [-0.0769]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.0109,  0.2298],\n",
      "         [-0.0931,  0.6217],\n",
      "         [ 0.0509, -0.3761],\n",
      "         [ 0.4751, -0.1054],\n",
      "         [-0.3111,  0.0936],\n",
      "         [-0.3466, -0.1195],\n",
      "         [-0.6644, -0.4071],\n",
      "         [ 0.5225, -0.6377]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.3930,  0.5600],\n",
      "        [ 0.1461,  0.2182],\n",
      "        [-0.3653,  0.4468],\n",
      "        [ 0.4469, -0.1145],\n",
      "        [ 0.3105,  0.4242],\n",
      "        [ 0.2381,  0.4212],\n",
      "        [ 0.0951, -0.2191],\n",
      "        [ 0.1531,  0.2177],\n",
      "        [ 0.0018, -0.1863],\n",
      "        [ 0.3415,  0.3800],\n",
      "        [ 0.3096,  0.4903],\n",
      "        [-0.4857, -0.4599],\n",
      "        [-0.4851,  0.5589],\n",
      "        [ 0.0948, -0.3417],\n",
      "        [ 0.5270, -0.1828],\n",
      "        [ 0.3031,  0.5741]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.6051,  0.6792, -0.3060,  0.5014, -0.5659,  0.6590, -0.3820, -0.6473,\n",
      "         0.4594, -0.6882, -0.4980,  0.5062,  0.6908, -0.3992,  0.1058,  0.3161])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.0666, -0.2646],\n",
      "        [ 0.4316,  0.0090],\n",
      "        [-0.2081, -0.1587],\n",
      "        [ 0.4332,  0.0231],\n",
      "        [-0.3643,  0.3523],\n",
      "        [ 0.4705, -0.0933],\n",
      "        [-0.2847, -0.4645],\n",
      "        [-0.4210,  0.1519],\n",
      "        [ 0.0625, -0.0447],\n",
      "        [-0.1864, -0.2417],\n",
      "        [ 0.4811, -0.2137],\n",
      "        [ 0.4459, -0.2160],\n",
      "        [-0.2100, -0.4998],\n",
      "        [-0.0569, -0.0867],\n",
      "        [-0.4653, -0.5671],\n",
      "        [ 0.0117, -0.0110]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.3699, -0.3619, -0.2436, -0.2419,  0.6174, -0.2749,  0.1408, -0.5510,\n",
      "         0.5276, -0.0904,  0.3809,  0.4615,  0.4147, -0.4714, -0.4375,  0.2338])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[ 0.3654],\n",
      "        [ 0.3143],\n",
      "        [ 0.5016],\n",
      "        [-0.1051],\n",
      "        [ 0.1446],\n",
      "        [-0.4473],\n",
      "        [ 0.1990],\n",
      "        [-0.3910],\n",
      "        [-0.0444],\n",
      "        [-0.5034],\n",
      "        [-0.0343],\n",
      "        [-0.2514],\n",
      "        [ 0.5319],\n",
      "        [-0.3594],\n",
      "        [ 0.5593],\n",
      "        [-0.5212]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[-0.6842, -0.2418],\n",
      "         [-0.5773,  0.2382],\n",
      "         [ 0.0048,  0.1336],\n",
      "         [-0.2672,  0.6078],\n",
      "         [ 0.0421,  0.2095],\n",
      "         [-0.5368,  0.2791],\n",
      "         [-0.3688,  0.4485],\n",
      "         [ 0.3102, -0.4404]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.5640,  0.2256],\n",
      "        [ 0.5394,  0.3916],\n",
      "        [ 0.0295,  0.1034],\n",
      "        [ 0.0037,  0.1362],\n",
      "        [ 0.1415, -0.2414],\n",
      "        [ 0.0546,  0.3609],\n",
      "        [-0.0010, -0.2010],\n",
      "        [ 0.3278, -0.2453],\n",
      "        [ 0.1191,  0.2056],\n",
      "        [-0.2085,  0.3384],\n",
      "        [ 0.1451, -0.4280],\n",
      "        [-0.4478,  0.0554],\n",
      "        [ 0.0387,  0.2555],\n",
      "        [-0.2081,  0.0466],\n",
      "        [ 0.1925, -0.2542],\n",
      "        [ 0.0897, -0.3717]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.4284, -0.6062,  0.6016, -0.3291,  0.4811, -0.4014, -0.4656, -0.0527,\n",
      "        -0.4113, -0.2437, -0.3551, -0.0945,  0.2693,  0.0388, -0.4153, -0.1554])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.1272,  0.1515],\n",
      "        [ 0.1914,  0.0867],\n",
      "        [-0.3478,  0.1419],\n",
      "        [ 0.0556,  0.0398],\n",
      "        [ 0.4346,  0.0758],\n",
      "        [-0.1252,  0.5376],\n",
      "        [ 0.0640, -0.2353],\n",
      "        [-0.1079,  0.4461],\n",
      "        [-0.2719, -0.4593],\n",
      "        [-0.2967,  0.3435],\n",
      "        [-0.3272, -0.4482],\n",
      "        [ 0.0693,  0.0269],\n",
      "        [-0.3663,  0.3639],\n",
      "        [ 0.1438, -0.4053],\n",
      "        [-0.4044,  0.0270],\n",
      "        [-0.4785, -0.2902]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([ 0.3396,  0.4416, -0.2323,  0.5940, -0.2068,  0.1324, -0.2647,  0.0115,\n",
      "        -0.0323, -0.7006,  0.0867, -0.0803, -0.2396, -0.1215,  0.1549, -0.3594])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.5588],\n",
      "        [-0.1854],\n",
      "        [ 0.2294],\n",
      "        [-0.2561],\n",
      "        [-0.0955],\n",
      "        [ 0.5735],\n",
      "        [-0.2914],\n",
      "        [ 0.5725],\n",
      "        [-0.0741],\n",
      "        [ 0.3218],\n",
      "        [ 0.2998],\n",
      "        [-0.3822],\n",
      "        [-0.3563],\n",
      "        [ 0.5496],\n",
      "        [-0.0744],\n",
      "        [-0.0719]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[-0.0338,  0.1477],\n",
      "         [ 0.5966,  0.0225],\n",
      "         [ 0.4871,  0.0651],\n",
      "         [-0.7005, -0.5643],\n",
      "         [-0.3639,  0.4034],\n",
      "         [ 0.4948,  0.2041],\n",
      "         [-0.7607, -0.7706],\n",
      "         [ 0.6114,  0.4534]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.3683,  0.3898],\n",
      "        [ 0.0233, -0.0824],\n",
      "        [-0.3103,  0.5481],\n",
      "        [-0.2894,  0.4302],\n",
      "        [-0.2476,  0.5695],\n",
      "        [-0.3882, -0.2825],\n",
      "        [-0.3700, -0.3993],\n",
      "        [ 0.3048,  0.1355],\n",
      "        [ 0.4851,  0.5037],\n",
      "        [ 0.2298,  0.3387],\n",
      "        [ 0.5471, -0.4326],\n",
      "        [ 0.1696, -0.4577],\n",
      "        [-0.0047, -0.2967],\n",
      "        [ 0.5357, -0.4115],\n",
      "        [-0.4844,  0.2209],\n",
      "        [ 0.2660, -0.2571]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.2215, -0.6576,  0.0758, -0.0179, -0.6385, -0.6964, -0.3410,  0.1676,\n",
      "         0.1132,  0.3955, -0.1038,  0.2373,  0.1248,  0.2526, -0.2084, -0.5044])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.1936, -0.1348],\n",
      "        [-0.0228,  0.3193],\n",
      "        [ 0.2251,  0.3710],\n",
      "        [-0.2429, -0.4419],\n",
      "        [ 0.2459, -0.3684],\n",
      "        [-0.5643,  0.4462],\n",
      "        [ 0.3251, -0.1158],\n",
      "        [ 0.5236, -0.1440],\n",
      "        [ 0.5302,  0.3617],\n",
      "        [ 0.0109, -0.4252],\n",
      "        [ 0.4336, -0.5736],\n",
      "        [ 0.1434, -0.5403],\n",
      "        [ 0.3103,  0.0663],\n",
      "        [-0.1986,  0.3172],\n",
      "        [-0.1821,  0.2559],\n",
      "        [ 0.3094,  0.3867]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([ 0.0957,  0.4757,  0.3497, -0.1633, -0.0261,  0.6573,  0.3944,  0.1508,\n",
      "        -0.5103, -0.4983,  0.1566,  0.6186, -0.6237,  0.5382,  0.5147,  0.6094])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[ 0.4411],\n",
      "        [ 0.1859],\n",
      "        [-0.2499],\n",
      "        [ 0.1413],\n",
      "        [ 0.0025],\n",
      "        [ 0.1082],\n",
      "        [-0.4625],\n",
      "        [ 0.4755],\n",
      "        [-0.1408],\n",
      "        [-0.0067],\n",
      "        [ 0.2147],\n",
      "        [ 0.0875],\n",
      "        [-0.5577],\n",
      "        [ 0.4764],\n",
      "        [-0.4939],\n",
      "        [-0.0297]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[ 0.6099,  0.7609],\n",
      "         [-0.3051, -0.2409],\n",
      "         [ 0.1521,  0.4379],\n",
      "         [-0.5223, -0.1077],\n",
      "         [-0.1979, -0.1383],\n",
      "         [ 0.6062,  0.4978],\n",
      "         [ 0.5789,  0.3727],\n",
      "         [ 0.5781,  0.2683]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.0142, -0.0325],\n",
      "        [-0.0176,  0.1003],\n",
      "        [-0.0364, -0.4952],\n",
      "        [ 0.3620, -0.2905],\n",
      "        [-0.4855, -0.0918],\n",
      "        [-0.1100,  0.0047],\n",
      "        [-0.5494,  0.0429],\n",
      "        [ 0.2660, -0.3365],\n",
      "        [ 0.0048,  0.3844],\n",
      "        [-0.5442,  0.3559],\n",
      "        [-0.3552, -0.2159],\n",
      "        [-0.2263,  0.1075],\n",
      "        [-0.3864,  0.5423],\n",
      "        [-0.3238,  0.0938],\n",
      "        [-0.4527, -0.4904],\n",
      "        [-0.1958,  0.1988]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.3395, -0.0514,  0.3965, -0.3852,  0.2906,  0.5652, -0.6366, -0.4547,\n",
      "        -0.0898, -0.1214,  0.4911,  0.3624, -0.0834, -0.2373, -0.6150, -0.6787])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.3867,  0.1252],\n",
      "        [-0.3288, -0.5606],\n",
      "        [-0.0042,  0.3854],\n",
      "        [-0.3334,  0.4593],\n",
      "        [ 0.2785, -0.0610],\n",
      "        [ 0.1597,  0.4051],\n",
      "        [ 0.0536, -0.1797],\n",
      "        [ 0.1383, -0.5528],\n",
      "        [-0.1362,  0.2769],\n",
      "        [ 0.1669, -0.0638],\n",
      "        [-0.2322,  0.4680],\n",
      "        [ 0.1951, -0.1763],\n",
      "        [-0.0873, -0.0844],\n",
      "        [ 0.1802,  0.3187],\n",
      "        [-0.1393,  0.5384],\n",
      "        [ 0.5670,  0.0855]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([ 0.6924,  0.3803,  0.0034,  0.2182,  0.2473, -0.3270, -0.4900, -0.3522,\n",
      "         0.1021, -0.0490, -0.0820,  0.3272, -0.4990, -0.5672, -0.5465,  0.2202])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[ 0.4054],\n",
      "        [ 0.0178],\n",
      "        [ 0.0278],\n",
      "        [ 0.2084],\n",
      "        [ 0.5864],\n",
      "        [-0.1332],\n",
      "        [ 0.3803],\n",
      "        [-0.5656],\n",
      "        [-0.5479],\n",
      "        [-0.2168],\n",
      "        [-0.0540],\n",
      "        [-0.1875],\n",
      "        [ 0.3588],\n",
      "        [-0.0532],\n",
      "        [-0.0368],\n",
      "        [-0.4030]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[ 0.1415, -0.3278],\n",
      "         [-0.3272,  0.1462],\n",
      "         [-0.5238,  0.1642],\n",
      "         [-0.0476, -0.4469],\n",
      "         [-0.7123, -0.5859],\n",
      "         [-0.1571,  0.6933],\n",
      "         [ 0.3163, -0.6155],\n",
      "         [-0.5335,  0.0067]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1748, -0.0205],\n",
      "        [ 0.0009, -0.4620],\n",
      "        [-0.5137, -0.4876],\n",
      "        [-0.4246, -0.0480],\n",
      "        [ 0.2837, -0.3683],\n",
      "        [-0.1288,  0.4915],\n",
      "        [ 0.1669,  0.0562],\n",
      "        [ 0.0585,  0.0794],\n",
      "        [ 0.0299,  0.0405],\n",
      "        [ 0.4894, -0.2687],\n",
      "        [-0.2507, -0.4586],\n",
      "        [-0.2680, -0.4692],\n",
      "        [-0.3699,  0.5351],\n",
      "        [ 0.2664, -0.3432],\n",
      "        [-0.2588,  0.2178],\n",
      "        [-0.1798,  0.2935]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.4837,  0.4550,  0.7010,  0.1509, -0.6584, -0.6066,  0.0641,  0.3554,\n",
      "         0.2777, -0.0088, -0.5690, -0.3076,  0.2934,  0.3688, -0.1423, -0.3892])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.0652, -0.0922],\n",
      "        [-0.2575,  0.5454],\n",
      "        [-0.3284,  0.3663],\n",
      "        [ 0.1361,  0.3722],\n",
      "        [-0.2287,  0.0775],\n",
      "        [-0.5405,  0.4810],\n",
      "        [ 0.3434, -0.5500],\n",
      "        [-0.1548,  0.3796],\n",
      "        [ 0.3156, -0.3295],\n",
      "        [-0.2516, -0.2901],\n",
      "        [-0.1360,  0.3119],\n",
      "        [ 0.3750,  0.2239],\n",
      "        [ 0.2265, -0.5238],\n",
      "        [-0.2807,  0.0268],\n",
      "        [-0.4966,  0.3249],\n",
      "        [ 0.1697, -0.3223]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([-0.1995, -0.6615,  0.4239,  0.3471, -0.2162,  0.4003,  0.2014,  0.2703,\n",
      "        -0.6686,  0.4701,  0.0401, -0.0946, -0.1585,  0.6869, -0.4937, -0.5139])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.3939],\n",
      "        [-0.4071],\n",
      "        [ 0.2938],\n",
      "        [-0.3230],\n",
      "        [-0.3267],\n",
      "        [ 0.2861],\n",
      "        [ 0.1640],\n",
      "        [ 0.3528],\n",
      "        [-0.2914],\n",
      "        [ 0.4046],\n",
      "        [-0.0032],\n",
      "        [ 0.2895],\n",
      "        [ 0.5869],\n",
      "        [ 0.1318],\n",
      "        [ 0.1570],\n",
      "        [ 0.0180]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevGATConvEncoder: 1-1                                     --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 268\n",
      "        GroupAddRev: 3-2                                 268\n",
      "        GroupAddRev: 3-3                                 268\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.6496, 0.6566, 0.6496, 0.7498, 0.6566, 0.7498, 0.7549, 0.7361, 0.7549,\n",
      "        0.7361], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.6496, 0.6566, 0.6496, 0.7498, 0.6566, 0.7498, 0.7549, 0.7361, 0.7549,\n",
      "        0.7361], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6322, 0.6496, 0.6566, 0.6522, 0.6448],\n",
      "        [0.6496, 0.7715, 0.7498, 0.7761, 0.7566],\n",
      "        [0.6566, 0.7498, 0.7383, 0.7549, 0.7361],\n",
      "        [0.6522, 0.7761, 0.7549, 0.7811, 0.7606],\n",
      "        [0.6448, 0.7566, 0.7361, 0.7606, 0.7429]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.6322, 0.6496, 0.6566, 0.6522, 0.6448],\n",
      "        [0.6496, 0.7715, 0.7498, 0.7761, 0.7566],\n",
      "        [0.6566, 0.7498, 0.7383, 0.7549, 0.7361],\n",
      "        [0.6522, 0.7761, 0.7549, 0.7811, 0.7606],\n",
      "        [0.6448, 0.7566, 0.7361, 0.7606, 0.7429]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.3274, -0.6573,  0.0495],\n",
      "        [ 0.1984, -1.0566, -0.2470],\n",
      "        [ 0.0495, -1.0153, -0.0608],\n",
      "        [ 0.2244, -1.0842, -0.2152],\n",
      "        [ 0.1249, -0.9888, -0.2609]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.3274, -0.6573,  0.0495],\n",
      "        [ 0.1984, -1.0566, -0.2470],\n",
      "        [ 0.0495, -1.0153, -0.0608],\n",
      "        [ 0.2244, -1.0842, -0.2152],\n",
      "        [ 0.1249, -0.9888, -0.2609]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6496, 0.6566, 0.6496, 0.7498, 0.6566, 0.7498, 0.7549, 0.7361, 0.7549,\n",
      "        0.7361], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.6496, 0.6566, 0.6496, 0.7498, 0.6566, 0.7498, 0.7549, 0.7361, 0.7549,\n",
      "        0.7361], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.6316, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.6316, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.36, 0.4553968253968254)\n",
      "AUC and precision metric test deserialized\n",
      "(0.36, 0.4553968253968254)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.3677,  0.3499,  0.2870,  0.0552,  0.0813, -0.2989],\n",
      "        [ 0.3575, -0.3941,  0.0746,  0.0895,  0.1527, -0.0648],\n",
      "        [ 0.1741,  0.2861,  0.0778, -0.0216, -0.2164,  0.2889],\n",
      "        [-0.1888,  0.2533,  0.3892,  0.0721, -0.0875, -0.0552]])), ('lin1.bias', tensor([ 0.0774, -0.0708,  0.3982,  0.1094])), ('lin2.weight', tensor([[ 0.1004, -0.1718,  0.2289,  0.1980],\n",
      "        [ 0.3355,  0.2274, -0.2182,  0.2301],\n",
      "        [ 0.2908,  0.3586,  0.2456, -0.2232]])), ('lin2.bias', tensor([-0.4312,  0.3470, -0.0575])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[ 0.1489,  0.3803],\n",
      "        [-0.6386, -0.4063]])), ('convs.0.convs.0.conv.lin.bias', tensor([ 0.5594, -0.2718])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.2059, -0.4216],\n",
      "        [-0.2608, -0.1189]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([0.1244, 0.5853])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.3806,  0.1800],\n",
      "        [ 0.5349, -0.2618]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[ 0.1303, -0.4867],\n",
      "        [-0.0996,  0.0366]])), ('convs.0.convs.1.conv.lin.bias', tensor([-0.5021,  0.0237])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.3883, -0.0597],\n",
      "        [ 0.4679, -0.3320]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.5552, -0.3418])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.6465, -0.1142],\n",
      "        [-0.4238, -0.1770]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.6186,  0.5076],\n",
      "        [ 0.6170,  0.6317]])), ('convs.1.convs.0.conv.lin.bias', tensor([ 0.2684, -0.1606])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.0791,  0.1674],\n",
      "        [ 0.0400, -0.2801]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.3072,  0.6732])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.6327, -0.2732],\n",
      "        [ 0.6112,  0.1806]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[-0.5788, -0.2886],\n",
      "        [-0.6387, -0.0800]])), ('convs.1.convs.1.conv.lin.bias', tensor([0.1758, 0.4217])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.4079, -0.0453],\n",
      "        [-0.4033,  0.4182]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([0.1544, 0.6867])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.2405, -0.1634],\n",
      "        [-0.1839,  0.4810]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[-0.5444,  0.1215],\n",
      "        [ 0.0178,  0.1841]])), ('convs.2.convs.0.conv.lin.bias', tensor([-0.2401,  0.3799])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.0087,  0.0957],\n",
      "        [-0.4051,  0.6023]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.0162, -0.1594])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.6107,  0.1304],\n",
      "        [-0.1462,  0.3834]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[-0.1237, -0.3217],\n",
      "        [ 0.0110, -0.2921]])), ('convs.2.convs.1.conv.lin.bias', tensor([0.4015, 0.7008])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.0510, -0.5076],\n",
      "        [-0.0918,  0.2757]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.4472, -0.0299])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.2450, -0.4461],\n",
      "        [ 0.0699, -0.1692]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[-0.5921,  0.5975],\n",
      "        [ 0.2818, -0.5119]])), ('convs.3.convs.0.conv.lin.bias', tensor([-0.3306,  0.2950])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.3003,  0.6500],\n",
      "        [ 0.5809,  0.0902]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([-0.0666,  0.4826])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[-0.1909,  0.6295],\n",
      "        [ 0.3997,  0.6750]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-0.0296,  0.2497],\n",
      "        [-0.4911,  0.1257]])), ('convs.3.convs.1.conv.lin.bias', tensor([-0.0385,  0.2235])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.1000, -0.1740],\n",
      "        [ 0.4985,  0.2079]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([ 0.3743, -0.0469])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[-0.6276, -0.3721],\n",
      "        [-0.2555, -0.5128]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevSAGEConvEncoder: 1-1                                    --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 40\n",
      "        GroupAddRev: 3-2                                 40\n",
      "        GroupAddRev: 3-3                                 40\n",
      "        GroupAddRev: 3-4                                 40\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.7871, 0.7869, 0.7871, 0.7912, 0.7869, 0.7912, 0.7910, 0.7908, 0.7910,\n",
      "        0.7908], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.7871, 0.7869, 0.7871, 0.7912, 0.7869, 0.7912, 0.7910, 0.7908, 0.7910,\n",
      "        0.7908], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7829, 0.7871, 0.7869, 0.7870, 0.7867],\n",
      "        [0.7871, 0.7914, 0.7912, 0.7913, 0.7910],\n",
      "        [0.7869, 0.7912, 0.7910, 0.7910, 0.7908],\n",
      "        [0.7870, 0.7913, 0.7910, 0.7911, 0.7909],\n",
      "        [0.7867, 0.7910, 0.7908, 0.7909, 0.7906]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.7829, 0.7871, 0.7869, 0.7870, 0.7867],\n",
      "        [0.7871, 0.7914, 0.7912, 0.7913, 0.7910],\n",
      "        [0.7869, 0.7912, 0.7910, 0.7910, 0.7908],\n",
      "        [0.7870, 0.7913, 0.7910, 0.7911, 0.7909],\n",
      "        [0.7867, 0.7910, 0.7908, 0.7909, 0.7906]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.7769,  0.6753,  0.4724],\n",
      "        [-0.8002,  0.6739,  0.4888],\n",
      "        [-0.7995,  0.6714,  0.4905],\n",
      "        [-0.7948,  0.6773,  0.4912],\n",
      "        [-0.7887,  0.6821,  0.4914]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.7769,  0.6753,  0.4724],\n",
      "        [-0.8002,  0.6739,  0.4888],\n",
      "        [-0.7995,  0.6714,  0.4905],\n",
      "        [-0.7948,  0.6773,  0.4912],\n",
      "        [-0.7887,  0.6821,  0.4914]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.7871, 0.7869, 0.7871, 0.7912, 0.7869, 0.7912, 0.7910, 0.7908, 0.7910,\n",
      "        0.7908], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.7871, 0.7869, 0.7871, 0.7912, 0.7869, 0.7912, 0.7910, 0.7908, 0.7910,\n",
      "        0.7908], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.7942, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.7942, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.52, 0.5587301587301587)\n",
      "AUC and precision metric test deserialized\n",
      "(0.52, 0.5587301587301587)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.4041, -0.3426, -0.1380,  0.2293,  0.2583, -0.3590],\n",
      "        [-0.2351, -0.3227,  0.1652, -0.2005,  0.1883,  0.0200],\n",
      "        [ 0.0652,  0.3291, -0.1150, -0.3124,  0.1374, -0.2278],\n",
      "        [ 0.3545, -0.3037, -0.3718, -0.1221,  0.1901,  0.2032],\n",
      "        [ 0.1888, -0.2081, -0.1509,  0.3721, -0.1318,  0.1487]])), ('lin1.bias', tensor([-0.1699,  0.2182,  0.0578, -0.3243,  0.3392])), ('lin2.weight', tensor([[-0.0743,  0.4034,  0.1269,  0.4621],\n",
      "        [-0.4623,  0.4872, -0.1708, -0.2238],\n",
      "        [ 0.4169,  0.3518,  0.1119, -0.1619]])), ('lin2.bias', tensor([-0.2027,  0.2787, -0.3515])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[ 0.0565,  0.2125, -0.5726, -0.6975,  0.1781],\n",
      "        [-0.3652, -0.3864,  0.4993,  0.4233,  0.6375],\n",
      "        [ 0.0211,  0.3120, -0.4009, -0.1943, -0.3415],\n",
      "        [ 0.0931, -0.0841, -0.3334, -0.2085, -0.0063],\n",
      "        [-0.6936,  0.0058,  0.3997, -0.0598,  0.4223]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.1105,  0.6091,  0.6940,  0.4202,  0.6162],\n",
      "        [ 0.7447,  0.1409, -0.1830,  0.1490, -0.1808],\n",
      "        [ 0.2422, -0.3095,  0.5884, -0.5606,  0.5357],\n",
      "        [-0.6201, -0.4089, -0.1908, -0.6119,  0.1633],\n",
      "        [ 0.4470,  0.2645, -0.0363,  0.4829, -0.3045]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.6927, -0.0524, -0.5373,  0.5974,  0.1481],\n",
      "        [ 0.7333, -0.5647, -0.0489, -0.2042,  0.5186],\n",
      "        [-0.7681,  0.4772, -0.0664,  0.5715, -0.0840],\n",
      "        [-0.3661, -0.1979,  0.7668, -0.6476,  0.3584]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[-0.6942, -0.3887,  0.4600, -0.3049],\n",
      "        [-0.7123,  0.3635, -0.4746, -0.4944],\n",
      "        [ 0.0949, -0.5818,  0.0844, -0.1142],\n",
      "        [ 0.1296, -0.3326,  0.3714,  0.6038]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "SimpleGCNEncoder: 1-1                       --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            15\n",
      "    LayerNorm: 2-3                         8\n",
      "    ModuleList: 2-4                        --\n",
      "        GCNConvBlock: 3-1                 40\n",
      "        GCNConvBlock: 3-2                 40\n",
      "        GCNConvBlock: 3-3                 34\n",
      "        GCNConvBlock: 3-4                 28\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941,\n",
      "        0.5941], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941,\n",
      "        0.5941], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941],\n",
      "        [0.5941, 0.5941, 0.5941, 0.5941, 0.5941]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.3580,  0.3707, -0.3397],\n",
      "        [ 0.3580,  0.3707, -0.3397],\n",
      "        [ 0.3580,  0.3707, -0.3397],\n",
      "        [ 0.3580,  0.3708, -0.3397],\n",
      "        [ 0.3580,  0.3707, -0.3397]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 0.3580,  0.3707, -0.3397],\n",
      "        [ 0.3580,  0.3707, -0.3397],\n",
      "        [ 0.3580,  0.3707, -0.3397],\n",
      "        [ 0.3580,  0.3708, -0.3397],\n",
      "        [ 0.3580,  0.3707, -0.3397]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941,\n",
      "        0.5941], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941, 0.5941,\n",
      "        0.5941], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4224, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.4224, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(1.0, 1.0)\n",
      "AUC and precision metric test deserialized\n",
      "(1.0, 1.0)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.3942, -0.1551, -0.2105,  0.2011,  0.0305, -0.0639],\n",
      "        [-0.2861, -0.0729,  0.3202, -0.0375, -0.0745,  0.4015],\n",
      "        [-0.2281, -0.2671,  0.1888, -0.3280,  0.1000,  0.0542],\n",
      "        [-0.2075, -0.1051, -0.0558,  0.2597, -0.2234,  0.2214],\n",
      "        [-0.2041,  0.1583,  0.1001,  0.0687,  0.1573,  0.3093]])), ('lin1.bias', tensor([-0.2870, -0.2704,  0.1986, -0.0522, -0.1373])), ('lin2.weight', tensor([[ 0.4327, -0.4103, -0.3534, -0.0287, -0.0092],\n",
      "        [-0.0014,  0.3418,  0.0338, -0.1705, -0.3610],\n",
      "        [ 0.2964,  0.1041,  0.2905,  0.2021, -0.2890]])), ('lin2.bias', tensor([-0.3986, -0.4380,  0.0720])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[-0.1928,  0.4421,  0.2535,  0.4625, -0.6294],\n",
      "        [ 0.0630,  0.5131,  0.3715,  0.0207, -0.5915],\n",
      "        [-0.3935,  0.6317,  0.0278, -0.3823, -0.7170],\n",
      "        [-0.3075, -0.4005,  0.0695, -0.2439, -0.4250],\n",
      "        [ 0.1738, -0.4653,  0.1010, -0.1931,  0.4067]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[ 0.2142,  0.1279, -0.4459, -0.1794, -0.2139],\n",
      "        [-0.7746, -0.6578,  0.6771, -0.5579,  0.5842],\n",
      "        [-0.0081,  0.1600, -0.2826, -0.1596, -0.5109],\n",
      "        [-0.7128, -0.4499, -0.2121,  0.4231, -0.7659],\n",
      "        [-0.0759, -0.6615,  0.4180,  0.6371,  0.6358]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[ 0.5117, -0.0076,  0.0535, -0.7372,  0.4456],\n",
      "        [-0.3066, -0.5261, -0.7547,  0.2570,  0.6705],\n",
      "        [ 0.7742,  0.5555, -0.7689, -0.3954, -0.0728],\n",
      "        [ 0.6663, -0.5218, -0.1327,  0.0961, -0.2495],\n",
      "        [-0.5622,  0.1283,  0.7356,  0.2803, -0.2627]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.0018,  0.4758, -0.2630, -0.5401,  0.5605],\n",
      "        [-0.5270, -0.0585,  0.2708,  0.2283, -0.5695],\n",
      "        [ 0.6127, -0.1618, -0.6670, -0.4109,  0.5731],\n",
      "        [ 0.7055, -0.5528,  0.6233,  0.3294,  0.1274],\n",
      "        [-0.5262,  0.7652,  0.5010, -0.3270, -0.0371]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "ResGCN2ConvEncoder: 1-1                     --\n",
      "    Linear: 2-1                            35\n",
      "    Linear: 2-2                            18\n",
      "    LayerNorm: 2-3                         10\n",
      "    ModuleList: 2-4                        --\n",
      "        GCN2ConvBlock: 3-1                35\n",
      "        GCN2ConvBlock: 3-2                35\n",
      "        GCN2ConvBlock: 3-3                35\n",
      "        GCN2ConvBlock: 3-4                35\n",
      "InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.6757, 0.6757, 0.6757, 0.6759, 0.6757, 0.6759, 0.6763, 0.6761, 0.6763,\n",
      "        0.6761], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.6757, 0.6757, 0.6757, 0.6759, 0.6757, 0.6759, 0.6763, 0.6761, 0.6763,\n",
      "        0.6761], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6756, 0.6757, 0.6757, 0.6756, 0.6748],\n",
      "        [0.6757, 0.6758, 0.6759, 0.6758, 0.6751],\n",
      "        [0.6757, 0.6759, 0.6763, 0.6763, 0.6761],\n",
      "        [0.6756, 0.6758, 0.6763, 0.6762, 0.6761],\n",
      "        [0.6748, 0.6751, 0.6761, 0.6761, 0.6770]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.6756, 0.6757, 0.6757, 0.6756, 0.6748],\n",
      "        [0.6757, 0.6758, 0.6759, 0.6758, 0.6751],\n",
      "        [0.6757, 0.6759, 0.6763, 0.6763, 0.6761],\n",
      "        [0.6756, 0.6758, 0.6763, 0.6762, 0.6761],\n",
      "        [0.6748, 0.6751, 0.6761, 0.6761, 0.6770]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.0234, -0.8478, -0.1200],\n",
      "        [-0.0146, -0.8491, -0.1161],\n",
      "        [ 0.0174, -0.8523, -0.1007],\n",
      "        [ 0.0209, -0.8522, -0.0985],\n",
      "        [ 0.0805, -0.8538, -0.0662]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.0234, -0.8478, -0.1200],\n",
      "        [-0.0146, -0.8491, -0.1161],\n",
      "        [ 0.0174, -0.8523, -0.1007],\n",
      "        [ 0.0209, -0.8522, -0.0985],\n",
      "        [ 0.0805, -0.8538, -0.0662]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6757, 0.6757, 0.6757, 0.6759, 0.6757, 0.6759, 0.6763, 0.6761, 0.6763,\n",
      "        0.6761], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.6757, 0.6757, 0.6757, 0.6759, 0.6757, 0.6759, 0.6763, 0.6761, 0.6763,\n",
      "        0.6761], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.5171, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.5171, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.76, 0.7595238095238095)\n",
      "AUC and precision metric test deserialized\n",
      "(0.76, 0.7595238095238095)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Rev GCN GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2027,  0.0842, -0.2556, -0.3627, -0.0155,  0.0632],\n",
      "        [-0.3919, -0.2855,  0.3913, -0.2973, -0.4062, -0.1891],\n",
      "        [-0.1459,  0.0273,  0.1528, -0.3318,  0.2813, -0.1317],\n",
      "        [ 0.2313, -0.0530,  0.2504,  0.1035, -0.0077,  0.3695]])), ('lin1.bias', tensor([-0.1967, -0.3027,  0.0154, -0.1612])), ('lin2.weight', tensor([[-0.2118, -0.0401, -0.0586, -0.4263],\n",
      "        [ 0.2573, -0.4807, -0.0494, -0.4652],\n",
      "        [-0.1517,  0.0972,  0.4721,  0.4866]])), ('lin2.bias', tensor([-0.2173, -0.4143, -0.4068])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-1.1745, -1.0302],\n",
      "        [-1.2170, -0.5205]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-1.0470,  0.5282],\n",
      "        [-0.7214, -0.1587]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.7945, -1.0285],\n",
      "        [-0.9623,  0.5211]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[-0.7442,  0.9109],\n",
      "        [-0.9560, -0.8442]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[ 0.4720, -0.5751],\n",
      "        [-0.1299, -0.1514]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[-0.2807,  1.0833],\n",
      "        [ 0.2265,  0.2896]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.6295,  0.0113],\n",
      "        [ 0.0710, -0.2708]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[ 0.3035, -0.1558],\n",
      "        [ 1.0685,  1.1823]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "RevGCNEncoder: 1-1                                         --\n",
      "    Linear: 2-1                                           28\n",
      "    Linear: 2-2                                           15\n",
      "    LayerNorm: 2-3                                        8\n",
      "    ModuleList: 2-4                                       --\n",
      "        GroupAddRev: 3-1                                 20\n",
      "        GroupAddRev: 3-2                                 20\n",
      "        GroupAddRev: 3-3                                 20\n",
      "        GroupAddRev: 3-4                                 20\n",
      "InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.6528, 0.6496, 0.6528, 0.6303, 0.6496, 0.6303, 0.6557, 0.6776, 0.6557,\n",
      "        0.6776], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.6528, 0.6496, 0.6528, 0.6303, 0.6496, 0.6303, 0.6557, 0.6776, 0.6557,\n",
      "        0.6776], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6763, 0.6528, 0.6496, 0.6828, 0.7122],\n",
      "        [0.6528, 0.6331, 0.6303, 0.6590, 0.6816],\n",
      "        [0.6496, 0.6303, 0.6276, 0.6557, 0.6776],\n",
      "        [0.6828, 0.6590, 0.6557, 0.6897, 0.7187],\n",
      "        [0.7122, 0.6816, 0.6776, 0.7187, 0.7644]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.6763, 0.6528, 0.6496, 0.6828, 0.7122],\n",
      "        [0.6528, 0.6331, 0.6303, 0.6590, 0.6816],\n",
      "        [0.6496, 0.6303, 0.6276, 0.6557, 0.6776],\n",
      "        [0.6828, 0.6590, 0.6557, 0.6897, 0.7187],\n",
      "        [0.7122, 0.6816, 0.6776, 0.7187, 0.7644]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.4469, -0.6391,  0.3586],\n",
      "        [-0.3443, -0.5455,  0.3598],\n",
      "        [-0.3336, -0.5326,  0.3566],\n",
      "        [-0.4514, -0.6655,  0.3899],\n",
      "        [-0.6464, -0.8440,  0.2172]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.4469, -0.6391,  0.3586],\n",
      "        [-0.3443, -0.5455,  0.3598],\n",
      "        [-0.3336, -0.5326,  0.3566],\n",
      "        [-0.4514, -0.6655,  0.3899],\n",
      "        [-0.6464, -0.8440,  0.2172]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6528, 0.6496, 0.6528, 0.6303, 0.6496, 0.6303, 0.6557, 0.6776, 0.6557,\n",
      "        0.6776], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.6528, 0.6496, 0.6528, 0.6303, 0.6496, 0.6303, 0.6557, 0.6776, 0.6557,\n",
      "        0.6776], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.6026, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.6026, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.039999999999999994, 0.36103174603174604)\n",
      "AUC and precision metric test deserialized\n",
      "(0.039999999999999994, 0.36103174603174604)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevGATConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevSAGEConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, SimpleGCNEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Rev GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_rev_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevGCNEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate VGAEv2 and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevGATConvEncoder: 2-1                                     --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       804\n",
      "    RevGATConvEncoder: 2-2                                     --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       804\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.9999, 0.2927, 0.9999, 0.3968, 0.2927, 0.3968, 0.6006, 0.3488, 0.6006,\n",
      "        0.3488], grad_fn=<SigmoidBackward0>), tensor([[ 0.1085, -0.7852, -0.1024],\n",
      "        [-0.1039, -0.0734, -0.5636],\n",
      "        [-0.1309, -0.0920, -0.5542],\n",
      "        [ 0.1302, -0.2592, -0.3620],\n",
      "        [ 0.2192, -0.2904, -0.3153]], grad_fn=<AddmmBackward0>), tensor([[ 0.3925, -0.4326, -0.2030],\n",
      "        [ 0.5797, -1.0506,  0.4932],\n",
      "        [ 0.1579, -0.3223,  0.0418],\n",
      "        [-0.0761, -0.1772, -0.1867],\n",
      "        [ 0.0497, -0.3136,  0.1545]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.8100, 0.4368, 0.5001, 0.5856, 0.7127],\n",
      "        [0.4368, 0.9977, 0.3399, 0.8520, 0.4937],\n",
      "        [0.5001, 0.3399, 0.7111, 0.4455, 0.2340],\n",
      "        [0.5856, 0.8520, 0.4455, 0.6516, 0.5708],\n",
      "        [0.7127, 0.4937, 0.2340, 0.5708, 0.9028]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.4668, -0.4281, -0.0524],\n",
      "        [-2.1934,  0.5761, -1.9433],\n",
      "        [ 2.8456,  0.2647, -0.5238],\n",
      "        [-0.1786,  1.2779, -0.0371],\n",
      "        [-0.6549, -0.0705, -1.3209]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[ 0.1085, -0.7852, -0.1024],\n",
      "        [-0.1039, -0.0734, -0.5636],\n",
      "        [-0.1309, -0.0920, -0.5542],\n",
      "        [ 0.1302, -0.2592, -0.3620],\n",
      "        [ 0.2192, -0.2904, -0.3153]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[ 0.3925, -0.4326, -0.2030],\n",
      "        [ 0.5797, -1.0506,  0.4932],\n",
      "        [ 0.1579, -0.3223,  0.0418],\n",
      "        [-0.0761, -0.1772, -0.1867],\n",
      "        [ 0.0497, -0.3136,  0.1545]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.2371, 0.7760, 0.2371, 0.0062, 0.7760, 0.0062, 0.4625, 0.2332, 0.4625,\n",
      "        0.2332], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(3.2393, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.24000000000000005, 0.4438888888888889)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevSAGEConvEncoder: 2-1                                    --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       160\n",
      "    RevSAGEConvEncoder: 2-2                                    --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       160\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.0022, 0.0229, 0.0022, 0.9983, 0.0229, 0.9983, 0.1985, 0.6112, 0.1985,\n",
      "        0.6112], grad_fn=<SigmoidBackward0>), tensor([[-0.3463, -0.0198,  0.6897],\n",
      "        [-0.4093, -0.0672,  0.6985],\n",
      "        [-0.4246, -0.0979,  0.7150],\n",
      "        [-0.4570, -0.1229,  0.7189],\n",
      "        [-0.4610,  0.0112,  0.5897]], grad_fn=<AddmmBackward0>), tensor([[-0.1651, -0.4016,  0.6511],\n",
      "        [-0.1540, -0.4022,  0.6438],\n",
      "        [-0.1595, -0.3948,  0.6382],\n",
      "        [-0.1776, -0.2955,  0.5316],\n",
      "        [-0.1859, -0.2229,  0.4496]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6556, 0.6239, 0.5078, 0.7547, 0.4683],\n",
      "        [0.6239, 0.6803, 0.3474, 0.8624, 0.7568],\n",
      "        [0.5078, 0.3474, 0.7752, 0.2241, 0.0820],\n",
      "        [0.7547, 0.8624, 0.2241, 1.0000, 0.7786],\n",
      "        [0.4683, 0.7568, 0.0820, 0.7786, 0.9925]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-1.7039,  0.2569,  0.5684],\n",
      "        [-0.7753, -1.0955, -1.6054],\n",
      "        [ 0.7294,  0.3601, -0.8507],\n",
      "        [-1.2966, -1.5096, -0.2676],\n",
      "        [-0.1484, -1.1596, -0.5919]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.3463, -0.0198,  0.6897],\n",
      "        [-0.4093, -0.0672,  0.6985],\n",
      "        [-0.4246, -0.0979,  0.7150],\n",
      "        [-0.4570, -0.1229,  0.7189],\n",
      "        [-0.4610,  0.0112,  0.5897]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.1651, -0.4016,  0.6511],\n",
      "        [-0.1540, -0.4022,  0.6438],\n",
      "        [-0.1595, -0.3948,  0.6382],\n",
      "        [-0.1776, -0.2955,  0.5316],\n",
      "        [-0.1859, -0.2229,  0.4496]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5317, 0.1633, 0.5317, 0.6001, 0.1633, 0.6001, 0.2207, 0.4944, 0.2207,\n",
      "        0.4944], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(3.0620, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.11999999999999997, 0.38126984126984126)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "VGEncoder: 1-1                                        --\n",
      "    SimpleGCNEncoder: 2-1                            --\n",
      "        Linear: 3-1                                 35\n",
      "        Linear: 3-2                                 15\n",
      "        LayerNorm: 3-3                              8\n",
      "        ModuleList: 3-4                             142\n",
      "    SimpleGCNEncoder: 2-2                            --\n",
      "        Linear: 3-5                                 35\n",
      "        Linear: 3-6                                 15\n",
      "        LayerNorm: 3-7                              8\n",
      "        ModuleList: 3-8                             142\n",
      "InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([1.5140e-01, 3.4862e-01, 1.5140e-01, 2.0609e-02, 3.4862e-01, 2.0609e-02,\n",
      "        9.5237e-06, 9.2547e-01, 9.5237e-06, 9.2547e-01],\n",
      "       grad_fn=<SigmoidBackward0>), tensor([[-0.3704,  0.7778,  0.4052],\n",
      "        [-0.3515,  0.7885,  0.3985],\n",
      "        [-0.3305,  0.7984,  0.3901],\n",
      "        [-0.3068,  0.8140,  0.3818],\n",
      "        [-0.2988,  0.8050,  0.3743]], grad_fn=<AddmmBackward0>), tensor([[-0.2795,  0.7396, -0.5102],\n",
      "        [-0.2795,  0.7373, -0.5096],\n",
      "        [-0.2795,  0.7363, -0.5093],\n",
      "        [-0.2795,  0.7343, -0.5088],\n",
      "        [-0.2795,  0.7349, -0.5090]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9946, 0.7729, 0.9337, 0.9750, 0.1292],\n",
      "        [0.7729, 0.9079, 0.5064, 0.2311, 0.5436],\n",
      "        [0.9337, 0.5064, 0.8305, 0.8980, 0.3516],\n",
      "        [0.9750, 0.2311, 0.8980, 0.9976, 0.0126],\n",
      "        [0.1292, 0.5436, 0.3516, 0.0126, 0.9944]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.0807,  1.0717,  0.3889],\n",
      "        [-0.6636, -0.3508,  0.2655],\n",
      "        [-0.0860, -0.0027,  0.4313],\n",
      "        [ 0.4865, -0.7089,  0.7553],\n",
      "        [-0.4064,  1.1361,  0.4074]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.3704,  0.7778,  0.4052],\n",
      "        [-0.3515,  0.7885,  0.3985],\n",
      "        [-0.3305,  0.7984,  0.3901],\n",
      "        [-0.3068,  0.8140,  0.3818],\n",
      "        [-0.2988,  0.8050,  0.3743]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.2795,  0.7396, -0.5102],\n",
      "        [-0.2795,  0.7373, -0.5096],\n",
      "        [-0.2795,  0.7363, -0.5093],\n",
      "        [-0.2795,  0.7343, -0.5088],\n",
      "        [-0.2795,  0.7349, -0.5090]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.4192, 0.5394, 0.4192, 0.5430, 0.5394, 0.5430, 0.5710, 0.5517, 0.5710,\n",
      "        0.5517], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4352, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.72, 0.6683333333333333)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "VGEncoder: 1-1                                   --\n",
      "    ResGCN2ConvEncoder: 2-1                     --\n",
      "        Linear: 3-1                            35\n",
      "        Linear: 3-2                            18\n",
      "        LayerNorm: 3-3                         10\n",
      "        ModuleList: 3-4                        140\n",
      "    ResGCN2ConvEncoder: 2-2                     --\n",
      "        Linear: 3-5                            35\n",
      "        Linear: 3-6                            18\n",
      "        LayerNorm: 3-7                         10\n",
      "        ModuleList: 3-8                        140\n",
      "InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.7806, 0.3630, 0.7806, 0.6373, 0.3630, 0.6373, 0.6287, 0.6522, 0.6287,\n",
      "        0.6522], grad_fn=<SigmoidBackward0>), tensor([[0.8288, 0.0686, 0.3205],\n",
      "        [0.8378, 0.0586, 0.3223],\n",
      "        [0.8358, 0.0583, 0.3219],\n",
      "        [0.8232, 0.0780, 0.3195],\n",
      "        [0.8496, 0.0406, 0.3246]], grad_fn=<AddmmBackward0>), tensor([[-0.8967, -0.1003, -1.2866],\n",
      "        [-0.8888, -0.1022, -1.2831],\n",
      "        [-0.8744, -0.1071, -1.2719],\n",
      "        [-0.9038, -0.0962, -1.2898],\n",
      "        [-0.7655, -0.1461, -1.1808]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.7991, 0.7889, 0.5493, 0.5835, 0.6175],\n",
      "        [0.7889, 0.8398, 0.6725, 0.6597, 0.6829],\n",
      "        [0.5493, 0.6725, 0.9635, 0.7635, 0.8987],\n",
      "        [0.5835, 0.6597, 0.7635, 0.6341, 0.6966],\n",
      "        [0.6175, 0.6829, 0.8987, 0.6966, 0.8246]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 1.0194, -1.2405,  0.2165],\n",
      "        [ 1.1300,  0.9967,  0.6143],\n",
      "        [ 1.7597,  0.4755,  0.3927],\n",
      "        [ 0.8306, -0.6250,  0.4739],\n",
      "        [ 0.6546, -0.4390,  0.6174]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[0.8288, 0.0686, 0.3205],\n",
      "        [0.8378, 0.0586, 0.3223],\n",
      "        [0.8358, 0.0583, 0.3219],\n",
      "        [0.8232, 0.0780, 0.3195],\n",
      "        [0.8496, 0.0406, 0.3246]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.8967, -0.1003, -1.2866],\n",
      "        [-0.8888, -0.1022, -1.2831],\n",
      "        [-0.8744, -0.1071, -1.2719],\n",
      "        [-0.9038, -0.0962, -1.2898],\n",
      "        [-0.7655, -0.1461, -1.1808]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.5121, 0.7840, 0.5121, 0.9372, 0.7840, 0.9372, 0.7942, 0.7659, 0.7942,\n",
      "        0.7659], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.6936, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.6, 0.6866666666666665)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Rev GCN VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevGCNEncoder: 2-1                                         --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       80\n",
      "    RevGCNEncoder: 2-2                                         --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       80\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.2199, 0.4751, 0.2199, 0.9998, 0.4751, 0.9998, 0.8138, 0.9998, 0.8138,\n",
      "        0.9998], grad_fn=<SigmoidBackward0>), tensor([[ 0.0962, -0.6022,  0.5591],\n",
      "        [ 0.0709, -0.5779,  0.4973],\n",
      "        [ 0.0606, -0.5921,  0.5033],\n",
      "        [ 0.1000, -0.6243,  0.5946],\n",
      "        [ 0.0672, -0.6052,  0.5284]], grad_fn=<AddmmBackward0>), tensor([[-0.4145,  0.2492,  0.1108],\n",
      "        [-0.3632,  0.1341,  0.1751],\n",
      "        [-0.3988,  0.2250,  0.1209],\n",
      "        [-0.4089,  0.2291,  0.1220],\n",
      "        [-0.3985,  0.2270,  0.1065]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9990, 0.9966, 0.9983, 0.9982, 0.4565],\n",
      "        [0.9966, 0.9928, 0.9960, 0.9868, 0.5485],\n",
      "        [0.9983, 0.9960, 0.9981, 0.9915, 0.6398],\n",
      "        [0.9982, 0.9868, 0.9915, 0.9999, 0.1326],\n",
      "        [0.4565, 0.5485, 0.6398, 0.1326, 0.9208]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.3936, -0.0693,  0.1502],\n",
      "        [ 1.2700, -0.3184, -0.1516],\n",
      "        [ 0.9204, -2.2874,  0.0165],\n",
      "        [ 0.1310, -1.5855,  0.8080],\n",
      "        [ 1.4126,  1.4634,  0.7262]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[ 0.0962, -0.6022,  0.5591],\n",
      "        [ 0.0709, -0.5779,  0.4973],\n",
      "        [ 0.0606, -0.5921,  0.5033],\n",
      "        [ 0.1000, -0.6243,  0.5946],\n",
      "        [ 0.0672, -0.6052,  0.5284]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.4145,  0.2492,  0.1108],\n",
      "        [-0.3632,  0.1341,  0.1751],\n",
      "        [-0.3988,  0.2250,  0.1209],\n",
      "        [-0.4089,  0.2291,  0.1220],\n",
      "        [-0.3985,  0.2270,  0.1065]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6223, 0.6279, 0.6223, 0.8693, 0.6279, 0.8693, 0.9773, 0.1156, 0.9773,\n",
      "        0.1156], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.5588, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.56, 0.7142857142857142)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gat_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Rev GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_rev_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test VGAE serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.norm.weight', tensor([1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0.])), ('_encoder_mu.conv.att', tensor([[[-0.7339, -0.3626, -0.7060],\n",
      "         [-0.1553,  1.0130, -1.0443]]])), ('_encoder_mu.conv.bias', tensor([0., 0., 0.])), ('_encoder_mu.conv.lin_l.weight', tensor([[ 0.6304, -0.2264,  0.6272],\n",
      "        [ 0.5438,  0.7960,  0.2522],\n",
      "        [ 0.4468,  0.1234, -0.3910],\n",
      "        [-0.3899, -0.7737,  0.4645],\n",
      "        [ 0.2371,  0.3295,  0.5477],\n",
      "        [ 0.0060, -0.2315,  0.1780]])), ('_encoder_mu.conv.lin_l.bias', tensor([ 0.0296,  0.2697, -0.3883,  0.3916, -0.4433, -0.0455])), ('_encoder_mu.conv.lin_r.weight', tensor([[ 0.4510, -0.5296, -0.3083],\n",
      "        [ 0.6905,  0.2204,  0.3145],\n",
      "        [ 0.5668,  0.1087, -0.4290],\n",
      "        [-0.4100,  0.3755,  0.5446],\n",
      "        [-0.8026,  0.2371, -0.3495],\n",
      "        [ 0.2396, -0.6471, -0.5171]])), ('_encoder_mu.conv.lin_r.bias', tensor([-0.1346, -0.3913, -0.3263, -0.3055, -0.4243, -0.0369])), ('_encoder_mu.conv.lin_edge.weight', tensor([[ 0.2864],\n",
      "        [ 0.7007],\n",
      "        [-0.0072],\n",
      "        [ 0.6992],\n",
      "        [-0.8522],\n",
      "        [ 0.5865]])), ('_shared_encoder.lin1.weight', tensor([[-0.2635,  0.1133,  0.3387, -0.0655,  0.2712, -0.1996],\n",
      "        [ 0.1346, -0.0931,  0.3003, -0.0186, -0.1444,  0.2334],\n",
      "        [-0.0885,  0.1963,  0.0644,  0.1575, -0.2968, -0.3965],\n",
      "        [ 0.2672,  0.2259,  0.2653,  0.1336, -0.2791,  0.3671]])), ('_shared_encoder.lin1.bias', tensor([0.3927, 0.2392, 0.1658, 0.0296])), ('_shared_encoder.lin2.weight', tensor([[ 0.0780,  0.2454, -0.0443, -0.3626],\n",
      "        [-0.2699,  0.1329, -0.0488,  0.3488],\n",
      "        [ 0.4305, -0.4888, -0.2137,  0.3801]])), ('_shared_encoder.lin2.bias', tensor([0.4260, 0.0158, 0.0590])), ('_shared_encoder.norm.weight', tensor([1., 1., 1., 1.])), ('_shared_encoder.norm.bias', tensor([0., 0., 0., 0.])), ('_shared_encoder.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.0.conv.att', tensor([[[-0.3106,  0.3870],\n",
      "         [ 0.0308,  0.0880],\n",
      "         [-0.3438, -0.5245],\n",
      "         [-0.7617,  0.0573],\n",
      "         [-0.6054,  0.0657],\n",
      "         [ 0.4623,  0.3508],\n",
      "         [-0.7689,  0.3363],\n",
      "         [ 0.1738, -0.4385]]])), ('_shared_encoder.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.0.conv.lin_l.weight', tensor([[-0.0161,  0.5222],\n",
      "        [ 0.1172,  0.3040],\n",
      "        [ 0.5764,  0.2063],\n",
      "        [ 0.3681, -0.4071],\n",
      "        [-0.1170, -0.5043],\n",
      "        [-0.1088,  0.0756],\n",
      "        [-0.4199,  0.5583],\n",
      "        [ 0.1852, -0.1080],\n",
      "        [ 0.4057,  0.2731],\n",
      "        [ 0.4059, -0.3293],\n",
      "        [-0.2401, -0.2590],\n",
      "        [ 0.1885,  0.4062],\n",
      "        [ 0.4256,  0.1782],\n",
      "        [-0.3798, -0.4495],\n",
      "        [-0.0069, -0.2911],\n",
      "        [ 0.5310, -0.0161]])), ('_shared_encoder.convs.0.convs.0.conv.lin_l.bias', tensor([ 0.6430, -0.2627,  0.3113,  0.2131, -0.4832,  0.0555,  0.4955,  0.1668,\n",
      "         0.3721, -0.2134, -0.0118, -0.5766,  0.2157, -0.6796, -0.2121, -0.0262])), ('_shared_encoder.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.3514, -0.3246],\n",
      "        [ 0.2176, -0.4722],\n",
      "        [ 0.0601,  0.2524],\n",
      "        [-0.5235, -0.5654],\n",
      "        [ 0.4151, -0.2985],\n",
      "        [-0.1295,  0.3487],\n",
      "        [-0.2962, -0.0972],\n",
      "        [-0.0375,  0.1403],\n",
      "        [ 0.4904, -0.2867],\n",
      "        [-0.5476, -0.4162],\n",
      "        [-0.0317,  0.0881],\n",
      "        [ 0.2438, -0.1484],\n",
      "        [ 0.1101, -0.0956],\n",
      "        [ 0.1999,  0.3858],\n",
      "        [ 0.4266,  0.5225],\n",
      "        [-0.3644,  0.2019]])), ('_shared_encoder.convs.0.convs.0.conv.lin_r.bias', tensor([-0.0041, -0.0709, -0.6429,  0.2507, -0.0043,  0.1986, -0.6561, -0.2800,\n",
      "        -0.0033,  0.6706,  0.4962,  0.3789, -0.4300,  0.3443, -0.6309,  0.6763])), ('_shared_encoder.convs.0.convs.0.conv.lin_edge.weight', tensor([[ 0.4467],\n",
      "        [ 0.0811],\n",
      "        [-0.4321],\n",
      "        [-0.5021],\n",
      "        [-0.1875],\n",
      "        [ 0.3176],\n",
      "        [-0.0807],\n",
      "        [ 0.2275],\n",
      "        [ 0.3519],\n",
      "        [-0.2440],\n",
      "        [ 0.5398],\n",
      "        [-0.1586],\n",
      "        [ 0.4514],\n",
      "        [ 0.4107],\n",
      "        [ 0.2661],\n",
      "        [ 0.2637]])), ('_shared_encoder.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.1.conv.att', tensor([[[-0.2573,  0.4515],\n",
      "         [-0.5759, -0.2638],\n",
      "         [ 0.4372, -0.0557],\n",
      "         [ 0.5809,  0.5484],\n",
      "         [ 0.7127, -0.3482],\n",
      "         [ 0.3427,  0.7578],\n",
      "         [ 0.3061,  0.1164],\n",
      "         [ 0.2821, -0.0577]]])), ('_shared_encoder.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.2114,  0.2619],\n",
      "        [ 0.4138,  0.4265],\n",
      "        [-0.4621, -0.2403],\n",
      "        [-0.3165,  0.0235],\n",
      "        [-0.2524,  0.4164],\n",
      "        [ 0.5473, -0.3074],\n",
      "        [ 0.2094,  0.0398],\n",
      "        [-0.3624,  0.1919],\n",
      "        [ 0.0204, -0.3507],\n",
      "        [-0.2074, -0.5603],\n",
      "        [ 0.5555,  0.2217],\n",
      "        [-0.2095,  0.4065],\n",
      "        [ 0.2757,  0.4436],\n",
      "        [ 0.2752,  0.4305],\n",
      "        [-0.4438, -0.3704],\n",
      "        [ 0.2492,  0.2467]])), ('_shared_encoder.convs.0.convs.1.conv.lin_l.bias', tensor([ 0.6513,  0.3560, -0.3887, -0.0124,  0.2293,  0.5141, -0.4379,  0.1591,\n",
      "        -0.4578, -0.3520, -0.5358, -0.3386, -0.3537,  0.3878,  0.4123,  0.1348])), ('_shared_encoder.convs.0.convs.1.conv.lin_r.weight', tensor([[-0.4928,  0.0853],\n",
      "        [-0.0062,  0.0717],\n",
      "        [-0.2764, -0.0339],\n",
      "        [ 0.2542,  0.3798],\n",
      "        [-0.5395, -0.0357],\n",
      "        [-0.0266,  0.4120],\n",
      "        [ 0.3523, -0.5508],\n",
      "        [ 0.4964,  0.5404],\n",
      "        [ 0.2800,  0.1342],\n",
      "        [-0.2710, -0.5193],\n",
      "        [-0.3449,  0.4742],\n",
      "        [-0.5341,  0.1091],\n",
      "        [-0.1265, -0.2365],\n",
      "        [ 0.5548,  0.0772],\n",
      "        [ 0.5155, -0.2131],\n",
      "        [ 0.0500,  0.0171]])), ('_shared_encoder.convs.0.convs.1.conv.lin_r.bias', tensor([ 0.4198, -0.6333,  0.6246, -0.4590, -0.1797,  0.3713, -0.4368, -0.6523,\n",
      "        -0.2268, -0.3306,  0.0444,  0.1930,  0.2580, -0.4486, -0.5751, -0.1827])), ('_shared_encoder.convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.3468],\n",
      "        [ 0.3129],\n",
      "        [ 0.3922],\n",
      "        [ 0.4991],\n",
      "        [-0.3984],\n",
      "        [-0.0553],\n",
      "        [-0.5111],\n",
      "        [-0.2084],\n",
      "        [ 0.4299],\n",
      "        [-0.3754],\n",
      "        [-0.1587],\n",
      "        [ 0.1485],\n",
      "        [-0.5650],\n",
      "        [ 0.1780],\n",
      "        [-0.2896],\n",
      "        [-0.5357]])), ('_shared_encoder.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.0.conv.att', tensor([[[-0.1566,  0.5433],\n",
      "         [-0.5298, -0.3726],\n",
      "         [ 0.4276, -0.4796],\n",
      "         [-0.1056, -0.3082],\n",
      "         [ 0.6042,  0.6946],\n",
      "         [-0.5636,  0.7271],\n",
      "         [ 0.4986, -0.7237],\n",
      "         [ 0.3078,  0.5248]]])), ('_shared_encoder.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.1879, -0.0152],\n",
      "        [ 0.3130, -0.0132],\n",
      "        [-0.2687, -0.0581],\n",
      "        [-0.3482, -0.0360],\n",
      "        [ 0.0699, -0.4967],\n",
      "        [ 0.1239,  0.5546],\n",
      "        [-0.0840,  0.0530],\n",
      "        [ 0.1579,  0.5440],\n",
      "        [-0.1802,  0.4056],\n",
      "        [ 0.5432,  0.4910],\n",
      "        [-0.0611,  0.1094],\n",
      "        [ 0.5686, -0.5155],\n",
      "        [-0.3561, -0.2160],\n",
      "        [-0.4422,  0.0449],\n",
      "        [-0.5515,  0.4050],\n",
      "        [-0.1000,  0.1180]])), ('_shared_encoder.convs.1.convs.0.conv.lin_l.bias', tensor([-0.1220, -0.3361,  0.0275, -0.5541,  0.2601, -0.0779, -0.3397, -0.1148,\n",
      "         0.2423,  0.1977, -0.6318,  0.1765, -0.6306, -0.5526,  0.0252, -0.1773])), ('_shared_encoder.convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.4216,  0.1161],\n",
      "        [-0.5496, -0.3936],\n",
      "        [-0.3648, -0.4603],\n",
      "        [ 0.0757,  0.0633],\n",
      "        [-0.0622,  0.0575],\n",
      "        [ 0.3497, -0.0993],\n",
      "        [-0.1409, -0.0974],\n",
      "        [-0.4102, -0.1473],\n",
      "        [-0.3154, -0.3425],\n",
      "        [-0.4250,  0.3404],\n",
      "        [ 0.0601, -0.5172],\n",
      "        [-0.4160,  0.5643],\n",
      "        [ 0.2018, -0.2559],\n",
      "        [-0.4700, -0.3533],\n",
      "        [-0.4106,  0.3572],\n",
      "        [-0.5541,  0.2574]])), ('_shared_encoder.convs.1.convs.0.conv.lin_r.bias', tensor([-0.3868, -0.0132,  0.0521, -0.4742,  0.3392,  0.1867,  0.3579, -0.5554,\n",
      "         0.1997, -0.1003, -0.1362, -0.0933,  0.1939,  0.3800,  0.1081,  0.3846])), ('_shared_encoder.convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.1004],\n",
      "        [-0.2913],\n",
      "        [-0.4446],\n",
      "        [ 0.4194],\n",
      "        [-0.5227],\n",
      "        [ 0.1318],\n",
      "        [-0.1150],\n",
      "        [-0.4113],\n",
      "        [-0.4663],\n",
      "        [ 0.4455],\n",
      "        [-0.2116],\n",
      "        [-0.4473],\n",
      "        [-0.0668],\n",
      "        [ 0.1472],\n",
      "        [ 0.1381],\n",
      "        [-0.2286]])), ('_shared_encoder.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.1.conv.att', tensor([[[-0.6926, -0.0123],\n",
      "         [-0.0851,  0.5074],\n",
      "         [-0.5209,  0.0721],\n",
      "         [ 0.3104, -0.3217],\n",
      "         [-0.1555, -0.3206],\n",
      "         [-0.5172,  0.5667],\n",
      "         [ 0.5171,  0.3039],\n",
      "         [-0.2416, -0.6417]]])), ('_shared_encoder.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.5698,  0.2723],\n",
      "        [-0.2605,  0.0881],\n",
      "        [-0.5484,  0.4376],\n",
      "        [-0.1330,  0.5569],\n",
      "        [ 0.3865,  0.1909],\n",
      "        [ 0.1792, -0.4054],\n",
      "        [ 0.4592, -0.5119],\n",
      "        [-0.1761,  0.4843],\n",
      "        [-0.1865,  0.4107],\n",
      "        [ 0.1399,  0.2090],\n",
      "        [ 0.1525,  0.0656],\n",
      "        [-0.1675, -0.1235],\n",
      "        [-0.1058,  0.0955],\n",
      "        [ 0.2510, -0.5557],\n",
      "        [-0.3967, -0.5688],\n",
      "        [ 0.0497,  0.5014]])), ('_shared_encoder.convs.1.convs.1.conv.lin_l.bias', tensor([-0.2087,  0.6784, -0.5402, -0.3805,  0.5361,  0.2232,  0.6634,  0.5131,\n",
      "        -0.4145, -0.3133,  0.3755,  0.4727, -0.6029, -0.2158, -0.6147, -0.2323])), ('_shared_encoder.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.0701,  0.5662],\n",
      "        [ 0.4573, -0.3719],\n",
      "        [-0.2989, -0.1810],\n",
      "        [ 0.3603, -0.2867],\n",
      "        [ 0.3862,  0.1975],\n",
      "        [-0.5476, -0.0244],\n",
      "        [ 0.0160,  0.1278],\n",
      "        [ 0.4870,  0.4450],\n",
      "        [-0.0930,  0.1301],\n",
      "        [ 0.2952,  0.0757],\n",
      "        [ 0.1703,  0.4296],\n",
      "        [ 0.0411, -0.1087],\n",
      "        [-0.5182,  0.2772],\n",
      "        [-0.5086, -0.0973],\n",
      "        [ 0.4217, -0.5037],\n",
      "        [ 0.1994,  0.4014]])), ('_shared_encoder.convs.1.convs.1.conv.lin_r.bias', tensor([ 0.3942,  0.2547,  0.1546,  0.5588,  0.0730, -0.3800,  0.1490,  0.2386,\n",
      "        -0.0968,  0.1888,  0.1370,  0.3575,  0.1495, -0.5045,  0.6038, -0.4011])), ('_shared_encoder.convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.2582],\n",
      "        [ 0.0249],\n",
      "        [ 0.4710],\n",
      "        [ 0.5886],\n",
      "        [ 0.3722],\n",
      "        [-0.3511],\n",
      "        [ 0.1197],\n",
      "        [-0.1611],\n",
      "        [ 0.3294],\n",
      "        [-0.0659],\n",
      "        [ 0.4335],\n",
      "        [-0.4128],\n",
      "        [ 0.2300],\n",
      "        [ 0.1084],\n",
      "        [-0.4959],\n",
      "        [ 0.1117]])), ('_shared_encoder.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.0.conv.att', tensor([[[-0.4927, -0.0523],\n",
      "         [ 0.0400,  0.7052],\n",
      "         [ 0.7245,  0.0237],\n",
      "         [-0.2834,  0.7387],\n",
      "         [-0.7726, -0.1476],\n",
      "         [ 0.0965, -0.2026],\n",
      "         [-0.4089, -0.1411],\n",
      "         [-0.3584, -0.4612]]])), ('_shared_encoder.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.4231, -0.2080],\n",
      "        [ 0.1016, -0.2137],\n",
      "        [-0.2656,  0.2476],\n",
      "        [ 0.1531,  0.2337],\n",
      "        [-0.1922, -0.3756],\n",
      "        [ 0.2867,  0.4990],\n",
      "        [-0.5558,  0.2513],\n",
      "        [-0.4396,  0.0874],\n",
      "        [-0.4432, -0.4967],\n",
      "        [ 0.1518, -0.2064],\n",
      "        [ 0.1280, -0.2874],\n",
      "        [-0.3153, -0.2263],\n",
      "        [-0.5365,  0.2540],\n",
      "        [ 0.2118,  0.2497],\n",
      "        [ 0.0263, -0.1679],\n",
      "        [ 0.4659,  0.4352]])), ('_shared_encoder.convs.2.convs.0.conv.lin_l.bias', tensor([-0.1800,  0.1324,  0.7046, -0.2825,  0.3467, -0.1948, -0.3580,  0.1119,\n",
      "        -0.6845,  0.4233,  0.1097,  0.0901, -0.2577, -0.5906,  0.2297,  0.1846])), ('_shared_encoder.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.5734,  0.5600],\n",
      "        [-0.0048, -0.3997],\n",
      "        [-0.2593,  0.0779],\n",
      "        [-0.3462, -0.1992],\n",
      "        [-0.2860,  0.2263],\n",
      "        [ 0.3924, -0.0925],\n",
      "        [ 0.3395,  0.4494],\n",
      "        [-0.2578,  0.3153],\n",
      "        [-0.2457,  0.2793],\n",
      "        [ 0.3031,  0.2292],\n",
      "        [-0.5643,  0.5437],\n",
      "        [ 0.2376, -0.5567],\n",
      "        [-0.1525,  0.5523],\n",
      "        [ 0.4121,  0.4706],\n",
      "        [ 0.2695,  0.4507],\n",
      "        [ 0.1784, -0.2825]])), ('_shared_encoder.convs.2.convs.0.conv.lin_r.bias', tensor([-0.6953, -0.1714, -0.2765, -0.6622,  0.2272, -0.1225,  0.0873, -0.5809,\n",
      "        -0.3810, -0.1063,  0.2235, -0.4595, -0.4071, -0.0042, -0.6098, -0.0094])), ('_shared_encoder.convs.2.convs.0.conv.lin_edge.weight', tensor([[ 0.2169],\n",
      "        [ 0.3410],\n",
      "        [ 0.2160],\n",
      "        [-0.5128],\n",
      "        [ 0.3909],\n",
      "        [-0.3556],\n",
      "        [-0.1310],\n",
      "        [ 0.5854],\n",
      "        [ 0.5891],\n",
      "        [ 0.4106],\n",
      "        [ 0.0801],\n",
      "        [ 0.2669],\n",
      "        [ 0.5632],\n",
      "        [ 0.2403],\n",
      "        [-0.0893],\n",
      "        [-0.0895]])), ('_shared_encoder.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_shared_encoder.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.1.conv.att', tensor([[[-0.4847,  0.1865],\n",
      "         [ 0.4375, -0.1901],\n",
      "         [-0.4902,  0.5437],\n",
      "         [ 0.6826, -0.0678],\n",
      "         [ 0.1046, -0.2991],\n",
      "         [ 0.3330, -0.4670],\n",
      "         [ 0.7353, -0.5270],\n",
      "         [-0.5899,  0.6598]]])), ('_shared_encoder.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_shared_encoder.convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.2964, -0.1394],\n",
      "        [-0.3091,  0.4065],\n",
      "        [ 0.3615, -0.3073],\n",
      "        [-0.1121,  0.1907],\n",
      "        [ 0.0251, -0.5067],\n",
      "        [ 0.2617,  0.4247],\n",
      "        [-0.2733,  0.4861],\n",
      "        [ 0.5683,  0.5280],\n",
      "        [ 0.2427,  0.2164],\n",
      "        [ 0.2161, -0.1544],\n",
      "        [-0.3203, -0.4197],\n",
      "        [-0.2727,  0.3536],\n",
      "        [-0.4963, -0.1175],\n",
      "        [-0.0566, -0.0194],\n",
      "        [ 0.1361,  0.1817],\n",
      "        [-0.5505, -0.0103]])), ('_shared_encoder.convs.2.convs.1.conv.lin_l.bias', tensor([-0.6872,  0.6213, -0.1208,  0.5965,  0.2573, -0.2482,  0.6221, -0.3185,\n",
      "        -0.3109, -0.6255, -0.0404, -0.4951,  0.5662, -0.1930,  0.4795, -0.6476])), ('_shared_encoder.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.2455, -0.4350],\n",
      "        [-0.0848, -0.1733],\n",
      "        [ 0.4288,  0.3656],\n",
      "        [ 0.3981, -0.1794],\n",
      "        [-0.1287, -0.4023],\n",
      "        [-0.3178, -0.5517],\n",
      "        [-0.2240,  0.0846],\n",
      "        [ 0.1187,  0.0073],\n",
      "        [ 0.2100, -0.0162],\n",
      "        [-0.3581, -0.5596],\n",
      "        [-0.3930, -0.0351],\n",
      "        [-0.0172,  0.0202],\n",
      "        [ 0.2771,  0.2644],\n",
      "        [-0.0750, -0.1348],\n",
      "        [-0.3491,  0.2751],\n",
      "        [-0.3466, -0.0838]])), ('_shared_encoder.convs.2.convs.1.conv.lin_r.bias', tensor([ 0.1635,  0.1267, -0.3192,  0.0386,  0.6017, -0.4523,  0.3068,  0.0024,\n",
      "        -0.1841, -0.2314, -0.1050,  0.5660, -0.4278,  0.4147, -0.1485,  0.1393])), ('_shared_encoder.convs.2.convs.1.conv.lin_edge.weight', tensor([[ 0.4158],\n",
      "        [-0.1396],\n",
      "        [-0.1544],\n",
      "        [-0.1445],\n",
      "        [-0.3788],\n",
      "        [ 0.4251],\n",
      "        [ 0.0020],\n",
      "        [ 0.0569],\n",
      "        [ 0.2045],\n",
      "        [ 0.2689],\n",
      "        [ 0.5784],\n",
      "        [ 0.1192],\n",
      "        [-0.1527],\n",
      "        [ 0.3973],\n",
      "        [-0.3997],\n",
      "        [ 0.3917]])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0.])), ('_encoder_logstd.conv.att', tensor([[[-0.9052, -0.9405, -0.8429],\n",
      "         [ 0.9461, -0.9698, -0.4812],\n",
      "         [-0.2276, -0.4291,  0.4502]]])), ('_encoder_logstd.conv.bias', tensor([0., 0., 0.])), ('_encoder_logstd.conv.lin_l.weight', tensor([[ 0.1473,  0.5569, -0.1527],\n",
      "        [ 0.5583,  0.5315,  0.4191],\n",
      "        [-0.6380,  0.4637, -0.4976],\n",
      "        [-0.0057,  0.3306,  0.0134],\n",
      "        [-0.4072, -0.0876,  0.5221],\n",
      "        [-0.5419,  0.2661,  0.4813],\n",
      "        [-0.1139, -0.4075, -0.6517],\n",
      "        [ 0.3369, -0.1480, -0.1068],\n",
      "        [-0.4994,  0.1581, -0.1125]])), ('_encoder_logstd.conv.lin_l.bias', tensor([-0.2284, -0.2365,  0.2996, -0.2425, -0.0064,  0.0581, -0.5104,  0.3481,\n",
      "        -0.2112])), ('_encoder_logstd.conv.lin_r.weight', tensor([[-0.4874, -0.1239,  0.1479],\n",
      "        [-0.3081, -0.0195,  0.5043],\n",
      "        [ 0.2214, -0.4347, -0.3466],\n",
      "        [-0.1146, -0.3376,  0.2656],\n",
      "        [ 0.5810,  0.3180, -0.0780],\n",
      "        [-0.5150,  0.1815, -0.0213],\n",
      "        [-0.1752,  0.0764, -0.6216],\n",
      "        [ 0.2804, -0.5254,  0.5664],\n",
      "        [-0.2612,  0.0204,  0.0592]])), ('_encoder_logstd.conv.lin_r.bias', tensor([-0.4619,  0.0316, -0.5295, -0.1263,  0.4010,  0.5107, -0.1797, -0.0934,\n",
      "         0.3614])), ('_encoder_logstd.conv.lin_edge.weight', tensor([[-0.3507],\n",
      "        [ 0.6516],\n",
      "        [-0.4487],\n",
      "        [-0.3788],\n",
      "        [ 0.4670],\n",
      "        [-0.7735],\n",
      "        [-0.1709],\n",
      "        [ 0.6846],\n",
      "        [ 0.4030]]))]), 'constructor_params': {'encoder_logstd_given': True, 'shared_encoder_given': True, 'encoder_logstd': {'state_dict': OrderedDict([('norm.weight', tensor([1., 1., 1.])), ('norm.bias', tensor([0., 0., 0.])), ('conv.att', tensor([[[-0.9052, -0.9405, -0.8429],\n",
      "         [ 0.9461, -0.9698, -0.4812],\n",
      "         [-0.2276, -0.4291,  0.4502]]])), ('conv.bias', tensor([0., 0., 0.])), ('conv.lin_l.weight', tensor([[ 0.1473,  0.5569, -0.1527],\n",
      "        [ 0.5583,  0.5315,  0.4191],\n",
      "        [-0.6380,  0.4637, -0.4976],\n",
      "        [-0.0057,  0.3306,  0.0134],\n",
      "        [-0.4072, -0.0876,  0.5221],\n",
      "        [-0.5419,  0.2661,  0.4813],\n",
      "        [-0.1139, -0.4075, -0.6517],\n",
      "        [ 0.3369, -0.1480, -0.1068],\n",
      "        [-0.4994,  0.1581, -0.1125]])), ('conv.lin_l.bias', tensor([-0.2284, -0.2365,  0.2996, -0.2425, -0.0064,  0.0581, -0.5104,  0.3481,\n",
      "        -0.2112])), ('conv.lin_r.weight', tensor([[-0.4874, -0.1239,  0.1479],\n",
      "        [-0.3081, -0.0195,  0.5043],\n",
      "        [ 0.2214, -0.4347, -0.3466],\n",
      "        [-0.1146, -0.3376,  0.2656],\n",
      "        [ 0.5810,  0.3180, -0.0780],\n",
      "        [-0.5150,  0.1815, -0.0213],\n",
      "        [-0.1752,  0.0764, -0.6216],\n",
      "        [ 0.2804, -0.5254,  0.5664],\n",
      "        [-0.2612,  0.0204,  0.0592]])), ('conv.lin_r.bias', tensor([-0.4619,  0.0316, -0.5295, -0.1263,  0.4010,  0.5107, -0.1797, -0.0934,\n",
      "         0.3614])), ('conv.lin_edge.weight', tensor([[-0.3507],\n",
      "        [ 0.6516],\n",
      "        [-0.4487],\n",
      "        [-0.3788],\n",
      "        [ 0.4670],\n",
      "        [-0.7735],\n",
      "        [-0.1709],\n",
      "        [ 0.6846],\n",
      "        [ 0.4030]]))]), 'constructor_params': {'in_channels': 3, 'out_channels': 3, 'version': 'v2', 'heads': 3, 'concat': False, 'dropout': 0.0, 'bias': True, 'add_self_loops': True, 'edge_dim': 1, 'fill_value': 'mean', 'project_multi_head': True}}, 'encoder_mu': {'state_dict': OrderedDict([('norm.weight', tensor([1., 1., 1.])), ('norm.bias', tensor([0., 0., 0.])), ('conv.att', tensor([[[-0.7339, -0.3626, -0.7060],\n",
      "         [-0.1553,  1.0130, -1.0443]]])), ('conv.bias', tensor([0., 0., 0.])), ('conv.lin_l.weight', tensor([[ 0.6304, -0.2264,  0.6272],\n",
      "        [ 0.5438,  0.7960,  0.2522],\n",
      "        [ 0.4468,  0.1234, -0.3910],\n",
      "        [-0.3899, -0.7737,  0.4645],\n",
      "        [ 0.2371,  0.3295,  0.5477],\n",
      "        [ 0.0060, -0.2315,  0.1780]])), ('conv.lin_l.bias', tensor([ 0.0296,  0.2697, -0.3883,  0.3916, -0.4433, -0.0455])), ('conv.lin_r.weight', tensor([[ 0.4510, -0.5296, -0.3083],\n",
      "        [ 0.6905,  0.2204,  0.3145],\n",
      "        [ 0.5668,  0.1087, -0.4290],\n",
      "        [-0.4100,  0.3755,  0.5446],\n",
      "        [-0.8026,  0.2371, -0.3495],\n",
      "        [ 0.2396, -0.6471, -0.5171]])), ('conv.lin_r.bias', tensor([-0.1346, -0.3913, -0.3263, -0.3055, -0.4243, -0.0369])), ('conv.lin_edge.weight', tensor([[ 0.2864],\n",
      "        [ 0.7007],\n",
      "        [-0.0072],\n",
      "        [ 0.6992],\n",
      "        [-0.8522],\n",
      "        [ 0.5865]]))]), 'constructor_params': {'in_channels': 3, 'out_channels': 3, 'version': 'v2', 'heads': 2, 'concat': False, 'dropout': 0.0, 'bias': True, 'add_self_loops': True, 'edge_dim': 1, 'fill_value': 'mean', 'project_multi_head': True}}, 'shared_encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2635,  0.1133,  0.3387, -0.0655,  0.2712, -0.1996],\n",
      "        [ 0.1346, -0.0931,  0.3003, -0.0186, -0.1444,  0.2334],\n",
      "        [-0.0885,  0.1963,  0.0644,  0.1575, -0.2968, -0.3965],\n",
      "        [ 0.2672,  0.2259,  0.2653,  0.1336, -0.2791,  0.3671]])), ('lin1.bias', tensor([0.3927, 0.2392, 0.1658, 0.0296])), ('lin2.weight', tensor([[ 0.0780,  0.2454, -0.0443, -0.3626],\n",
      "        [-0.2699,  0.1329, -0.0488,  0.3488],\n",
      "        [ 0.4305, -0.4888, -0.2137,  0.3801]])), ('lin2.bias', tensor([0.4260, 0.0158, 0.0590])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[-0.3106,  0.3870],\n",
      "         [ 0.0308,  0.0880],\n",
      "         [-0.3438, -0.5245],\n",
      "         [-0.7617,  0.0573],\n",
      "         [-0.6054,  0.0657],\n",
      "         [ 0.4623,  0.3508],\n",
      "         [-0.7689,  0.3363],\n",
      "         [ 0.1738, -0.4385]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.0161,  0.5222],\n",
      "        [ 0.1172,  0.3040],\n",
      "        [ 0.5764,  0.2063],\n",
      "        [ 0.3681, -0.4071],\n",
      "        [-0.1170, -0.5043],\n",
      "        [-0.1088,  0.0756],\n",
      "        [-0.4199,  0.5583],\n",
      "        [ 0.1852, -0.1080],\n",
      "        [ 0.4057,  0.2731],\n",
      "        [ 0.4059, -0.3293],\n",
      "        [-0.2401, -0.2590],\n",
      "        [ 0.1885,  0.4062],\n",
      "        [ 0.4256,  0.1782],\n",
      "        [-0.3798, -0.4495],\n",
      "        [-0.0069, -0.2911],\n",
      "        [ 0.5310, -0.0161]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([ 0.6430, -0.2627,  0.3113,  0.2131, -0.4832,  0.0555,  0.4955,  0.1668,\n",
      "         0.3721, -0.2134, -0.0118, -0.5766,  0.2157, -0.6796, -0.2121, -0.0262])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.3514, -0.3246],\n",
      "        [ 0.2176, -0.4722],\n",
      "        [ 0.0601,  0.2524],\n",
      "        [-0.5235, -0.5654],\n",
      "        [ 0.4151, -0.2985],\n",
      "        [-0.1295,  0.3487],\n",
      "        [-0.2962, -0.0972],\n",
      "        [-0.0375,  0.1403],\n",
      "        [ 0.4904, -0.2867],\n",
      "        [-0.5476, -0.4162],\n",
      "        [-0.0317,  0.0881],\n",
      "        [ 0.2438, -0.1484],\n",
      "        [ 0.1101, -0.0956],\n",
      "        [ 0.1999,  0.3858],\n",
      "        [ 0.4266,  0.5225],\n",
      "        [-0.3644,  0.2019]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([-0.0041, -0.0709, -0.6429,  0.2507, -0.0043,  0.1986, -0.6561, -0.2800,\n",
      "        -0.0033,  0.6706,  0.4962,  0.3789, -0.4300,  0.3443, -0.6309,  0.6763])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[ 0.4467],\n",
      "        [ 0.0811],\n",
      "        [-0.4321],\n",
      "        [-0.5021],\n",
      "        [-0.1875],\n",
      "        [ 0.3176],\n",
      "        [-0.0807],\n",
      "        [ 0.2275],\n",
      "        [ 0.3519],\n",
      "        [-0.2440],\n",
      "        [ 0.5398],\n",
      "        [-0.1586],\n",
      "        [ 0.4514],\n",
      "        [ 0.4107],\n",
      "        [ 0.2661],\n",
      "        [ 0.2637]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[-0.2573,  0.4515],\n",
      "         [-0.5759, -0.2638],\n",
      "         [ 0.4372, -0.0557],\n",
      "         [ 0.5809,  0.5484],\n",
      "         [ 0.7127, -0.3482],\n",
      "         [ 0.3427,  0.7578],\n",
      "         [ 0.3061,  0.1164],\n",
      "         [ 0.2821, -0.0577]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.2114,  0.2619],\n",
      "        [ 0.4138,  0.4265],\n",
      "        [-0.4621, -0.2403],\n",
      "        [-0.3165,  0.0235],\n",
      "        [-0.2524,  0.4164],\n",
      "        [ 0.5473, -0.3074],\n",
      "        [ 0.2094,  0.0398],\n",
      "        [-0.3624,  0.1919],\n",
      "        [ 0.0204, -0.3507],\n",
      "        [-0.2074, -0.5603],\n",
      "        [ 0.5555,  0.2217],\n",
      "        [-0.2095,  0.4065],\n",
      "        [ 0.2757,  0.4436],\n",
      "        [ 0.2752,  0.4305],\n",
      "        [-0.4438, -0.3704],\n",
      "        [ 0.2492,  0.2467]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.6513,  0.3560, -0.3887, -0.0124,  0.2293,  0.5141, -0.4379,  0.1591,\n",
      "        -0.4578, -0.3520, -0.5358, -0.3386, -0.3537,  0.3878,  0.4123,  0.1348])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.4928,  0.0853],\n",
      "        [-0.0062,  0.0717],\n",
      "        [-0.2764, -0.0339],\n",
      "        [ 0.2542,  0.3798],\n",
      "        [-0.5395, -0.0357],\n",
      "        [-0.0266,  0.4120],\n",
      "        [ 0.3523, -0.5508],\n",
      "        [ 0.4964,  0.5404],\n",
      "        [ 0.2800,  0.1342],\n",
      "        [-0.2710, -0.5193],\n",
      "        [-0.3449,  0.4742],\n",
      "        [-0.5341,  0.1091],\n",
      "        [-0.1265, -0.2365],\n",
      "        [ 0.5548,  0.0772],\n",
      "        [ 0.5155, -0.2131],\n",
      "        [ 0.0500,  0.0171]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.4198, -0.6333,  0.6246, -0.4590, -0.1797,  0.3713, -0.4368, -0.6523,\n",
      "        -0.2268, -0.3306,  0.0444,  0.1930,  0.2580, -0.4486, -0.5751, -0.1827])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.3468],\n",
      "        [ 0.3129],\n",
      "        [ 0.3922],\n",
      "        [ 0.4991],\n",
      "        [-0.3984],\n",
      "        [-0.0553],\n",
      "        [-0.5111],\n",
      "        [-0.2084],\n",
      "        [ 0.4299],\n",
      "        [-0.3754],\n",
      "        [-0.1587],\n",
      "        [ 0.1485],\n",
      "        [-0.5650],\n",
      "        [ 0.1780],\n",
      "        [-0.2896],\n",
      "        [-0.5357]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[-0.1566,  0.5433],\n",
      "         [-0.5298, -0.3726],\n",
      "         [ 0.4276, -0.4796],\n",
      "         [-0.1056, -0.3082],\n",
      "         [ 0.6042,  0.6946],\n",
      "         [-0.5636,  0.7271],\n",
      "         [ 0.4986, -0.7237],\n",
      "         [ 0.3078,  0.5248]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.1879, -0.0152],\n",
      "        [ 0.3130, -0.0132],\n",
      "        [-0.2687, -0.0581],\n",
      "        [-0.3482, -0.0360],\n",
      "        [ 0.0699, -0.4967],\n",
      "        [ 0.1239,  0.5546],\n",
      "        [-0.0840,  0.0530],\n",
      "        [ 0.1579,  0.5440],\n",
      "        [-0.1802,  0.4056],\n",
      "        [ 0.5432,  0.4910],\n",
      "        [-0.0611,  0.1094],\n",
      "        [ 0.5686, -0.5155],\n",
      "        [-0.3561, -0.2160],\n",
      "        [-0.4422,  0.0449],\n",
      "        [-0.5515,  0.4050],\n",
      "        [-0.1000,  0.1180]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.1220, -0.3361,  0.0275, -0.5541,  0.2601, -0.0779, -0.3397, -0.1148,\n",
      "         0.2423,  0.1977, -0.6318,  0.1765, -0.6306, -0.5526,  0.0252, -0.1773])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.4216,  0.1161],\n",
      "        [-0.5496, -0.3936],\n",
      "        [-0.3648, -0.4603],\n",
      "        [ 0.0757,  0.0633],\n",
      "        [-0.0622,  0.0575],\n",
      "        [ 0.3497, -0.0993],\n",
      "        [-0.1409, -0.0974],\n",
      "        [-0.4102, -0.1473],\n",
      "        [-0.3154, -0.3425],\n",
      "        [-0.4250,  0.3404],\n",
      "        [ 0.0601, -0.5172],\n",
      "        [-0.4160,  0.5643],\n",
      "        [ 0.2018, -0.2559],\n",
      "        [-0.4700, -0.3533],\n",
      "        [-0.4106,  0.3572],\n",
      "        [-0.5541,  0.2574]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([-0.3868, -0.0132,  0.0521, -0.4742,  0.3392,  0.1867,  0.3579, -0.5554,\n",
      "         0.1997, -0.1003, -0.1362, -0.0933,  0.1939,  0.3800,  0.1081,  0.3846])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.1004],\n",
      "        [-0.2913],\n",
      "        [-0.4446],\n",
      "        [ 0.4194],\n",
      "        [-0.5227],\n",
      "        [ 0.1318],\n",
      "        [-0.1150],\n",
      "        [-0.4113],\n",
      "        [-0.4663],\n",
      "        [ 0.4455],\n",
      "        [-0.2116],\n",
      "        [-0.4473],\n",
      "        [-0.0668],\n",
      "        [ 0.1472],\n",
      "        [ 0.1381],\n",
      "        [-0.2286]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[-0.6926, -0.0123],\n",
      "         [-0.0851,  0.5074],\n",
      "         [-0.5209,  0.0721],\n",
      "         [ 0.3104, -0.3217],\n",
      "         [-0.1555, -0.3206],\n",
      "         [-0.5172,  0.5667],\n",
      "         [ 0.5171,  0.3039],\n",
      "         [-0.2416, -0.6417]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.5698,  0.2723],\n",
      "        [-0.2605,  0.0881],\n",
      "        [-0.5484,  0.4376],\n",
      "        [-0.1330,  0.5569],\n",
      "        [ 0.3865,  0.1909],\n",
      "        [ 0.1792, -0.4054],\n",
      "        [ 0.4592, -0.5119],\n",
      "        [-0.1761,  0.4843],\n",
      "        [-0.1865,  0.4107],\n",
      "        [ 0.1399,  0.2090],\n",
      "        [ 0.1525,  0.0656],\n",
      "        [-0.1675, -0.1235],\n",
      "        [-0.1058,  0.0955],\n",
      "        [ 0.2510, -0.5557],\n",
      "        [-0.3967, -0.5688],\n",
      "        [ 0.0497,  0.5014]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.2087,  0.6784, -0.5402, -0.3805,  0.5361,  0.2232,  0.6634,  0.5131,\n",
      "        -0.4145, -0.3133,  0.3755,  0.4727, -0.6029, -0.2158, -0.6147, -0.2323])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.0701,  0.5662],\n",
      "        [ 0.4573, -0.3719],\n",
      "        [-0.2989, -0.1810],\n",
      "        [ 0.3603, -0.2867],\n",
      "        [ 0.3862,  0.1975],\n",
      "        [-0.5476, -0.0244],\n",
      "        [ 0.0160,  0.1278],\n",
      "        [ 0.4870,  0.4450],\n",
      "        [-0.0930,  0.1301],\n",
      "        [ 0.2952,  0.0757],\n",
      "        [ 0.1703,  0.4296],\n",
      "        [ 0.0411, -0.1087],\n",
      "        [-0.5182,  0.2772],\n",
      "        [-0.5086, -0.0973],\n",
      "        [ 0.4217, -0.5037],\n",
      "        [ 0.1994,  0.4014]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([ 0.3942,  0.2547,  0.1546,  0.5588,  0.0730, -0.3800,  0.1490,  0.2386,\n",
      "        -0.0968,  0.1888,  0.1370,  0.3575,  0.1495, -0.5045,  0.6038, -0.4011])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.2582],\n",
      "        [ 0.0249],\n",
      "        [ 0.4710],\n",
      "        [ 0.5886],\n",
      "        [ 0.3722],\n",
      "        [-0.3511],\n",
      "        [ 0.1197],\n",
      "        [-0.1611],\n",
      "        [ 0.3294],\n",
      "        [-0.0659],\n",
      "        [ 0.4335],\n",
      "        [-0.4128],\n",
      "        [ 0.2300],\n",
      "        [ 0.1084],\n",
      "        [-0.4959],\n",
      "        [ 0.1117]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[-0.4927, -0.0523],\n",
      "         [ 0.0400,  0.7052],\n",
      "         [ 0.7245,  0.0237],\n",
      "         [-0.2834,  0.7387],\n",
      "         [-0.7726, -0.1476],\n",
      "         [ 0.0965, -0.2026],\n",
      "         [-0.4089, -0.1411],\n",
      "         [-0.3584, -0.4612]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.4231, -0.2080],\n",
      "        [ 0.1016, -0.2137],\n",
      "        [-0.2656,  0.2476],\n",
      "        [ 0.1531,  0.2337],\n",
      "        [-0.1922, -0.3756],\n",
      "        [ 0.2867,  0.4990],\n",
      "        [-0.5558,  0.2513],\n",
      "        [-0.4396,  0.0874],\n",
      "        [-0.4432, -0.4967],\n",
      "        [ 0.1518, -0.2064],\n",
      "        [ 0.1280, -0.2874],\n",
      "        [-0.3153, -0.2263],\n",
      "        [-0.5365,  0.2540],\n",
      "        [ 0.2118,  0.2497],\n",
      "        [ 0.0263, -0.1679],\n",
      "        [ 0.4659,  0.4352]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.1800,  0.1324,  0.7046, -0.2825,  0.3467, -0.1948, -0.3580,  0.1119,\n",
      "        -0.6845,  0.4233,  0.1097,  0.0901, -0.2577, -0.5906,  0.2297,  0.1846])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.5734,  0.5600],\n",
      "        [-0.0048, -0.3997],\n",
      "        [-0.2593,  0.0779],\n",
      "        [-0.3462, -0.1992],\n",
      "        [-0.2860,  0.2263],\n",
      "        [ 0.3924, -0.0925],\n",
      "        [ 0.3395,  0.4494],\n",
      "        [-0.2578,  0.3153],\n",
      "        [-0.2457,  0.2793],\n",
      "        [ 0.3031,  0.2292],\n",
      "        [-0.5643,  0.5437],\n",
      "        [ 0.2376, -0.5567],\n",
      "        [-0.1525,  0.5523],\n",
      "        [ 0.4121,  0.4706],\n",
      "        [ 0.2695,  0.4507],\n",
      "        [ 0.1784, -0.2825]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([-0.6953, -0.1714, -0.2765, -0.6622,  0.2272, -0.1225,  0.0873, -0.5809,\n",
      "        -0.3810, -0.1063,  0.2235, -0.4595, -0.4071, -0.0042, -0.6098, -0.0094])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[ 0.2169],\n",
      "        [ 0.3410],\n",
      "        [ 0.2160],\n",
      "        [-0.5128],\n",
      "        [ 0.3909],\n",
      "        [-0.3556],\n",
      "        [-0.1310],\n",
      "        [ 0.5854],\n",
      "        [ 0.5891],\n",
      "        [ 0.4106],\n",
      "        [ 0.0801],\n",
      "        [ 0.2669],\n",
      "        [ 0.5632],\n",
      "        [ 0.2403],\n",
      "        [-0.0893],\n",
      "        [-0.0895]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[-0.4847,  0.1865],\n",
      "         [ 0.4375, -0.1901],\n",
      "         [-0.4902,  0.5437],\n",
      "         [ 0.6826, -0.0678],\n",
      "         [ 0.1046, -0.2991],\n",
      "         [ 0.3330, -0.4670],\n",
      "         [ 0.7353, -0.5270],\n",
      "         [-0.5899,  0.6598]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.2964, -0.1394],\n",
      "        [-0.3091,  0.4065],\n",
      "        [ 0.3615, -0.3073],\n",
      "        [-0.1121,  0.1907],\n",
      "        [ 0.0251, -0.5067],\n",
      "        [ 0.2617,  0.4247],\n",
      "        [-0.2733,  0.4861],\n",
      "        [ 0.5683,  0.5280],\n",
      "        [ 0.2427,  0.2164],\n",
      "        [ 0.2161, -0.1544],\n",
      "        [-0.3203, -0.4197],\n",
      "        [-0.2727,  0.3536],\n",
      "        [-0.4963, -0.1175],\n",
      "        [-0.0566, -0.0194],\n",
      "        [ 0.1361,  0.1817],\n",
      "        [-0.5505, -0.0103]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.6872,  0.6213, -0.1208,  0.5965,  0.2573, -0.2482,  0.6221, -0.3185,\n",
      "        -0.3109, -0.6255, -0.0404, -0.4951,  0.5662, -0.1930,  0.4795, -0.6476])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.2455, -0.4350],\n",
      "        [-0.0848, -0.1733],\n",
      "        [ 0.4288,  0.3656],\n",
      "        [ 0.3981, -0.1794],\n",
      "        [-0.1287, -0.4023],\n",
      "        [-0.3178, -0.5517],\n",
      "        [-0.2240,  0.0846],\n",
      "        [ 0.1187,  0.0073],\n",
      "        [ 0.2100, -0.0162],\n",
      "        [-0.3581, -0.5596],\n",
      "        [-0.3930, -0.0351],\n",
      "        [-0.0172,  0.0202],\n",
      "        [ 0.2771,  0.2644],\n",
      "        [-0.0750, -0.1348],\n",
      "        [-0.3491,  0.2751],\n",
      "        [-0.3466, -0.0838]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([ 0.1635,  0.1267, -0.3192,  0.0386,  0.6017, -0.4523,  0.3068,  0.0024,\n",
      "        -0.1841, -0.2314, -0.1050,  0.5660, -0.4278,  0.4147, -0.1485,  0.1393])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[ 0.4158],\n",
      "        [-0.1396],\n",
      "        [-0.1544],\n",
      "        [-0.1445],\n",
      "        [-0.3788],\n",
      "        [ 0.4251],\n",
      "        [ 0.0020],\n",
      "        [ 0.0569],\n",
      "        [ 0.2045],\n",
      "        [ 0.2689],\n",
      "        [ 0.5784],\n",
      "        [ 0.1192],\n",
      "        [-0.1527],\n",
      "        [ 0.3973],\n",
      "        [-0.3997],\n",
      "        [ 0.3917]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): GATConvBlock(\n",
      "      (norm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(3, 3, heads=2)\n",
      "    )\n",
      "    (_shared_encoder): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): GATConvBlock(\n",
      "      (norm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(3, 3, heads=3)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    GATConvBlock: 2-1                                          --\n",
      "        LayerNorm: 3-1                                        6\n",
      "        GATv2Conv: 3-2                                        63\n",
      "    RevGATConvEncoder: 2-2                                     --\n",
      "        Linear: 3-3                                           28\n",
      "        Linear: 3-4                                           15\n",
      "        LayerNorm: 3-5                                        8\n",
      "        ModuleList: 3-6                                       804\n",
      "    GATConvBlock: 2-3                                          --\n",
      "        LayerNorm: 3-7                                        6\n",
      "        GATv2Conv: 3-8                                        93\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,023\n",
      "Trainable params: 1,023\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.9795, 0.3396, 0.9795, 0.7884, 0.3396, 0.7884, 0.8231, 0.4807, 0.8231,\n",
      "        0.4807], grad_fn=<SigmoidBackward0>), tensor([[ 0.7005,  0.4816, -0.3206],\n",
      "        [ 0.6308,  0.4911, -0.3301],\n",
      "        [ 0.7166,  0.4718, -0.3297],\n",
      "        [ 0.8082,  0.4487, -0.3496],\n",
      "        [ 0.8815,  0.4249, -0.3318]], grad_fn=<AddBackward0>), tensor([[-0.5837,  0.3564, -0.0053],\n",
      "        [-0.5702,  0.3548,  0.0078],\n",
      "        [-0.5906,  0.3623,  0.0037],\n",
      "        [-0.6259,  0.3758,  0.0262],\n",
      "        [-0.6473,  0.3819, -0.0424]], grad_fn=<AddBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.9476, 0.8265, 0.9476, 0.3379, 0.8265, 0.3379, 0.5665, 0.2862, 0.5665,\n",
      "        0.2862], grad_fn=<SigmoidBackward0>), tensor([[ 0.7005,  0.4816, -0.3206],\n",
      "        [ 0.6308,  0.4911, -0.3301],\n",
      "        [ 0.7166,  0.4718, -0.3297],\n",
      "        [ 0.8082,  0.4487, -0.3496],\n",
      "        [ 0.8815,  0.4249, -0.3318]], grad_fn=<AddBackward0>), tensor([[-0.5837,  0.3564, -0.0053],\n",
      "        [-0.5702,  0.3548,  0.0078],\n",
      "        [-0.5906,  0.3623,  0.0037],\n",
      "        [-0.6259,  0.3758,  0.0262],\n",
      "        [-0.6473,  0.3819, -0.0424]], grad_fn=<AddBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.9131, 0.9989, 0.2125, 0.5862, 0.2080],\n",
      "        [0.9989, 1.0000, 0.0154, 0.8382, 0.2145],\n",
      "        [0.2125, 0.0154, 0.9709, 0.9329, 0.9611],\n",
      "        [0.5862, 0.8382, 0.9329, 0.9666, 0.9721],\n",
      "        [0.2080, 0.2145, 0.9611, 0.9721, 0.9985]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.8257, 0.3746, 0.2278, 0.3657, 0.4201],\n",
      "        [0.3746, 0.8232, 0.9005, 0.5248, 0.7226],\n",
      "        [0.2278, 0.9005, 0.9887, 0.9613, 0.8279],\n",
      "        [0.3657, 0.5248, 0.9613, 0.9994, 0.6372],\n",
      "        [0.4201, 0.7226, 0.8279, 0.6372, 0.6526]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.5007, -0.9600, -0.3649],\n",
      "        [ 2.0329,  1.3595, -0.4160],\n",
      "        [ 1.6023, -2.0482, -0.9179],\n",
      "        [ 0.0720,  0.0296, -0.1818],\n",
      "        [ 1.1593, -0.8105, -2.2396]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[ 1.5536,  1.9568,  0.4317],\n",
      "        [ 0.2061,  0.7059, -0.5007],\n",
      "        [ 0.7984,  0.0178,  0.2477],\n",
      "        [ 0.1851,  2.4486, -0.8181],\n",
      "        [ 1.0515, -1.2604,  0.0537]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[ 0.7005,  0.4816, -0.3206],\n",
      "        [ 0.6308,  0.4911, -0.3301],\n",
      "        [ 0.7166,  0.4718, -0.3297],\n",
      "        [ 0.8082,  0.4487, -0.3496],\n",
      "        [ 0.8815,  0.4249, -0.3318]], grad_fn=<AddBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.5837,  0.3564, -0.0053],\n",
      "        [-0.5702,  0.3548,  0.0078],\n",
      "        [-0.5906,  0.3623,  0.0037],\n",
      "        [-0.6259,  0.3758,  0.0262],\n",
      "        [-0.6473,  0.3819, -0.0424]], grad_fn=<AddBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[ 0.7005,  0.4816, -0.3206],\n",
      "        [ 0.6308,  0.4911, -0.3301],\n",
      "        [ 0.7166,  0.4718, -0.3297],\n",
      "        [ 0.8082,  0.4487, -0.3496],\n",
      "        [ 0.8815,  0.4249, -0.3318]], grad_fn=<AddBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.5837,  0.3564, -0.0053],\n",
      "        [-0.5702,  0.3548,  0.0078],\n",
      "        [-0.5906,  0.3623,  0.0037],\n",
      "        [-0.6259,  0.3758,  0.0262],\n",
      "        [-0.6473,  0.3819, -0.0424]], grad_fn=<AddBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.8626, 0.5509, 0.8626, 0.5460, 0.5509, 0.5460, 0.4858, 0.6912, 0.4858,\n",
      "        0.6912], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.8064, 0.8365, 0.8064, 0.8499, 0.8365, 0.8499, 0.9996, 0.0536, 0.9996,\n",
      "        0.0536], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.3363, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(3.6560, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.52, 0.7088888888888889)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.2, 0.4046031746031746)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.0818,  0.3616, -0.2862, -0.0862, -0.2156,  0.3113],\n",
      "        [ 0.1669, -0.3936,  0.2417,  0.2197,  0.1241, -0.1508],\n",
      "        [ 0.1030,  0.3213, -0.3063, -0.2821, -0.1072,  0.3427],\n",
      "        [-0.3124, -0.1524,  0.3538,  0.2180,  0.2227,  0.2267]])), ('_encoder_mu.lin1.bias', tensor([-0.0034, -0.2244,  0.2646, -0.2791])), ('_encoder_mu.lin2.weight', tensor([[ 0.2775, -0.4703, -0.4374,  0.0821],\n",
      "        [ 0.0777, -0.3361, -0.0352, -0.1157],\n",
      "        [-0.3139, -0.2008,  0.1086,  0.4861]])), ('_encoder_mu.lin2.bias', tensor([-0.0869, -0.3272, -0.0650])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.lin.weight', tensor([[-0.3311,  0.3996],\n",
      "        [-0.6210, -0.3158]])), ('_encoder_mu.convs.0.convs.0.conv.lin.bias', tensor([0.2871, 0.5496])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.weight', tensor([[-0.0437,  0.1789],\n",
      "        [ 0.5985,  0.0011]])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.bias', tensor([0.0343, 0.2949])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.3932,  0.2002],\n",
      "        [ 0.4037, -0.2429]])), ('_encoder_mu.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.lin.weight', tensor([[-0.5983,  0.5006],\n",
      "        [-0.3889, -0.6685]])), ('_encoder_mu.convs.0.convs.1.conv.lin.bias', tensor([-0.5882,  0.1010])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.2922, -0.3530],\n",
      "        [ 0.4436, -0.5252]])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.bias', tensor([-0.0811, -0.4269])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.weight', tensor([[-0.2347, -0.1094],\n",
      "        [ 0.1618, -0.0045]])), ('_encoder_mu.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.lin.weight', tensor([[-0.5846, -0.4711],\n",
      "        [-0.2320,  0.0684]])), ('_encoder_mu.convs.1.convs.0.conv.lin.bias', tensor([-0.2029,  0.4024])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.2218,  0.1563],\n",
      "        [-0.4377, -0.3457]])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.bias', tensor([-0.2055,  0.0075])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4863, -0.4636],\n",
      "        [ 0.1174,  0.1502]])), ('_encoder_mu.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.lin.weight', tensor([[-0.3584,  0.6204],\n",
      "        [ 0.3311,  0.2496]])), ('_encoder_mu.convs.1.convs.1.conv.lin.bias', tensor([-0.1929, -0.5964])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.weight', tensor([[-0.0830, -0.4777],\n",
      "        [ 0.6663,  0.0478]])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.bias', tensor([-0.3244, -0.0213])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.4515, -0.3057],\n",
      "        [ 0.2158,  0.2279]])), ('_encoder_mu.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.lin.weight', tensor([[-0.6621,  0.3728],\n",
      "        [ 0.2988,  0.1779]])), ('_encoder_mu.convs.2.convs.0.conv.lin.bias', tensor([0.5475, 0.0292])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.weight', tensor([[-0.6143,  0.5184],\n",
      "        [-0.0790, -0.7031]])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.bias', tensor([0.1760, 0.3472])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.6681,  0.6621],\n",
      "        [-0.0465,  0.0537]])), ('_encoder_mu.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.lin.weight', tensor([[ 0.1943, -0.5664],\n",
      "        [-0.6510,  0.6701]])), ('_encoder_mu.convs.2.convs.1.conv.lin.bias', tensor([ 0.3987, -0.6590])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.6034,  0.2682],\n",
      "        [ 0.2591, -0.1420]])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.bias', tensor([ 0.6560, -0.1747])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.1029,  0.3608],\n",
      "        [ 0.1188, -0.2037]])), ('_encoder_mu.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.0.conv.lin.weight', tensor([[-0.5693,  0.6223],\n",
      "        [-0.5252,  0.6914]])), ('_encoder_mu.convs.3.convs.0.conv.lin.bias', tensor([ 0.1320, -0.2757])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.weight', tensor([[-0.6290, -0.5982],\n",
      "        [ 0.0727,  0.4263]])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.bias', tensor([ 0.5569, -0.3345])), ('_encoder_mu.convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.3312, -0.4540],\n",
      "        [-0.4906,  0.3388]])), ('_encoder_mu.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.1.conv.lin.weight', tensor([[ 0.3382,  0.0451],\n",
      "        [ 0.0812, -0.4790]])), ('_encoder_mu.convs.3.convs.1.conv.lin.bias', tensor([-0.0029,  0.6910])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.weight', tensor([[-0.6645,  0.5810],\n",
      "        [ 0.5129, -0.0264]])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.bias', tensor([ 0.6582, -0.0911])), ('_encoder_mu.convs.3.convs.1.conv.lin_r.weight', tensor([[-0.3793,  0.3250],\n",
      "        [ 0.6282,  0.1488]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.2143,  0.1754,  0.2791, -0.1246, -0.1094,  0.1836],\n",
      "        [ 0.0784, -0.0875,  0.3267,  0.0547,  0.1710,  0.1937],\n",
      "        [ 0.3771, -0.3076, -0.1947, -0.1618,  0.1120,  0.3359],\n",
      "        [ 0.1367,  0.3823,  0.1223,  0.1750,  0.2029, -0.0529]])), ('_encoder_logstd.lin1.bias', tensor([-0.0324, -0.3186,  0.1616,  0.1033])), ('_encoder_logstd.lin2.weight', tensor([[ 0.0450, -0.3906, -0.0188,  0.3569],\n",
      "        [ 0.1628,  0.3174, -0.0354, -0.4497],\n",
      "        [-0.1946, -0.0445,  0.3364, -0.0257]])), ('_encoder_logstd.lin2.bias', tensor([-0.0531, -0.1149, -0.3244])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.lin.weight', tensor([[ 0.1906, -0.2594],\n",
      "        [-0.2711,  0.7020]])), ('_encoder_logstd.convs.0.convs.0.conv.lin.bias', tensor([ 0.0911, -0.5526])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.3382,  0.0179],\n",
      "        [-0.4125, -0.2815]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.bias', tensor([ 0.4437, -0.3290])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.weight', tensor([[0.4338, 0.5503],\n",
      "        [0.5311, 0.0834]])), ('_encoder_logstd.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.lin.weight', tensor([[-0.5475, -0.6396],\n",
      "        [-0.2432, -0.2228]])), ('_encoder_logstd.convs.0.convs.1.conv.lin.bias', tensor([ 0.4764, -0.6513])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.3207,  0.5832],\n",
      "        [ 0.1274, -0.5329]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.bias', tensor([0.4049, 0.5362])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.weight', tensor([[-0.2923, -0.3454],\n",
      "        [-0.4836, -0.3135]])), ('_encoder_logstd.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.lin.weight', tensor([[ 0.1226,  0.3992],\n",
      "        [-0.0605,  0.4066]])), ('_encoder_logstd.convs.1.convs.0.conv.lin.bias', tensor([ 0.0890, -0.5829])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.1554, -0.5145],\n",
      "        [ 0.3258, -0.2873]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.bias', tensor([-0.4626,  0.3862])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.1696, -0.2671],\n",
      "        [ 0.3125,  0.4396]])), ('_encoder_logstd.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.lin.weight', tensor([[ 0.5352,  0.2946],\n",
      "        [-0.3087,  0.0326]])), ('_encoder_logstd.convs.1.convs.1.conv.lin.bias', tensor([-0.1665,  0.1299])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.weight', tensor([[-0.3172, -0.5108],\n",
      "        [-0.5216,  0.2983]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.bias', tensor([-0.1309,  0.0469])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.2320, -0.1085],\n",
      "        [-0.3312, -0.5144]])), ('_encoder_logstd.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.lin.weight', tensor([[ 0.1603, -0.5158],\n",
      "        [ 0.5510,  0.4303]])), ('_encoder_logstd.convs.2.convs.0.conv.lin.bias', tensor([ 0.2239, -0.0950])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.0939, -0.2724],\n",
      "        [ 0.5907,  0.0045]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.bias', tensor([0.3806, 0.3491])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.6468, -0.6355],\n",
      "        [-0.5969,  0.2963]])), ('_encoder_logstd.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.lin.weight', tensor([[-0.2745,  0.0981],\n",
      "        [-0.4131,  0.2573]])), ('_encoder_logstd.convs.2.convs.1.conv.lin.bias', tensor([ 0.6554, -0.2805])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.3769, -0.5365],\n",
      "        [-0.2070,  0.0671]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.bias', tensor([-0.3224,  0.3870])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.4678,  0.1431],\n",
      "        [ 0.7003,  0.5244]])), ('_encoder_logstd.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.0.conv.lin.weight', tensor([[ 0.4602,  0.0956],\n",
      "        [-0.5192, -0.4589]])), ('_encoder_logstd.convs.3.convs.0.conv.lin.bias', tensor([ 0.5941, -0.3087])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.weight', tensor([[-0.2126, -0.0893],\n",
      "        [ 0.0276,  0.3680]])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.bias', tensor([0.5552, 0.5798])), ('_encoder_logstd.convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.1385,  0.6228],\n",
      "        [ 0.2518, -0.2220]])), ('_encoder_logstd.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.1.conv.lin.weight', tensor([[-0.3091, -0.3283],\n",
      "        [-0.0006,  0.3709]])), ('_encoder_logstd.convs.3.convs.1.conv.lin.bias', tensor([-0.4216, -0.2464])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.5033, -0.4469],\n",
      "        [-0.3061, -0.4146]])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.bias', tensor([ 0.6592, -0.0607])), ('_encoder_logstd.convs.3.convs.1.conv.lin_r.weight', tensor([[-0.3389, -0.1676],\n",
      "        [-0.4417, -0.2415]]))]), 'constructor_params': {'encoder_logstd_given': False, 'shared_encoder_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2143,  0.1754,  0.2791, -0.1246, -0.1094,  0.1836],\n",
      "        [ 0.0784, -0.0875,  0.3267,  0.0547,  0.1710,  0.1937],\n",
      "        [ 0.3771, -0.3076, -0.1947, -0.1618,  0.1120,  0.3359],\n",
      "        [ 0.1367,  0.3823,  0.1223,  0.1750,  0.2029, -0.0529]])), ('lin1.bias', tensor([-0.0324, -0.3186,  0.1616,  0.1033])), ('lin2.weight', tensor([[ 0.0450, -0.3906, -0.0188,  0.3569],\n",
      "        [ 0.1628,  0.3174, -0.0354, -0.4497],\n",
      "        [-0.1946, -0.0445,  0.3364, -0.0257]])), ('lin2.bias', tensor([-0.0531, -0.1149, -0.3244])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[ 0.1906, -0.2594],\n",
      "        [-0.2711,  0.7020]])), ('convs.0.convs.0.conv.lin.bias', tensor([ 0.0911, -0.5526])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.3382,  0.0179],\n",
      "        [-0.4125, -0.2815]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([ 0.4437, -0.3290])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[0.4338, 0.5503],\n",
      "        [0.5311, 0.0834]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.5475, -0.6396],\n",
      "        [-0.2432, -0.2228]])), ('convs.0.convs.1.conv.lin.bias', tensor([ 0.4764, -0.6513])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.3207,  0.5832],\n",
      "        [ 0.1274, -0.5329]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([0.4049, 0.5362])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.2923, -0.3454],\n",
      "        [-0.4836, -0.3135]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[ 0.1226,  0.3992],\n",
      "        [-0.0605,  0.4066]])), ('convs.1.convs.0.conv.lin.bias', tensor([ 0.0890, -0.5829])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.1554, -0.5145],\n",
      "        [ 0.3258, -0.2873]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.4626,  0.3862])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.1696, -0.2671],\n",
      "        [ 0.3125,  0.4396]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[ 0.5352,  0.2946],\n",
      "        [-0.3087,  0.0326]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.1665,  0.1299])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.3172, -0.5108],\n",
      "        [-0.5216,  0.2983]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.1309,  0.0469])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.2320, -0.1085],\n",
      "        [-0.3312, -0.5144]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[ 0.1603, -0.5158],\n",
      "        [ 0.5510,  0.4303]])), ('convs.2.convs.0.conv.lin.bias', tensor([ 0.2239, -0.0950])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.0939, -0.2724],\n",
      "        [ 0.5907,  0.0045]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([0.3806, 0.3491])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.6468, -0.6355],\n",
      "        [-0.5969,  0.2963]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[-0.2745,  0.0981],\n",
      "        [-0.4131,  0.2573]])), ('convs.2.convs.1.conv.lin.bias', tensor([ 0.6554, -0.2805])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.3769, -0.5365],\n",
      "        [-0.2070,  0.0671]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.3224,  0.3870])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.4678,  0.1431],\n",
      "        [ 0.7003,  0.5244]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.4602,  0.0956],\n",
      "        [-0.5192, -0.4589]])), ('convs.3.convs.0.conv.lin.bias', tensor([ 0.5941, -0.3087])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.2126, -0.0893],\n",
      "        [ 0.0276,  0.3680]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([0.5552, 0.5798])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.1385,  0.6228],\n",
      "        [ 0.2518, -0.2220]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-0.3091, -0.3283],\n",
      "        [-0.0006,  0.3709]])), ('convs.3.convs.1.conv.lin.bias', tensor([-0.4216, -0.2464])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.5033, -0.4469],\n",
      "        [-0.3061, -0.4146]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([ 0.6592, -0.0607])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[-0.3389, -0.1676],\n",
      "        [-0.4417, -0.2415]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.0818,  0.3616, -0.2862, -0.0862, -0.2156,  0.3113],\n",
      "        [ 0.1669, -0.3936,  0.2417,  0.2197,  0.1241, -0.1508],\n",
      "        [ 0.1030,  0.3213, -0.3063, -0.2821, -0.1072,  0.3427],\n",
      "        [-0.3124, -0.1524,  0.3538,  0.2180,  0.2227,  0.2267]])), ('lin1.bias', tensor([-0.0034, -0.2244,  0.2646, -0.2791])), ('lin2.weight', tensor([[ 0.2775, -0.4703, -0.4374,  0.0821],\n",
      "        [ 0.0777, -0.3361, -0.0352, -0.1157],\n",
      "        [-0.3139, -0.2008,  0.1086,  0.4861]])), ('lin2.bias', tensor([-0.0869, -0.3272, -0.0650])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.3311,  0.3996],\n",
      "        [-0.6210, -0.3158]])), ('convs.0.convs.0.conv.lin.bias', tensor([0.2871, 0.5496])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.0437,  0.1789],\n",
      "        [ 0.5985,  0.0011]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([0.0343, 0.2949])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.3932,  0.2002],\n",
      "        [ 0.4037, -0.2429]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.5983,  0.5006],\n",
      "        [-0.3889, -0.6685]])), ('convs.0.convs.1.conv.lin.bias', tensor([-0.5882,  0.1010])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.2922, -0.3530],\n",
      "        [ 0.4436, -0.5252]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.0811, -0.4269])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.2347, -0.1094],\n",
      "        [ 0.1618, -0.0045]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.5846, -0.4711],\n",
      "        [-0.2320,  0.0684]])), ('convs.1.convs.0.conv.lin.bias', tensor([-0.2029,  0.4024])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.2218,  0.1563],\n",
      "        [-0.4377, -0.3457]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.2055,  0.0075])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4863, -0.4636],\n",
      "        [ 0.1174,  0.1502]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[-0.3584,  0.6204],\n",
      "        [ 0.3311,  0.2496]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.1929, -0.5964])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.0830, -0.4777],\n",
      "        [ 0.6663,  0.0478]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.3244, -0.0213])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.4515, -0.3057],\n",
      "        [ 0.2158,  0.2279]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[-0.6621,  0.3728],\n",
      "        [ 0.2988,  0.1779]])), ('convs.2.convs.0.conv.lin.bias', tensor([0.5475, 0.0292])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.6143,  0.5184],\n",
      "        [-0.0790, -0.7031]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([0.1760, 0.3472])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.6681,  0.6621],\n",
      "        [-0.0465,  0.0537]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.1943, -0.5664],\n",
      "        [-0.6510,  0.6701]])), ('convs.2.convs.1.conv.lin.bias', tensor([ 0.3987, -0.6590])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.6034,  0.2682],\n",
      "        [ 0.2591, -0.1420]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.6560, -0.1747])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.1029,  0.3608],\n",
      "        [ 0.1188, -0.2037]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[-0.5693,  0.6223],\n",
      "        [-0.5252,  0.6914]])), ('convs.3.convs.0.conv.lin.bias', tensor([ 0.1320, -0.2757])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.6290, -0.5982],\n",
      "        [ 0.0727,  0.4263]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([ 0.5569, -0.3345])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.3312, -0.4540],\n",
      "        [-0.4906,  0.3388]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[ 0.3382,  0.0451],\n",
      "        [ 0.0812, -0.4790]])), ('convs.3.convs.1.conv.lin.bias', tensor([-0.0029,  0.6910])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[-0.6645,  0.5810],\n",
      "        [ 0.5129, -0.0264]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([ 0.6582, -0.0911])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[-0.3793,  0.3250],\n",
      "        [ 0.6282,  0.1488]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevSAGEConvEncoder: 2-1                                    --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       160\n",
      "    RevSAGEConvEncoder: 2-2                                    --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       160\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.8180, 0.8323, 0.8180, 0.8915, 0.8323, 0.8915, 0.5271, 0.5338, 0.5271,\n",
      "        0.5338], grad_fn=<SigmoidBackward0>), tensor([[-0.0568, -0.4135,  0.4279],\n",
      "        [ 0.0765, -0.2070, -0.3991],\n",
      "        [-0.0744, -0.2210, -0.3374],\n",
      "        [-0.0973, -0.2200, -0.3304],\n",
      "        [-0.3003, -0.2544, -0.2065]], grad_fn=<AddmmBackward0>), tensor([[-0.6523,  0.4433, -0.4717],\n",
      "        [-0.5702,  0.2958, -0.4131],\n",
      "        [-0.6244,  0.4252, -0.4684],\n",
      "        [-0.5145,  0.3440, -0.4681],\n",
      "        [-0.6273,  0.3730, -0.4278]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.7833, 0.8454, 0.7833, 0.9476, 0.8454, 0.9476, 0.1989, 0.3391, 0.1989,\n",
      "        0.3391], grad_fn=<SigmoidBackward0>), tensor([[-0.0568, -0.4135,  0.4279],\n",
      "        [ 0.0765, -0.2070, -0.3991],\n",
      "        [-0.0744, -0.2210, -0.3374],\n",
      "        [-0.0973, -0.2200, -0.3304],\n",
      "        [-0.3003, -0.2544, -0.2065]], grad_fn=<AddmmBackward0>), tensor([[-0.6523,  0.4433, -0.4717],\n",
      "        [-0.5702,  0.2958, -0.4131],\n",
      "        [-0.6244,  0.4252, -0.4684],\n",
      "        [-0.5145,  0.3440, -0.4681],\n",
      "        [-0.6273,  0.3730, -0.4278]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6738, 0.7456, 0.6419, 0.0801, 0.8265],\n",
      "        [0.7456, 0.8983, 0.7382, 0.0131, 0.9442],\n",
      "        [0.6419, 0.7382, 0.6292, 0.1037, 0.8104],\n",
      "        [0.0801, 0.0131, 0.1037, 0.9999, 0.0030],\n",
      "        [0.8265, 0.9442, 0.8104, 0.0030, 0.9828]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[1.0000, 0.8306, 0.9874, 0.9978, 0.3686],\n",
      "        [0.8306, 0.7529, 0.5713, 0.6651, 0.5533],\n",
      "        [0.9874, 0.5713, 0.8705, 0.8950, 0.4688],\n",
      "        [0.9978, 0.6651, 0.8950, 0.9480, 0.4384],\n",
      "        [0.3686, 0.5533, 0.4688, 0.4384, 0.5379]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.0773,  2.1189,  0.8553],\n",
      "        [-0.4151, -3.3058, -1.5255],\n",
      "        [ 0.3971,  0.8028,  0.0658],\n",
      "        [-0.7527, -1.8984,  0.0624],\n",
      "        [-0.1116, -1.8630, -0.3293]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-0.1452,  1.1581, -0.2945],\n",
      "        [ 1.5800,  2.1484,  0.1315],\n",
      "        [ 1.2762, -0.1697, -0.9512],\n",
      "        [ 1.0090, -1.3896, -1.3030],\n",
      "        [-0.9255,  0.2957, -0.0275]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.0568, -0.4135,  0.4279],\n",
      "        [ 0.0765, -0.2070, -0.3991],\n",
      "        [-0.0744, -0.2210, -0.3374],\n",
      "        [-0.0973, -0.2200, -0.3304],\n",
      "        [-0.3003, -0.2544, -0.2065]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.6523,  0.4433, -0.4717],\n",
      "        [-0.5702,  0.2958, -0.4131],\n",
      "        [-0.6244,  0.4252, -0.4684],\n",
      "        [-0.5145,  0.3440, -0.4681],\n",
      "        [-0.6273,  0.3730, -0.4278]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.0568, -0.4135,  0.4279],\n",
      "        [ 0.0765, -0.2070, -0.3991],\n",
      "        [-0.0744, -0.2210, -0.3374],\n",
      "        [-0.0973, -0.2200, -0.3304],\n",
      "        [-0.3003, -0.2544, -0.2065]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.6523,  0.4433, -0.4717],\n",
      "        [-0.5702,  0.2958, -0.4131],\n",
      "        [-0.6244,  0.4252, -0.4684],\n",
      "        [-0.5145,  0.3440, -0.4681],\n",
      "        [-0.6273,  0.3730, -0.4278]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.3558, 0.4461, 0.3558, 0.1770, 0.4461, 0.1770, 0.6436, 0.7116, 0.6436,\n",
      "        0.7116], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.9946, 0.9966, 0.9946, 0.9518, 0.9966, 0.9518, 0.8961, 0.6790, 0.8961,\n",
      "        0.6790], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4850, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(3.6370, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.27999999999999997, 0.43555555555555553)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.72, 0.8253968253968254)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.1883, -0.0900, -0.3038, -0.1330,  0.1498,  0.3522],\n",
      "        [ 0.0153,  0.2900,  0.3711,  0.2801,  0.0387,  0.0490],\n",
      "        [ 0.2495,  0.2949,  0.2164, -0.1605,  0.0855,  0.1638],\n",
      "        [-0.3612, -0.2148, -0.0397,  0.1101, -0.2869, -0.3758],\n",
      "        [ 0.3415,  0.3288, -0.1653,  0.1578,  0.2501,  0.0604]])), ('_encoder_mu.lin1.bias', tensor([-0.2306, -0.1131,  0.0393,  0.3510,  0.2199])), ('_encoder_mu.lin2.weight', tensor([[-0.1441, -0.4564, -0.0651, -0.0157],\n",
      "        [ 0.4606,  0.3523, -0.1549, -0.0237],\n",
      "        [-0.4053, -0.1541,  0.0077,  0.2954]])), ('_encoder_mu.lin2.bias', tensor([-0.0866,  0.3462, -0.0833])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.lin.weight', tensor([[ 4.7641e-01,  6.6051e-01, -1.9445e-01,  7.0087e-01,  2.0297e-01],\n",
      "        [ 4.3939e-02, -6.7339e-01, -9.5045e-02,  6.4211e-01,  5.4138e-01],\n",
      "        [ 4.9900e-01, -1.6042e-01, -6.6330e-01,  1.8283e-01,  5.2815e-01],\n",
      "        [ 4.2828e-01,  2.1461e-01, -2.6480e-01,  1.2034e-04,  3.7808e-01],\n",
      "        [-6.3266e-01, -4.4158e-01,  7.4924e-01,  7.1682e-01,  5.0222e-01]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.lin.weight', tensor([[-0.5532, -0.0603, -0.0769, -0.4253, -0.4302],\n",
      "        [ 0.0775,  0.7625, -0.7238, -0.1251,  0.7559],\n",
      "        [-0.2880,  0.6824, -0.4257,  0.5806,  0.1990],\n",
      "        [ 0.2047, -0.4352,  0.6843,  0.7447, -0.5987],\n",
      "        [ 0.6316, -0.4058, -0.1504,  0.1489, -0.4576]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.lin.weight', tensor([[-0.1441, -0.4581, -0.0556, -0.3039, -0.5746],\n",
      "        [-0.3996,  0.7748,  0.3954,  0.1510,  0.2597],\n",
      "        [-0.0736,  0.2234, -0.4734,  0.5250, -0.1368],\n",
      "        [ 0.5649, -0.8110, -0.1720, -0.8089, -0.1989]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.lin.weight', tensor([[ 0.7523,  0.8296, -0.7852,  0.3449],\n",
      "        [ 0.5484,  0.7474, -0.0335,  0.5145],\n",
      "        [-0.7612, -0.7487, -0.5473, -0.0209],\n",
      "        [-0.2369,  0.8292, -0.2258, -0.3433]])), ('_encoder_logstd.lin1.weight', tensor([[-0.2927,  0.2287,  0.2105,  0.4009, -0.3959,  0.3714],\n",
      "        [ 0.2501,  0.2880, -0.3553, -0.2047,  0.1841, -0.2446],\n",
      "        [ 0.0080, -0.3714,  0.0241,  0.3616, -0.1490, -0.0130],\n",
      "        [-0.0941, -0.1831,  0.1839, -0.0507, -0.2258, -0.1087],\n",
      "        [-0.3506,  0.3858,  0.3270,  0.0166,  0.3955,  0.1675]])), ('_encoder_logstd.lin1.bias', tensor([-0.1417, -0.1586,  0.2469,  0.3244, -0.0048])), ('_encoder_logstd.lin2.weight', tensor([[-0.4554,  0.4977,  0.4802,  0.2671],\n",
      "        [-0.3924,  0.3832,  0.3622,  0.0601],\n",
      "        [ 0.2659,  0.2795, -0.3411,  0.1104]])), ('_encoder_logstd.lin2.bias', tensor([ 0.0888, -0.3862, -0.2959])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.lin.weight', tensor([[-0.3167, -0.2007, -0.4774, -0.2560, -0.3778],\n",
      "        [ 0.4880,  0.1659, -0.6002,  0.5629,  0.4597],\n",
      "        [-0.5488, -0.2647,  0.3688,  0.5858, -0.6930],\n",
      "        [-0.3938,  0.0057,  0.1388,  0.5466, -0.6393],\n",
      "        [-0.6298,  0.0830,  0.1664,  0.4287, -0.0324]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.lin.weight', tensor([[ 0.4054, -0.4021,  0.0293,  0.1673, -0.2471],\n",
      "        [-0.6274, -0.4467,  0.0792,  0.3910,  0.2682],\n",
      "        [-0.5780, -0.2183,  0.5418, -0.5258,  0.3289],\n",
      "        [-0.1032,  0.0556, -0.4152, -0.0903,  0.0139],\n",
      "        [ 0.2294,  0.1454,  0.1595, -0.3038, -0.5833]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.lin.weight', tensor([[ 0.8047,  0.5990,  0.4898,  0.3313, -0.6835],\n",
      "        [-0.8128,  0.4201,  0.6876,  0.1341,  0.5280],\n",
      "        [-0.0536,  0.0760,  0.1153,  0.3707, -0.8082],\n",
      "        [-0.7546, -0.2204,  0.4447, -0.1645,  0.7238]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.lin.weight', tensor([[-0.0491, -0.6729,  0.1446, -0.1741],\n",
      "        [-0.3741, -0.0963, -0.7690, -0.6457],\n",
      "        [-0.7879, -0.0047, -0.3314, -0.2389],\n",
      "        [-0.2710, -0.0250, -0.0947, -0.5205]]))]), 'constructor_params': {'encoder_logstd_given': False, 'shared_encoder_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2927,  0.2287,  0.2105,  0.4009, -0.3959,  0.3714],\n",
      "        [ 0.2501,  0.2880, -0.3553, -0.2047,  0.1841, -0.2446],\n",
      "        [ 0.0080, -0.3714,  0.0241,  0.3616, -0.1490, -0.0130],\n",
      "        [-0.0941, -0.1831,  0.1839, -0.0507, -0.2258, -0.1087],\n",
      "        [-0.3506,  0.3858,  0.3270,  0.0166,  0.3955,  0.1675]])), ('lin1.bias', tensor([-0.1417, -0.1586,  0.2469,  0.3244, -0.0048])), ('lin2.weight', tensor([[-0.4554,  0.4977,  0.4802,  0.2671],\n",
      "        [-0.3924,  0.3832,  0.3622,  0.0601],\n",
      "        [ 0.2659,  0.2795, -0.3411,  0.1104]])), ('lin2.bias', tensor([ 0.0888, -0.3862, -0.2959])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[-0.3167, -0.2007, -0.4774, -0.2560, -0.3778],\n",
      "        [ 0.4880,  0.1659, -0.6002,  0.5629,  0.4597],\n",
      "        [-0.5488, -0.2647,  0.3688,  0.5858, -0.6930],\n",
      "        [-0.3938,  0.0057,  0.1388,  0.5466, -0.6393],\n",
      "        [-0.6298,  0.0830,  0.1664,  0.4287, -0.0324]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.4054, -0.4021,  0.0293,  0.1673, -0.2471],\n",
      "        [-0.6274, -0.4467,  0.0792,  0.3910,  0.2682],\n",
      "        [-0.5780, -0.2183,  0.5418, -0.5258,  0.3289],\n",
      "        [-0.1032,  0.0556, -0.4152, -0.0903,  0.0139],\n",
      "        [ 0.2294,  0.1454,  0.1595, -0.3038, -0.5833]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.8047,  0.5990,  0.4898,  0.3313, -0.6835],\n",
      "        [-0.8128,  0.4201,  0.6876,  0.1341,  0.5280],\n",
      "        [-0.0536,  0.0760,  0.1153,  0.3707, -0.8082],\n",
      "        [-0.7546, -0.2204,  0.4447, -0.1645,  0.7238]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[-0.0491, -0.6729,  0.1446, -0.1741],\n",
      "        [-0.3741, -0.0963, -0.7690, -0.6457],\n",
      "        [-0.7879, -0.0047, -0.3314, -0.2389],\n",
      "        [-0.2710, -0.0250, -0.0947, -0.5205]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.1883, -0.0900, -0.3038, -0.1330,  0.1498,  0.3522],\n",
      "        [ 0.0153,  0.2900,  0.3711,  0.2801,  0.0387,  0.0490],\n",
      "        [ 0.2495,  0.2949,  0.2164, -0.1605,  0.0855,  0.1638],\n",
      "        [-0.3612, -0.2148, -0.0397,  0.1101, -0.2869, -0.3758],\n",
      "        [ 0.3415,  0.3288, -0.1653,  0.1578,  0.2501,  0.0604]])), ('lin1.bias', tensor([-0.2306, -0.1131,  0.0393,  0.3510,  0.2199])), ('lin2.weight', tensor([[-0.1441, -0.4564, -0.0651, -0.0157],\n",
      "        [ 0.4606,  0.3523, -0.1549, -0.0237],\n",
      "        [-0.4053, -0.1541,  0.0077,  0.2954]])), ('lin2.bias', tensor([-0.0866,  0.3462, -0.0833])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[ 4.7641e-01,  6.6051e-01, -1.9445e-01,  7.0087e-01,  2.0297e-01],\n",
      "        [ 4.3939e-02, -6.7339e-01, -9.5045e-02,  6.4211e-01,  5.4138e-01],\n",
      "        [ 4.9900e-01, -1.6042e-01, -6.6330e-01,  1.8283e-01,  5.2815e-01],\n",
      "        [ 4.2828e-01,  2.1461e-01, -2.6480e-01,  1.2034e-04,  3.7808e-01],\n",
      "        [-6.3266e-01, -4.4158e-01,  7.4924e-01,  7.1682e-01,  5.0222e-01]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[-0.5532, -0.0603, -0.0769, -0.4253, -0.4302],\n",
      "        [ 0.0775,  0.7625, -0.7238, -0.1251,  0.7559],\n",
      "        [-0.2880,  0.6824, -0.4257,  0.5806,  0.1990],\n",
      "        [ 0.2047, -0.4352,  0.6843,  0.7447, -0.5987],\n",
      "        [ 0.6316, -0.4058, -0.1504,  0.1489, -0.4576]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[-0.1441, -0.4581, -0.0556, -0.3039, -0.5746],\n",
      "        [-0.3996,  0.7748,  0.3954,  0.1510,  0.2597],\n",
      "        [-0.0736,  0.2234, -0.4734,  0.5250, -0.1368],\n",
      "        [ 0.5649, -0.8110, -0.1720, -0.8089, -0.1989]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 0.7523,  0.8296, -0.7852,  0.3449],\n",
      "        [ 0.5484,  0.7474, -0.0335,  0.5145],\n",
      "        [-0.7612, -0.7487, -0.5473, -0.0209],\n",
      "        [-0.2369,  0.8292, -0.2258, -0.3433]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "VGEncoder: 1-1                                        --\n",
      "    SimpleGCNEncoder: 2-1                            --\n",
      "        Linear: 3-1                                 35\n",
      "        Linear: 3-2                                 15\n",
      "        LayerNorm: 3-3                              8\n",
      "        ModuleList: 3-4                             142\n",
      "    SimpleGCNEncoder: 2-2                            --\n",
      "        Linear: 3-5                                 35\n",
      "        Linear: 3-6                                 15\n",
      "        LayerNorm: 3-7                              8\n",
      "        ModuleList: 3-8                             142\n",
      "InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "forward() original\n",
      "(tensor([1.0000, 0.3430, 1.0000, 0.4853, 0.3430, 0.4853, 0.8439, 0.6723, 0.8439,\n",
      "        0.6723], grad_fn=<SigmoidBackward0>), tensor([[-0.3300,  0.6527, -0.1466],\n",
      "        [-0.3297,  0.6530, -0.1471],\n",
      "        [-0.3294,  0.6533, -0.1476],\n",
      "        [-0.3301,  0.6525, -0.1462],\n",
      "        [-0.3278,  0.6549, -0.1506]], grad_fn=<AddmmBackward0>), tensor([[ 0.5732, -0.1206, -0.2144],\n",
      "        [ 0.5957, -0.0852, -0.2894],\n",
      "        [ 0.6126, -0.0628, -0.3814],\n",
      "        [ 0.6687,  0.0037, -0.5841],\n",
      "        [ 0.6386, -0.0280, -0.4567]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([9.2658e-01, 1.5328e-02, 9.2658e-01, 9.9460e-01, 1.5328e-02, 9.9460e-01,\n",
      "        1.4754e-04, 9.9889e-01, 1.4754e-04, 9.9889e-01],\n",
      "       grad_fn=<SigmoidBackward0>), tensor([[-0.3300,  0.6527, -0.1466],\n",
      "        [-0.3297,  0.6530, -0.1471],\n",
      "        [-0.3294,  0.6533, -0.1476],\n",
      "        [-0.3301,  0.6525, -0.1462],\n",
      "        [-0.3278,  0.6549, -0.1506]], grad_fn=<AddmmBackward0>), tensor([[ 0.5732, -0.1206, -0.2144],\n",
      "        [ 0.5957, -0.0852, -0.2894],\n",
      "        [ 0.6126, -0.0628, -0.3814],\n",
      "        [ 0.6687,  0.0037, -0.5841],\n",
      "        [ 0.6386, -0.0280, -0.4567]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7624, 0.3661, 0.7135, 0.6210, 0.1145],\n",
      "        [0.3661, 0.9992, 0.2645, 0.6867, 0.9996],\n",
      "        [0.7135, 0.2645, 0.7845, 0.5323, 0.1266],\n",
      "        [0.6210, 0.6867, 0.5323, 0.6019, 0.5160],\n",
      "        [0.1145, 0.9996, 0.1266, 0.5160, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.9909, 0.0090, 0.0182, 0.0038, 0.2440],\n",
      "        [0.0090, 0.9959, 0.9766, 0.9968, 0.8867],\n",
      "        [0.0182, 0.9766, 0.9808, 0.9807, 0.6646],\n",
      "        [0.0038, 0.9968, 0.9807, 0.9996, 0.8144],\n",
      "        [0.2440, 0.8867, 0.6646, 0.8144, 0.7992]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.6409,  1.6273,  0.5561],\n",
      "        [-0.7769,  0.6274, -0.0130],\n",
      "        [-0.5053,  1.2320, -1.0898],\n",
      "        [-2.3058,  0.1220,  0.1570],\n",
      "        [-0.3283, -0.2607,  0.5779]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[ 1.5602,  0.1073, -0.4217],\n",
      "        [-1.0796,  3.2374,  0.0356],\n",
      "        [ 3.0400,  1.6831, -0.8214],\n",
      "        [ 1.2980,  0.4551, -0.1635],\n",
      "        [-1.8827,  1.4109, -0.8547]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.3300,  0.6527, -0.1466],\n",
      "        [-0.3297,  0.6530, -0.1471],\n",
      "        [-0.3294,  0.6533, -0.1476],\n",
      "        [-0.3301,  0.6525, -0.1462],\n",
      "        [-0.3278,  0.6549, -0.1506]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[ 0.5732, -0.1206, -0.2144],\n",
      "        [ 0.5957, -0.0852, -0.2894],\n",
      "        [ 0.6126, -0.0628, -0.3814],\n",
      "        [ 0.6687,  0.0037, -0.5841],\n",
      "        [ 0.6386, -0.0280, -0.4567]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.3300,  0.6527, -0.1466],\n",
      "        [-0.3297,  0.6530, -0.1471],\n",
      "        [-0.3294,  0.6533, -0.1476],\n",
      "        [-0.3301,  0.6525, -0.1462],\n",
      "        [-0.3278,  0.6549, -0.1506]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[ 0.5732, -0.1206, -0.2144],\n",
      "        [ 0.5957, -0.0852, -0.2894],\n",
      "        [ 0.6126, -0.0628, -0.3814],\n",
      "        [ 0.6687,  0.0037, -0.5841],\n",
      "        [ 0.6386, -0.0280, -0.4567]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.8196, 0.9346, 0.8196, 0.9173, 0.9346, 0.9173, 0.9102, 0.9530, 0.9102,\n",
      "        0.9530], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.7254, 0.9997, 0.7254, 0.9065, 0.9997, 0.9065, 0.8735, 0.7297, 0.8735,\n",
      "        0.7297], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(3.8821, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(1.5493, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.32000000000000006, 0.4442857142857143)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.6000000000000001, 0.6726190476190477)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[ 0.0700,  0.3917, -0.1945, -0.0099,  0.0103,  0.2063],\n",
      "        [ 0.0720,  0.3330, -0.0467, -0.0582, -0.3186,  0.3813],\n",
      "        [ 0.0403,  0.0343,  0.3663, -0.3947, -0.1545,  0.0928],\n",
      "        [ 0.2112,  0.2748,  0.2742,  0.0883, -0.0237, -0.3392],\n",
      "        [ 0.3953,  0.3087, -0.0029,  0.3569,  0.0954,  0.0729]])), ('_encoder_mu.lin1.bias', tensor([-0.2770, -0.2105,  0.0739,  0.0728, -0.0883])), ('_encoder_mu.lin2.weight', tensor([[-0.3584, -0.0148, -0.0624, -0.0734,  0.2768],\n",
      "        [-0.4430, -0.4073, -0.3074,  0.0994, -0.0576],\n",
      "        [ 0.0270, -0.0329, -0.1269,  0.1811, -0.3640]])), ('_encoder_mu.lin2.bias', tensor([0.0104, 0.4416, 0.0196])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.weight1', tensor([[ 0.3266, -0.7061, -0.7501,  0.5209,  0.3623],\n",
      "        [-0.5514, -0.2357, -0.3980,  0.4237, -0.7428],\n",
      "        [-0.3172,  0.6037,  0.7012, -0.3033, -0.7603],\n",
      "        [ 0.0640,  0.3729,  0.1269,  0.2632, -0.0233],\n",
      "        [-0.5589,  0.1177,  0.0490, -0.6652,  0.2311]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.weight1', tensor([[-0.3842, -0.7136,  0.0325,  0.6180, -0.4740],\n",
      "        [-0.4760, -0.6267,  0.2786,  0.4395,  0.7737],\n",
      "        [ 0.4855, -0.3606,  0.4966, -0.1906,  0.7028],\n",
      "        [-0.2182, -0.6356,  0.1477,  0.5074,  0.5803],\n",
      "        [ 0.2664,  0.0788, -0.6015, -0.7575, -0.4040]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.weight1', tensor([[-0.0677,  0.7476, -0.0637,  0.3341,  0.0472],\n",
      "        [ 0.6649, -0.6864,  0.2813,  0.6538, -0.0564],\n",
      "        [-0.4675, -0.5839,  0.3551, -0.3469, -0.1486],\n",
      "        [ 0.2407,  0.4149, -0.0884, -0.1585,  0.4654],\n",
      "        [-0.2172, -0.2102, -0.4245,  0.4191,  0.0396]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.weight1', tensor([[-0.4510,  0.7163, -0.6567,  0.1846,  0.5570],\n",
      "        [-0.6306,  0.3185,  0.0541,  0.0687,  0.4646],\n",
      "        [ 0.5705, -0.0862,  0.3807,  0.6841, -0.6074],\n",
      "        [ 0.3793, -0.0086,  0.2092, -0.1121,  0.2233],\n",
      "        [-0.5140, -0.4242,  0.0146,  0.0960,  0.0728]])), ('_encoder_logstd.lin1.weight', tensor([[-0.3172, -0.2134, -0.1335,  0.3862,  0.0529, -0.4026],\n",
      "        [-0.1170, -0.0932,  0.3615, -0.3730,  0.1930,  0.1032],\n",
      "        [-0.0212, -0.3790, -0.1612, -0.3488,  0.0955,  0.2432],\n",
      "        [ 0.0637,  0.2192,  0.1584, -0.3084, -0.0875, -0.3158],\n",
      "        [-0.2638, -0.4032,  0.0035, -0.1792,  0.0486,  0.3862]])), ('_encoder_logstd.lin1.bias', tensor([-0.1092, -0.4061, -0.1822,  0.3522,  0.1167])), ('_encoder_logstd.lin2.weight', tensor([[-0.0394,  0.1286,  0.1753,  0.1192,  0.2088],\n",
      "        [ 0.1151,  0.4380,  0.3681, -0.3178, -0.0859],\n",
      "        [ 0.3609, -0.2225,  0.2217, -0.2985, -0.2992]])), ('_encoder_logstd.lin2.bias', tensor([0.3272, 0.4434, 0.3509])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.weight1', tensor([[-0.6701, -0.3300, -0.0957,  0.1373, -0.1263],\n",
      "        [ 0.2848, -0.2999,  0.3977,  0.7185,  0.5949],\n",
      "        [ 0.5538, -0.2620,  0.1218,  0.6189,  0.6174],\n",
      "        [-0.3361, -0.1860,  0.4091,  0.3552, -0.6142],\n",
      "        [-0.5171, -0.4838, -0.2699,  0.5234, -0.0291]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.weight1', tensor([[-0.6630, -0.4296,  0.2694,  0.3445,  0.6639],\n",
      "        [ 0.3783,  0.2842,  0.6987,  0.5675,  0.6552],\n",
      "        [ 0.2027, -0.4615,  0.6530,  0.3450,  0.6753],\n",
      "        [ 0.0657,  0.2396,  0.0286,  0.2654, -0.4039],\n",
      "        [ 0.4063,  0.1828,  0.0447, -0.7108, -0.2360]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.weight1', tensor([[ 0.1091, -0.0443,  0.2624, -0.0507, -0.5341],\n",
      "        [-0.3103, -0.0358, -0.0384,  0.2064, -0.1043],\n",
      "        [ 0.6295,  0.2772,  0.6850,  0.0859,  0.4926],\n",
      "        [-0.1618,  0.1068,  0.3971, -0.1775,  0.5809],\n",
      "        [-0.7106, -0.3967, -0.3201,  0.4551, -0.3386]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.weight1', tensor([[-0.0229, -0.5312,  0.7707,  0.2516,  0.3078],\n",
      "        [ 0.7190, -0.7374, -0.2372, -0.2678, -0.5199],\n",
      "        [ 0.5440, -0.2902, -0.5536,  0.7205, -0.0992],\n",
      "        [ 0.5497, -0.5610, -0.7098, -0.2346, -0.6447],\n",
      "        [-0.2300,  0.6651, -0.3218, -0.3422, -0.5902]]))]), 'constructor_params': {'encoder_logstd_given': False, 'shared_encoder_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.3172, -0.2134, -0.1335,  0.3862,  0.0529, -0.4026],\n",
      "        [-0.1170, -0.0932,  0.3615, -0.3730,  0.1930,  0.1032],\n",
      "        [-0.0212, -0.3790, -0.1612, -0.3488,  0.0955,  0.2432],\n",
      "        [ 0.0637,  0.2192,  0.1584, -0.3084, -0.0875, -0.3158],\n",
      "        [-0.2638, -0.4032,  0.0035, -0.1792,  0.0486,  0.3862]])), ('lin1.bias', tensor([-0.1092, -0.4061, -0.1822,  0.3522,  0.1167])), ('lin2.weight', tensor([[-0.0394,  0.1286,  0.1753,  0.1192,  0.2088],\n",
      "        [ 0.1151,  0.4380,  0.3681, -0.3178, -0.0859],\n",
      "        [ 0.3609, -0.2225,  0.2217, -0.2985, -0.2992]])), ('lin2.bias', tensor([0.3272, 0.4434, 0.3509])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[-0.6701, -0.3300, -0.0957,  0.1373, -0.1263],\n",
      "        [ 0.2848, -0.2999,  0.3977,  0.7185,  0.5949],\n",
      "        [ 0.5538, -0.2620,  0.1218,  0.6189,  0.6174],\n",
      "        [-0.3361, -0.1860,  0.4091,  0.3552, -0.6142],\n",
      "        [-0.5171, -0.4838, -0.2699,  0.5234, -0.0291]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.6630, -0.4296,  0.2694,  0.3445,  0.6639],\n",
      "        [ 0.3783,  0.2842,  0.6987,  0.5675,  0.6552],\n",
      "        [ 0.2027, -0.4615,  0.6530,  0.3450,  0.6753],\n",
      "        [ 0.0657,  0.2396,  0.0286,  0.2654, -0.4039],\n",
      "        [ 0.4063,  0.1828,  0.0447, -0.7108, -0.2360]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[ 0.1091, -0.0443,  0.2624, -0.0507, -0.5341],\n",
      "        [-0.3103, -0.0358, -0.0384,  0.2064, -0.1043],\n",
      "        [ 0.6295,  0.2772,  0.6850,  0.0859,  0.4926],\n",
      "        [-0.1618,  0.1068,  0.3971, -0.1775,  0.5809],\n",
      "        [-0.7106, -0.3967, -0.3201,  0.4551, -0.3386]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.0229, -0.5312,  0.7707,  0.2516,  0.3078],\n",
      "        [ 0.7190, -0.7374, -0.2372, -0.2678, -0.5199],\n",
      "        [ 0.5440, -0.2902, -0.5536,  0.7205, -0.0992],\n",
      "        [ 0.5497, -0.5610, -0.7098, -0.2346, -0.6447],\n",
      "        [-0.2300,  0.6651, -0.3218, -0.3422, -0.5902]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0700,  0.3917, -0.1945, -0.0099,  0.0103,  0.2063],\n",
      "        [ 0.0720,  0.3330, -0.0467, -0.0582, -0.3186,  0.3813],\n",
      "        [ 0.0403,  0.0343,  0.3663, -0.3947, -0.1545,  0.0928],\n",
      "        [ 0.2112,  0.2748,  0.2742,  0.0883, -0.0237, -0.3392],\n",
      "        [ 0.3953,  0.3087, -0.0029,  0.3569,  0.0954,  0.0729]])), ('lin1.bias', tensor([-0.2770, -0.2105,  0.0739,  0.0728, -0.0883])), ('lin2.weight', tensor([[-0.3584, -0.0148, -0.0624, -0.0734,  0.2768],\n",
      "        [-0.4430, -0.4073, -0.3074,  0.0994, -0.0576],\n",
      "        [ 0.0270, -0.0329, -0.1269,  0.1811, -0.3640]])), ('lin2.bias', tensor([0.0104, 0.4416, 0.0196])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[ 0.3266, -0.7061, -0.7501,  0.5209,  0.3623],\n",
      "        [-0.5514, -0.2357, -0.3980,  0.4237, -0.7428],\n",
      "        [-0.3172,  0.6037,  0.7012, -0.3033, -0.7603],\n",
      "        [ 0.0640,  0.3729,  0.1269,  0.2632, -0.0233],\n",
      "        [-0.5589,  0.1177,  0.0490, -0.6652,  0.2311]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.3842, -0.7136,  0.0325,  0.6180, -0.4740],\n",
      "        [-0.4760, -0.6267,  0.2786,  0.4395,  0.7737],\n",
      "        [ 0.4855, -0.3606,  0.4966, -0.1906,  0.7028],\n",
      "        [-0.2182, -0.6356,  0.1477,  0.5074,  0.5803],\n",
      "        [ 0.2664,  0.0788, -0.6015, -0.7575, -0.4040]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[-0.0677,  0.7476, -0.0637,  0.3341,  0.0472],\n",
      "        [ 0.6649, -0.6864,  0.2813,  0.6538, -0.0564],\n",
      "        [-0.4675, -0.5839,  0.3551, -0.3469, -0.1486],\n",
      "        [ 0.2407,  0.4149, -0.0884, -0.1585,  0.4654],\n",
      "        [-0.2172, -0.2102, -0.4245,  0.4191,  0.0396]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.4510,  0.7163, -0.6567,  0.1846,  0.5570],\n",
      "        [-0.6306,  0.3185,  0.0541,  0.0687,  0.4646],\n",
      "        [ 0.5705, -0.0862,  0.3807,  0.6841, -0.6074],\n",
      "        [ 0.3793, -0.0086,  0.2092, -0.1121,  0.2233],\n",
      "        [-0.5140, -0.4242,  0.0146,  0.0960,  0.0728]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "VGEncoder: 1-1                                   --\n",
      "    ResGCN2ConvEncoder: 2-1                     --\n",
      "        Linear: 3-1                            35\n",
      "        Linear: 3-2                            18\n",
      "        LayerNorm: 3-3                         10\n",
      "        ModuleList: 3-4                        140\n",
      "    ResGCN2ConvEncoder: 2-2                     --\n",
      "        Linear: 3-5                            35\n",
      "        Linear: 3-6                            18\n",
      "        LayerNorm: 3-7                         10\n",
      "        ModuleList: 3-8                        140\n",
      "InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "forward() original\n",
      "(tensor([0.0016, 0.0620, 0.0016, 0.6798, 0.0620, 0.6798, 0.1468, 0.0383, 0.1468,\n",
      "        0.0383], grad_fn=<SigmoidBackward0>), tensor([[ 0.0261,  0.0563, -0.3486],\n",
      "        [ 0.0405,  0.0676, -0.3566],\n",
      "        [ 0.0335,  0.0642, -0.3520],\n",
      "        [-0.0747, -0.0128, -0.2923],\n",
      "        [ 0.1283,  0.1374, -0.3996]], grad_fn=<AddmmBackward0>), tensor([[0.3915, 0.4093, 0.3080],\n",
      "        [0.3914, 0.4090, 0.3083],\n",
      "        [0.3919, 0.4176, 0.3080],\n",
      "        [0.3911, 0.4228, 0.3123],\n",
      "        [0.3931, 0.4290, 0.3058]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.9937, 0.5752, 0.9937, 0.8931, 0.5752, 0.8931, 0.9354, 0.4004, 0.9354,\n",
      "        0.4004], grad_fn=<SigmoidBackward0>), tensor([[ 0.0261,  0.0563, -0.3486],\n",
      "        [ 0.0405,  0.0676, -0.3566],\n",
      "        [ 0.0335,  0.0642, -0.3520],\n",
      "        [-0.0747, -0.0128, -0.2923],\n",
      "        [ 0.1283,  0.1374, -0.3996]], grad_fn=<AddmmBackward0>), tensor([[0.3915, 0.4093, 0.3080],\n",
      "        [0.3914, 0.4090, 0.3083],\n",
      "        [0.3919, 0.4176, 0.3080],\n",
      "        [0.3911, 0.4228, 0.3123],\n",
      "        [0.3931, 0.4290, 0.3058]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.8198, 0.3928, 0.1679, 0.5345, 0.6464],\n",
      "        [0.3928, 0.7702, 0.2254, 0.0516, 0.2902],\n",
      "        [0.1679, 0.2254, 0.9962, 0.9982, 0.9790],\n",
      "        [0.5345, 0.0516, 0.9982, 1.0000, 0.9994],\n",
      "        [0.6464, 0.2902, 0.9790, 0.9994, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.8399, 0.7094, 0.0950, 0.7103, 0.8148],\n",
      "        [0.7094, 0.7476, 0.0817, 0.9134, 0.3314],\n",
      "        [0.0950, 0.0817, 1.0000, 0.0812, 0.9675],\n",
      "        [0.7103, 0.9134, 0.0812, 0.9994, 0.0620],\n",
      "        [0.8148, 0.3314, 0.9675, 0.0620, 0.9978]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.6428, -2.0802, -1.1590],\n",
      "        [ 2.0773,  2.4307, -2.3631],\n",
      "        [-0.1496,  0.4543,  1.0291],\n",
      "        [-0.1324, -0.8207,  1.3412],\n",
      "        [ 1.3191,  1.3914,  0.7317]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-1.2644,  2.3216, -0.6475],\n",
      "        [ 1.3003,  1.7911,  1.1297],\n",
      "        [-0.1300,  0.6524, -1.1402],\n",
      "        [ 2.3328, -0.3789, -1.4886],\n",
      "        [ 1.1682,  1.4567, -0.9802]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[ 0.0261,  0.0563, -0.3486],\n",
      "        [ 0.0405,  0.0676, -0.3566],\n",
      "        [ 0.0335,  0.0642, -0.3520],\n",
      "        [-0.0747, -0.0128, -0.2923],\n",
      "        [ 0.1283,  0.1374, -0.3996]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[0.3915, 0.4093, 0.3080],\n",
      "        [0.3914, 0.4090, 0.3083],\n",
      "        [0.3919, 0.4176, 0.3080],\n",
      "        [0.3911, 0.4228, 0.3123],\n",
      "        [0.3931, 0.4290, 0.3058]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[ 0.0261,  0.0563, -0.3486],\n",
      "        [ 0.0405,  0.0676, -0.3566],\n",
      "        [ 0.0335,  0.0642, -0.3520],\n",
      "        [-0.0747, -0.0128, -0.2923],\n",
      "        [ 0.1283,  0.1374, -0.3996]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[0.3915, 0.4093, 0.3080],\n",
      "        [0.3914, 0.4090, 0.3083],\n",
      "        [0.3919, 0.4176, 0.3080],\n",
      "        [0.3911, 0.4228, 0.3123],\n",
      "        [0.3931, 0.4290, 0.3058]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.5068, 0.0085, 0.5068, 0.4365, 0.0085, 0.4365, 0.0532, 0.8504, 0.0532,\n",
      "        0.8504], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([8.9549e-01, 3.5318e-04, 8.9549e-01, 9.1172e-01, 3.5318e-04, 9.1172e-01,\n",
      "        1.7166e-01, 9.9956e-01, 1.7166e-01, 9.9956e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.7057, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(1.6215, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.6, 0.6087301587301588)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.56, 0.5944444444444444)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Rev GCN VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.2424, -0.2318,  0.3161,  0.0233,  0.2418,  0.3968],\n",
      "        [-0.3989, -0.1223, -0.2432,  0.2080, -0.2447, -0.1038],\n",
      "        [-0.3664,  0.1570, -0.2762,  0.3085, -0.1833, -0.3722],\n",
      "        [ 0.1680, -0.1799,  0.1642, -0.3207, -0.3340, -0.0547]])), ('_encoder_mu.lin1.bias', tensor([-0.0439, -0.3965,  0.2183,  0.0496])), ('_encoder_mu.lin2.weight', tensor([[ 0.4735,  0.2709,  0.4437, -0.3701],\n",
      "        [-0.4780, -0.3478, -0.0866, -0.4875],\n",
      "        [ 0.4665,  0.2895, -0.4388, -0.2270]])), ('_encoder_mu.lin2.bias', tensor([ 0.3949, -0.3179, -0.4278])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.lin.weight', tensor([[-0.3340,  1.0861],\n",
      "        [ 0.7798, -0.6047]])), ('_encoder_mu.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.lin.weight', tensor([[ 1.0199, -1.1811],\n",
      "        [-0.3248,  0.7380]])), ('_encoder_mu.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.lin.weight', tensor([[-1.1700,  0.4589],\n",
      "        [ 0.5635,  0.2227]])), ('_encoder_mu.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.lin.weight', tensor([[ 0.3102, -0.9843],\n",
      "        [-0.7604,  0.4988]])), ('_encoder_mu.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.lin.weight', tensor([[-1.0953, -0.9725],\n",
      "        [-0.7613,  0.4623]])), ('_encoder_mu.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.lin.weight', tensor([[ 0.2022,  0.6010],\n",
      "        [-1.1924, -0.8216]])), ('_encoder_mu.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.0.conv.lin.weight', tensor([[-0.2341,  0.9496],\n",
      "        [-0.4554, -0.8138]])), ('_encoder_mu.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.1.conv.lin.weight', tensor([[ 0.1678,  0.8371],\n",
      "        [-1.1463, -0.0629]])), ('_encoder_logstd.lin1.weight', tensor([[-0.0672, -0.0085, -0.0830, -0.3990, -0.1319,  0.0913],\n",
      "        [-0.1335, -0.1265, -0.1778, -0.1275,  0.0151, -0.0097],\n",
      "        [-0.3075, -0.2235,  0.1112, -0.0841,  0.1699, -0.1498],\n",
      "        [ 0.1279,  0.1200,  0.0666, -0.2221,  0.0638, -0.1239]])), ('_encoder_logstd.lin1.bias', tensor([-0.1256, -0.0325,  0.3844,  0.2254])), ('_encoder_logstd.lin2.weight', tensor([[-0.2361, -0.2461, -0.2219, -0.4117],\n",
      "        [ 0.2123,  0.1922,  0.1013, -0.0225],\n",
      "        [ 0.2441,  0.3135,  0.0643, -0.0772]])), ('_encoder_logstd.lin2.bias', tensor([-0.0268, -0.4035, -0.2456])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.lin.weight', tensor([[-0.1694, -1.0749],\n",
      "        [ 0.4417,  0.3519]])), ('_encoder_logstd.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.lin.weight', tensor([[-1.0483, -0.4479],\n",
      "        [-0.9142, -1.0661]])), ('_encoder_logstd.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.lin.weight', tensor([[ 0.3056, -0.1912],\n",
      "        [ 1.1842,  1.0209]])), ('_encoder_logstd.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.lin.weight', tensor([[-0.4396, -0.4054],\n",
      "        [ 0.0925, -0.1162]])), ('_encoder_logstd.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.lin.weight', tensor([[ 1.2003, -0.3460],\n",
      "        [-1.0822, -0.6201]])), ('_encoder_logstd.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.lin.weight', tensor([[ 0.0912, -0.4514],\n",
      "        [-0.9888, -0.5396]])), ('_encoder_logstd.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.0.conv.lin.weight', tensor([[-0.7893,  1.1955],\n",
      "        [-0.7308, -0.6149]])), ('_encoder_logstd.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.1.conv.lin.weight', tensor([[-1.1361,  0.3825],\n",
      "        [-1.1083, -0.3482]]))]), 'constructor_params': {'encoder_logstd_given': False, 'shared_encoder_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.0672, -0.0085, -0.0830, -0.3990, -0.1319,  0.0913],\n",
      "        [-0.1335, -0.1265, -0.1778, -0.1275,  0.0151, -0.0097],\n",
      "        [-0.3075, -0.2235,  0.1112, -0.0841,  0.1699, -0.1498],\n",
      "        [ 0.1279,  0.1200,  0.0666, -0.2221,  0.0638, -0.1239]])), ('lin1.bias', tensor([-0.1256, -0.0325,  0.3844,  0.2254])), ('lin2.weight', tensor([[-0.2361, -0.2461, -0.2219, -0.4117],\n",
      "        [ 0.2123,  0.1922,  0.1013, -0.0225],\n",
      "        [ 0.2441,  0.3135,  0.0643, -0.0772]])), ('lin2.bias', tensor([-0.0268, -0.4035, -0.2456])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.1694, -1.0749],\n",
      "        [ 0.4417,  0.3519]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-1.0483, -0.4479],\n",
      "        [-0.9142, -1.0661]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[ 0.3056, -0.1912],\n",
      "        [ 1.1842,  1.0209]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[-0.4396, -0.4054],\n",
      "        [ 0.0925, -0.1162]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[ 1.2003, -0.3460],\n",
      "        [-1.0822, -0.6201]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.0912, -0.4514],\n",
      "        [-0.9888, -0.5396]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[-0.7893,  1.1955],\n",
      "        [-0.7308, -0.6149]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-1.1361,  0.3825],\n",
      "        [-1.1083, -0.3482]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'num_groups': 2, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2424, -0.2318,  0.3161,  0.0233,  0.2418,  0.3968],\n",
      "        [-0.3989, -0.1223, -0.2432,  0.2080, -0.2447, -0.1038],\n",
      "        [-0.3664,  0.1570, -0.2762,  0.3085, -0.1833, -0.3722],\n",
      "        [ 0.1680, -0.1799,  0.1642, -0.3207, -0.3340, -0.0547]])), ('lin1.bias', tensor([-0.0439, -0.3965,  0.2183,  0.0496])), ('lin2.weight', tensor([[ 0.4735,  0.2709,  0.4437, -0.3701],\n",
      "        [-0.4780, -0.3478, -0.0866, -0.4875],\n",
      "        [ 0.4665,  0.2895, -0.4388, -0.2270]])), ('lin2.bias', tensor([ 0.3949, -0.3179, -0.4278])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.3340,  1.0861],\n",
      "        [ 0.7798, -0.6047]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[ 1.0199, -1.1811],\n",
      "        [-0.3248,  0.7380]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-1.1700,  0.4589],\n",
      "        [ 0.5635,  0.2227]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[ 0.3102, -0.9843],\n",
      "        [-0.7604,  0.4988]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[-1.0953, -0.9725],\n",
      "        [-0.7613,  0.4623]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.2022,  0.6010],\n",
      "        [-1.1924, -0.8216]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[-0.2341,  0.9496],\n",
      "        [-0.4554, -0.8138]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[ 0.1678,  0.8371],\n",
      "        [-1.1463, -0.0629]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(GCNConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(2, 2)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "VGEncoder: 1-1                                                  --\n",
      "    RevGCNEncoder: 2-1                                         --\n",
      "        Linear: 3-1                                           28\n",
      "        Linear: 3-2                                           15\n",
      "        LayerNorm: 3-3                                        8\n",
      "        ModuleList: 3-4                                       80\n",
      "    RevGCNEncoder: 2-2                                         --\n",
      "        Linear: 3-5                                           28\n",
      "        Linear: 3-6                                           15\n",
      "        LayerNorm: 3-7                                        8\n",
      "        ModuleList: 3-8                                       80\n",
      "InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.9072, 0.0082, 0.9072, 0.5903, 0.0082, 0.5903, 0.9908, 0.8492, 0.9908,\n",
      "        0.8492], grad_fn=<SigmoidBackward0>), tensor([[ 0.9186, -0.3611, -1.1176],\n",
      "        [ 1.0258, -0.3890, -0.9224],\n",
      "        [ 0.9287, -0.4514, -0.8077],\n",
      "        [ 0.9043, -0.4748, -0.7573],\n",
      "        [ 0.9638, -0.4414, -0.8114]], grad_fn=<AddmmBackward0>), tensor([[-0.2965, -0.1681,  0.0822],\n",
      "        [-0.3079, -0.1371,  0.1438],\n",
      "        [-0.3203, -0.1060,  0.1769],\n",
      "        [-0.3251, -0.1024,  0.2134],\n",
      "        [-0.3225, -0.1069,  0.2143]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.9988, 0.9457, 0.9988, 0.9567, 0.9457, 0.9567, 0.7773, 0.7468, 0.7773,\n",
      "        0.7468], grad_fn=<SigmoidBackward0>), tensor([[ 0.9186, -0.3611, -1.1176],\n",
      "        [ 1.0258, -0.3890, -0.9224],\n",
      "        [ 0.9287, -0.4514, -0.8077],\n",
      "        [ 0.9043, -0.4748, -0.7573],\n",
      "        [ 0.9638, -0.4414, -0.8114]], grad_fn=<AddmmBackward0>), tensor([[-0.2965, -0.1681,  0.0822],\n",
      "        [-0.3079, -0.1371,  0.1438],\n",
      "        [-0.3203, -0.1060,  0.1769],\n",
      "        [-0.3251, -0.1024,  0.2134],\n",
      "        [-0.3225, -0.1069,  0.2143]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7423, 0.6897, 0.2872, 0.8921, 0.4483],\n",
      "        [0.6897, 0.9628, 0.3350, 0.9724, 0.8309],\n",
      "        [0.2872, 0.3350, 0.6859, 0.1431, 0.5457],\n",
      "        [0.8921, 0.9724, 0.1431, 1.0000, 0.8995],\n",
      "        [0.4483, 0.8309, 0.5457, 0.8995, 0.8093]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.8682, 0.9451, 0.5822, 0.8432, 0.9666],\n",
      "        [0.9451, 0.9891, 0.7008, 0.9229, 0.9942],\n",
      "        [0.5822, 0.7008, 0.7546, 0.4790, 0.8602],\n",
      "        [0.8432, 0.9229, 0.4790, 0.8436, 0.9105],\n",
      "        [0.9666, 0.9942, 0.8602, 0.9105, 0.9998]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.8761, -0.2816, -1.9856],\n",
      "        [ 1.6706,  0.5185, -1.2173],\n",
      "        [ 0.8120, -2.1667, -1.8299],\n",
      "        [ 2.2171, -1.4758, -0.9763],\n",
      "        [ 0.9919, -1.2711, -1.9421]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[ 1.6672,  0.7356,  0.1171],\n",
      "        [ 1.6510, -0.3908, -0.1126],\n",
      "        [-0.7178, -0.1823, -0.5793],\n",
      "        [ 1.6941, -1.6530,  0.6200],\n",
      "        [ 0.4096, -1.5491, -1.8431]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[ 0.9186, -0.3611, -1.1176],\n",
      "        [ 1.0258, -0.3890, -0.9224],\n",
      "        [ 0.9287, -0.4514, -0.8077],\n",
      "        [ 0.9043, -0.4748, -0.7573],\n",
      "        [ 0.9638, -0.4414, -0.8114]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.2965, -0.1681,  0.0822],\n",
      "        [-0.3079, -0.1371,  0.1438],\n",
      "        [-0.3203, -0.1060,  0.1769],\n",
      "        [-0.3251, -0.1024,  0.2134],\n",
      "        [-0.3225, -0.1069,  0.2143]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[ 0.9186, -0.3611, -1.1176],\n",
      "        [ 1.0258, -0.3890, -0.9224],\n",
      "        [ 0.9287, -0.4514, -0.8077],\n",
      "        [ 0.9043, -0.4748, -0.7573],\n",
      "        [ 0.9638, -0.4414, -0.8114]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.2965, -0.1681,  0.0822],\n",
      "        [-0.3079, -0.1371,  0.1438],\n",
      "        [-0.3203, -0.1060,  0.1769],\n",
      "        [-0.3251, -0.1024,  0.2134],\n",
      "        [-0.3225, -0.1069,  0.2143]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([1.0000, 0.2065, 1.0000, 0.8615, 0.2065, 0.8615, 0.8499, 0.8816, 0.8499,\n",
      "        0.8816], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.9590, 0.9968, 0.9590, 0.9783, 0.9968, 0.9783, 0.9625, 0.7966, 0.9625,\n",
      "        0.7966], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.0814, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(4.4481, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.6, 0.6944444444444444)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.68, 0.7644444444444445)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(shared_encoder=gat_enc, encoder_mu=GATConvBlock(in_channels=3, out_channels=3, heads=2, edge_dim=1), encoder_logstd=GATConvBlock(out_channels=3, in_channels=3, heads=3, edge_dim=1))\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, encoder_mu_constructor=GATConvBlock, shared_encoder_constructor=RevGATConvEncoder, encoder_logstd_constructor=GATConvBlock)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, RevSAGEConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, SimpleGCNEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, ResGCN2ConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Rev GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_rev_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, RevGCNEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate classifier and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevGAT encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MeanAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.7419, 0.2581]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevSAGE encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SumAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.7255, 0.2745]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "SimpleGCN encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.4152, 0.5848]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet LSTM aggregation\n",
      "ProtMotionNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): LSTMAggregation(3, 3)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.4875, 0.5125]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet softmax aggregation\n",
      "ProtMotionNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SoftmaxAggregation(learn=True)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.5870, 0.4130]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevGCN encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): RevGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([[0.5085, 0.4915]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RevGAT encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gat_enc,\n",
    "    encoder_out_channels=gat_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='mean_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevSAGE encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=sage_enc,\n",
    "    encoder_out_channels=sage_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='add_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"SimpleGCN encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='max_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet LSTM aggregation\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='lstm'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet softmax aggregation\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='softmax'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevGCN encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn_rev_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='max_pool'\n",
    ")\n",
    "print(protnet)\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test classifier serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RevGAT encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MeanAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.6299, 0.3701]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.7381, 0.2619]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevSAGE encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SumAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.4642, 0.5358]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.5090, 0.4910]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "SimpleGCN encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.6209, 0.3791]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.6209, 0.3791]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet LSTM aggregation\n",
      "ProtMotionNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): LSTMAggregation(3, 3)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.5239, 0.4761]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.5239, 0.4761]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 encoder protnet softmax aggregation\n",
      "ProtMotionNet(\n",
      "  (_encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): SoftmaxAggregation(learn=True)\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.7050, 0.2950]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.7050, 0.2950]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "RevGCN encoder protnet\n",
      "ProtMotionNet(\n",
      "  (_encoder): RevGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(GCNConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(2, 2)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (_readout_aggregation): MaxAggregation()\n",
      "  (_dense_layers): ModuleList(\n",
      "    (0): Linear(3, 3, bias=True)\n",
      "    (1): Linear(3, 3, bias=True)\n",
      "    (2): Linear(3, 2, bias=True)\n",
      "    (3): Linear(2, 2, bias=True)\n",
      "  )\n",
      ")\n",
      "forward() original\n",
      "tensor([[0.6022, 0.3978]], grad_fn=<SoftmaxBackward0>)\n",
      "forward() deserialized\n",
      "tensor([[0.6022, 0.3978]], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RevGAT encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gat_enc,\n",
    "    encoder_out_channels=gat_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='mean_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMotionNet.from_constructor_params(constr_params, RevGATConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevSAGE encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=sage_enc,\n",
    "    encoder_out_channels=sage_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.3,\n",
    "    readout='add_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMotionNet.from_constructor_params(constr_params, RevSAGEConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"SimpleGCN encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='max_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMotionNet.from_constructor_params(constr_params, SimpleGCNEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet LSTM aggregation\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='lstm'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMotionNet.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"ResGCN2 encoder protnet softmax aggregation\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn2_enc,\n",
    "    encoder_out_channels=gcn2_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='softmax'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMotionNet.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"RevGCN encoder protnet\")\n",
    "protnet = ProtMotionNet(\n",
    "    encoder=gcn_rev_enc,\n",
    "    encoder_out_channels=gcn_enc.out_channels,\n",
    "    dense_units=[3, 3, 2, 2],\n",
    "    dense_activations=['gelu', 'relu', 'sigmoid', 'softmax'],\n",
    "    dropout=0.0,\n",
    "    readout='max_pool'\n",
    ")\n",
    "constr_params = protnet.serialize_constructor_params()\n",
    "state_dict = protnet.state_dict()\n",
    "protnet2 = ProtMotionNet.from_constructor_params(constr_params, RevGCNEncoder)\n",
    "protnet2.load_state_dict(state_dict)\n",
    "print(protnet2)\n",
    "print(\"forward() original\")\n",
    "print(protnet(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized\")\n",
    "print(protnet2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\cleaned\\\\pretraining\\\\train\\\\params\\\\params.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [339], line 67\u001B[0m\n\u001B[0;32m     64\u001B[0m BATCH_SIZE \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m     65\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 67\u001B[0m ds_train \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPRETRAIN_CLEANED_TRAIN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpretrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m ds_val \u001B[38;5;241m=\u001B[39m load_dataset(PRETRAIN_CLEANED_VAL, dataset_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpretrain\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     70\u001B[0m dl_train \u001B[38;5;241m=\u001B[39m DataLoader(ds_train, batch_size\u001B[38;5;241m=\u001B[39mBATCH_SIZE, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Desktop\\Python\\protein-reconstruction\\preprocessing\\dataset.py:378\u001B[0m, in \u001B[0;36mload_dataset\u001B[1;34m(path, dataset_type)\u001B[0m\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid dataset type \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, it must be one of: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mDATASET_TYPES\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    377\u001B[0m \u001B[38;5;66;03m# Load parameters\u001B[39;00m\n\u001B[1;32m--> 378\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[43m__load_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPARAMS_DIR_SUFFIX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;66;03m# Load dataset\u001B[39;00m\n\u001B[0;32m    381\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\Python\\protein-reconstruction\\preprocessing\\dataset.py:55\u001B[0m, in \u001B[0;36m__load_params\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;124;03mReads a csv file and a json file containing the parameters, and combines them into a single dictionary.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;124;03m:return: A dictionary of parameters.\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# Read other parameters from json file\u001B[39;00m\n\u001B[1;32m---> 55\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPARAMS_JSON_SUFFIX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[0;32m     56\u001B[0m     params \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(fp)\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdf_param_name\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# Read param dataframe from csv\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data\\\\cleaned\\\\pretraining\\\\train\\\\params\\\\params.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch_geometric.nn import Linear\n",
    "from models.layers import SerializableModule\n",
    "from torch.nn import ModuleList, LayerNorm\n",
    "from torch import Tensor\n",
    "from typing import Any, List, Optional\n",
    "from torch_geometric.nn.models import GroupAddRev\n",
    "import torch_geometric.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class RevResWrapper(SerializableModule):\n",
    "    def serialize_constructor_params(self, *args, **kwargs) -> dict:\n",
    "        pass\n",
    "\n",
    "    def __init__(self, rev_res_module: torch.nn.Module):\n",
    "        super().__init__()\n",
    "        self.rev_res_module_list_wrapper = ModuleList()\n",
    "\n",
    "        # This is the only fucking way to make it work, we are not sure why,\n",
    "        # but for some reason torch requires that the calls to rev res modules to be in a for loop, otherwise weird memory errors will be thrown on forward() call\n",
    "        for i in range(0, 1):\n",
    "            self.rev_res_module_list_wrapper.append(rev_res_module)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        for i  in range(0, 1):\n",
    "            output = None\n",
    "            for rev_res_module in self.rev_res_module_list_wrapper:\n",
    "                output = rev_res_module(*args, **kwargs)\n",
    "            return output\n",
    "\n",
    "\n",
    "class Giggino(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Giggino, self).__init__()\n",
    "        self.split_dim = -1\n",
    "        self.num_groups = 2\n",
    "        #self.convs = ModuleList([GATConvBlock(5, 5, heads=5), GATConvBlock(5, 5, heads=5)])\n",
    "        self.conv3 = GATConvBlock(10, 10, heads=5)\n",
    "        self.conv = VGEncoder(shared_encoder=RevGATConvEncoder(10, 10, 10, 2), encoder_mu=GATConvBlock(10, 10, heads=2), encoder_logstd=GATConvBlock(10, 10, heads=2))\n",
    "        self.conv2 = RevGATConvEncoder(10, 10, 10, 2)\n",
    "        self.conv5 = RevGATConvEncoder(10, 10, 10, 2)\n",
    "        self.conv3 = RevSAGEConvEncoder(10, 10, 10, 2)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        for i in range(0, 2):\n",
    "            self.convs.append(RevGATConvEncoder(10, 10, 10, 2))\n",
    "\n",
    "        self.conv4 = RevResWrapper(RevGATConvEncoder(10, 10, 10, 2))\n",
    "        self.ciao = nn.Linear(10, 10)\n",
    "        self.ciao4 = GCN2ConvBlock(10)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        ciao = x\n",
    "        ciao3 = ciao\n",
    "        # il prblema  creare due variabili\n",
    "        ciao = self.conv4(ciao, edge_index)\n",
    "        #yield ciao\n",
    "        a = self.ciao(ciao) + ciao\n",
    "        b = self.ciao4(ciao, x0=a, edge_index=edge_index)\n",
    "        #yield self.conv5(ciao, edge_index)\n",
    "        return a, b\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ds_train = load_dataset(PRETRAIN_CLEANED_TRAIN, dataset_type=\"pretrain\")\n",
    "ds_val = load_dataset(PRETRAIN_CLEANED_VAL, dataset_type=\"pretrain\")\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "count = 0\n",
    "g = Giggino()\n",
    "g.to(device)\n",
    "for el in iter(dl_train):\n",
    "    el.to(device)\n",
    "    print(g.forward(el.x, el.edge_index))\n",
    "    if count > 5:\n",
    "        break\n",
    "    count += 1\n",
    "print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8469545d",
   "language": "python",
   "display_name": "PyCharm (connectome-nn-generators)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}