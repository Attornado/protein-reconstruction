{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torchinfo\n",
    "import torch_geometric.utils.convert as tgc\n",
    "import numpy as np\n",
    "from typing import final\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "from models.layers import GATConvBlock, SAGEConvBlock, GCN2ConvBlock, GCNConvBlock\n",
    "from models.pretraining.encoders import SimpleGCNEncoder, ResGCN2ConvEncoder, RevSAGEConvEncoder, RevGATConvEncoder\n",
    "from models.pretraining.gae import GAEv2\n",
    "from models.pretraining.vgae import VGAEv2, VGEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define graph and plot it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "_POSITION_ATTRIBUTE: final = \"pos\"\n",
    "_X_MIN: final = 0\n",
    "_X_MAX: final = 2\n",
    "_Y_MIN: final = 0\n",
    "_Y_MAX: final = 2\n",
    "g = nx.Graph()\n",
    "g.add_node(0, x=[1., 0., 1.2, 1.1, 0.2, 0.1])\n",
    "g.add_node(1, x=[0., 1., 0, 1.2, 1.1, 0.2])\n",
    "g.add_node(2, x=[0.4, 1., 0.1, 0.2, 0.7, 0.3])\n",
    "g.add_node(3, x=[1., 1.2, 0.9, 0.9, 0.5, 0.4])\n",
    "g.add_node(4, x=[1., 1.3, 0.4, 0.3, 1.8, 0.45])\n",
    "g.add_edge(1, 0, edge_weight=1.0)\n",
    "g.add_edge(1, 2, edge_weight=2.)\n",
    "g.add_edge(2, 0, edge_weight=1.)\n",
    "g.add_edge(3, 2, edge_weight=1.)\n",
    "g.add_edge(4, 2, edge_weight=1.)\n",
    "\n",
    "print(g.nodes(data=True))\n",
    "print(g.edges(data=True))\n",
    "print(\"ciao\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {'x': [1.0, 0.0, 1.2, 1.1, 0.2, 0.1]}), (1, {'x': [0.0, 1.0, 0, 1.2, 1.1, 0.2]}), (2, {'x': [0.4, 1.0, 0.1, 0.2, 0.7, 0.3]}), (3, {'x': [1.0, 1.2, 0.9, 0.9, 0.5, 0.4]}), (4, {'x': [1.0, 1.3, 0.4, 0.3, 1.8, 0.45]})]\n",
      "[(0, 1, {'edge_weight': 1.0}), (0, 2, {'edge_weight': 1.0}), (1, 2, {'edge_weight': 2.0}), (2, 3, {'edge_weight': 1.0}), (2, 4, {'edge_weight': 1.0})]\n",
      "ciao\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "#888",
          "width": 0.5
         },
         "mode": "lines",
         "x": [
          -1.1791686595280402,
          -2.476171491669146,
          null,
          -1.1791686595280402,
          -1.8564715309535855,
          null,
          -2.476171491669146,
          -1.8564715309535855,
          null,
          -1.8564715309535855,
          -0.5952503444617084,
          null,
          -1.8564715309535855,
          0.004331156058819314,
          null
         ],
         "y": [
          -0.9224337970927577,
          0.08741931103485996,
          null,
          -0.9224337970927577,
          -0.11037293429365101,
          null,
          0.08741931103485996,
          -0.11037293429365101,
          null,
          -0.11037293429365101,
          1.0940188980042775,
          null,
          -0.11037293429365101,
          -1.2332911910953983,
          null
         ],
         "type": "scatter"
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": [
           2,
           2,
           4,
           1,
           1
          ],
          "colorbar": {
           "thickness": 15,
           "title": {
            "side": "right",
            "text": "Node Connections"
           },
           "xanchor": "left"
          },
          "colorscale": [
           [
            0.0,
            "rgb(255,255,217)"
           ],
           [
            0.125,
            "rgb(237,248,177)"
           ],
           [
            0.25,
            "rgb(199,233,180)"
           ],
           [
            0.375,
            "rgb(127,205,187)"
           ],
           [
            0.5,
            "rgb(65,182,196)"
           ],
           [
            0.625,
            "rgb(29,145,192)"
           ],
           [
            0.75,
            "rgb(34,94,168)"
           ],
           [
            0.875,
            "rgb(37,52,148)"
           ],
           [
            1.0,
            "rgb(8,29,88)"
           ]
          ],
          "line": {
           "width": 2
          },
          "reversescale": true,
          "showscale": true,
          "size": 10
         },
         "mode": "markers",
         "text": [
          "node 0, # of connections: 2",
          "node 1, # of connections: 2",
          "node 2, # of connections: 4",
          "node 3, # of connections: 1",
          "node 4, # of connections: 1"
         ],
         "x": [
          -1.1791686595280402,
          -2.476171491669146,
          -1.8564715309535855,
          -0.5952503444617084,
          0.004331156058819314
         ],
         "y": [
          -0.9224337970927577,
          0.08741931103485996,
          -0.11037293429365101,
          1.0940188980042775,
          -1.2332911910953983
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>",
          "x": 0.005,
          "xref": "paper",
          "y": -0.002,
          "yref": "paper"
         }
        ],
        "hovermode": "closest",
        "margin": {
         "b": 20,
         "l": 5,
         "r": 5,
         "t": 40
        },
        "showlegend": false,
        "title": {
         "font": {
          "size": 16
         },
         "text": "<br>Network graph made with Python"
        },
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"34a622fc-f044-4a5b-bbe6-8e86c10da54a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"34a622fc-f044-4a5b-bbe6-8e86c10da54a\")) {                    Plotly.newPlot(                        \"34a622fc-f044-4a5b-bbe6-8e86c10da54a\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[-1.1791686595280402,-2.476171491669146,null,-1.1791686595280402,-1.8564715309535855,null,-2.476171491669146,-1.8564715309535855,null,-1.8564715309535855,-0.5952503444617084,null,-1.8564715309535855,0.004331156058819314,null],\"y\":[-0.9224337970927577,0.08741931103485996,null,-0.9224337970927577,-0.11037293429365101,null,0.08741931103485996,-0.11037293429365101,null,-0.11037293429365101,1.0940188980042775,null,-0.11037293429365101,-1.2332911910953983,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[2,2,4,1,1],\"colorbar\":{\"thickness\":15,\"title\":{\"side\":\"right\",\"text\":\"Node Connections\"},\"xanchor\":\"left\"},\"colorscale\":[[0.0,\"rgb(255,255,217)\"],[0.125,\"rgb(237,248,177)\"],[0.25,\"rgb(199,233,180)\"],[0.375,\"rgb(127,205,187)\"],[0.5,\"rgb(65,182,196)\"],[0.625,\"rgb(29,145,192)\"],[0.75,\"rgb(34,94,168)\"],[0.875,\"rgb(37,52,148)\"],[1.0,\"rgb(8,29,88)\"]],\"line\":{\"width\":2},\"reversescale\":true,\"showscale\":true,\"size\":10},\"mode\":\"markers\",\"text\":[\"node 0, # of connections: 2\",\"node 1, # of connections: 2\",\"node 2, # of connections: 4\",\"node 3, # of connections: 1\",\"node 4, # of connections: 1\"],\"x\":[-1.1791686595280402,-2.476171491669146,-1.8564715309535855,-0.5952503444617084,0.004331156058819314],\"y\":[-0.9224337970927577,0.08741931103485996,-0.11037293429365101,1.0940188980042775,-1.2332911910953983],\"type\":\"scatter\"}],                        {\"annotations\":[{\"showarrow\":false,\"text\":\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\"x\":0.005,\"xref\":\"paper\",\"y\":-0.002,\"yref\":\"paper\"}],\"hovermode\":\"closest\",\"margin\":{\"b\":20,\"l\":5,\"r\":5,\"t\":40},\"showlegend\":false,\"title\":{\"font\":{\"size\":16},\"text\":\"<br>Network graph made with Python\"},\"xaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"showticklabels\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('34a622fc-f044-4a5b-bbe6-8e86c10da54a');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(nx.get_node_attributes(g, \"pos\",)) == 0:\n",
    "    pos = {i: (random.gauss(_X_MIN, _X_MAX), random.gauss(_Y_MIN, _Y_MAX)) for i in g.nodes}\n",
    "    nx.set_node_attributes(g, pos, \"pos\")\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in g.edges():\n",
    "    x0, y0 = g.nodes[edge[0]]['pos']\n",
    "    x1, y1 = g.nodes[edge[1]]['pos']\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "for node in g.nodes():\n",
    "    x, y = g.nodes[node]['pos']\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(g.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    node_text.append(f'node {node}, # of connections: ' + str(len(adjacencies[1])))\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text\n",
    "\n",
    "# noinspection PyTypeChecker\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                layout=go.Layout(\n",
    "                    title='<br>Network graph made with Python',\n",
    "                    titlefont_size=16,\n",
    "                    showlegend=False,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=20,l=5,r=5,t=40),\n",
    "                    annotations=[ dict(\n",
    "                        text=\"Python code: <a href='https://plotly.com/ipython-notebooks/network-graphs/'> https://plotly.com/ipython-notebooks/network-graphs/</a>\",\n",
    "                        showarrow=False,\n",
    "                        xref=\"paper\", yref=\"paper\",\n",
    "                        x=0.005, y=-0.002 ) ],\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert graph in PyTorch geometric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5, 6], edge_index=[2, 10], pos=[5, 2], edge_weight=[10])\n",
      "tensor([1., 1., 1., 2., 1., 2., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "pyg = tgc.from_networkx(g)\n",
    "print(pyg)\n",
    "print(pyg.edge_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=2)\n",
      ")\n",
      "GATConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GATv2Conv(6, 3, heads=1)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "SAGEConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): SAGEConv(6, 3, aggr=mean)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCNConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCNConv(6, 3)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.6, beta=1.0)\n",
      ")\n",
      "GCN2ConvBlock(\n",
      "  (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv): GCN2Conv(6, alpha=0.5, beta=1.0)\n",
      ")\n",
      "tensor([[ 0.5131, -0.3270, -0.0742],\n",
      "        [-0.0083, -0.3630,  0.0352],\n",
      "        [ 0.4540, -0.3327, -0.1593],\n",
      "        [ 0.0209, -0.3417, -0.1250],\n",
      "        [-0.0056, -0.0678, -0.4775]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.1360, -0.5767,  1.2441],\n",
      "        [-0.1462, -0.7924,  1.3404],\n",
      "        [-0.0095, -0.9050,  1.2583],\n",
      "        [-0.0259, -0.8523,  1.2479],\n",
      "        [ 0.1639, -1.5781,  1.5681]], grad_fn=<AsStridedBackward0>)\n",
      "tensor([[-0.2758, -0.3628, -0.8319],\n",
      "        [-0.4536, -0.1758, -0.7020],\n",
      "        [-0.4987,  0.3171, -0.0523],\n",
      "        [-0.2352,  0.2479, -0.1189],\n",
      "        [-0.4848,  0.1979, -0.6418]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.2560, -1.4206,  0.7240],\n",
      "        [ 0.2005, -1.3674, -0.0446],\n",
      "        [ 0.8538, -1.2881, -0.3728],\n",
      "        [ 0.6748, -1.4078,  0.8287],\n",
      "        [ 0.7133, -1.1638,  0.2711]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.0556,  2.3799, -2.2449],\n",
      "        [ 0.3869,  1.9599, -2.7116],\n",
      "        [-0.1781,  3.9107, -2.2006],\n",
      "        [-0.0192,  1.0107, -1.9042],\n",
      "        [-0.0192,  1.0107, -1.9042]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.2643,  0.3464,  0.1123],\n",
      "        [ 0.3055,  0.2032,  0.2755],\n",
      "        [ 0.1971,  0.5308,  0.4645],\n",
      "        [ 0.3095, -0.3165,  0.3404],\n",
      "        [-0.1365,  0.2971,  0.8253]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 0.0690,  1.6432,  1.4752,  0.6229, -0.7025, -1.1043],\n",
      "        [ 0.4111,  1.0658,  0.7177, -0.2560, -0.0924, -0.6538],\n",
      "        [ 0.5535,  1.1998,  0.5455, -0.2164, -0.3731, -0.6405],\n",
      "        [ 0.4261,  1.8471,  0.6980,  0.4068, -0.9505, -0.9644],\n",
      "        [ 0.9104,  1.3197,  0.9811, -0.6619, -0.1909, -0.7787]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.8385,  0.4366,  0.5372, -0.8386,  0.5243,  0.5160],\n",
      "        [ 0.2275,  0.2910,  0.7037, -0.4631,  0.2334,  0.4206],\n",
      "        [ 0.3941,  0.7742,  0.6255, -0.4397,  0.3127,  0.3085],\n",
      "        [ 1.0582,  0.8745,  0.5567, -0.7139,  0.5228,  0.0320],\n",
      "        [ 0.0075,  1.2360,  0.6310, -0.1927,  0.3131,  0.5594]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gat0 = GATConvBlock(6, 3, dropout=0.3, heads=2, edge_dim=1)\n",
    "gat1 = GATConvBlock(6, 3, heads=1, edge_dim=1, concat=True)\n",
    "\n",
    "sage0 = SAGEConvBlock(6, 3, project=True)\n",
    "sage1 = SAGEConvBlock(6, 3, project=False)\n",
    "\n",
    "gcn0 = GCNConvBlock(6, 3, normalize=False)\n",
    "gcn1 = GCNConvBlock(6, 3, normalize=True)\n",
    "\n",
    "gcn20 = GCN2ConvBlock(6, 0.6)\n",
    "gcn21 = GCN2ConvBlock(6, 0.5)\n",
    "\n",
    "print(gat0)\n",
    "print(gat1)\n",
    "print(sage0)\n",
    "print(sage1)\n",
    "print(gcn0)\n",
    "print(gcn1)\n",
    "print(gcn20)\n",
    "print(gcn21)\n",
    "\n",
    "print(gat0(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(gat1(pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(sage0(pyg.x, edge_index=pyg.edge_index))\n",
    "print(sage1(pyg.x, edge_index=pyg.edge_index))\n",
    "print(gcn0(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn1(pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn20(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(gcn21(pyg.x, x0=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate encoders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             268\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             268\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[ 0.3645, -0.9919,  0.5989],\n",
      "        [ 0.3906, -1.0175,  0.6087],\n",
      "        [ 0.1913, -0.8897,  0.5072],\n",
      "        [ 0.1147, -0.8486,  0.4650],\n",
      "        [ 0.0705, -0.8136,  0.4451]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             40\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             40\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             40\n",
      "│    └─GroupAddRev: 2-4                                 --\n",
      "│    │    └─ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "tensor([[0.9980, 0.4868, 0.0448],\n",
      "        [1.0044, 0.4872, 0.0561],\n",
      "        [0.9897, 0.4863, 0.0302],\n",
      "        [1.0237, 0.4969, 0.0768],\n",
      "        [0.9690, 0.4597, 0.0325]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            15\n",
      "├─LayerNorm: 1-3                         8\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCNConvBlock: 2-1                 --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCNConv: 3-2                 30\n",
      "│    └─GCNConvBlock: 2-2                 --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCNConv: 3-4                 30\n",
      "│    └─GCNConvBlock: 2-3                 --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCNConv: 3-6                 24\n",
      "│    └─GCNConvBlock: 2-4                 --\n",
      "│    │    └─LayerNorm: 3-7               8\n",
      "│    │    └─GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[-0.0883, -0.5557, -0.6590],\n",
      "        [-0.0883, -0.5557, -0.6590],\n",
      "        [-0.0884, -0.5563, -0.6593],\n",
      "        [-0.0889, -0.5581, -0.6603],\n",
      "        [-0.0883, -0.5557, -0.6590]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "ResGCN2 Encoder\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            18\n",
      "├─LayerNorm: 1-3                         10\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCN2ConvBlock: 2-1                --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCN2Conv: 3-2                25\n",
      "│    └─GCN2ConvBlock: 2-2                --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCN2Conv: 3-4                25\n",
      "│    └─GCN2ConvBlock: 2-3                --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCN2Conv: 3-6                25\n",
      "│    └─GCN2ConvBlock: 2-4                --\n",
      "│    │    └─LayerNorm: 3-7               10\n",
      "│    │    └─GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "tensor([[ 0.4426, -0.0820,  0.4323],\n",
      "        [ 0.4425, -0.0822,  0.4320],\n",
      "        [ 0.4386, -0.0868,  0.4265],\n",
      "        [ 0.4153, -0.1182,  0.3900],\n",
      "        [ 0.4553, -0.0623,  0.4542]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gat_enc = RevGATConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=3,\n",
    "    dropout=0.0,\n",
    "    version=\"v2\",\n",
    "    edge_dim=1,\n",
    "    heads=8,\n",
    "    num_groups=2,\n",
    "    concat=False,\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual GAT Encoder\")\n",
    "print(gat_enc)\n",
    "print(torchinfo.summary(gat_enc))\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "sage_enc = RevSAGEConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=4,\n",
    "    out_channels=3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0,\n",
    "    project=True,\n",
    "    root_weight=True,\n",
    "    num_groups=2,\n",
    "    aggr='mean',\n",
    "    normalize_hidden=True\n",
    ")\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "print(sage_enc)\n",
    "print(torchinfo.summary(sage_enc))\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn_enc = SimpleGCNEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    conv_dims=[5, 5, 4, 4],\n",
    "    dropout=0.0,\n",
    "    improved=True\n",
    ")\n",
    "print(\"Simple GCN Encoder\")\n",
    "print(gcn_enc)\n",
    "print(torchinfo.summary(gcn_enc))\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "gcn2_enc = ResGCN2ConvEncoder(\n",
    "    in_channels=6,\n",
    "    hidden_channels=5,\n",
    "    out_channels=3,\n",
    "    alpha=0.3,\n",
    "    num_convs=4,\n",
    "    dropout=0.0\n",
    ")\n",
    "print(\"ResGCN2 Encoder\")\n",
    "print(gcn2_enc)\n",
    "print(torchinfo.summary(gcn2_enc))\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test encoders serialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevGATConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(GATConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GATv2Conv(2, 2, heads=8)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevGATConvEncoder                                       --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             268\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             268\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             268\n",
      "================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.3645, -0.9919,  0.5989],\n",
      "        [ 0.3906, -1.0175,  0.6087],\n",
      "        [ 0.1913, -0.8897,  0.5072],\n",
      "        [ 0.1147, -0.8486,  0.4650],\n",
      "        [ 0.0705, -0.8136,  0.4451]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.3645, -0.9919,  0.5989],\n",
      "        [ 0.3906, -1.0175,  0.6087],\n",
      "        [ 0.1913, -0.8897,  0.5072],\n",
      "        [ 0.1147, -0.8486,  0.4650],\n",
      "        [ 0.0705, -0.8136,  0.4451]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}\n",
      "RevSAGEConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (1): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (2): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "    (3): GroupAddRev(SAGEConvBlock(\n",
      "      (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): SAGEConv(2, 2, aggr=mean)\n",
      "    ), num_groups=2)\n",
      "  )\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "RevSAGEConvEncoder                                      --\n",
      "├─Linear: 1-1                                           28\n",
      "├─Linear: 1-2                                           15\n",
      "├─LayerNorm: 1-3                                        8\n",
      "├─ModuleList: 1-4                                       --\n",
      "│    └─GroupAddRev: 2-1                                 --\n",
      "│    │    └─ModuleList: 3-1                             40\n",
      "│    └─GroupAddRev: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-2                             40\n",
      "│    └─GroupAddRev: 2-3                                 --\n",
      "│    │    └─ModuleList: 3-3                             40\n",
      "│    └─GroupAddRev: 2-4                                 --\n",
      "│    │    └─ModuleList: 3-4                             40\n",
      "================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[0.9980, 0.4868, 0.0448],\n",
      "        [1.0044, 0.4872, 0.0561],\n",
      "        [0.9897, 0.4863, 0.0302],\n",
      "        [1.0237, 0.4969, 0.0768],\n",
      "        [0.9690, 0.4597, 0.0325]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[0.9980, 0.4868, 0.0448],\n",
      "        [1.0044, 0.4872, 0.0561],\n",
      "        [0.9897, 0.4863, 0.0302],\n",
      "        [1.0237, 0.4969, 0.0768],\n",
      "        [0.9690, 0.4597, 0.0325]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}\n",
      "SimpleGCNEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (1): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 5)\n",
      "    )\n",
      "    (2): GCNConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(5, 4)\n",
      "    )\n",
      "    (3): GCNConvBlock(\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCNConv(4, 4)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleGCNEncoder                         --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            15\n",
      "├─LayerNorm: 1-3                         8\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCNConvBlock: 2-1                 --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCNConv: 3-2                 30\n",
      "│    └─GCNConvBlock: 2-2                 --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCNConv: 3-4                 30\n",
      "│    └─GCNConvBlock: 2-3                 --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCNConv: 3-6                 24\n",
      "│    └─GCNConvBlock: 2-4                 --\n",
      "│    │    └─LayerNorm: 3-7               8\n",
      "│    │    └─GCNConv: 3-8                 20\n",
      "=================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[-0.0883, -0.5557, -0.6590],\n",
      "        [-0.0883, -0.5557, -0.6590],\n",
      "        [-0.0884, -0.5563, -0.6593],\n",
      "        [-0.0889, -0.5581, -0.6603],\n",
      "        [-0.0883, -0.5557, -0.6590]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[-0.0883, -0.5557, -0.6590],\n",
      "        [-0.0883, -0.5557, -0.6590],\n",
      "        [-0.0884, -0.5563, -0.6593],\n",
      "        [-0.0889, -0.5581, -0.6603],\n",
      "        [-0.0883, -0.5557, -0.6590]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 Encoder\n",
      "{'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}\n",
      "ResGCN2ConvEncoder(\n",
      "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "  (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (1): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (2): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "    (3): GCN2ConvBlock(\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ResGCN2ConvEncoder                       --\n",
      "├─Linear: 1-1                            35\n",
      "├─Linear: 1-2                            18\n",
      "├─LayerNorm: 1-3                         10\n",
      "├─ModuleList: 1-4                        --\n",
      "│    └─GCN2ConvBlock: 2-1                --\n",
      "│    │    └─LayerNorm: 3-1               10\n",
      "│    │    └─GCN2Conv: 3-2                25\n",
      "│    └─GCN2ConvBlock: 2-2                --\n",
      "│    │    └─LayerNorm: 3-3               10\n",
      "│    │    └─GCN2Conv: 3-4                25\n",
      "│    └─GCN2ConvBlock: 2-3                --\n",
      "│    │    └─LayerNorm: 3-5               10\n",
      "│    │    └─GCN2Conv: 3-6                25\n",
      "│    └─GCN2ConvBlock: 2-4                --\n",
      "│    │    └─LayerNorm: 3-7               10\n",
      "│    │    └─GCN2Conv: 3-8                25\n",
      "=================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\n",
      "Original: \n",
      "tensor([[ 0.4402, -0.0854,  0.4284],\n",
      "        [ 0.4397, -0.0859,  0.4277],\n",
      "        [ 0.4378, -0.0880,  0.4251],\n",
      "        [ 0.4148, -0.1190,  0.3892],\n",
      "        [ 0.4569, -0.0601,  0.4567]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "Deserialized: \n",
      "tensor([[ 0.4402, -0.0854,  0.4284],\n",
      "        [ 0.4397, -0.0859,  0.4277],\n",
      "        [ 0.4378, -0.0880,  0.4251],\n",
      "        [ 0.4148, -0.1190,  0.3892],\n",
      "        [ 0.4569, -0.0601,  0.4567]], grad_fn=<AddmmBackward0>)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT Encoder\")\n",
    "constr_params = gat_enc.serialize_constructor_params()\n",
    "state_dict = gat_enc.state_dict()\n",
    "print(constr_params)\n",
    "gat_enc2 = RevGATConvEncoder.from_constructor_params(constr_params)\n",
    "gat_enc2.load_state_dict(state_dict)\n",
    "print(gat_enc2)\n",
    "print(torchinfo.summary(gat_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gat_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gat_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE Encoder\")\n",
    "constr_params = sage_enc.serialize_constructor_params()\n",
    "state_dict = sage_enc.state_dict()\n",
    "print(constr_params)\n",
    "sage_enc2 = RevSAGEConvEncoder.from_constructor_params(constr_params)\n",
    "sage_enc2.load_state_dict(state_dict)\n",
    "print(sage_enc2)\n",
    "print(torchinfo.summary(sage_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(sage_enc(pyg.x, pyg.edge_index))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(sage_enc2(pyg.x, pyg.edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN Encoder\")\n",
    "constr_params = gcn_enc.serialize_constructor_params()\n",
    "state_dict = gcn_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn_enc2 = SimpleGCNEncoder.from_constructor_params(constr_params)\n",
    "gcn_enc2.load_state_dict(state_dict)\n",
    "print(gcn_enc2)\n",
    "print(torchinfo.summary(gcn_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 Encoder\")\n",
    "constr_params = gcn2_enc.serialize_constructor_params()\n",
    "state_dict = gcn2_enc.state_dict()\n",
    "print(constr_params)\n",
    "gcn2_enc2 = ResGCN2ConvEncoder.from_constructor_params(constr_params)\n",
    "gcn2_enc2.load_state_dict(state_dict)\n",
    "print(gcn2_enc2)\n",
    "print(torchinfo.summary(gcn2_enc2))\n",
    "print(\"\\n\\nOriginal: \")\n",
    "print(gcn2_enc(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"\\n\\nDeserialized: \")\n",
    "print(gcn2_enc2(pyg.x, pyg.edge_index, pyg.edge_weight))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate and test GAEv2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevGATConvEncoder: 1-1                                     --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 268\n",
      "│    │    └─GroupAddRev: 3-2                                 268\n",
      "│    │    └─GroupAddRev: 3-3                                 268\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.7125, 0.7372, 0.7125, 0.6859, 0.7372, 0.6859, 0.7078, 0.7095, 0.7078,\n",
      "        0.7095], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.7872, 0.7125, 0.7372, 0.7601, 0.7549],\n",
      "        [0.7125, 0.6927, 0.6859, 0.6748, 0.6887],\n",
      "        [0.7372, 0.6859, 0.6979, 0.7078, 0.7095],\n",
      "        [0.7601, 0.6748, 0.7078, 0.7395, 0.7286],\n",
      "        [0.7549, 0.6887, 0.7095, 0.7286, 0.7253]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.8125,  0.1942, -0.7814],\n",
      "        [-0.8002, -0.1803, -0.3740],\n",
      "        [-0.7341,  0.0532, -0.5438],\n",
      "        [-0.6391,  0.3105, -0.7339],\n",
      "        [-0.7383,  0.1766, -0.6283]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.7125, 0.7372, 0.7125, 0.6859, 0.7372, 0.6859, 0.7078, 0.7095, 0.7078,\n",
      "        0.7095], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.6275, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.39999999999999997, 0.4720634920634921)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevSAGEConvEncoder: 1-1                                    --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 40\n",
      "│    │    └─GroupAddRev: 3-2                                 40\n",
      "│    │    └─GroupAddRev: 3-3                                 40\n",
      "│    │    └─GroupAddRev: 3-4                                 40\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.7006, 0.7009, 0.7006, 0.7026, 0.7009, 0.7026, 0.7026, 0.7018, 0.7026,\n",
      "        0.7018], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6989, 0.7006, 0.7009, 0.7007, 0.6998],\n",
      "        [0.7006, 0.7024, 0.7026, 0.7024, 0.7016],\n",
      "        [0.7009, 0.7026, 0.7028, 0.7026, 0.7018],\n",
      "        [0.7007, 0.7024, 0.7026, 0.7025, 0.7016],\n",
      "        [0.6998, 0.7016, 0.7018, 0.7016, 0.7008]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.3860,  0.7487,  0.3642],\n",
      "        [-0.3943,  0.7531,  0.3689],\n",
      "        [-0.3953,  0.7536,  0.3695],\n",
      "        [-0.3945,  0.7532,  0.3690],\n",
      "        [-0.3904,  0.7510,  0.3667]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.7006, 0.7009, 0.7006, 0.7026, 0.7009, 0.7026, 0.7026, 0.7018, 0.7026,\n",
      "        0.7018], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.5623, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.6799999999999999, 0.7753968253968253)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─SimpleGCNEncoder: 1-1                       --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            15\n",
      "│    └─LayerNorm: 2-3                         8\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCNConvBlock: 3-1                 40\n",
      "│    │    └─GCNConvBlock: 3-2                 40\n",
      "│    │    └─GCNConvBlock: 3-3                 34\n",
      "│    │    └─GCNConvBlock: 3-4                 28\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790,\n",
      "        0.7790], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.7790, 0.7790, 0.7790, 0.7790, 0.7790],\n",
      "        [0.7790, 0.7790, 0.7790, 0.7790, 0.7790],\n",
      "        [0.7790, 0.7790, 0.7790, 0.7790, 0.7790],\n",
      "        [0.7790, 0.7790, 0.7790, 0.7790, 0.7790],\n",
      "        [0.7790, 0.7790, 0.7790, 0.7790, 0.7790]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.1918,  0.7851, -0.7788],\n",
      "        [ 0.1918,  0.7851, -0.7788],\n",
      "        [ 0.1918,  0.7851, -0.7788],\n",
      "        [ 0.1918,  0.7851, -0.7788],\n",
      "        [ 0.1919,  0.7852, -0.7788]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790, 0.7790,\n",
      "        0.7790], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.7593, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.44000000000000006, 0.5942857142857143)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─ResGCN2ConvEncoder: 1-1                     --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            18\n",
      "│    └─LayerNorm: 2-3                         10\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCN2ConvBlock: 3-1                35\n",
      "│    │    └─GCN2ConvBlock: 3-2                35\n",
      "│    │    └─GCN2ConvBlock: 3-3                35\n",
      "│    │    └─GCN2ConvBlock: 3-4                35\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward()\n",
      "tensor([0.6299, 0.6310, 0.6299, 0.6277, 0.6310, 0.6277, 0.6351, 0.6305, 0.6351,\n",
      "        0.6305], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.6334, 0.6299, 0.6310, 0.6376, 0.6325],\n",
      "        [0.6299, 0.6266, 0.6277, 0.6339, 0.6293],\n",
      "        [0.6310, 0.6277, 0.6289, 0.6351, 0.6305],\n",
      "        [0.6376, 0.6339, 0.6351, 0.6419, 0.6367],\n",
      "        [0.6325, 0.6293, 0.6305, 0.6367, 0.6322]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[0.5424, 0.4968, 0.0772],\n",
      "        [0.5433, 0.4631, 0.0893],\n",
      "        [0.5467, 0.4669, 0.1026],\n",
      "        [0.5481, 0.5235, 0.0963],\n",
      "        [0.5510, 0.4722, 0.1228]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.6299, 0.6310, 0.6299, 0.6277, 0.6310, 0.6277, 0.6351, 0.6305, 0.6351,\n",
      "        0.6305], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(1.4658, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.24, 0.419047619047619)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "print(gae)\n",
    "print(torchinfo.summary(gae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test serialization for GAE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.3017,  0.0780,  0.3780, -0.2731, -0.1171,  0.2941],\n",
      "        [-0.1848,  0.2964, -0.2858, -0.0216, -0.3562,  0.3056],\n",
      "        [-0.2245,  0.2626, -0.1170,  0.1236, -0.3463,  0.1923],\n",
      "        [-0.3265, -0.1130, -0.0322, -0.3334, -0.2413, -0.0834]])), ('lin1.bias', tensor([ 0.1149, -0.2528, -0.2822,  0.1887])), ('lin2.weight', tensor([[-0.4647, -0.2695,  0.0881, -0.0825],\n",
      "        [ 0.1337, -0.1715,  0.0899,  0.0364],\n",
      "        [ 0.4216, -0.3230, -0.0765,  0.4799]])), ('lin2.bias', tensor([-0.4023, -0.3164, -0.4138])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[-0.0849,  0.3083],\n",
      "         [-0.5168,  0.1050],\n",
      "         [-0.2693,  0.2103],\n",
      "         [-0.4785, -0.6156],\n",
      "         [ 0.0797,  0.0698],\n",
      "         [ 0.1820,  0.1289],\n",
      "         [ 0.3655, -0.7177],\n",
      "         [ 0.3010, -0.7745]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.5109, -0.3294],\n",
      "        [-0.0338, -0.4436],\n",
      "        [ 0.2230,  0.2464],\n",
      "        [-0.1550, -0.2737],\n",
      "        [-0.5282,  0.4971],\n",
      "        [-0.3728,  0.4198],\n",
      "        [-0.3653, -0.3209],\n",
      "        [ 0.1850, -0.2888],\n",
      "        [-0.0811, -0.1713],\n",
      "        [-0.1321,  0.4244],\n",
      "        [-0.4166, -0.4082],\n",
      "        [ 0.3208, -0.2254],\n",
      "        [-0.4996,  0.0592],\n",
      "        [-0.5430, -0.1356],\n",
      "        [ 0.5698, -0.3622],\n",
      "        [ 0.4800,  0.5247]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([ 0.6823,  0.6728,  0.4636,  0.6160,  0.0055, -0.2869,  0.6356,  0.1134,\n",
      "        -0.1292, -0.1627,  0.2713, -0.1296,  0.5468,  0.3686, -0.1877, -0.6602])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[-0.1483, -0.2814],\n",
      "        [-0.3829, -0.1310],\n",
      "        [-0.2592, -0.1816],\n",
      "        [-0.5477,  0.4798],\n",
      "        [-0.0026,  0.4382],\n",
      "        [ 0.2586, -0.3473],\n",
      "        [ 0.4749, -0.5177],\n",
      "        [ 0.1343, -0.3253],\n",
      "        [-0.2818,  0.0838],\n",
      "        [ 0.4113,  0.4467],\n",
      "        [-0.3125,  0.5767],\n",
      "        [-0.0625, -0.3005],\n",
      "        [-0.1819,  0.4866],\n",
      "        [ 0.0550, -0.0069],\n",
      "        [-0.3898,  0.4695],\n",
      "        [ 0.0297,  0.4957]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([-0.2325, -0.5864, -0.4562, -0.0516, -0.1381, -0.4386, -0.1399, -0.1537,\n",
      "         0.0150, -0.0047,  0.6998, -0.4464,  0.5766, -0.5783, -0.2412, -0.4357])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[ 0.1391],\n",
      "        [ 0.5623],\n",
      "        [ 0.1554],\n",
      "        [-0.4797],\n",
      "        [ 0.0782],\n",
      "        [ 0.4473],\n",
      "        [ 0.4126],\n",
      "        [ 0.4439],\n",
      "        [-0.0277],\n",
      "        [-0.4450],\n",
      "        [ 0.5228],\n",
      "        [ 0.0936],\n",
      "        [ 0.5152],\n",
      "        [-0.4890],\n",
      "        [-0.4132],\n",
      "        [ 0.3308]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[-0.1608,  0.3115],\n",
      "         [-0.4356,  0.1752],\n",
      "         [-0.1488,  0.6178],\n",
      "         [ 0.3117,  0.7416],\n",
      "         [ 0.1409,  0.5293],\n",
      "         [ 0.2129, -0.4072],\n",
      "         [ 0.3417,  0.6352],\n",
      "         [ 0.6810, -0.2203]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.2774,  0.2805],\n",
      "        [-0.3346,  0.5302],\n",
      "        [-0.3227, -0.3378],\n",
      "        [ 0.3580, -0.1069],\n",
      "        [ 0.5065,  0.3451],\n",
      "        [ 0.4850,  0.4401],\n",
      "        [ 0.0246, -0.4069],\n",
      "        [ 0.0443,  0.4651],\n",
      "        [ 0.2652,  0.2379],\n",
      "        [-0.0472, -0.1724],\n",
      "        [ 0.4144,  0.3181],\n",
      "        [ 0.0698,  0.1478],\n",
      "        [-0.4548,  0.3767],\n",
      "        [-0.2263, -0.2464],\n",
      "        [-0.3676,  0.5574],\n",
      "        [ 0.1224, -0.0231]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.3618,  0.4111,  0.6591,  0.5513, -0.1249, -0.6854, -0.5629,  0.3473,\n",
      "         0.5712,  0.0521,  0.0949,  0.3223,  0.1988,  0.0092, -0.6182,  0.0912])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.2188,  0.5029],\n",
      "        [-0.3640,  0.0727],\n",
      "        [ 0.4550, -0.2026],\n",
      "        [ 0.5038, -0.4254],\n",
      "        [-0.3197, -0.2525],\n",
      "        [-0.2584, -0.2914],\n",
      "        [-0.1505,  0.0435],\n",
      "        [-0.5229, -0.4458],\n",
      "        [-0.2645, -0.1560],\n",
      "        [-0.0879,  0.1598],\n",
      "        [ 0.3952, -0.5663],\n",
      "        [ 0.4331, -0.4030],\n",
      "        [ 0.1714,  0.1275],\n",
      "        [-0.4398, -0.3103],\n",
      "        [ 0.4134, -0.0785],\n",
      "        [-0.2513,  0.4131]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.4750, -0.5828, -0.0091, -0.6816,  0.4137,  0.5025, -0.0367,  0.5590,\n",
      "        -0.5167, -0.4564,  0.6161,  0.4072,  0.3679, -0.2518, -0.6245,  0.0106])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[-0.1194],\n",
      "        [-0.2548],\n",
      "        [-0.3055],\n",
      "        [ 0.4406],\n",
      "        [ 0.0684],\n",
      "        [ 0.2122],\n",
      "        [-0.5372],\n",
      "        [-0.3605],\n",
      "        [ 0.4866],\n",
      "        [ 0.1865],\n",
      "        [ 0.5633],\n",
      "        [-0.4287],\n",
      "        [ 0.0157],\n",
      "        [ 0.0393],\n",
      "        [ 0.5224],\n",
      "        [ 0.3274]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[ 0.7458, -0.0991],\n",
      "         [ 0.1714, -0.1862],\n",
      "         [ 0.0347, -0.3757],\n",
      "         [ 0.1507,  0.0755],\n",
      "         [ 0.1937,  0.0774],\n",
      "         [ 0.2806, -0.4334],\n",
      "         [-0.3196, -0.2935],\n",
      "         [ 0.0201, -0.2804]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.2646,  0.1357],\n",
      "        [-0.5728,  0.2420],\n",
      "        [-0.0930,  0.5642],\n",
      "        [-0.3850,  0.0057],\n",
      "        [-0.0551, -0.1161],\n",
      "        [-0.1037,  0.4894],\n",
      "        [-0.3105, -0.2427],\n",
      "        [-0.5277, -0.5375],\n",
      "        [-0.0297, -0.4592],\n",
      "        [-0.3618, -0.4601],\n",
      "        [ 0.2409,  0.0433],\n",
      "        [ 0.2680, -0.0866],\n",
      "        [ 0.0627,  0.3850],\n",
      "        [-0.0506,  0.1015],\n",
      "        [ 0.4023,  0.1432],\n",
      "        [ 0.0685, -0.2526]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.0659,  0.0479,  0.3008, -0.4777, -0.0656, -0.1181, -0.3519,  0.3076,\n",
      "         0.5189, -0.3584,  0.3915,  0.1187, -0.5162,  0.0768, -0.0530,  0.3094])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.5749,  0.4215],\n",
      "        [ 0.0659,  0.2217],\n",
      "        [-0.5046,  0.3731],\n",
      "        [ 0.4005,  0.3769],\n",
      "        [ 0.0344, -0.2779],\n",
      "        [-0.1751,  0.2355],\n",
      "        [-0.3822, -0.4080],\n",
      "        [-0.0439,  0.1824],\n",
      "        [ 0.1149,  0.4953],\n",
      "        [ 0.3820,  0.2440],\n",
      "        [-0.0451, -0.4017],\n",
      "        [-0.1230,  0.2483],\n",
      "        [ 0.1398, -0.2820],\n",
      "        [-0.4247,  0.3529],\n",
      "        [ 0.2524, -0.1756],\n",
      "        [-0.5159,  0.1781]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([-0.1956, -0.1102,  0.5657,  0.4576,  0.3482, -0.1040, -0.0980,  0.1194,\n",
      "         0.3730,  0.1784, -0.2407,  0.1066, -0.5329, -0.3205,  0.4239, -0.0181])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.5593],\n",
      "        [-0.3294],\n",
      "        [ 0.1453],\n",
      "        [-0.0007],\n",
      "        [ 0.0247],\n",
      "        [ 0.3435],\n",
      "        [-0.3777],\n",
      "        [ 0.4078],\n",
      "        [-0.0097],\n",
      "        [ 0.2583],\n",
      "        [-0.2669],\n",
      "        [ 0.5907],\n",
      "        [ 0.0349],\n",
      "        [ 0.1314],\n",
      "        [ 0.4815],\n",
      "        [ 0.3022]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[ 0.5589, -0.6398],\n",
      "         [ 0.4778, -0.3384],\n",
      "         [-0.4482,  0.0570],\n",
      "         [ 0.0673,  0.1434],\n",
      "         [ 0.7195,  0.4778],\n",
      "         [-0.0631, -0.7036],\n",
      "         [ 0.5460, -0.7468],\n",
      "         [-0.7532, -0.5655]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.0120, -0.2397],\n",
      "        [ 0.3982,  0.2178],\n",
      "        [ 0.0998, -0.5157],\n",
      "        [-0.0843,  0.5390],\n",
      "        [-0.5320, -0.1520],\n",
      "        [-0.0222,  0.3162],\n",
      "        [ 0.2118,  0.2191],\n",
      "        [-0.0900, -0.1052],\n",
      "        [ 0.0163, -0.3583],\n",
      "        [ 0.1359,  0.1205],\n",
      "        [ 0.1057,  0.0663],\n",
      "        [ 0.1754,  0.5054],\n",
      "        [-0.5071, -0.3715],\n",
      "        [-0.3090,  0.4814],\n",
      "        [-0.1505, -0.2245],\n",
      "        [ 0.5194,  0.1331]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.2189, -0.6494, -0.2602,  0.1282,  0.1933,  0.5834, -0.7033, -0.6522,\n",
      "         0.2650,  0.2103,  0.6603, -0.4712,  0.5528, -0.3030, -0.3106, -0.5769])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-2.6545e-01,  5.4186e-01],\n",
      "        [ 5.3903e-01,  1.0278e-01],\n",
      "        [ 4.8046e-01, -4.4076e-01],\n",
      "        [-1.6679e-02, -2.4485e-01],\n",
      "        [ 5.2311e-01,  1.0986e-01],\n",
      "        [ 3.9851e-02, -1.3795e-01],\n",
      "        [-3.7288e-01, -5.5980e-01],\n",
      "        [-1.1615e-01, -1.6722e-01],\n",
      "        [ 3.7529e-01,  4.9725e-01],\n",
      "        [-5.1442e-01,  3.4824e-01],\n",
      "        [ 2.6035e-04, -2.0575e-01],\n",
      "        [ 2.2327e-01,  3.8147e-01],\n",
      "        [ 4.6066e-01, -1.8790e-01],\n",
      "        [-4.1688e-01, -1.9824e-01],\n",
      "        [ 3.8989e-01,  2.9309e-01],\n",
      "        [ 5.2653e-01, -2.2611e-01]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([-0.6170, -0.5745, -0.6422, -0.6806,  0.1610,  0.6979, -0.3487,  0.6148,\n",
      "         0.5862,  0.0361,  0.6040, -0.6529,  0.1786, -0.5932,  0.2691, -0.6230])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.3543],\n",
      "        [-0.4937],\n",
      "        [ 0.2696],\n",
      "        [-0.1488],\n",
      "        [ 0.1824],\n",
      "        [ 0.5420],\n",
      "        [ 0.0840],\n",
      "        [-0.4886],\n",
      "        [-0.2255],\n",
      "        [-0.0614],\n",
      "        [ 0.1414],\n",
      "        [-0.5506],\n",
      "        [-0.0127],\n",
      "        [ 0.4258],\n",
      "        [ 0.3540],\n",
      "        [-0.1128]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[-0.5885,  0.7154],\n",
      "         [-0.4758, -0.2191],\n",
      "         [ 0.4279,  0.3177],\n",
      "         [-0.4313,  0.3699],\n",
      "         [ 0.3210,  0.1004],\n",
      "         [-0.4485, -0.0224],\n",
      "         [ 0.5250, -0.3297],\n",
      "         [ 0.0418, -0.3387]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.5740,  0.1584],\n",
      "        [ 0.2060,  0.3518],\n",
      "        [ 0.0529, -0.4861],\n",
      "        [ 0.5436,  0.4322],\n",
      "        [ 0.0182, -0.0523],\n",
      "        [-0.5486, -0.0290],\n",
      "        [-0.4166, -0.1115],\n",
      "        [-0.2989, -0.1474],\n",
      "        [-0.1393,  0.5610],\n",
      "        [ 0.4520,  0.0329],\n",
      "        [-0.1253,  0.3834],\n",
      "        [ 0.2950, -0.3869],\n",
      "        [ 0.4869,  0.5612],\n",
      "        [ 0.1209,  0.3026],\n",
      "        [ 0.2181,  0.3610],\n",
      "        [-0.2793,  0.3633]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.1686,  0.3788,  0.1659, -0.2538, -0.1769, -0.6416,  0.0563, -0.3472,\n",
      "        -0.1047,  0.7020, -0.3811,  0.5822, -0.4785,  0.0434,  0.6169, -0.0091])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.1651,  0.4802],\n",
      "        [-0.4510,  0.5600],\n",
      "        [ 0.3954,  0.4364],\n",
      "        [-0.0575,  0.3077],\n",
      "        [ 0.4184,  0.3170],\n",
      "        [-0.1674, -0.4336],\n",
      "        [ 0.0863, -0.0259],\n",
      "        [-0.5264,  0.0872],\n",
      "        [-0.3721,  0.1082],\n",
      "        [ 0.3502, -0.4504],\n",
      "        [-0.1362, -0.0942],\n",
      "        [ 0.3683, -0.5186],\n",
      "        [-0.2696, -0.4311],\n",
      "        [ 0.2756, -0.1809],\n",
      "        [-0.0263,  0.5481],\n",
      "        [-0.5624, -0.3458]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([ 0.4252, -0.3304, -0.3486,  0.6150, -0.5658, -0.3080, -0.0082,  0.5237,\n",
      "        -0.3720, -0.4128, -0.1825,  0.2024,  0.3619,  0.6591,  0.4520,  0.1796])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[ 0.4721],\n",
      "        [ 0.3608],\n",
      "        [-0.3663],\n",
      "        [-0.5243],\n",
      "        [ 0.3625],\n",
      "        [ 0.2913],\n",
      "        [ 0.1818],\n",
      "        [ 0.2678],\n",
      "        [-0.1612],\n",
      "        [-0.5335],\n",
      "        [-0.4980],\n",
      "        [ 0.0505],\n",
      "        [ 0.5105],\n",
      "        [-0.1228],\n",
      "        [ 0.4650],\n",
      "        [ 0.4905]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[-0.6697, -0.1301],\n",
      "         [ 0.6566, -0.2033],\n",
      "         [-0.6489,  0.7410],\n",
      "         [-0.6175, -0.5529],\n",
      "         [-0.1853,  0.6939],\n",
      "         [-0.0385,  0.2764],\n",
      "         [ 0.7341, -0.5509],\n",
      "         [-0.5606, -0.2168]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.1209,  0.4295],\n",
      "        [ 0.3941, -0.2858],\n",
      "        [-0.2231, -0.2047],\n",
      "        [-0.5294,  0.4362],\n",
      "        [ 0.4160, -0.5496],\n",
      "        [ 0.5345,  0.3445],\n",
      "        [-0.1393,  0.3485],\n",
      "        [ 0.4456, -0.5261],\n",
      "        [ 0.3878, -0.1287],\n",
      "        [ 0.1443, -0.0066],\n",
      "        [ 0.1150, -0.1481],\n",
      "        [-0.3805, -0.3963],\n",
      "        [-0.5467,  0.1279],\n",
      "        [-0.1125, -0.0848],\n",
      "        [-0.3781,  0.4095],\n",
      "        [ 0.2832, -0.2317]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([ 0.3220, -0.0059, -0.6632, -0.4108,  0.6365,  0.1204,  0.5642, -0.0079,\n",
      "        -0.0883, -0.6538, -0.2726,  0.4325, -0.6827,  0.3571, -0.3965,  0.6028])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.4746, -0.4940],\n",
      "        [ 0.2610,  0.1750],\n",
      "        [-0.5297,  0.1677],\n",
      "        [-0.2733,  0.2048],\n",
      "        [-0.0284, -0.3903],\n",
      "        [ 0.2509, -0.3607],\n",
      "        [ 0.4235,  0.1285],\n",
      "        [-0.2410, -0.2701],\n",
      "        [ 0.2333,  0.1687],\n",
      "        [ 0.3900, -0.4224],\n",
      "        [ 0.1283,  0.5431],\n",
      "        [-0.0638, -0.1398],\n",
      "        [-0.0566,  0.2647],\n",
      "        [-0.2464, -0.4441],\n",
      "        [-0.1540,  0.2923],\n",
      "        [ 0.3544,  0.0297]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([ 6.9666e-01,  1.6894e-01, -7.9780e-02,  5.4032e-04, -4.9079e-01,\n",
      "        -4.3893e-01,  2.1743e-01, -1.3887e-01,  5.4840e-01,  4.1004e-01,\n",
      "         3.2733e-01,  4.7143e-01,  6.8541e-01,  5.7854e-01, -7.1617e-02,\n",
      "        -5.2360e-01])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[ 0.4485],\n",
      "        [-0.4244],\n",
      "        [-0.4069],\n",
      "        [ 0.5371],\n",
      "        [-0.1272],\n",
      "        [ 0.3611],\n",
      "        [ 0.3213],\n",
      "        [ 0.5862],\n",
      "        [ 0.0766],\n",
      "        [-0.3654],\n",
      "        [-0.1367],\n",
      "        [-0.3710],\n",
      "        [ 0.0995],\n",
      "        [ 0.0700],\n",
      "        [ 0.4832],\n",
      "        [-0.3660]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevGATConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(GATConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GATv2Conv(2, 2, heads=8)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevGATConvEncoder: 1-1                                     --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 268\n",
      "│    │    └─GroupAddRev: 3-2                                 268\n",
      "│    │    └─GroupAddRev: 3-3                                 268\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 855\n",
      "Trainable params: 855\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.8080, 0.8007, 0.8080, 0.7955, 0.8007, 0.7955, 0.8060, 0.8026, 0.8060,\n",
      "        0.8026], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.8080, 0.8007, 0.8080, 0.7955, 0.8007, 0.7955, 0.8060, 0.8026, 0.8060,\n",
      "        0.8026], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.8141, 0.8080, 0.8007, 0.8196, 0.8160],\n",
      "        [0.8080, 0.8040, 0.7955, 0.8131, 0.8098],\n",
      "        [0.8007, 0.7955, 0.7878, 0.8060, 0.8026],\n",
      "        [0.8196, 0.8131, 0.8060, 0.8251, 0.8215],\n",
      "        [0.8160, 0.8098, 0.8026, 0.8215, 0.8179]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.8141, 0.8080, 0.8007, 0.8196, 0.8160],\n",
      "        [0.8080, 0.8040, 0.7955, 0.8131, 0.8098],\n",
      "        [0.8007, 0.7955, 0.7878, 0.8060, 0.8026],\n",
      "        [0.8196, 0.8131, 0.8060, 0.8251, 0.8215],\n",
      "        [0.8160, 0.8098, 0.8026, 0.8215, 0.8179]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-1.1768, -0.0936,  0.2888],\n",
      "        [-1.1661, -0.1406,  0.1791],\n",
      "        [-1.1158, -0.1111,  0.2335],\n",
      "        [-1.2027, -0.0862,  0.3123],\n",
      "        [-1.1857, -0.0910,  0.2969]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-1.1768, -0.0936,  0.2888],\n",
      "        [-1.1661, -0.1406,  0.1791],\n",
      "        [-1.1158, -0.1111,  0.2335],\n",
      "        [-1.2027, -0.0862,  0.3123],\n",
      "        [-1.1857, -0.0910,  0.2969]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.8080, 0.8007, 0.8080, 0.7955, 0.8007, 0.7955, 0.8060, 0.8026, 0.8060,\n",
      "        0.8026], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.8080, 0.8007, 0.8080, 0.7955, 0.8007, 0.7955, 0.8060, 0.8026, 0.8060,\n",
      "        0.8026], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.9131, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.9131, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.0, 0.3543650793650793)\n",
      "AUC and precision metric test deserialized\n",
      "(0.0, 0.3543650793650793)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.3440,  0.3446,  0.2299,  0.1118, -0.1775,  0.3356],\n",
      "        [-0.2017, -0.2177,  0.2403,  0.0980,  0.2302,  0.3640],\n",
      "        [ 0.1852,  0.1010,  0.2344, -0.1093, -0.1250,  0.3289],\n",
      "        [-0.2776,  0.3683, -0.1023, -0.4004,  0.1981,  0.1960]])), ('lin1.bias', tensor([ 0.2503,  0.2835, -0.1521, -0.3924])), ('lin2.weight', tensor([[-0.0382,  0.3930,  0.0931, -0.2495],\n",
      "        [-0.4050,  0.0171, -0.4664, -0.4805],\n",
      "        [-0.4507,  0.3402, -0.4564,  0.1331]])), ('lin2.bias', tensor([-0.4061, -0.1643, -0.2246])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[ 0.6888,  0.5366],\n",
      "        [-0.2619, -0.4264]])), ('convs.0.convs.0.conv.lin.bias', tensor([ 0.5370, -0.0937])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.2790, -0.1986],\n",
      "        [-0.0833, -0.3520]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.6011,  0.2948])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.5302, -0.5848],\n",
      "        [ 0.3345, -0.5769]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.2741,  0.3650],\n",
      "        [-0.6543,  0.5245]])), ('convs.0.convs.1.conv.lin.bias', tensor([-0.1894,  0.1268])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.4732, -0.3489],\n",
      "        [ 0.5123,  0.2895]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([0.6624, 0.2561])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.3688, -0.5204],\n",
      "        [ 0.2609, -0.1654]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[ 0.6646,  0.3302],\n",
      "        [ 0.0590, -0.6093]])), ('convs.1.convs.0.conv.lin.bias', tensor([0.0343, 0.4454])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[0.0172, 0.6584],\n",
      "        [0.3274, 0.1423]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.0159,  0.4844])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.0916,  0.3998],\n",
      "        [ 0.4594, -0.0497]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[ 0.6691,  0.1987],\n",
      "        [ 0.3946, -0.0196]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.4633, -0.3136])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.3804, -0.5767],\n",
      "        [-0.0966, -0.2097]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([ 0.2514, -0.6923])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.1096,  0.1661],\n",
      "        [ 0.3300,  0.6545]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[-0.5972,  0.4872],\n",
      "        [-0.0584,  0.5705]])), ('convs.2.convs.0.conv.lin.bias', tensor([0.3740, 0.6594])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.2209, -0.6443],\n",
      "        [-0.4876,  0.0657]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([0.3824, 0.3071])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2527,  0.5910],\n",
      "        [ 0.3582, -0.5785]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.1039, -0.0146],\n",
      "        [ 0.4365, -0.0990]])), ('convs.2.convs.1.conv.lin.bias', tensor([0.2257, 0.4663])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[ 0.5554,  0.2207],\n",
      "        [-0.5391,  0.5856]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([0.3824, 0.5937])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.4762,  0.5613],\n",
      "        [-0.4117,  0.4930]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.3133, -0.2984],\n",
      "        [-0.2060, -0.2587]])), ('convs.3.convs.0.conv.lin.bias', tensor([-0.5337, -0.6226])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.1596, -0.3400],\n",
      "        [-0.4842,  0.4713]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([0.5621, 0.0462])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[-0.0975,  0.6757],\n",
      "        [ 0.1286, -0.5915]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[ 0.4448, -0.1483],\n",
      "        [-0.5698, -0.1322]])), ('convs.3.convs.1.conv.lin.bias', tensor([-0.6911,  0.3663])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.0242,  0.2250],\n",
      "        [-0.3304,  0.0790]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([-0.0600,  0.0660])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[ 0.6013,  0.3017],\n",
      "        [ 0.2492, -0.2450]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): RevSAGEConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (1): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (2): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "      (3): GroupAddRev(SAGEConvBlock(\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): SAGEConv(2, 2, aggr=mean)\n",
      "      ), num_groups=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "=====================================================================================\n",
      "Layer (type:depth-idx)                                       Param #\n",
      "=====================================================================================\n",
      "GAEv2                                                        --\n",
      "├─RevSAGEConvEncoder: 1-1                                    --\n",
      "│    └─Linear: 2-1                                           28\n",
      "│    └─Linear: 2-2                                           15\n",
      "│    └─LayerNorm: 2-3                                        8\n",
      "│    └─ModuleList: 2-4                                       --\n",
      "│    │    └─GroupAddRev: 3-1                                 40\n",
      "│    │    └─GroupAddRev: 3-2                                 40\n",
      "│    │    └─GroupAddRev: 3-3                                 40\n",
      "│    │    └─GroupAddRev: 3-4                                 40\n",
      "├─InnerProductDecoder: 1-2                                   --\n",
      "=====================================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "=====================================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.5423, 0.5233, 0.5423, 0.5237, 0.5233, 0.5237, 0.5210, 0.5214, 0.5210,\n",
      "        0.5214], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.5423, 0.5233, 0.5423, 0.5237, 0.5233, 0.5237, 0.5210, 0.5214, 0.5210,\n",
      "        0.5214], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.5368, 0.5423, 0.5233, 0.5444, 0.5312],\n",
      "        [0.5423, 0.5500, 0.5237, 0.5542, 0.5351],\n",
      "        [0.5233, 0.5237, 0.5216, 0.5210, 0.5214],\n",
      "        [0.5444, 0.5542, 0.5210, 0.5611, 0.5360],\n",
      "        [0.5312, 0.5351, 0.5214, 0.5360, 0.5269]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.5368, 0.5423, 0.5233, 0.5444, 0.5312],\n",
      "        [0.5423, 0.5500, 0.5237, 0.5542, 0.5351],\n",
      "        [0.5233, 0.5237, 0.5216, 0.5210, 0.5214],\n",
      "        [0.5444, 0.5542, 0.5210, 0.5611, 0.5360],\n",
      "        [0.5312, 0.5351, 0.5214, 0.5360, 0.5269]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.1482, -0.3543,  0.0108],\n",
      "        [ 0.1506, -0.4177, -0.0596],\n",
      "        [ 0.1290, -0.2043,  0.1679],\n",
      "        [ 0.1078, -0.4617, -0.1448],\n",
      "        [ 0.1221, -0.3001,  0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 0.1482, -0.3543,  0.0108],\n",
      "        [ 0.1506, -0.4177, -0.0596],\n",
      "        [ 0.1290, -0.2043,  0.1679],\n",
      "        [ 0.1078, -0.4617, -0.1448],\n",
      "        [ 0.1221, -0.3001,  0.0514]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.5423, 0.5233, 0.5423, 0.5237, 0.5233, 0.5237, 0.5210, 0.5214, 0.5210,\n",
      "        0.5214], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.5423, 0.5233, 0.5423, 0.5237, 0.5233, 0.5237, 0.5210, 0.5214, 0.5210,\n",
      "        0.5214], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4190, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.4190, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.12, 0.38769841269841265)\n",
      "AUC and precision metric test deserialized\n",
      "(0.12, 0.38769841269841265)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.3532,  0.3470, -0.3769,  0.0236,  0.2244, -0.0083],\n",
      "        [-0.1470, -0.3346, -0.0881,  0.2674, -0.0147,  0.0906],\n",
      "        [-0.0258,  0.2546,  0.2074,  0.2993, -0.0746, -0.2103],\n",
      "        [ 0.3761,  0.2118,  0.3400,  0.1359, -0.1318,  0.1199],\n",
      "        [-0.1220,  0.1682,  0.2974,  0.3131, -0.1334,  0.0531]])), ('lin1.bias', tensor([ 0.0773,  0.1347, -0.2941, -0.0453, -0.3258])), ('lin2.weight', tensor([[-0.4494, -0.2768, -0.1311,  0.4270],\n",
      "        [-0.3370,  0.4347,  0.2605, -0.2507],\n",
      "        [ 0.1866,  0.1938,  0.1923,  0.1230]])), ('lin2.bias', tensor([ 0.2997, -0.3666, -0.0165])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[-0.1578,  0.4103, -0.2277, -0.2683,  0.0599],\n",
      "        [ 0.5114, -0.5315,  0.5056,  0.4563, -0.3751],\n",
      "        [-0.6761, -0.1537,  0.7101,  0.5373, -0.3678],\n",
      "        [ 0.3519, -0.4590, -0.7617, -0.5530, -0.3982],\n",
      "        [ 0.4497,  0.0581,  0.6541,  0.3980,  0.1024]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[-0.0234,  0.1729,  0.1140,  0.6686,  0.2908],\n",
      "        [-0.7376, -0.5078, -0.0478, -0.6331,  0.0549],\n",
      "        [-0.6542, -0.2505,  0.0695,  0.1113, -0.2877],\n",
      "        [ 0.3241, -0.2320,  0.5331,  0.3482,  0.4929],\n",
      "        [ 0.3335, -0.0940, -0.6178,  0.0170,  0.1121]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.6355, -0.6250,  0.4713, -0.3538,  0.4022],\n",
      "        [-0.5583, -0.6964,  0.1350,  0.5161, -0.7670],\n",
      "        [ 0.1984, -0.0395,  0.5282,  0.3269, -0.7360],\n",
      "        [-0.1193,  0.2422, -0.2517,  0.1265, -0.0911]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 0.5023,  0.6153, -0.4350,  0.8302],\n",
      "        [ 0.7685, -0.5736,  0.0327,  0.5153],\n",
      "        [-0.8135, -0.0966,  0.6923,  0.4076],\n",
      "        [ 0.8565, -0.1854,  0.2970, -0.4845]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): SimpleGCNEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (1): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 5)\n",
      "      )\n",
      "      (2): GCNConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(5, 4)\n",
      "      )\n",
      "      (3): GCNConvBlock(\n",
      "        (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCNConv(4, 4)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─SimpleGCNEncoder: 1-1                       --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            15\n",
      "│    └─LayerNorm: 2-3                         8\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCNConvBlock: 3-1                 40\n",
      "│    │    └─GCNConvBlock: 3-2                 40\n",
      "│    │    └─GCNConvBlock: 3-3                 34\n",
      "│    │    └─GCNConvBlock: 3-4                 28\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 200\n",
      "Trainable params: 200\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.6289, 0.6345, 0.6289, 0.6359, 0.6345, 0.6359, 0.6674, 0.6337, 0.6674,\n",
      "        0.6337], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.6289, 0.6345, 0.6289, 0.6359, 0.6345, 0.6359, 0.6674, 0.6337, 0.6674,\n",
      "        0.6337], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6276, 0.6289, 0.6345, 0.6589, 0.6268],\n",
      "        [0.6289, 0.6302, 0.6359, 0.6605, 0.6281],\n",
      "        [0.6345, 0.6359, 0.6419, 0.6674, 0.6337],\n",
      "        [0.6589, 0.6605, 0.6674, 0.6976, 0.6579],\n",
      "        [0.6268, 0.6281, 0.6337, 0.6579, 0.6259]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.6276, 0.6289, 0.6345, 0.6589, 0.6268],\n",
      "        [0.6289, 0.6302, 0.6359, 0.6605, 0.6281],\n",
      "        [0.6345, 0.6359, 0.6419, 0.6674, 0.6337],\n",
      "        [0.6589, 0.6605, 0.6674, 0.6976, 0.6579],\n",
      "        [0.6268, 0.6281, 0.6337, 0.6579, 0.6259]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 0.5817, -0.3482,  0.2496],\n",
      "        [ 0.5882, -0.3523,  0.2512],\n",
      "        [ 0.6163, -0.3707,  0.2574],\n",
      "        [ 0.7360, -0.4803,  0.2523],\n",
      "        [ 0.5776, -0.3457,  0.2485]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[ 0.5817, -0.3482,  0.2496],\n",
      "        [ 0.5882, -0.3523,  0.2512],\n",
      "        [ 0.6163, -0.3707,  0.2574],\n",
      "        [ 0.7360, -0.4803,  0.2523],\n",
      "        [ 0.5776, -0.3457,  0.2485]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6289, 0.6345, 0.6289, 0.6359, 0.6345, 0.6359, 0.6674, 0.6337, 0.6674,\n",
      "        0.6337], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.6289, 0.6345, 0.6289, 0.6359, 0.6345, 0.6359, 0.6674, 0.6337, 0.6674,\n",
      "        0.6337], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4869, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.4869, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.52, 0.6192857142857142)\n",
      "AUC and precision metric test deserialized\n",
      "(0.52, 0.6192857142857142)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 GAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2325, -0.3910, -0.4033,  0.1353, -0.3581,  0.4010],\n",
      "        [-0.3126,  0.0995, -0.1801, -0.0190,  0.3423,  0.0199],\n",
      "        [ 0.1369,  0.1108,  0.2694,  0.0414, -0.1732,  0.0361],\n",
      "        [ 0.1408,  0.3727, -0.1498,  0.0949, -0.0873, -0.0261],\n",
      "        [ 0.3255, -0.4030,  0.2755, -0.1116, -0.1231, -0.1083]])), ('lin1.bias', tensor([ 0.3476,  0.0741,  0.2516, -0.3905,  0.3370])), ('lin2.weight', tensor([[ 0.1500,  0.2271,  0.3883, -0.2684,  0.1757],\n",
      "        [ 0.4102, -0.1115,  0.1068, -0.1047, -0.1568],\n",
      "        [ 0.3958, -0.1076, -0.3786, -0.2421, -0.0791]])), ('lin2.bias', tensor([-0.4462, -0.0746,  0.0429])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[ 2.3513e-01, -2.2262e-04,  8.5371e-02,  6.7372e-01,  3.9232e-01],\n",
      "        [ 7.0971e-02, -6.9667e-01,  6.5186e-01,  3.5120e-01,  3.1478e-01],\n",
      "        [-1.0492e-01, -1.0710e-01,  6.4295e-01, -1.1939e-01,  6.4171e-01],\n",
      "        [-5.2457e-01,  7.5785e-01, -1.1984e-01,  5.8344e-01, -9.4771e-02],\n",
      "        [-1.0659e-01,  6.8841e-01, -1.7746e-01, -2.1307e-01,  5.5856e-01]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[ 0.2845, -0.6523,  0.0311,  0.2724, -0.6217],\n",
      "        [ 0.3423,  0.6522, -0.2953,  0.4144,  0.3282],\n",
      "        [ 0.7159,  0.1455,  0.2215, -0.7564,  0.5847],\n",
      "        [-0.4122, -0.3796,  0.4810,  0.0374,  0.5262],\n",
      "        [-0.1045, -0.5858,  0.6848, -0.3789,  0.0172]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[-0.4439, -0.2399, -0.4019,  0.4395, -0.1479],\n",
      "        [-0.7222, -0.6692, -0.0720, -0.0091, -0.2039],\n",
      "        [-0.0296,  0.7162,  0.1932,  0.5556, -0.2106],\n",
      "        [ 0.5034, -0.4304,  0.1493, -0.1119, -0.4772],\n",
      "        [-0.4076,  0.3941,  0.3413,  0.5806,  0.0601]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[ 0.0022,  0.5577, -0.7467,  0.1695,  0.4372],\n",
      "        [-0.4015,  0.5860,  0.5741,  0.5818,  0.1527],\n",
      "        [ 0.6965, -0.1374, -0.7490,  0.6183, -0.2720],\n",
      "        [-0.1102, -0.4281,  0.7131,  0.6516,  0.0740],\n",
      "        [ 0.3961,  0.2872, -0.0083,  0.0818, -0.0311]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'decoder': None}\n",
      "GAEv2(\n",
      "  (encoder): ResGCN2ConvEncoder(\n",
      "    (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "    (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "    (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (1): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (2): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "      (3): GCN2ConvBlock(\n",
      "        (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "GAEv2                                         --\n",
      "├─ResGCN2ConvEncoder: 1-1                     --\n",
      "│    └─Linear: 2-1                            35\n",
      "│    └─Linear: 2-2                            18\n",
      "│    └─LayerNorm: 2-3                         10\n",
      "│    └─ModuleList: 2-4                        --\n",
      "│    │    └─GCN2ConvBlock: 3-1                35\n",
      "│    │    └─GCN2ConvBlock: 3-2                35\n",
      "│    │    └─GCN2ConvBlock: 3-3                35\n",
      "│    │    └─GCN2ConvBlock: 3-4                35\n",
      "├─InnerProductDecoder: 1-2                    --\n",
      "======================================================================\n",
      "Total params: 203\n",
      "Trainable params: 203\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "Reconstruction forward() original\n",
      "tensor([0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336,\n",
      "        0.6336], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward() deserialized\n",
      "tensor([0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336,\n",
      "        0.6336], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6335, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6337]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized\n",
      "tensor([[0.6335, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6336],\n",
      "        [0.6336, 0.6336, 0.6336, 0.6336, 0.6337]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.2321, -0.0486, -0.7008],\n",
      "        [-0.2314, -0.0484, -0.7012],\n",
      "        [-0.2263, -0.0468, -0.7031],\n",
      "        [-0.2222, -0.0455, -0.7046],\n",
      "        [-0.2152, -0.0433, -0.7070]], grad_fn=<AddmmBackward0>)\n",
      "Latent space encoding deserialized\n",
      "tensor([[-0.2321, -0.0486, -0.7008],\n",
      "        [-0.2314, -0.0484, -0.7012],\n",
      "        [-0.2263, -0.0468, -0.7031],\n",
      "        [-0.2222, -0.0455, -0.7046],\n",
      "        [-0.2152, -0.0433, -0.7070]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336,\n",
      "        0.6336], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized\n",
      "tensor([0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336, 0.6336,\n",
      "        0.6336], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.4604, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized\n",
      "tensor(1.4604, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.56, 0.5976190476190476)\n",
      "AUC and precision metric test deserialized\n",
      "(0.56, 0.5976190476190476)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT GAE\")\n",
    "gae = GAEv2(encoder=gat_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevGATConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE GAE\")\n",
    "gae = GAEv2(encoder=sage_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, RevSAGEConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN GAE\")\n",
    "gae = GAEv2(encoder=gcn_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, SimpleGCNEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 GAE\")\n",
    "gae = GAEv2(encoder=gcn2_enc)\n",
    "constr_params = gae.serialize_constructor_params()\n",
    "state_dict = gae.state_dict()\n",
    "print(\"Constructor params: \")\n",
    "print(constr_params)\n",
    "gae2 = GAEv2.from_constructor_params(constr_params, ResGCN2ConvEncoder)\n",
    "gae2.load_state_dict(state_dict)\n",
    "print(gae2)\n",
    "print(torchinfo.summary(gae2))\n",
    "print(\"Reconstruction forward() original\")\n",
    "print(gae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward() deserialized\")\n",
    "print(gae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(gae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized\")\n",
    "print(gae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Reconstruction decode() original\")\n",
    "print(gae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized\")\n",
    "print(gae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "print(gae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized\")\n",
    "print(gae2.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = gae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized\")\n",
    "z = gae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(gae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate VGAEv2 and test it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevGATConvEncoder: 2-1                                     --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       804\n",
      "│    └─RevGATConvEncoder: 2-2                                     --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       804\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.6106, 0.7208, 0.6106, 0.9955, 0.7208, 0.9955, 0.0528, 0.3623, 0.0528,\n",
      "        0.3623], grad_fn=<SigmoidBackward0>), tensor([[-0.8471, -0.2427,  0.8385],\n",
      "        [-0.2212, -0.6708,  0.4080],\n",
      "        [ 0.0238, -0.7763,  0.0583],\n",
      "        [-0.6177, -0.3758,  0.6969],\n",
      "        [ 0.0555, -0.8462,  0.0341]], grad_fn=<AddmmBackward0>), tensor([[ 0.0812,  0.4508, -0.5011],\n",
      "        [ 0.4735,  0.9162, -0.7041],\n",
      "        [ 0.6912,  0.8253, -0.4952],\n",
      "        [ 0.5237,  0.7329, -0.2883],\n",
      "        [ 0.6863,  0.7997, -0.4405]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[9.9998e-01, 7.1849e-04, 9.7898e-01, 2.6633e-01, 9.9893e-01],\n",
      "        [7.1849e-04, 9.9944e-01, 9.0995e-03, 9.9291e-01, 4.6883e-04],\n",
      "        [9.7898e-01, 9.0995e-03, 9.5863e-01, 2.7661e-02, 9.9377e-01],\n",
      "        [2.6633e-01, 9.9291e-01, 2.7661e-02, 9.9948e-01, 5.7332e-03],\n",
      "        [9.9893e-01, 4.6883e-04, 9.9377e-01, 5.7332e-03, 9.9975e-01]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-0.9816,  1.7863,  1.3263],\n",
      "        [ 2.1516, -3.2685,  0.2225],\n",
      "        [ 2.0924,  0.5778,  0.6916],\n",
      "        [-4.6887, -2.1909,  1.5324],\n",
      "        [ 0.2697,  0.5375, -0.0090]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.8471, -0.2427,  0.8385],\n",
      "        [-0.2212, -0.6708,  0.4080],\n",
      "        [ 0.0238, -0.7763,  0.0583],\n",
      "        [-0.6177, -0.3758,  0.6969],\n",
      "        [ 0.0555, -0.8462,  0.0341]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[ 0.0812,  0.4508, -0.5011],\n",
      "        [ 0.4735,  0.9162, -0.7041],\n",
      "        [ 0.6912,  0.8253, -0.4952],\n",
      "        [ 0.5237,  0.7329, -0.2883],\n",
      "        [ 0.6863,  0.7997, -0.4405]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([4.7325e-04, 4.7393e-01, 4.7325e-04, 9.4089e-01, 4.7393e-01, 9.4089e-01,\n",
      "        4.4657e-05, 7.0447e-01, 4.4657e-05, 7.0447e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(4.6261, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.48, 0.6422222222222222)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevSAGEConvEncoder: 2-1                                    --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       160\n",
      "│    └─RevSAGEConvEncoder: 2-2                                    --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       160\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.0175, 0.6734, 0.0175, 0.1285, 0.6734, 0.1285, 0.5903, 0.0890, 0.5903,\n",
      "        0.0890], grad_fn=<SigmoidBackward0>), tensor([[ 0.7178, -0.1950,  0.1824],\n",
      "        [ 0.4362, -0.0966,  0.3814],\n",
      "        [ 0.3083, -0.0807,  0.4159],\n",
      "        [ 0.4592, -0.0938,  0.3900],\n",
      "        [ 0.6519, -0.0580,  0.4614]], grad_fn=<AddmmBackward0>), tensor([[-0.7079,  0.5212,  0.0309],\n",
      "        [-1.0302,  0.7857,  0.1644],\n",
      "        [-1.0277,  0.8932, -0.1178],\n",
      "        [-0.8997,  0.7061,  0.0481],\n",
      "        [-1.0173,  0.8530, -0.0394]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[9.9991e-01, 7.7817e-01, 8.1977e-03, 8.5862e-05, 7.7057e-01],\n",
      "        [7.7817e-01, 6.2590e-01, 3.2987e-01, 2.9254e-01, 7.7573e-01],\n",
      "        [8.1977e-03, 3.2987e-01, 9.7258e-01, 9.9563e-01, 1.7978e-01],\n",
      "        [8.5862e-05, 2.9254e-01, 9.9563e-01, 9.9996e-01, 3.8618e-01],\n",
      "        [7.7057e-01, 7.7573e-01, 1.7978e-01, 3.8618e-01, 9.8155e-01]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[ 0.5655, -3.7880, -0.3702],\n",
      "        [ 0.5757,  1.9216,  0.3970],\n",
      "        [ 0.6337,  3.5808, -0.6150],\n",
      "        [ 0.5004,  1.1440, -0.9866],\n",
      "        [ 0.9361,  2.0057, -1.3919]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[ 0.7178, -0.1950,  0.1824],\n",
      "        [ 0.4362, -0.0966,  0.3814],\n",
      "        [ 0.3083, -0.0807,  0.4159],\n",
      "        [ 0.4592, -0.0938,  0.3900],\n",
      "        [ 0.6519, -0.0580,  0.4614]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.7079,  0.5212,  0.0309],\n",
      "        [-1.0302,  0.7857,  0.1644],\n",
      "        [-1.0277,  0.8932, -0.1178],\n",
      "        [-0.8997,  0.7061,  0.0481],\n",
      "        [-1.0173,  0.8530, -0.0394]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([8.2415e-04, 2.3104e-06, 8.2415e-04, 9.9909e-01, 2.3104e-06, 9.9909e-01,\n",
      "        9.9344e-01, 9.9982e-01, 9.9344e-01, 9.9982e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(6.0675, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.6, 0.7888888888888888)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "├─VGEncoder: 1-1                                        --\n",
      "│    └─SimpleGCNEncoder: 2-1                            --\n",
      "│    │    └─Linear: 3-1                                 35\n",
      "│    │    └─Linear: 3-2                                 15\n",
      "│    │    └─LayerNorm: 3-3                              8\n",
      "│    │    └─ModuleList: 3-4                             142\n",
      "│    └─SimpleGCNEncoder: 2-2                            --\n",
      "│    │    └─Linear: 3-5                                 35\n",
      "│    │    └─Linear: 3-6                                 15\n",
      "│    │    └─LayerNorm: 3-7                              8\n",
      "│    │    └─ModuleList: 3-8                             142\n",
      "├─InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.7919, 0.6896, 0.7919, 0.9998, 0.6896, 0.9998, 0.0288, 1.0000, 0.0288,\n",
      "        1.0000], grad_fn=<SigmoidBackward0>), tensor([[-1.1006, -0.2708,  0.4863],\n",
      "        [-1.1008, -0.2707,  0.4864],\n",
      "        [-1.1009, -0.2707,  0.4865],\n",
      "        [-1.0979, -0.2716,  0.4844],\n",
      "        [-1.1041, -0.2697,  0.4887]], grad_fn=<AddmmBackward0>), tensor([[-0.1998,  0.1162,  0.3870],\n",
      "        [-0.1998,  0.1162,  0.3870],\n",
      "        [-0.1999,  0.1162,  0.3869],\n",
      "        [-0.1998,  0.1162,  0.3870],\n",
      "        [-0.1998,  0.1162,  0.3870]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[0.9728, 0.7050, 0.6577, 0.0342, 0.9985],\n",
      "        [0.7050, 0.9999, 0.3789, 0.0025, 0.9941],\n",
      "        [0.6577, 0.3789, 0.6012, 0.2078, 0.6509],\n",
      "        [0.0342, 0.0025, 0.2078, 1.0000, 0.0014],\n",
      "        [0.9985, 0.9941, 0.6509, 0.0014, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-2.0710, -0.9597,  1.6053],\n",
      "        [-2.4194, -0.7536,  2.3517],\n",
      "        [-1.1401,  0.6769,  0.5418],\n",
      "        [-1.4002, -0.2355,  0.2944],\n",
      "        [-2.0148, -0.0814, -0.8234]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-1.1006, -0.2708,  0.4863],\n",
      "        [-1.1008, -0.2707,  0.4864],\n",
      "        [-1.1009, -0.2707,  0.4865],\n",
      "        [-1.0979, -0.2716,  0.4844],\n",
      "        [-1.1041, -0.2697,  0.4887]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[-0.1998,  0.1162,  0.3870],\n",
      "        [-0.1998,  0.1162,  0.3870],\n",
      "        [-0.1999,  0.1162,  0.3869],\n",
      "        [-0.1998,  0.1162,  0.3870],\n",
      "        [-0.1998,  0.1162,  0.3870]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([0.9999, 0.9297, 0.9999, 0.9713, 0.9297, 0.9713, 0.8315, 0.8576, 0.8315,\n",
      "        0.8576], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(3.4072, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.32, 0.5638888888888889)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "├─VGEncoder: 1-1                                   --\n",
      "│    └─ResGCN2ConvEncoder: 2-1                     --\n",
      "│    │    └─Linear: 3-1                            35\n",
      "│    │    └─Linear: 3-2                            18\n",
      "│    │    └─LayerNorm: 3-3                         10\n",
      "│    │    └─ModuleList: 3-4                        140\n",
      "│    └─ResGCN2ConvEncoder: 2-2                     --\n",
      "│    │    └─Linear: 3-5                            35\n",
      "│    │    └─Linear: 3-6                            18\n",
      "│    │    └─LayerNorm: 3-7                         10\n",
      "│    │    └─ModuleList: 3-8                        140\n",
      "├─InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "Reconstruction forward()\n",
      "(tensor([0.9476, 0.9797, 0.9476, 0.5629, 0.9797, 0.5629, 0.5995, 0.3898, 0.5995,\n",
      "        0.3898], grad_fn=<SigmoidBackward0>), tensor([[-0.3088,  0.1684, -0.5681],\n",
      "        [-0.3096,  0.1678, -0.5681],\n",
      "        [-0.3164,  0.1640, -0.5719],\n",
      "        [-0.3335,  0.1523, -0.5888],\n",
      "        [-0.3268,  0.1635, -0.5704]], grad_fn=<AddmmBackward0>), tensor([[ 0.8895, -0.6560,  0.7386],\n",
      "        [ 0.8584, -0.6253,  0.6117],\n",
      "        [ 0.6683, -0.4574,  0.2002],\n",
      "        [ 0.4110, -0.2446, -0.2048],\n",
      "        [ 0.3447, -0.0539, -0.1948]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all()\n",
      "tensor([[1.0000, 1.0000, 0.9971, 0.2369, 1.0000],\n",
      "        [1.0000, 1.0000, 0.9985, 0.1191, 1.0000],\n",
      "        [0.9971, 0.9985, 0.9393, 0.2278, 0.9988],\n",
      "        [0.2369, 0.1191, 0.2278, 0.8428, 0.0151],\n",
      "        [1.0000, 1.0000, 0.9988, 0.0151, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding\n",
      "tensor([[-3.2632,  1.1329, -5.5720],\n",
      "        [-0.1641,  0.5291,  2.3413],\n",
      "        [-1.9471, -1.2239,  0.0168],\n",
      "        [-2.2782,  1.1586,  1.1170],\n",
      "        [-1.4023,  0.7164, -0.9219]], grad_fn=<AddBackward0>)\n",
      "Mu\n",
      "tensor([[-0.3088,  0.1684, -0.5681],\n",
      "        [-0.3096,  0.1678, -0.5681],\n",
      "        [-0.3164,  0.1640, -0.5719],\n",
      "        [-0.3335,  0.1523, -0.5888],\n",
      "        [-0.3268,  0.1635, -0.5704]], grad_fn=<AddmmBackward0>)\n",
      "log(std)\n",
      "tensor([[ 0.8895, -0.6560,  0.7386],\n",
      "        [ 0.8584, -0.6253,  0.6117],\n",
      "        [ 0.6683, -0.4574,  0.2002],\n",
      "        [ 0.4110, -0.2446, -0.2048],\n",
      "        [ 0.3447, -0.0539, -0.1948]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode()\n",
      "tensor([6.7161e-06, 9.9241e-01, 6.7161e-06, 4.2827e-01, 9.9241e-01, 4.2827e-01,\n",
      "        9.5420e-01, 8.6272e-01, 9.5420e-01, 8.6272e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss\n",
      "tensor(6.5906, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test\n",
      "(0.36, 0.48571428571428565)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gat_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(vgae)\n",
    "print(torchinfo.summary(vgae))\n",
    "print(\"Reconstruction forward()\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all()\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode()\")\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss\")\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"AUC and precision metric test\")\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test VGAE serialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversible residual GAT VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.3068,  0.0589,  0.0485, -0.3847, -0.2539, -0.0323],\n",
      "        [-0.1433,  0.2027, -0.2680, -0.1653,  0.2488,  0.3773],\n",
      "        [ 0.1245,  0.2250, -0.1455, -0.2873, -0.3446,  0.1250],\n",
      "        [ 0.3235,  0.3735, -0.2686,  0.3273,  0.1007, -0.0134]])), ('_encoder_mu.lin1.bias', tensor([-0.2244, -0.3042, -0.2610,  0.2541])), ('_encoder_mu.lin2.weight', tensor([[ 0.0941, -0.4091,  0.2512, -0.2293],\n",
      "        [ 0.0881, -0.3363, -0.0651,  0.4542],\n",
      "        [ 0.0251,  0.4587,  0.3038, -0.3096]])), ('_encoder_mu.lin2.bias', tensor([ 0.2598, -0.2703,  0.4144])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.att', tensor([[[-0.2768, -0.6540],\n",
      "         [ 0.5075,  0.6671],\n",
      "         [-0.7037, -0.7081],\n",
      "         [-0.5656, -0.4043],\n",
      "         [-0.4006,  0.2189],\n",
      "         [-0.4630, -0.0304],\n",
      "         [ 0.0293, -0.5021],\n",
      "         [-0.3583,  0.7282]]])), ('_encoder_mu.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.weight', tensor([[-0.2069,  0.2488],\n",
      "        [-0.0174, -0.3471],\n",
      "        [-0.5660, -0.0501],\n",
      "        [-0.4380, -0.4690],\n",
      "        [ 0.3812, -0.2462],\n",
      "        [-0.0264, -0.4652],\n",
      "        [-0.0734,  0.3424],\n",
      "        [ 0.1330,  0.1066],\n",
      "        [ 0.4647, -0.4542],\n",
      "        [-0.1934, -0.1227],\n",
      "        [ 0.5655,  0.5384],\n",
      "        [-0.5136,  0.2894],\n",
      "        [-0.2546, -0.2826],\n",
      "        [ 0.2353, -0.5041],\n",
      "        [-0.1363, -0.1420],\n",
      "        [-0.0242,  0.4963]])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.bias', tensor([-0.0820,  0.2123, -0.1398, -0.5763, -0.1774, -0.3227,  0.2910,  0.1348,\n",
      "        -0.3463, -0.3762, -0.0804,  0.3177,  0.2343, -0.0732, -0.2789,  0.4207])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.0733,  0.2075],\n",
      "        [-0.3927,  0.3644],\n",
      "        [-0.4830,  0.5225],\n",
      "        [ 0.0337,  0.4835],\n",
      "        [ 0.5585, -0.5206],\n",
      "        [-0.3539,  0.2864],\n",
      "        [ 0.0534, -0.1104],\n",
      "        [ 0.0601, -0.5349],\n",
      "        [-0.5210, -0.4819],\n",
      "        [ 0.3540,  0.1530],\n",
      "        [ 0.3293,  0.1283],\n",
      "        [-0.2768,  0.0872],\n",
      "        [ 0.2229,  0.4739],\n",
      "        [ 0.2970, -0.4703],\n",
      "        [ 0.4133, -0.4904],\n",
      "        [ 0.0985, -0.1509]])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.bias', tensor([-0.5517, -0.0565, -0.0645,  0.5801, -0.6113,  0.4869, -0.5101, -0.0422,\n",
      "         0.4355, -0.6581, -0.6662, -0.1843,  0.5753, -0.2941,  0.2782, -0.3117])), ('_encoder_mu.convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.4526],\n",
      "        [-0.4365],\n",
      "        [ 0.4322],\n",
      "        [-0.0543],\n",
      "        [ 0.2112],\n",
      "        [-0.1270],\n",
      "        [-0.0041],\n",
      "        [ 0.2127],\n",
      "        [-0.4278],\n",
      "        [-0.2588],\n",
      "        [ 0.0942],\n",
      "        [-0.5901],\n",
      "        [ 0.0943],\n",
      "        [ 0.4815],\n",
      "        [ 0.5164],\n",
      "        [-0.1972]])), ('_encoder_mu.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.att', tensor([[[ 0.0963,  0.1856],\n",
      "         [-0.4371, -0.6088],\n",
      "         [-0.0035,  0.5699],\n",
      "         [-0.4598, -0.4169],\n",
      "         [ 0.1420,  0.6392],\n",
      "         [-0.7623,  0.2573],\n",
      "         [ 0.2988,  0.6839],\n",
      "         [-0.4506,  0.4911]]])), ('_encoder_mu.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.4589,  0.2293],\n",
      "        [-0.4556, -0.0252],\n",
      "        [ 0.3119, -0.3674],\n",
      "        [ 0.4898,  0.5111],\n",
      "        [-0.3795,  0.5216],\n",
      "        [ 0.1416, -0.2221],\n",
      "        [-0.4573, -0.3275],\n",
      "        [-0.0543,  0.2606],\n",
      "        [-0.2548,  0.0078],\n",
      "        [-0.4759, -0.5260],\n",
      "        [-0.5336,  0.4030],\n",
      "        [ 0.2779,  0.1897],\n",
      "        [ 0.1945, -0.4290],\n",
      "        [-0.3593, -0.3557],\n",
      "        [ 0.5362, -0.3579],\n",
      "        [ 0.4966,  0.1002]])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.bias', tensor([ 0.7063, -0.2534, -0.6035,  0.1445, -0.5157, -0.3711, -0.0791,  0.2745,\n",
      "        -0.4890, -0.3041,  0.5152,  0.6795,  0.4054, -0.5104,  0.6395,  0.5653])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.weight', tensor([[-0.5115,  0.2950],\n",
      "        [-0.1293, -0.2907],\n",
      "        [ 0.5339,  0.5260],\n",
      "        [ 0.4498, -0.0092],\n",
      "        [ 0.3141,  0.2711],\n",
      "        [-0.4862, -0.4821],\n",
      "        [-0.4090, -0.5308],\n",
      "        [-0.5067,  0.0783],\n",
      "        [-0.0908,  0.1584],\n",
      "        [ 0.3168, -0.2186],\n",
      "        [ 0.4006,  0.1036],\n",
      "        [ 0.5557,  0.4512],\n",
      "        [-0.3894,  0.4157],\n",
      "        [ 0.0075,  0.0601],\n",
      "        [-0.1332,  0.3375],\n",
      "        [ 0.3656,  0.2547]])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.bias', tensor([-0.1005,  0.2290,  0.0897, -0.0934,  0.5834,  0.4439,  0.5221, -0.0322,\n",
      "        -0.2920, -0.1361, -0.0723, -0.1107,  0.2051, -0.0985, -0.1019, -0.1342])), ('_encoder_mu.convs.0.convs.1.conv.lin_edge.weight', tensor([[ 0.3882],\n",
      "        [-0.5147],\n",
      "        [-0.4988],\n",
      "        [ 0.3515],\n",
      "        [ 0.0937],\n",
      "        [ 0.2161],\n",
      "        [ 0.3253],\n",
      "        [ 0.0207],\n",
      "        [ 0.4605],\n",
      "        [ 0.3971],\n",
      "        [-0.4594],\n",
      "        [ 0.4816],\n",
      "        [ 0.3190],\n",
      "        [-0.4242],\n",
      "        [-0.0464],\n",
      "        [-0.1515]])), ('_encoder_mu.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.att', tensor([[[-0.1587, -0.5650],\n",
      "         [-0.5181, -0.5930],\n",
      "         [ 0.5221,  0.3797],\n",
      "         [ 0.0535, -0.5302],\n",
      "         [-0.7456, -0.2567],\n",
      "         [-0.6409, -0.6913],\n",
      "         [-0.3258, -0.3577],\n",
      "         [-0.4099, -0.2937]]])), ('_encoder_mu.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.2473, -0.4930],\n",
      "        [ 0.3984, -0.1487],\n",
      "        [-0.4708,  0.1904],\n",
      "        [ 0.3662, -0.5278],\n",
      "        [ 0.5446,  0.0223],\n",
      "        [ 0.3078, -0.1578],\n",
      "        [-0.3457,  0.4837],\n",
      "        [-0.3449,  0.5573],\n",
      "        [-0.1503, -0.0343],\n",
      "        [-0.2176,  0.5131],\n",
      "        [ 0.5556,  0.1248],\n",
      "        [-0.4485, -0.5379],\n",
      "        [-0.5437, -0.3185],\n",
      "        [-0.4914,  0.1351],\n",
      "        [ 0.0675,  0.1092],\n",
      "        [-0.4982, -0.2294]])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.bias', tensor([-0.3774, -0.1208,  0.0570,  0.0604, -0.0647,  0.1191,  0.4720, -0.4167,\n",
      "        -0.4982,  0.3374,  0.5216,  0.6714,  0.2746,  0.6443,  0.1353, -0.3978])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4823, -0.3608],\n",
      "        [ 0.2411,  0.2713],\n",
      "        [ 0.2058, -0.4548],\n",
      "        [-0.5023, -0.0054],\n",
      "        [-0.4694,  0.3301],\n",
      "        [ 0.4907,  0.4533],\n",
      "        [ 0.4776,  0.3136],\n",
      "        [ 0.5065, -0.0318],\n",
      "        [ 0.0935,  0.3919],\n",
      "        [-0.1015, -0.1438],\n",
      "        [-0.1028,  0.1561],\n",
      "        [-0.1108,  0.5466],\n",
      "        [-0.0935, -0.2763],\n",
      "        [-0.4236, -0.3160],\n",
      "        [ 0.0867,  0.2073],\n",
      "        [ 0.4071,  0.3618]])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.bias', tensor([ 0.0815, -0.6161,  0.6873,  0.6116, -0.2703, -0.4015,  0.1455, -0.4794,\n",
      "         0.6414,  0.5414, -0.5200,  0.3492, -0.0236, -0.6990, -0.0552, -0.5271])), ('_encoder_mu.convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.4506],\n",
      "        [ 0.5934],\n",
      "        [ 0.5263],\n",
      "        [-0.5354],\n",
      "        [ 0.2415],\n",
      "        [-0.0983],\n",
      "        [ 0.3998],\n",
      "        [-0.3803],\n",
      "        [ 0.5670],\n",
      "        [ 0.3804],\n",
      "        [ 0.4056],\n",
      "        [-0.2385],\n",
      "        [-0.3703],\n",
      "        [-0.1175],\n",
      "        [-0.4168],\n",
      "        [-0.2308]])), ('_encoder_mu.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.att', tensor([[[-0.5442, -0.5150],\n",
      "         [-0.2734,  0.5966],\n",
      "         [-0.3033,  0.2305],\n",
      "         [-0.5090, -0.4078],\n",
      "         [ 0.1013, -0.1307],\n",
      "         [-0.0041, -0.1208],\n",
      "         [ 0.2673, -0.5190],\n",
      "         [-0.1743,  0.5808]]])), ('_encoder_mu.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.0816, -0.3004],\n",
      "        [ 0.4735, -0.3894],\n",
      "        [-0.0849, -0.0661],\n",
      "        [-0.5572, -0.0710],\n",
      "        [-0.2438, -0.5416],\n",
      "        [-0.4809, -0.3530],\n",
      "        [-0.2228, -0.3762],\n",
      "        [-0.1955,  0.3356],\n",
      "        [ 0.3218, -0.2228],\n",
      "        [-0.0933, -0.0079],\n",
      "        [ 0.2719,  0.2141],\n",
      "        [ 0.5400, -0.3934],\n",
      "        [-0.1070, -0.5551],\n",
      "        [-0.1657, -0.0540],\n",
      "        [ 0.3155, -0.2211],\n",
      "        [-0.1109, -0.3054]])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.bias', tensor([ 0.1952,  0.3202, -0.0293, -0.3942, -0.2941, -0.2945,  0.6052, -0.5890,\n",
      "         0.3188, -0.4771,  0.6781, -0.2430,  0.3314,  0.1400,  0.6760,  0.0911])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.2019, -0.0304],\n",
      "        [-0.2394,  0.4563],\n",
      "        [-0.4459,  0.4822],\n",
      "        [-0.0776,  0.2828],\n",
      "        [-0.1022, -0.0450],\n",
      "        [ 0.2343, -0.3456],\n",
      "        [ 0.4119, -0.5448],\n",
      "        [ 0.5180,  0.1752],\n",
      "        [-0.1934, -0.0211],\n",
      "        [ 0.0455, -0.5567],\n",
      "        [ 0.0850, -0.2354],\n",
      "        [ 0.3583, -0.0282],\n",
      "        [-0.1587,  0.5638],\n",
      "        [-0.2037, -0.1875],\n",
      "        [-0.5196, -0.4773],\n",
      "        [-0.1871, -0.4141]])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.bias', tensor([ 0.3115,  0.2190,  0.2406,  0.0086, -0.0182, -0.6175,  0.6676,  0.5673,\n",
      "        -0.2907, -0.0124,  0.3834, -0.1400, -0.6092,  0.5860, -0.1100,  0.0544])), ('_encoder_mu.convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.4400],\n",
      "        [ 0.0794],\n",
      "        [ 0.5032],\n",
      "        [-0.2128],\n",
      "        [ 0.2322],\n",
      "        [ 0.2403],\n",
      "        [-0.1293],\n",
      "        [ 0.2180],\n",
      "        [-0.5760],\n",
      "        [ 0.5913],\n",
      "        [ 0.0200],\n",
      "        [ 0.4967],\n",
      "        [-0.4005],\n",
      "        [-0.4179],\n",
      "        [ 0.1777],\n",
      "        [-0.4841]])), ('_encoder_mu.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.att', tensor([[[ 0.5968,  0.3160],\n",
      "         [-0.2640, -0.3246],\n",
      "         [-0.4402, -0.3196],\n",
      "         [-0.2527, -0.5609],\n",
      "         [ 0.6976,  0.0540],\n",
      "         [ 0.3489, -0.6638],\n",
      "         [-0.6394, -0.4376],\n",
      "         [-0.2194, -0.6624]]])), ('_encoder_mu.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.weight', tensor([[ 4.2546e-01,  1.9456e-01],\n",
      "        [-1.1623e-01, -4.3876e-01],\n",
      "        [ 5.7602e-01,  4.4163e-01],\n",
      "        [ 2.5691e-01, -5.5048e-01],\n",
      "        [ 3.5440e-01, -5.6441e-01],\n",
      "        [-2.3621e-02, -4.3352e-01],\n",
      "        [ 3.7816e-01, -5.7229e-01],\n",
      "        [ 4.9604e-02, -4.7165e-01],\n",
      "        [-4.5662e-01,  2.9483e-01],\n",
      "        [ 3.2547e-01, -1.6630e-03],\n",
      "        [-4.2323e-01,  6.0108e-02],\n",
      "        [ 4.2193e-01, -5.0073e-01],\n",
      "        [-3.4148e-01, -3.8781e-01],\n",
      "        [-1.9043e-02, -3.8060e-01],\n",
      "        [ 3.2938e-01,  4.0612e-01],\n",
      "        [-3.1763e-04,  2.4483e-01]])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.bias', tensor([-0.0248, -0.2238, -0.4008,  0.5462, -0.5306, -0.6846, -0.0885,  0.0755,\n",
      "        -0.6799,  0.1757,  0.5258, -0.3215,  0.5559, -0.1353, -0.0215, -0.6363])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.4427,  0.4430],\n",
      "        [ 0.2451, -0.5012],\n",
      "        [-0.1145, -0.2010],\n",
      "        [ 0.1313,  0.4863],\n",
      "        [ 0.5699, -0.3404],\n",
      "        [ 0.4717, -0.2635],\n",
      "        [ 0.4786,  0.4045],\n",
      "        [ 0.3899,  0.4570],\n",
      "        [-0.5462,  0.2486],\n",
      "        [ 0.3961, -0.4682],\n",
      "        [ 0.2189,  0.2488],\n",
      "        [-0.0941,  0.2784],\n",
      "        [ 0.4460, -0.5266],\n",
      "        [ 0.1027,  0.1255],\n",
      "        [-0.0675,  0.4702],\n",
      "        [-0.5143, -0.2818]])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.bias', tensor([-0.5194,  0.6153,  0.0712,  0.0785, -0.0608, -0.5557,  0.6481, -0.2167,\n",
      "        -0.0490, -0.0111, -0.2560,  0.5716, -0.2599,  0.5866,  0.2347,  0.1591])), ('_encoder_mu.convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.5237],\n",
      "        [ 0.0188],\n",
      "        [ 0.2148],\n",
      "        [-0.0914],\n",
      "        [-0.1709],\n",
      "        [-0.4723],\n",
      "        [ 0.5061],\n",
      "        [-0.1947],\n",
      "        [ 0.4283],\n",
      "        [ 0.0346],\n",
      "        [-0.0891],\n",
      "        [ 0.2167],\n",
      "        [-0.5905],\n",
      "        [-0.3143],\n",
      "        [-0.5808],\n",
      "        [ 0.0696]])), ('_encoder_mu.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.att', tensor([[[-0.5346,  0.1147],\n",
      "         [-0.0248, -0.1866],\n",
      "         [ 0.5602, -0.1882],\n",
      "         [-0.1828, -0.0542],\n",
      "         [ 0.6187, -0.6374],\n",
      "         [ 0.7439,  0.7593],\n",
      "         [ 0.5308,  0.7016],\n",
      "         [ 0.0684,  0.6340]]])), ('_encoder_mu.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.2656,  0.1500],\n",
      "        [-0.2625,  0.5636],\n",
      "        [ 0.3178,  0.2618],\n",
      "        [ 0.0103, -0.4851],\n",
      "        [ 0.5105,  0.0840],\n",
      "        [-0.5043, -0.5214],\n",
      "        [ 0.4017, -0.1804],\n",
      "        [-0.3955, -0.5226],\n",
      "        [-0.4612,  0.5612],\n",
      "        [ 0.0396,  0.2694],\n",
      "        [ 0.4455, -0.0580],\n",
      "        [-0.4643, -0.3167],\n",
      "        [ 0.3848, -0.0631],\n",
      "        [-0.0346, -0.3531],\n",
      "        [-0.3589, -0.4475],\n",
      "        [ 0.3233,  0.2891]])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.bias', tensor([-0.6525,  0.5237, -0.0254, -0.4130,  0.6356, -0.1854, -0.4803,  0.6261,\n",
      "        -0.0224,  0.5017, -0.1301, -0.3794,  0.5871,  0.1785, -0.3664,  0.1327])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.3052,  0.4494],\n",
      "        [-0.4696,  0.2987],\n",
      "        [-0.0292, -0.3817],\n",
      "        [ 0.3955, -0.4988],\n",
      "        [ 0.1798, -0.5387],\n",
      "        [-0.3340,  0.4086],\n",
      "        [-0.0282, -0.2209],\n",
      "        [-0.5278, -0.1812],\n",
      "        [ 0.2735, -0.4354],\n",
      "        [ 0.4241,  0.3406],\n",
      "        [ 0.2377,  0.1681],\n",
      "        [ 0.1032, -0.2276],\n",
      "        [-0.3509, -0.5566],\n",
      "        [ 0.1934,  0.0937],\n",
      "        [-0.3835,  0.0234],\n",
      "        [-0.0079,  0.2338]])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.bias', tensor([ 0.2755,  0.5385, -0.1506, -0.3214,  0.2174,  0.3578,  0.1015,  0.6884,\n",
      "         0.5600,  0.2922, -0.3039,  0.2204,  0.4721,  0.2314, -0.6743, -0.2724])), ('_encoder_mu.convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.0249],\n",
      "        [-0.0716],\n",
      "        [ 0.0679],\n",
      "        [-0.0188],\n",
      "        [-0.5118],\n",
      "        [ 0.5075],\n",
      "        [-0.5767],\n",
      "        [ 0.1704],\n",
      "        [ 0.0532],\n",
      "        [-0.2623],\n",
      "        [ 0.2756],\n",
      "        [ 0.1723],\n",
      "        [ 0.5694],\n",
      "        [-0.1091],\n",
      "        [-0.2716],\n",
      "        [ 0.2617]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.2364, -0.0260, -0.3128, -0.2900,  0.0986,  0.3585],\n",
      "        [ 0.3868, -0.2202, -0.1776,  0.3854, -0.1441,  0.2898],\n",
      "        [ 0.1053, -0.2702,  0.3197, -0.0806, -0.0989,  0.3448],\n",
      "        [ 0.0281, -0.0462, -0.0544, -0.2868, -0.1255,  0.1520]])), ('_encoder_logstd.lin1.bias', tensor([ 0.3807, -0.2784, -0.0380, -0.2963])), ('_encoder_logstd.lin2.weight', tensor([[-0.2083, -0.0413,  0.0030,  0.1130],\n",
      "        [-0.0651,  0.4006,  0.1143, -0.3300],\n",
      "        [-0.0174, -0.1230, -0.2525, -0.0159]])), ('_encoder_logstd.lin2.bias', tensor([ 0.0906,  0.3761, -0.2239])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.att', tensor([[[ 0.1393,  0.2747],\n",
      "         [-0.5176, -0.5423],\n",
      "         [-0.2722,  0.5530],\n",
      "         [-0.4417, -0.1892],\n",
      "         [-0.3533,  0.0859],\n",
      "         [ 0.3505,  0.1545],\n",
      "         [ 0.2542, -0.6413],\n",
      "         [-0.5659,  0.7686]]])), ('_encoder_logstd.convs.0.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.5498, -0.1538],\n",
      "        [ 0.5069,  0.2513],\n",
      "        [-0.1292,  0.3487],\n",
      "        [ 0.4946, -0.1707],\n",
      "        [ 0.4620,  0.4480],\n",
      "        [-0.2585, -0.4966],\n",
      "        [ 0.3748, -0.5603],\n",
      "        [-0.2476,  0.5008],\n",
      "        [-0.1298,  0.2858],\n",
      "        [ 0.3996, -0.5491],\n",
      "        [ 0.3954,  0.3691],\n",
      "        [-0.3818,  0.2450],\n",
      "        [-0.5346,  0.0832],\n",
      "        [ 0.3659,  0.1049],\n",
      "        [ 0.1175,  0.5021],\n",
      "        [ 0.0510,  0.4696]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.bias', tensor([-0.2610,  0.0743, -0.3784,  0.3902, -0.1284,  0.5964, -0.2784,  0.3515,\n",
      "         0.6611, -0.1916, -0.5944,  0.2718, -0.6457,  0.4944,  0.6373, -0.5221])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.weight', tensor([[-0.5754,  0.3850],\n",
      "        [-0.2260, -0.5282],\n",
      "        [-0.5670,  0.0668],\n",
      "        [-0.5302, -0.1354],\n",
      "        [-0.2665,  0.0201],\n",
      "        [ 0.3914,  0.5518],\n",
      "        [-0.0025, -0.0760],\n",
      "        [ 0.3800,  0.5635],\n",
      "        [ 0.4936,  0.0191],\n",
      "        [ 0.5337, -0.1706],\n",
      "        [-0.5210, -0.2458],\n",
      "        [ 0.4569,  0.4431],\n",
      "        [ 0.4749, -0.3793],\n",
      "        [ 0.4902,  0.2144],\n",
      "        [-0.4622, -0.0267],\n",
      "        [ 0.5608, -0.0246]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.bias', tensor([-0.6062,  0.4779,  0.2400,  0.2621,  0.6466, -0.5172,  0.2054,  0.6920,\n",
      "        -0.6851,  0.3426,  0.0944, -0.4983, -0.5258,  0.4243, -0.1824,  0.1155])), ('_encoder_logstd.convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.4876],\n",
      "        [ 0.2543],\n",
      "        [ 0.0584],\n",
      "        [ 0.4937],\n",
      "        [ 0.0209],\n",
      "        [ 0.3464],\n",
      "        [-0.2338],\n",
      "        [-0.0220],\n",
      "        [-0.2600],\n",
      "        [-0.5699],\n",
      "        [ 0.2420],\n",
      "        [-0.4233],\n",
      "        [ 0.4955],\n",
      "        [-0.3438],\n",
      "        [ 0.5132],\n",
      "        [ 0.5272]])), ('_encoder_logstd.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.att', tensor([[[ 0.7255, -0.5257],\n",
      "         [-0.4851,  0.6959],\n",
      "         [-0.7051, -0.5405],\n",
      "         [ 0.1783, -0.4688],\n",
      "         [-0.4715, -0.0973],\n",
      "         [-0.4243,  0.7224],\n",
      "         [ 0.0214, -0.7254],\n",
      "         [-0.2177, -0.2942]]])), ('_encoder_logstd.convs.0.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.0697,  0.0931],\n",
      "        [ 0.2472,  0.0224],\n",
      "        [-0.5510,  0.2885],\n",
      "        [-0.1468,  0.3947],\n",
      "        [ 0.3622,  0.1763],\n",
      "        [ 0.2097, -0.0388],\n",
      "        [ 0.4139,  0.2078],\n",
      "        [ 0.1067,  0.3280],\n",
      "        [-0.0418, -0.1097],\n",
      "        [-0.1564, -0.3070],\n",
      "        [-0.0464,  0.1918],\n",
      "        [-0.5623,  0.3779],\n",
      "        [-0.3171,  0.4701],\n",
      "        [-0.5030,  0.0634],\n",
      "        [-0.4681, -0.5644],\n",
      "        [ 0.0149,  0.2888]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.bias', tensor([-0.0267, -0.1416, -0.4261, -0.0417,  0.6551,  0.6213,  0.3822, -0.4620,\n",
      "         0.4755,  0.7036,  0.1096,  0.0247, -0.5233, -0.4579, -0.3345, -0.5855])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.1616,  0.3647],\n",
      "        [-0.1790,  0.1739],\n",
      "        [-0.3465,  0.4754],\n",
      "        [ 0.4130, -0.1391],\n",
      "        [-0.1764, -0.2807],\n",
      "        [ 0.2819,  0.4222],\n",
      "        [ 0.0104,  0.5489],\n",
      "        [-0.3279, -0.4720],\n",
      "        [-0.4336,  0.2059],\n",
      "        [-0.0137,  0.1097],\n",
      "        [-0.5249, -0.1993],\n",
      "        [-0.2200, -0.5753],\n",
      "        [ 0.4726, -0.0697],\n",
      "        [-0.4704,  0.5514],\n",
      "        [ 0.3843, -0.2866],\n",
      "        [-0.0238, -0.2754]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.bias', tensor([ 0.3537, -0.2213, -0.6720,  0.4619,  0.6822, -0.5538, -0.1585, -0.5773,\n",
      "         0.5580, -0.0548, -0.0017, -0.3788, -0.7056,  0.2133,  0.1168, -0.5287])), ('_encoder_logstd.convs.0.convs.1.conv.lin_edge.weight', tensor([[ 0.5659],\n",
      "        [ 0.0949],\n",
      "        [ 0.2362],\n",
      "        [ 0.1047],\n",
      "        [-0.2561],\n",
      "        [ 0.4159],\n",
      "        [ 0.5886],\n",
      "        [ 0.3098],\n",
      "        [ 0.5033],\n",
      "        [ 0.5076],\n",
      "        [ 0.3205],\n",
      "        [-0.1778],\n",
      "        [ 0.5557],\n",
      "        [ 0.3097],\n",
      "        [ 0.4650],\n",
      "        [-0.2402]])), ('_encoder_logstd.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.att', tensor([[[ 0.4336,  0.0685],\n",
      "         [-0.3797, -0.5602],\n",
      "         [ 0.3742, -0.7398],\n",
      "         [ 0.7618,  0.1429],\n",
      "         [ 0.1907,  0.3746],\n",
      "         [ 0.1525,  0.6044],\n",
      "         [ 0.4095,  0.3985],\n",
      "         [ 0.3371, -0.1628]]])), ('_encoder_logstd.convs.1.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.3284,  0.2820],\n",
      "        [ 0.2509,  0.5238],\n",
      "        [-0.1176, -0.2105],\n",
      "        [ 0.3488, -0.3179],\n",
      "        [ 0.2127, -0.3779],\n",
      "        [ 0.1899, -0.1329],\n",
      "        [-0.3286,  0.3674],\n",
      "        [ 0.5707, -0.2868],\n",
      "        [ 0.1680, -0.4641],\n",
      "        [-0.0578, -0.1146],\n",
      "        [ 0.3093,  0.1744],\n",
      "        [ 0.0373, -0.1488],\n",
      "        [-0.2811,  0.5216],\n",
      "        [-0.5596,  0.4527],\n",
      "        [-0.3542,  0.1026],\n",
      "        [ 0.1567, -0.2256]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.bias', tensor([ 0.5379, -0.5051,  0.1606, -0.5388, -0.7013, -0.1291, -0.1549, -0.5292,\n",
      "         0.1272,  0.3622,  0.2046,  0.0851,  0.2451,  0.0659, -0.2804,  0.1050])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4767,  0.3908],\n",
      "        [-0.0324, -0.0044],\n",
      "        [-0.3632, -0.3258],\n",
      "        [ 0.1022, -0.0051],\n",
      "        [-0.4893, -0.5420],\n",
      "        [-0.2084, -0.1100],\n",
      "        [ 0.0483,  0.0198],\n",
      "        [ 0.1671, -0.2885],\n",
      "        [-0.4059,  0.1975],\n",
      "        [ 0.0501, -0.2813],\n",
      "        [ 0.5744,  0.3335],\n",
      "        [ 0.1340,  0.3373],\n",
      "        [ 0.3126,  0.2883],\n",
      "        [-0.5594,  0.5769],\n",
      "        [-0.5755, -0.0081],\n",
      "        [ 0.4861,  0.0585]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.bias', tensor([-0.2508, -0.3825,  0.6427, -0.1424, -0.1368, -0.3809, -0.0123,  0.4039,\n",
      "         0.6212, -0.3010,  0.1647, -0.3800,  0.3956, -0.0217, -0.1814,  0.6328])), ('_encoder_logstd.convs.1.convs.0.conv.lin_edge.weight', tensor([[ 1.5253e-04],\n",
      "        [ 8.4086e-02],\n",
      "        [ 1.3160e-01],\n",
      "        [ 3.3861e-01],\n",
      "        [ 4.3957e-01],\n",
      "        [-3.5326e-01],\n",
      "        [ 2.0101e-01],\n",
      "        [ 3.5744e-01],\n",
      "        [-2.0052e-01],\n",
      "        [-5.1481e-01],\n",
      "        [-4.8570e-01],\n",
      "        [-1.6561e-01],\n",
      "        [-5.2420e-01],\n",
      "        [ 2.8489e-01],\n",
      "        [-3.6551e-01],\n",
      "        [-4.9963e-01]])), ('_encoder_logstd.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.att', tensor([[[ 0.6711, -0.1082],\n",
      "         [-0.2006, -0.0134],\n",
      "         [ 0.5792,  0.5302],\n",
      "         [-0.3282, -0.5806],\n",
      "         [ 0.2280,  0.5543],\n",
      "         [-0.7126,  0.7588],\n",
      "         [-0.4687,  0.6230],\n",
      "         [ 0.6700,  0.5367]]])), ('_encoder_logstd.convs.1.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.2733,  0.3220],\n",
      "        [-0.4823, -0.4254],\n",
      "        [-0.5159,  0.2810],\n",
      "        [-0.1638, -0.4670],\n",
      "        [-0.5410,  0.0652],\n",
      "        [ 0.2010,  0.0278],\n",
      "        [ 0.3391,  0.1627],\n",
      "        [ 0.5731, -0.2069],\n",
      "        [-0.2492, -0.5700],\n",
      "        [-0.1157,  0.0369],\n",
      "        [-0.0521, -0.5592],\n",
      "        [ 0.2806, -0.0714],\n",
      "        [ 0.3930, -0.1625],\n",
      "        [ 0.1128,  0.0407],\n",
      "        [-0.3120, -0.2017],\n",
      "        [ 0.2303,  0.3750]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.bias', tensor([ 0.4194, -0.5568,  0.2699, -0.2415,  0.6648,  0.1347,  0.5596,  0.2841,\n",
      "        -0.2268, -0.5531,  0.5202, -0.6590,  0.1538,  0.3611,  0.6176,  0.6330])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.weight', tensor([[-0.4193,  0.4443],\n",
      "        [-0.3372,  0.4352],\n",
      "        [-0.0819, -0.1298],\n",
      "        [ 0.3636, -0.3985],\n",
      "        [-0.0932,  0.4158],\n",
      "        [-0.5343, -0.0191],\n",
      "        [-0.4954, -0.2959],\n",
      "        [ 0.2798, -0.1118],\n",
      "        [-0.4399, -0.4425],\n",
      "        [ 0.4126,  0.1821],\n",
      "        [-0.0916,  0.5327],\n",
      "        [ 0.3498, -0.5195],\n",
      "        [-0.0134, -0.1212],\n",
      "        [-0.1040, -0.5610],\n",
      "        [ 0.4015,  0.2260],\n",
      "        [-0.4951,  0.4170]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.bias', tensor([-0.0305, -0.2249,  0.0724, -0.6204, -0.5277, -0.5341, -0.4195, -0.3051,\n",
      "         0.4624,  0.3206,  0.2647,  0.3841, -0.4248, -0.4721, -0.2626,  0.0654])), ('_encoder_logstd.convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.5739],\n",
      "        [ 0.3835],\n",
      "        [ 0.0187],\n",
      "        [-0.3464],\n",
      "        [ 0.0745],\n",
      "        [-0.2202],\n",
      "        [ 0.0291],\n",
      "        [-0.3667],\n",
      "        [-0.1135],\n",
      "        [ 0.2656],\n",
      "        [-0.0951],\n",
      "        [ 0.3067],\n",
      "        [-0.0801],\n",
      "        [ 0.5317],\n",
      "        [-0.1844],\n",
      "        [-0.0253]])), ('_encoder_logstd.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.att', tensor([[[-0.5323, -0.3251],\n",
      "         [ 0.5153,  0.1537],\n",
      "         [-0.5446, -0.6885],\n",
      "         [-0.5770,  0.1144],\n",
      "         [ 0.1010,  0.4822],\n",
      "         [ 0.6236,  0.5775],\n",
      "         [ 0.3555, -0.1263],\n",
      "         [-0.1925,  0.0906]]])), ('_encoder_logstd.convs.2.convs.0.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.weight', tensor([[-0.1809, -0.0562],\n",
      "        [ 0.2262,  0.3447],\n",
      "        [-0.1454, -0.5530],\n",
      "        [-0.4777, -0.0394],\n",
      "        [-0.1968,  0.0710],\n",
      "        [ 0.2120, -0.2599],\n",
      "        [-0.3172, -0.4445],\n",
      "        [ 0.1277, -0.5708],\n",
      "        [-0.2346,  0.2559],\n",
      "        [ 0.1162,  0.3792],\n",
      "        [ 0.5271,  0.5389],\n",
      "        [-0.2116,  0.2644],\n",
      "        [ 0.3026,  0.3405],\n",
      "        [ 0.4450,  0.1194],\n",
      "        [-0.2452, -0.1633],\n",
      "        [ 0.0877,  0.5549]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.bias', tensor([ 0.2443, -0.5032, -0.3362,  0.0612,  0.0370,  0.2122, -0.5563, -0.0540,\n",
      "        -0.0271,  0.3462,  0.0465, -0.2932,  0.2395, -0.5554, -0.4718,  0.1566])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.3354, -0.1462],\n",
      "        [ 0.0614,  0.3611],\n",
      "        [ 0.4672,  0.0539],\n",
      "        [ 0.0514, -0.2131],\n",
      "        [ 0.5128, -0.4740],\n",
      "        [-0.4196,  0.1310],\n",
      "        [ 0.5276,  0.4984],\n",
      "        [ 0.5480, -0.0990],\n",
      "        [ 0.3829,  0.3711],\n",
      "        [-0.0050,  0.2463],\n",
      "        [ 0.3655,  0.2264],\n",
      "        [ 0.0183, -0.4729],\n",
      "        [ 0.1472, -0.0087],\n",
      "        [-0.1244, -0.0096],\n",
      "        [-0.2379,  0.4168],\n",
      "        [ 0.0510, -0.4297]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.bias', tensor([ 0.6199,  0.6233, -0.1953, -0.2202,  0.2418,  0.5919, -0.3287, -0.2141,\n",
      "        -0.2753, -0.6265, -0.5103, -0.5475,  0.7007, -0.3251,  0.4705, -0.6412])), ('_encoder_logstd.convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.5056],\n",
      "        [ 0.3348],\n",
      "        [-0.2095],\n",
      "        [ 0.0314],\n",
      "        [ 0.5723],\n",
      "        [ 0.1265],\n",
      "        [ 0.5483],\n",
      "        [ 0.5560],\n",
      "        [ 0.2079],\n",
      "        [ 0.0439],\n",
      "        [-0.2522],\n",
      "        [-0.3003],\n",
      "        [ 0.4728],\n",
      "        [-0.5394],\n",
      "        [-0.4179],\n",
      "        [ 0.3486]])), ('_encoder_logstd.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.att', tensor([[[-0.6334, -0.3999],\n",
      "         [-0.7262,  0.4788],\n",
      "         [-0.0380, -0.7492],\n",
      "         [ 0.3251, -0.3997],\n",
      "         [ 0.1294,  0.0099],\n",
      "         [ 0.2635, -0.2234],\n",
      "         [ 0.0447, -0.5856],\n",
      "         [ 0.4085,  0.6600]]])), ('_encoder_logstd.convs.2.convs.1.conv.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.0781, -0.5557],\n",
      "        [ 0.1690,  0.0092],\n",
      "        [ 0.2915, -0.3443],\n",
      "        [ 0.4446, -0.0554],\n",
      "        [-0.0633, -0.3738],\n",
      "        [-0.1920,  0.5118],\n",
      "        [-0.1761,  0.3078],\n",
      "        [-0.3551, -0.5579],\n",
      "        [ 0.4098, -0.2545],\n",
      "        [-0.1925,  0.4696],\n",
      "        [ 0.3004, -0.5615],\n",
      "        [ 0.2521, -0.3382],\n",
      "        [ 0.4913, -0.3525],\n",
      "        [-0.0950, -0.4158],\n",
      "        [-0.5374, -0.1855],\n",
      "        [ 0.3202,  0.4836]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.bias', tensor([-0.3467, -0.5645,  0.5597,  0.0349, -0.1096,  0.0560,  0.2513, -0.5980,\n",
      "         0.1215, -0.5566, -0.4869,  0.3992, -0.6570, -0.4537,  0.1836, -0.6559])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.3775, -0.1263],\n",
      "        [-0.5364,  0.5575],\n",
      "        [ 0.1788,  0.5474],\n",
      "        [-0.5430,  0.2379],\n",
      "        [-0.5500,  0.1106],\n",
      "        [ 0.4459, -0.4647],\n",
      "        [-0.2224,  0.1454],\n",
      "        [-0.3311, -0.2254],\n",
      "        [-0.3656,  0.5703],\n",
      "        [ 0.0798,  0.3998],\n",
      "        [ 0.0848, -0.4758],\n",
      "        [-0.3160, -0.2909],\n",
      "        [ 0.4923, -0.3462],\n",
      "        [-0.4088,  0.0420],\n",
      "        [-0.3578,  0.2698],\n",
      "        [-0.1612,  0.2817]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.bias', tensor([ 0.0600, -0.6916, -0.3534,  0.1866,  0.3741, -0.4645,  0.4777, -0.1677,\n",
      "         0.0327,  0.4721, -0.2835, -0.2524,  0.1745,  0.6977,  0.1681,  0.6098])), ('_encoder_logstd.convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.0111],\n",
      "        [-0.2416],\n",
      "        [ 0.0759],\n",
      "        [-0.4943],\n",
      "        [-0.1707],\n",
      "        [ 0.2476],\n",
      "        [-0.3312],\n",
      "        [ 0.3584],\n",
      "        [ 0.0296],\n",
      "        [-0.4877],\n",
      "        [ 0.4730],\n",
      "        [ 0.2641],\n",
      "        [-0.5897],\n",
      "        [ 0.2253],\n",
      "        [ 0.0274],\n",
      "        [-0.1242]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2364, -0.0260, -0.3128, -0.2900,  0.0986,  0.3585],\n",
      "        [ 0.3868, -0.2202, -0.1776,  0.3854, -0.1441,  0.2898],\n",
      "        [ 0.1053, -0.2702,  0.3197, -0.0806, -0.0989,  0.3448],\n",
      "        [ 0.0281, -0.0462, -0.0544, -0.2868, -0.1255,  0.1520]])), ('lin1.bias', tensor([ 0.3807, -0.2784, -0.0380, -0.2963])), ('lin2.weight', tensor([[-0.2083, -0.0413,  0.0030,  0.1130],\n",
      "        [-0.0651,  0.4006,  0.1143, -0.3300],\n",
      "        [-0.0174, -0.1230, -0.2525, -0.0159]])), ('lin2.bias', tensor([ 0.0906,  0.3761, -0.2239])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[ 0.1393,  0.2747],\n",
      "         [-0.5176, -0.5423],\n",
      "         [-0.2722,  0.5530],\n",
      "         [-0.4417, -0.1892],\n",
      "         [-0.3533,  0.0859],\n",
      "         [ 0.3505,  0.1545],\n",
      "         [ 0.2542, -0.6413],\n",
      "         [-0.5659,  0.7686]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.5498, -0.1538],\n",
      "        [ 0.5069,  0.2513],\n",
      "        [-0.1292,  0.3487],\n",
      "        [ 0.4946, -0.1707],\n",
      "        [ 0.4620,  0.4480],\n",
      "        [-0.2585, -0.4966],\n",
      "        [ 0.3748, -0.5603],\n",
      "        [-0.2476,  0.5008],\n",
      "        [-0.1298,  0.2858],\n",
      "        [ 0.3996, -0.5491],\n",
      "        [ 0.3954,  0.3691],\n",
      "        [-0.3818,  0.2450],\n",
      "        [-0.5346,  0.0832],\n",
      "        [ 0.3659,  0.1049],\n",
      "        [ 0.1175,  0.5021],\n",
      "        [ 0.0510,  0.4696]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.2610,  0.0743, -0.3784,  0.3902, -0.1284,  0.5964, -0.2784,  0.3515,\n",
      "         0.6611, -0.1916, -0.5944,  0.2718, -0.6457,  0.4944,  0.6373, -0.5221])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[-0.5754,  0.3850],\n",
      "        [-0.2260, -0.5282],\n",
      "        [-0.5670,  0.0668],\n",
      "        [-0.5302, -0.1354],\n",
      "        [-0.2665,  0.0201],\n",
      "        [ 0.3914,  0.5518],\n",
      "        [-0.0025, -0.0760],\n",
      "        [ 0.3800,  0.5635],\n",
      "        [ 0.4936,  0.0191],\n",
      "        [ 0.5337, -0.1706],\n",
      "        [-0.5210, -0.2458],\n",
      "        [ 0.4569,  0.4431],\n",
      "        [ 0.4749, -0.3793],\n",
      "        [ 0.4902,  0.2144],\n",
      "        [-0.4622, -0.0267],\n",
      "        [ 0.5608, -0.0246]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([-0.6062,  0.4779,  0.2400,  0.2621,  0.6466, -0.5172,  0.2054,  0.6920,\n",
      "        -0.6851,  0.3426,  0.0944, -0.4983, -0.5258,  0.4243, -0.1824,  0.1155])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.4876],\n",
      "        [ 0.2543],\n",
      "        [ 0.0584],\n",
      "        [ 0.4937],\n",
      "        [ 0.0209],\n",
      "        [ 0.3464],\n",
      "        [-0.2338],\n",
      "        [-0.0220],\n",
      "        [-0.2600],\n",
      "        [-0.5699],\n",
      "        [ 0.2420],\n",
      "        [-0.4233],\n",
      "        [ 0.4955],\n",
      "        [-0.3438],\n",
      "        [ 0.5132],\n",
      "        [ 0.5272]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.7255, -0.5257],\n",
      "         [-0.4851,  0.6959],\n",
      "         [-0.7051, -0.5405],\n",
      "         [ 0.1783, -0.4688],\n",
      "         [-0.4715, -0.0973],\n",
      "         [-0.4243,  0.7224],\n",
      "         [ 0.0214, -0.7254],\n",
      "         [-0.2177, -0.2942]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.0697,  0.0931],\n",
      "        [ 0.2472,  0.0224],\n",
      "        [-0.5510,  0.2885],\n",
      "        [-0.1468,  0.3947],\n",
      "        [ 0.3622,  0.1763],\n",
      "        [ 0.2097, -0.0388],\n",
      "        [ 0.4139,  0.2078],\n",
      "        [ 0.1067,  0.3280],\n",
      "        [-0.0418, -0.1097],\n",
      "        [-0.1564, -0.3070],\n",
      "        [-0.0464,  0.1918],\n",
      "        [-0.5623,  0.3779],\n",
      "        [-0.3171,  0.4701],\n",
      "        [-0.5030,  0.0634],\n",
      "        [-0.4681, -0.5644],\n",
      "        [ 0.0149,  0.2888]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.0267, -0.1416, -0.4261, -0.0417,  0.6551,  0.6213,  0.3822, -0.4620,\n",
      "         0.4755,  0.7036,  0.1096,  0.0247, -0.5233, -0.4579, -0.3345, -0.5855])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.1616,  0.3647],\n",
      "        [-0.1790,  0.1739],\n",
      "        [-0.3465,  0.4754],\n",
      "        [ 0.4130, -0.1391],\n",
      "        [-0.1764, -0.2807],\n",
      "        [ 0.2819,  0.4222],\n",
      "        [ 0.0104,  0.5489],\n",
      "        [-0.3279, -0.4720],\n",
      "        [-0.4336,  0.2059],\n",
      "        [-0.0137,  0.1097],\n",
      "        [-0.5249, -0.1993],\n",
      "        [-0.2200, -0.5753],\n",
      "        [ 0.4726, -0.0697],\n",
      "        [-0.4704,  0.5514],\n",
      "        [ 0.3843, -0.2866],\n",
      "        [-0.0238, -0.2754]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([ 0.3537, -0.2213, -0.6720,  0.4619,  0.6822, -0.5538, -0.1585, -0.5773,\n",
      "         0.5580, -0.0548, -0.0017, -0.3788, -0.7056,  0.2133,  0.1168, -0.5287])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[ 0.5659],\n",
      "        [ 0.0949],\n",
      "        [ 0.2362],\n",
      "        [ 0.1047],\n",
      "        [-0.2561],\n",
      "        [ 0.4159],\n",
      "        [ 0.5886],\n",
      "        [ 0.3098],\n",
      "        [ 0.5033],\n",
      "        [ 0.5076],\n",
      "        [ 0.3205],\n",
      "        [-0.1778],\n",
      "        [ 0.5557],\n",
      "        [ 0.3097],\n",
      "        [ 0.4650],\n",
      "        [-0.2402]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[ 0.4336,  0.0685],\n",
      "         [-0.3797, -0.5602],\n",
      "         [ 0.3742, -0.7398],\n",
      "         [ 0.7618,  0.1429],\n",
      "         [ 0.1907,  0.3746],\n",
      "         [ 0.1525,  0.6044],\n",
      "         [ 0.4095,  0.3985],\n",
      "         [ 0.3371, -0.1628]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.3284,  0.2820],\n",
      "        [ 0.2509,  0.5238],\n",
      "        [-0.1176, -0.2105],\n",
      "        [ 0.3488, -0.3179],\n",
      "        [ 0.2127, -0.3779],\n",
      "        [ 0.1899, -0.1329],\n",
      "        [-0.3286,  0.3674],\n",
      "        [ 0.5707, -0.2868],\n",
      "        [ 0.1680, -0.4641],\n",
      "        [-0.0578, -0.1146],\n",
      "        [ 0.3093,  0.1744],\n",
      "        [ 0.0373, -0.1488],\n",
      "        [-0.2811,  0.5216],\n",
      "        [-0.5596,  0.4527],\n",
      "        [-0.3542,  0.1026],\n",
      "        [ 0.1567, -0.2256]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.5379, -0.5051,  0.1606, -0.5388, -0.7013, -0.1291, -0.1549, -0.5292,\n",
      "         0.1272,  0.3622,  0.2046,  0.0851,  0.2451,  0.0659, -0.2804,  0.1050])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4767,  0.3908],\n",
      "        [-0.0324, -0.0044],\n",
      "        [-0.3632, -0.3258],\n",
      "        [ 0.1022, -0.0051],\n",
      "        [-0.4893, -0.5420],\n",
      "        [-0.2084, -0.1100],\n",
      "        [ 0.0483,  0.0198],\n",
      "        [ 0.1671, -0.2885],\n",
      "        [-0.4059,  0.1975],\n",
      "        [ 0.0501, -0.2813],\n",
      "        [ 0.5744,  0.3335],\n",
      "        [ 0.1340,  0.3373],\n",
      "        [ 0.3126,  0.2883],\n",
      "        [-0.5594,  0.5769],\n",
      "        [-0.5755, -0.0081],\n",
      "        [ 0.4861,  0.0585]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([-0.2508, -0.3825,  0.6427, -0.1424, -0.1368, -0.3809, -0.0123,  0.4039,\n",
      "         0.6212, -0.3010,  0.1647, -0.3800,  0.3956, -0.0217, -0.1814,  0.6328])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[ 1.5253e-04],\n",
      "        [ 8.4086e-02],\n",
      "        [ 1.3160e-01],\n",
      "        [ 3.3861e-01],\n",
      "        [ 4.3957e-01],\n",
      "        [-3.5326e-01],\n",
      "        [ 2.0101e-01],\n",
      "        [ 3.5744e-01],\n",
      "        [-2.0052e-01],\n",
      "        [-5.1481e-01],\n",
      "        [-4.8570e-01],\n",
      "        [-1.6561e-01],\n",
      "        [-5.2420e-01],\n",
      "        [ 2.8489e-01],\n",
      "        [-3.6551e-01],\n",
      "        [-4.9963e-01]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[ 0.6711, -0.1082],\n",
      "         [-0.2006, -0.0134],\n",
      "         [ 0.5792,  0.5302],\n",
      "         [-0.3282, -0.5806],\n",
      "         [ 0.2280,  0.5543],\n",
      "         [-0.7126,  0.7588],\n",
      "         [-0.4687,  0.6230],\n",
      "         [ 0.6700,  0.5367]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.2733,  0.3220],\n",
      "        [-0.4823, -0.4254],\n",
      "        [-0.5159,  0.2810],\n",
      "        [-0.1638, -0.4670],\n",
      "        [-0.5410,  0.0652],\n",
      "        [ 0.2010,  0.0278],\n",
      "        [ 0.3391,  0.1627],\n",
      "        [ 0.5731, -0.2069],\n",
      "        [-0.2492, -0.5700],\n",
      "        [-0.1157,  0.0369],\n",
      "        [-0.0521, -0.5592],\n",
      "        [ 0.2806, -0.0714],\n",
      "        [ 0.3930, -0.1625],\n",
      "        [ 0.1128,  0.0407],\n",
      "        [-0.3120, -0.2017],\n",
      "        [ 0.2303,  0.3750]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([ 0.4194, -0.5568,  0.2699, -0.2415,  0.6648,  0.1347,  0.5596,  0.2841,\n",
      "        -0.2268, -0.5531,  0.5202, -0.6590,  0.1538,  0.3611,  0.6176,  0.6330])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-0.4193,  0.4443],\n",
      "        [-0.3372,  0.4352],\n",
      "        [-0.0819, -0.1298],\n",
      "        [ 0.3636, -0.3985],\n",
      "        [-0.0932,  0.4158],\n",
      "        [-0.5343, -0.0191],\n",
      "        [-0.4954, -0.2959],\n",
      "        [ 0.2798, -0.1118],\n",
      "        [-0.4399, -0.4425],\n",
      "        [ 0.4126,  0.1821],\n",
      "        [-0.0916,  0.5327],\n",
      "        [ 0.3498, -0.5195],\n",
      "        [-0.0134, -0.1212],\n",
      "        [-0.1040, -0.5610],\n",
      "        [ 0.4015,  0.2260],\n",
      "        [-0.4951,  0.4170]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([-0.0305, -0.2249,  0.0724, -0.6204, -0.5277, -0.5341, -0.4195, -0.3051,\n",
      "         0.4624,  0.3206,  0.2647,  0.3841, -0.4248, -0.4721, -0.2626,  0.0654])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.5739],\n",
      "        [ 0.3835],\n",
      "        [ 0.0187],\n",
      "        [-0.3464],\n",
      "        [ 0.0745],\n",
      "        [-0.2202],\n",
      "        [ 0.0291],\n",
      "        [-0.3667],\n",
      "        [-0.1135],\n",
      "        [ 0.2656],\n",
      "        [-0.0951],\n",
      "        [ 0.3067],\n",
      "        [-0.0801],\n",
      "        [ 0.5317],\n",
      "        [-0.1844],\n",
      "        [-0.0253]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[-0.5323, -0.3251],\n",
      "         [ 0.5153,  0.1537],\n",
      "         [-0.5446, -0.6885],\n",
      "         [-0.5770,  0.1144],\n",
      "         [ 0.1010,  0.4822],\n",
      "         [ 0.6236,  0.5775],\n",
      "         [ 0.3555, -0.1263],\n",
      "         [-0.1925,  0.0906]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[-0.1809, -0.0562],\n",
      "        [ 0.2262,  0.3447],\n",
      "        [-0.1454, -0.5530],\n",
      "        [-0.4777, -0.0394],\n",
      "        [-0.1968,  0.0710],\n",
      "        [ 0.2120, -0.2599],\n",
      "        [-0.3172, -0.4445],\n",
      "        [ 0.1277, -0.5708],\n",
      "        [-0.2346,  0.2559],\n",
      "        [ 0.1162,  0.3792],\n",
      "        [ 0.5271,  0.5389],\n",
      "        [-0.2116,  0.2644],\n",
      "        [ 0.3026,  0.3405],\n",
      "        [ 0.4450,  0.1194],\n",
      "        [-0.2452, -0.1633],\n",
      "        [ 0.0877,  0.5549]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([ 0.2443, -0.5032, -0.3362,  0.0612,  0.0370,  0.2122, -0.5563, -0.0540,\n",
      "        -0.0271,  0.3462,  0.0465, -0.2932,  0.2395, -0.5554, -0.4718,  0.1566])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.3354, -0.1462],\n",
      "        [ 0.0614,  0.3611],\n",
      "        [ 0.4672,  0.0539],\n",
      "        [ 0.0514, -0.2131],\n",
      "        [ 0.5128, -0.4740],\n",
      "        [-0.4196,  0.1310],\n",
      "        [ 0.5276,  0.4984],\n",
      "        [ 0.5480, -0.0990],\n",
      "        [ 0.3829,  0.3711],\n",
      "        [-0.0050,  0.2463],\n",
      "        [ 0.3655,  0.2264],\n",
      "        [ 0.0183, -0.4729],\n",
      "        [ 0.1472, -0.0087],\n",
      "        [-0.1244, -0.0096],\n",
      "        [-0.2379,  0.4168],\n",
      "        [ 0.0510, -0.4297]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([ 0.6199,  0.6233, -0.1953, -0.2202,  0.2418,  0.5919, -0.3287, -0.2141,\n",
      "        -0.2753, -0.6265, -0.5103, -0.5475,  0.7007, -0.3251,  0.4705, -0.6412])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.5056],\n",
      "        [ 0.3348],\n",
      "        [-0.2095],\n",
      "        [ 0.0314],\n",
      "        [ 0.5723],\n",
      "        [ 0.1265],\n",
      "        [ 0.5483],\n",
      "        [ 0.5560],\n",
      "        [ 0.2079],\n",
      "        [ 0.0439],\n",
      "        [-0.2522],\n",
      "        [-0.3003],\n",
      "        [ 0.4728],\n",
      "        [-0.5394],\n",
      "        [-0.4179],\n",
      "        [ 0.3486]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[-0.6334, -0.3999],\n",
      "         [-0.7262,  0.4788],\n",
      "         [-0.0380, -0.7492],\n",
      "         [ 0.3251, -0.3997],\n",
      "         [ 0.1294,  0.0099],\n",
      "         [ 0.2635, -0.2234],\n",
      "         [ 0.0447, -0.5856],\n",
      "         [ 0.4085,  0.6600]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.0781, -0.5557],\n",
      "        [ 0.1690,  0.0092],\n",
      "        [ 0.2915, -0.3443],\n",
      "        [ 0.4446, -0.0554],\n",
      "        [-0.0633, -0.3738],\n",
      "        [-0.1920,  0.5118],\n",
      "        [-0.1761,  0.3078],\n",
      "        [-0.3551, -0.5579],\n",
      "        [ 0.4098, -0.2545],\n",
      "        [-0.1925,  0.4696],\n",
      "        [ 0.3004, -0.5615],\n",
      "        [ 0.2521, -0.3382],\n",
      "        [ 0.4913, -0.3525],\n",
      "        [-0.0950, -0.4158],\n",
      "        [-0.5374, -0.1855],\n",
      "        [ 0.3202,  0.4836]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.3467, -0.5645,  0.5597,  0.0349, -0.1096,  0.0560,  0.2513, -0.5980,\n",
      "         0.1215, -0.5566, -0.4869,  0.3992, -0.6570, -0.4537,  0.1836, -0.6559])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.3775, -0.1263],\n",
      "        [-0.5364,  0.5575],\n",
      "        [ 0.1788,  0.5474],\n",
      "        [-0.5430,  0.2379],\n",
      "        [-0.5500,  0.1106],\n",
      "        [ 0.4459, -0.4647],\n",
      "        [-0.2224,  0.1454],\n",
      "        [-0.3311, -0.2254],\n",
      "        [-0.3656,  0.5703],\n",
      "        [ 0.0798,  0.3998],\n",
      "        [ 0.0848, -0.4758],\n",
      "        [-0.3160, -0.2909],\n",
      "        [ 0.4923, -0.3462],\n",
      "        [-0.4088,  0.0420],\n",
      "        [-0.3578,  0.2698],\n",
      "        [-0.1612,  0.2817]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([ 0.0600, -0.6916, -0.3534,  0.1866,  0.3741, -0.4645,  0.4777, -0.1677,\n",
      "         0.0327,  0.4721, -0.2835, -0.2524,  0.1745,  0.6977,  0.1681,  0.6098])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.0111],\n",
      "        [-0.2416],\n",
      "        [ 0.0759],\n",
      "        [-0.4943],\n",
      "        [-0.1707],\n",
      "        [ 0.2476],\n",
      "        [-0.3312],\n",
      "        [ 0.3584],\n",
      "        [ 0.0296],\n",
      "        [-0.4877],\n",
      "        [ 0.4730],\n",
      "        [ 0.2641],\n",
      "        [-0.5897],\n",
      "        [ 0.2253],\n",
      "        [ 0.0274],\n",
      "        [-0.1242]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.3068,  0.0589,  0.0485, -0.3847, -0.2539, -0.0323],\n",
      "        [-0.1433,  0.2027, -0.2680, -0.1653,  0.2488,  0.3773],\n",
      "        [ 0.1245,  0.2250, -0.1455, -0.2873, -0.3446,  0.1250],\n",
      "        [ 0.3235,  0.3735, -0.2686,  0.3273,  0.1007, -0.0134]])), ('lin1.bias', tensor([-0.2244, -0.3042, -0.2610,  0.2541])), ('lin2.weight', tensor([[ 0.0941, -0.4091,  0.2512, -0.2293],\n",
      "        [ 0.0881, -0.3363, -0.0651,  0.4542],\n",
      "        [ 0.0251,  0.4587,  0.3038, -0.3096]])), ('lin2.bias', tensor([ 0.2598, -0.2703,  0.4144])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.att', tensor([[[-0.2768, -0.6540],\n",
      "         [ 0.5075,  0.6671],\n",
      "         [-0.7037, -0.7081],\n",
      "         [-0.5656, -0.4043],\n",
      "         [-0.4006,  0.2189],\n",
      "         [-0.4630, -0.0304],\n",
      "         [ 0.0293, -0.5021],\n",
      "         [-0.3583,  0.7282]]])), ('convs.0.convs.0.conv.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[-0.2069,  0.2488],\n",
      "        [-0.0174, -0.3471],\n",
      "        [-0.5660, -0.0501],\n",
      "        [-0.4380, -0.4690],\n",
      "        [ 0.3812, -0.2462],\n",
      "        [-0.0264, -0.4652],\n",
      "        [-0.0734,  0.3424],\n",
      "        [ 0.1330,  0.1066],\n",
      "        [ 0.4647, -0.4542],\n",
      "        [-0.1934, -0.1227],\n",
      "        [ 0.5655,  0.5384],\n",
      "        [-0.5136,  0.2894],\n",
      "        [-0.2546, -0.2826],\n",
      "        [ 0.2353, -0.5041],\n",
      "        [-0.1363, -0.1420],\n",
      "        [-0.0242,  0.4963]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([-0.0820,  0.2123, -0.1398, -0.5763, -0.1774, -0.3227,  0.2910,  0.1348,\n",
      "        -0.3463, -0.3762, -0.0804,  0.3177,  0.2343, -0.0732, -0.2789,  0.4207])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.0733,  0.2075],\n",
      "        [-0.3927,  0.3644],\n",
      "        [-0.4830,  0.5225],\n",
      "        [ 0.0337,  0.4835],\n",
      "        [ 0.5585, -0.5206],\n",
      "        [-0.3539,  0.2864],\n",
      "        [ 0.0534, -0.1104],\n",
      "        [ 0.0601, -0.5349],\n",
      "        [-0.5210, -0.4819],\n",
      "        [ 0.3540,  0.1530],\n",
      "        [ 0.3293,  0.1283],\n",
      "        [-0.2768,  0.0872],\n",
      "        [ 0.2229,  0.4739],\n",
      "        [ 0.2970, -0.4703],\n",
      "        [ 0.4133, -0.4904],\n",
      "        [ 0.0985, -0.1509]])), ('convs.0.convs.0.conv.lin_r.bias', tensor([-0.5517, -0.0565, -0.0645,  0.5801, -0.6113,  0.4869, -0.5101, -0.0422,\n",
      "         0.4355, -0.6581, -0.6662, -0.1843,  0.5753, -0.2941,  0.2782, -0.3117])), ('convs.0.convs.0.conv.lin_edge.weight', tensor([[-0.4526],\n",
      "        [-0.4365],\n",
      "        [ 0.4322],\n",
      "        [-0.0543],\n",
      "        [ 0.2112],\n",
      "        [-0.1270],\n",
      "        [-0.0041],\n",
      "        [ 0.2127],\n",
      "        [-0.4278],\n",
      "        [-0.2588],\n",
      "        [ 0.0942],\n",
      "        [-0.5901],\n",
      "        [ 0.0943],\n",
      "        [ 0.4815],\n",
      "        [ 0.5164],\n",
      "        [-0.1972]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.att', tensor([[[ 0.0963,  0.1856],\n",
      "         [-0.4371, -0.6088],\n",
      "         [-0.0035,  0.5699],\n",
      "         [-0.4598, -0.4169],\n",
      "         [ 0.1420,  0.6392],\n",
      "         [-0.7623,  0.2573],\n",
      "         [ 0.2988,  0.6839],\n",
      "         [-0.4506,  0.4911]]])), ('convs.0.convs.1.conv.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.4589,  0.2293],\n",
      "        [-0.4556, -0.0252],\n",
      "        [ 0.3119, -0.3674],\n",
      "        [ 0.4898,  0.5111],\n",
      "        [-0.3795,  0.5216],\n",
      "        [ 0.1416, -0.2221],\n",
      "        [-0.4573, -0.3275],\n",
      "        [-0.0543,  0.2606],\n",
      "        [-0.2548,  0.0078],\n",
      "        [-0.4759, -0.5260],\n",
      "        [-0.5336,  0.4030],\n",
      "        [ 0.2779,  0.1897],\n",
      "        [ 0.1945, -0.4290],\n",
      "        [-0.3593, -0.3557],\n",
      "        [ 0.5362, -0.3579],\n",
      "        [ 0.4966,  0.1002]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([ 0.7063, -0.2534, -0.6035,  0.1445, -0.5157, -0.3711, -0.0791,  0.2745,\n",
      "        -0.4890, -0.3041,  0.5152,  0.6795,  0.4054, -0.5104,  0.6395,  0.5653])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[-0.5115,  0.2950],\n",
      "        [-0.1293, -0.2907],\n",
      "        [ 0.5339,  0.5260],\n",
      "        [ 0.4498, -0.0092],\n",
      "        [ 0.3141,  0.2711],\n",
      "        [-0.4862, -0.4821],\n",
      "        [-0.4090, -0.5308],\n",
      "        [-0.5067,  0.0783],\n",
      "        [-0.0908,  0.1584],\n",
      "        [ 0.3168, -0.2186],\n",
      "        [ 0.4006,  0.1036],\n",
      "        [ 0.5557,  0.4512],\n",
      "        [-0.3894,  0.4157],\n",
      "        [ 0.0075,  0.0601],\n",
      "        [-0.1332,  0.3375],\n",
      "        [ 0.3656,  0.2547]])), ('convs.0.convs.1.conv.lin_r.bias', tensor([-0.1005,  0.2290,  0.0897, -0.0934,  0.5834,  0.4439,  0.5221, -0.0322,\n",
      "        -0.2920, -0.1361, -0.0723, -0.1107,  0.2051, -0.0985, -0.1019, -0.1342])), ('convs.0.convs.1.conv.lin_edge.weight', tensor([[ 0.3882],\n",
      "        [-0.5147],\n",
      "        [-0.4988],\n",
      "        [ 0.3515],\n",
      "        [ 0.0937],\n",
      "        [ 0.2161],\n",
      "        [ 0.3253],\n",
      "        [ 0.0207],\n",
      "        [ 0.4605],\n",
      "        [ 0.3971],\n",
      "        [-0.4594],\n",
      "        [ 0.4816],\n",
      "        [ 0.3190],\n",
      "        [-0.4242],\n",
      "        [-0.0464],\n",
      "        [-0.1515]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.att', tensor([[[-0.1587, -0.5650],\n",
      "         [-0.5181, -0.5930],\n",
      "         [ 0.5221,  0.3797],\n",
      "         [ 0.0535, -0.5302],\n",
      "         [-0.7456, -0.2567],\n",
      "         [-0.6409, -0.6913],\n",
      "         [-0.3258, -0.3577],\n",
      "         [-0.4099, -0.2937]]])), ('convs.1.convs.0.conv.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.2473, -0.4930],\n",
      "        [ 0.3984, -0.1487],\n",
      "        [-0.4708,  0.1904],\n",
      "        [ 0.3662, -0.5278],\n",
      "        [ 0.5446,  0.0223],\n",
      "        [ 0.3078, -0.1578],\n",
      "        [-0.3457,  0.4837],\n",
      "        [-0.3449,  0.5573],\n",
      "        [-0.1503, -0.0343],\n",
      "        [-0.2176,  0.5131],\n",
      "        [ 0.5556,  0.1248],\n",
      "        [-0.4485, -0.5379],\n",
      "        [-0.5437, -0.3185],\n",
      "        [-0.4914,  0.1351],\n",
      "        [ 0.0675,  0.1092],\n",
      "        [-0.4982, -0.2294]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([-0.3774, -0.1208,  0.0570,  0.0604, -0.0647,  0.1191,  0.4720, -0.4167,\n",
      "        -0.4982,  0.3374,  0.5216,  0.6714,  0.2746,  0.6443,  0.1353, -0.3978])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.4823, -0.3608],\n",
      "        [ 0.2411,  0.2713],\n",
      "        [ 0.2058, -0.4548],\n",
      "        [-0.5023, -0.0054],\n",
      "        [-0.4694,  0.3301],\n",
      "        [ 0.4907,  0.4533],\n",
      "        [ 0.4776,  0.3136],\n",
      "        [ 0.5065, -0.0318],\n",
      "        [ 0.0935,  0.3919],\n",
      "        [-0.1015, -0.1438],\n",
      "        [-0.1028,  0.1561],\n",
      "        [-0.1108,  0.5466],\n",
      "        [-0.0935, -0.2763],\n",
      "        [-0.4236, -0.3160],\n",
      "        [ 0.0867,  0.2073],\n",
      "        [ 0.4071,  0.3618]])), ('convs.1.convs.0.conv.lin_r.bias', tensor([ 0.0815, -0.6161,  0.6873,  0.6116, -0.2703, -0.4015,  0.1455, -0.4794,\n",
      "         0.6414,  0.5414, -0.5200,  0.3492, -0.0236, -0.6990, -0.0552, -0.5271])), ('convs.1.convs.0.conv.lin_edge.weight', tensor([[-0.4506],\n",
      "        [ 0.5934],\n",
      "        [ 0.5263],\n",
      "        [-0.5354],\n",
      "        [ 0.2415],\n",
      "        [-0.0983],\n",
      "        [ 0.3998],\n",
      "        [-0.3803],\n",
      "        [ 0.5670],\n",
      "        [ 0.3804],\n",
      "        [ 0.4056],\n",
      "        [-0.2385],\n",
      "        [-0.3703],\n",
      "        [-0.1175],\n",
      "        [-0.4168],\n",
      "        [-0.2308]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.att', tensor([[[-0.5442, -0.5150],\n",
      "         [-0.2734,  0.5966],\n",
      "         [-0.3033,  0.2305],\n",
      "         [-0.5090, -0.4078],\n",
      "         [ 0.1013, -0.1307],\n",
      "         [-0.0041, -0.1208],\n",
      "         [ 0.2673, -0.5190],\n",
      "         [-0.1743,  0.5808]]])), ('convs.1.convs.1.conv.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.0816, -0.3004],\n",
      "        [ 0.4735, -0.3894],\n",
      "        [-0.0849, -0.0661],\n",
      "        [-0.5572, -0.0710],\n",
      "        [-0.2438, -0.5416],\n",
      "        [-0.4809, -0.3530],\n",
      "        [-0.2228, -0.3762],\n",
      "        [-0.1955,  0.3356],\n",
      "        [ 0.3218, -0.2228],\n",
      "        [-0.0933, -0.0079],\n",
      "        [ 0.2719,  0.2141],\n",
      "        [ 0.5400, -0.3934],\n",
      "        [-0.1070, -0.5551],\n",
      "        [-0.1657, -0.0540],\n",
      "        [ 0.3155, -0.2211],\n",
      "        [-0.1109, -0.3054]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([ 0.1952,  0.3202, -0.0293, -0.3942, -0.2941, -0.2945,  0.6052, -0.5890,\n",
      "         0.3188, -0.4771,  0.6781, -0.2430,  0.3314,  0.1400,  0.6760,  0.0911])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.2019, -0.0304],\n",
      "        [-0.2394,  0.4563],\n",
      "        [-0.4459,  0.4822],\n",
      "        [-0.0776,  0.2828],\n",
      "        [-0.1022, -0.0450],\n",
      "        [ 0.2343, -0.3456],\n",
      "        [ 0.4119, -0.5448],\n",
      "        [ 0.5180,  0.1752],\n",
      "        [-0.1934, -0.0211],\n",
      "        [ 0.0455, -0.5567],\n",
      "        [ 0.0850, -0.2354],\n",
      "        [ 0.3583, -0.0282],\n",
      "        [-0.1587,  0.5638],\n",
      "        [-0.2037, -0.1875],\n",
      "        [-0.5196, -0.4773],\n",
      "        [-0.1871, -0.4141]])), ('convs.1.convs.1.conv.lin_r.bias', tensor([ 0.3115,  0.2190,  0.2406,  0.0086, -0.0182, -0.6175,  0.6676,  0.5673,\n",
      "        -0.2907, -0.0124,  0.3834, -0.1400, -0.6092,  0.5860, -0.1100,  0.0544])), ('convs.1.convs.1.conv.lin_edge.weight', tensor([[-0.4400],\n",
      "        [ 0.0794],\n",
      "        [ 0.5032],\n",
      "        [-0.2128],\n",
      "        [ 0.2322],\n",
      "        [ 0.2403],\n",
      "        [-0.1293],\n",
      "        [ 0.2180],\n",
      "        [-0.5760],\n",
      "        [ 0.5913],\n",
      "        [ 0.0200],\n",
      "        [ 0.4967],\n",
      "        [-0.4005],\n",
      "        [-0.4179],\n",
      "        [ 0.1777],\n",
      "        [-0.4841]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.att', tensor([[[ 0.5968,  0.3160],\n",
      "         [-0.2640, -0.3246],\n",
      "         [-0.4402, -0.3196],\n",
      "         [-0.2527, -0.5609],\n",
      "         [ 0.6976,  0.0540],\n",
      "         [ 0.3489, -0.6638],\n",
      "         [-0.6394, -0.4376],\n",
      "         [-0.2194, -0.6624]]])), ('convs.2.convs.0.conv.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 4.2546e-01,  1.9456e-01],\n",
      "        [-1.1623e-01, -4.3876e-01],\n",
      "        [ 5.7602e-01,  4.4163e-01],\n",
      "        [ 2.5691e-01, -5.5048e-01],\n",
      "        [ 3.5440e-01, -5.6441e-01],\n",
      "        [-2.3621e-02, -4.3352e-01],\n",
      "        [ 3.7816e-01, -5.7229e-01],\n",
      "        [ 4.9604e-02, -4.7165e-01],\n",
      "        [-4.5662e-01,  2.9483e-01],\n",
      "        [ 3.2547e-01, -1.6630e-03],\n",
      "        [-4.2323e-01,  6.0108e-02],\n",
      "        [ 4.2193e-01, -5.0073e-01],\n",
      "        [-3.4148e-01, -3.8781e-01],\n",
      "        [-1.9043e-02, -3.8060e-01],\n",
      "        [ 3.2938e-01,  4.0612e-01],\n",
      "        [-3.1763e-04,  2.4483e-01]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.0248, -0.2238, -0.4008,  0.5462, -0.5306, -0.6846, -0.0885,  0.0755,\n",
      "        -0.6799,  0.1757,  0.5258, -0.3215,  0.5559, -0.1353, -0.0215, -0.6363])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[ 0.4427,  0.4430],\n",
      "        [ 0.2451, -0.5012],\n",
      "        [-0.1145, -0.2010],\n",
      "        [ 0.1313,  0.4863],\n",
      "        [ 0.5699, -0.3404],\n",
      "        [ 0.4717, -0.2635],\n",
      "        [ 0.4786,  0.4045],\n",
      "        [ 0.3899,  0.4570],\n",
      "        [-0.5462,  0.2486],\n",
      "        [ 0.3961, -0.4682],\n",
      "        [ 0.2189,  0.2488],\n",
      "        [-0.0941,  0.2784],\n",
      "        [ 0.4460, -0.5266],\n",
      "        [ 0.1027,  0.1255],\n",
      "        [-0.0675,  0.4702],\n",
      "        [-0.5143, -0.2818]])), ('convs.2.convs.0.conv.lin_r.bias', tensor([-0.5194,  0.6153,  0.0712,  0.0785, -0.0608, -0.5557,  0.6481, -0.2167,\n",
      "        -0.0490, -0.0111, -0.2560,  0.5716, -0.2599,  0.5866,  0.2347,  0.1591])), ('convs.2.convs.0.conv.lin_edge.weight', tensor([[-0.5237],\n",
      "        [ 0.0188],\n",
      "        [ 0.2148],\n",
      "        [-0.0914],\n",
      "        [-0.1709],\n",
      "        [-0.4723],\n",
      "        [ 0.5061],\n",
      "        [-0.1947],\n",
      "        [ 0.4283],\n",
      "        [ 0.0346],\n",
      "        [-0.0891],\n",
      "        [ 0.2167],\n",
      "        [-0.5905],\n",
      "        [-0.3143],\n",
      "        [-0.5808],\n",
      "        [ 0.0696]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.att', tensor([[[-0.5346,  0.1147],\n",
      "         [-0.0248, -0.1866],\n",
      "         [ 0.5602, -0.1882],\n",
      "         [-0.1828, -0.0542],\n",
      "         [ 0.6187, -0.6374],\n",
      "         [ 0.7439,  0.7593],\n",
      "         [ 0.5308,  0.7016],\n",
      "         [ 0.0684,  0.6340]]])), ('convs.2.convs.1.conv.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.2656,  0.1500],\n",
      "        [-0.2625,  0.5636],\n",
      "        [ 0.3178,  0.2618],\n",
      "        [ 0.0103, -0.4851],\n",
      "        [ 0.5105,  0.0840],\n",
      "        [-0.5043, -0.5214],\n",
      "        [ 0.4017, -0.1804],\n",
      "        [-0.3955, -0.5226],\n",
      "        [-0.4612,  0.5612],\n",
      "        [ 0.0396,  0.2694],\n",
      "        [ 0.4455, -0.0580],\n",
      "        [-0.4643, -0.3167],\n",
      "        [ 0.3848, -0.0631],\n",
      "        [-0.0346, -0.3531],\n",
      "        [-0.3589, -0.4475],\n",
      "        [ 0.3233,  0.2891]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.6525,  0.5237, -0.0254, -0.4130,  0.6356, -0.1854, -0.4803,  0.6261,\n",
      "        -0.0224,  0.5017, -0.1301, -0.3794,  0.5871,  0.1785, -0.3664,  0.1327])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[ 0.3052,  0.4494],\n",
      "        [-0.4696,  0.2987],\n",
      "        [-0.0292, -0.3817],\n",
      "        [ 0.3955, -0.4988],\n",
      "        [ 0.1798, -0.5387],\n",
      "        [-0.3340,  0.4086],\n",
      "        [-0.0282, -0.2209],\n",
      "        [-0.5278, -0.1812],\n",
      "        [ 0.2735, -0.4354],\n",
      "        [ 0.4241,  0.3406],\n",
      "        [ 0.2377,  0.1681],\n",
      "        [ 0.1032, -0.2276],\n",
      "        [-0.3509, -0.5566],\n",
      "        [ 0.1934,  0.0937],\n",
      "        [-0.3835,  0.0234],\n",
      "        [-0.0079,  0.2338]])), ('convs.2.convs.1.conv.lin_r.bias', tensor([ 0.2755,  0.5385, -0.1506, -0.3214,  0.2174,  0.3578,  0.1015,  0.6884,\n",
      "         0.5600,  0.2922, -0.3039,  0.2204,  0.4721,  0.2314, -0.6743, -0.2724])), ('convs.2.convs.1.conv.lin_edge.weight', tensor([[-0.0249],\n",
      "        [-0.0716],\n",
      "        [ 0.0679],\n",
      "        [-0.0188],\n",
      "        [-0.5118],\n",
      "        [ 0.5075],\n",
      "        [-0.5767],\n",
      "        [ 0.1704],\n",
      "        [ 0.0532],\n",
      "        [-0.2623],\n",
      "        [ 0.2756],\n",
      "        [ 0.1723],\n",
      "        [ 0.5694],\n",
      "        [-0.1091],\n",
      "        [-0.2716],\n",
      "        [ 0.2617]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 3, 'dropout': 0.0, 'version': 'v2', 'edge_dim': 1, 'heads': 8, 'concat': False, 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevGATConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(GATConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GATv2Conv(2, 2, heads=8)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevGATConvEncoder: 2-1                                     --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       804\n",
      "│    └─RevGATConvEncoder: 2-2                                     --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       804\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 1,710\n",
      "Trainable params: 1,710\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.0477, 0.0943, 0.0477, 0.9879, 0.0943, 0.9879, 0.0048, 0.0621, 0.0048,\n",
      "        0.0621], grad_fn=<SigmoidBackward0>), tensor([[-0.0077,  0.3837,  0.0431],\n",
      "        [-0.1192,  0.4805, -0.0973],\n",
      "        [-0.0594,  0.4295, -0.0221],\n",
      "        [-0.0961,  0.4581, -0.0680],\n",
      "        [-0.1003,  0.4431, -0.0718]], grad_fn=<AddmmBackward0>), tensor([[ 0.0520,  0.8629, -0.5433],\n",
      "        [-0.0840,  0.7217, -0.3581],\n",
      "        [-0.1578,  0.4513, -0.3224],\n",
      "        [ 0.0068,  0.7711, -0.4832],\n",
      "        [-0.1483,  0.4229, -0.3455]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.5211, 0.0713, 0.5211, 0.4957, 0.0713, 0.4957, 0.4524, 0.2370, 0.4524,\n",
      "        0.2370], grad_fn=<SigmoidBackward0>), tensor([[-0.0077,  0.3837,  0.0431],\n",
      "        [-0.1192,  0.4805, -0.0973],\n",
      "        [-0.0594,  0.4295, -0.0221],\n",
      "        [-0.0961,  0.4581, -0.0680],\n",
      "        [-0.1003,  0.4431, -0.0718]], grad_fn=<AddmmBackward0>), tensor([[ 0.0520,  0.8629, -0.5433],\n",
      "        [-0.0840,  0.7217, -0.3581],\n",
      "        [-0.1578,  0.4513, -0.3224],\n",
      "        [ 0.0068,  0.7711, -0.4832],\n",
      "        [-0.1483,  0.4229, -0.3455]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.6969, 0.8070, 0.5542, 0.6874, 0.7110],\n",
      "        [0.8070, 1.0000, 0.9281, 0.9270, 1.0000],\n",
      "        [0.5542, 0.9281, 0.8573, 0.8035, 0.9840],\n",
      "        [0.6874, 0.9270, 0.8035, 0.8310, 0.9654],\n",
      "        [0.7110, 1.0000, 0.9840, 0.9654, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.9986, 0.9774, 0.0397, 0.0522, 0.9844],\n",
      "        [0.9774, 0.9832, 0.0054, 0.0665, 0.9508],\n",
      "        [0.0397, 0.0054, 0.9995, 0.9518, 0.0510],\n",
      "        [0.0522, 0.0665, 0.9518, 0.8840, 0.0888],\n",
      "        [0.9844, 0.9508, 0.0510, 0.0888, 0.9502]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[ 2.2039,  3.0646, -0.7071],\n",
      "        [-0.9405, -1.5986,  0.0055],\n",
      "        [-0.3795, -1.3403,  0.2755],\n",
      "        [-0.2838, -2.5329,  0.5690],\n",
      "        [-0.1192,  0.6906,  1.2555]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[ 0.5193,  0.3765,  0.3888],\n",
      "        [ 0.1906,  1.1094, -0.0454],\n",
      "        [ 0.2865,  1.6166, -0.9843],\n",
      "        [-1.6065,  2.4485, -0.1525],\n",
      "        [-0.4377,  0.4811,  0.4040]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.0077,  0.3837,  0.0431],\n",
      "        [-0.1192,  0.4805, -0.0973],\n",
      "        [-0.0594,  0.4295, -0.0221],\n",
      "        [-0.0961,  0.4581, -0.0680],\n",
      "        [-0.1003,  0.4431, -0.0718]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[ 0.0520,  0.8629, -0.5433],\n",
      "        [-0.0840,  0.7217, -0.3581],\n",
      "        [-0.1578,  0.4513, -0.3224],\n",
      "        [ 0.0068,  0.7711, -0.4832],\n",
      "        [-0.1483,  0.4229, -0.3455]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.0077,  0.3837,  0.0431],\n",
      "        [-0.1192,  0.4805, -0.0973],\n",
      "        [-0.0594,  0.4295, -0.0221],\n",
      "        [-0.0961,  0.4581, -0.0680],\n",
      "        [-0.1003,  0.4431, -0.0718]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[ 0.0520,  0.8629, -0.5433],\n",
      "        [-0.0840,  0.7217, -0.3581],\n",
      "        [-0.1578,  0.4513, -0.3224],\n",
      "        [ 0.0068,  0.7711, -0.4832],\n",
      "        [-0.1483,  0.4229, -0.3455]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.4759, 0.9714, 0.4759, 0.4804, 0.9714, 0.4804, 0.9594, 0.7899, 0.9594,\n",
      "        0.7899], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([7.3642e-01, 9.5114e-01, 7.3642e-01, 1.0000e+00, 9.5114e-01, 1.0000e+00,\n",
      "        2.3483e-05, 7.8266e-02, 2.3483e-05, 7.8266e-02],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.8779, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(6.8639, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.39999999999999997, 0.5768253968253969)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.6, 0.5926190476190476)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Reversible residual SAGE VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[-0.2069,  0.2229,  0.0383,  0.0180,  0.0883,  0.2456],\n",
      "        [-0.3949,  0.0344, -0.2330, -0.0659, -0.2363, -0.2055],\n",
      "        [-0.1614, -0.1606, -0.3862,  0.3437, -0.3458, -0.0019],\n",
      "        [-0.0784,  0.2087,  0.4053, -0.2976,  0.3410,  0.1618]])), ('_encoder_mu.lin1.bias', tensor([-0.2483,  0.1345,  0.3746,  0.0937])), ('_encoder_mu.lin2.weight', tensor([[ 0.4846, -0.0844, -0.2578, -0.3446],\n",
      "        [ 0.0149,  0.4080, -0.4526,  0.3784],\n",
      "        [-0.3600, -0.2582,  0.1504, -0.2708]])), ('_encoder_mu.lin2.bias', tensor([-0.2519,  0.2434,  0.1186])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.0.conv.lin.weight', tensor([[-0.2267,  0.6022],\n",
      "        [-0.0239, -0.6242]])), ('_encoder_mu.convs.0.convs.0.conv.lin.bias', tensor([-0.0164, -0.5859])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.1888,  0.3423],\n",
      "        [-0.3902, -0.2755]])), ('_encoder_mu.convs.0.convs.0.conv.lin_l.bias', tensor([ 0.6926, -0.2892])), ('_encoder_mu.convs.0.convs.0.conv.lin_r.weight', tensor([[-0.0860, -0.3561],\n",
      "        [ 0.5024, -0.4829]])), ('_encoder_mu.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.0.convs.1.conv.lin.weight', tensor([[-0.0564, -0.0684],\n",
      "        [ 0.3398,  0.4225]])), ('_encoder_mu.convs.0.convs.1.conv.lin.bias', tensor([0.3329, 0.0030])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.weight', tensor([[-0.3034, -0.5949],\n",
      "        [-0.3108, -0.4007]])), ('_encoder_mu.convs.0.convs.1.conv.lin_l.bias', tensor([-0.6313,  0.1179])), ('_encoder_mu.convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.4542, -0.5805],\n",
      "        [-0.6374,  0.1322]])), ('_encoder_mu.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.0.conv.lin.weight', tensor([[-0.2223, -0.0024],\n",
      "        [ 0.5252,  0.1772]])), ('_encoder_mu.convs.1.convs.0.conv.lin.bias', tensor([ 0.4300, -0.6146])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.1243,  0.0015],\n",
      "        [-0.3334, -0.0134]])), ('_encoder_mu.convs.1.convs.0.conv.lin_l.bias', tensor([ 0.2236, -0.0980])), ('_encoder_mu.convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.2621, -0.3204],\n",
      "        [-0.4315, -0.1549]])), ('_encoder_mu.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.1.convs.1.conv.lin.weight', tensor([[ 0.2514,  0.6689],\n",
      "        [ 0.2730, -0.0525]])), ('_encoder_mu.convs.1.convs.1.conv.lin.bias', tensor([-0.4456, -0.3050])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.weight', tensor([[-0.5756, -0.0405],\n",
      "        [ 0.6401,  0.0142]])), ('_encoder_mu.convs.1.convs.1.conv.lin_l.bias', tensor([-0.6854,  0.6192])), ('_encoder_mu.convs.1.convs.1.conv.lin_r.weight', tensor([[-1.1812e-01,  6.3304e-01],\n",
      "        [ 1.4208e-01,  5.4789e-04]])), ('_encoder_mu.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.0.conv.lin.weight', tensor([[-0.5506,  0.5808],\n",
      "        [ 0.4755, -0.1085]])), ('_encoder_mu.convs.2.convs.0.conv.lin.bias', tensor([ 0.6535, -0.6913])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.0458,  0.6219],\n",
      "        [-0.2181, -0.6882]])), ('_encoder_mu.convs.2.convs.0.conv.lin_l.bias', tensor([-0.3495, -0.2523])), ('_encoder_mu.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2491, -0.3502],\n",
      "        [ 0.5041, -0.6441]])), ('_encoder_mu.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.2.convs.1.conv.lin.weight', tensor([[ 0.3082,  0.0648],\n",
      "        [-0.6376, -0.5532]])), ('_encoder_mu.convs.2.convs.1.conv.lin.bias', tensor([ 0.5833, -0.1440])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.3444,  0.3145],\n",
      "        [-0.6138,  0.5859]])), ('_encoder_mu.convs.2.convs.1.conv.lin_l.bias', tensor([-0.1156,  0.4184])), ('_encoder_mu.convs.2.convs.1.conv.lin_r.weight', tensor([[-0.0198, -0.2733],\n",
      "        [ 0.6305, -0.5540]])), ('_encoder_mu.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.0.conv.lin.weight', tensor([[ 0.3593, -0.4489],\n",
      "        [-0.6007, -0.5099]])), ('_encoder_mu.convs.3.convs.0.conv.lin.bias', tensor([0.1263, 0.3657])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.weight', tensor([[-0.5746,  0.0189],\n",
      "        [ 0.0391,  0.0488]])), ('_encoder_mu.convs.3.convs.0.conv.lin_l.bias', tensor([ 0.2973, -0.1904])), ('_encoder_mu.convs.3.convs.0.conv.lin_r.weight', tensor([[-0.4705,  0.4192],\n",
      "        [ 0.5346,  0.7009]])), ('_encoder_mu.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_mu.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_mu.convs.3.convs.1.conv.lin.weight', tensor([[-0.6586,  0.3934],\n",
      "        [-0.4657, -0.5717]])), ('_encoder_mu.convs.3.convs.1.conv.lin.bias', tensor([ 0.2181, -0.4675])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.4174, -0.2520],\n",
      "        [-0.5828,  0.2882]])), ('_encoder_mu.convs.3.convs.1.conv.lin_l.bias', tensor([ 0.3432, -0.4348])), ('_encoder_mu.convs.3.convs.1.conv.lin_r.weight', tensor([[ 0.4427,  0.3356],\n",
      "        [-0.0147, -0.3548]])), ('_encoder_logstd.lin1.weight', tensor([[ 0.0054, -0.2031, -0.0314, -0.2394,  0.2686, -0.3836],\n",
      "        [-0.3950,  0.2310,  0.3105, -0.2955, -0.3816, -0.3703],\n",
      "        [ 0.0674, -0.2796,  0.2716, -0.2575,  0.1144,  0.3309],\n",
      "        [ 0.3514,  0.2478,  0.0679, -0.3832, -0.3897,  0.1669]])), ('_encoder_logstd.lin1.bias', tensor([-0.1543, -0.1334,  0.3143, -0.0931])), ('_encoder_logstd.lin2.weight', tensor([[ 0.2334, -0.2410,  0.3189,  0.4304],\n",
      "        [ 0.4109, -0.3183, -0.0542,  0.1895],\n",
      "        [-0.4163, -0.2093, -0.0465, -0.2016]])), ('_encoder_logstd.lin2.bias', tensor([ 0.0053, -0.4309,  0.4162])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.0.conv.lin.weight', tensor([[0.0146, 0.3763],\n",
      "        [0.5879, 0.3477]])), ('_encoder_logstd.convs.0.convs.0.conv.lin.bias', tensor([ 0.6043, -0.1345])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.4270, -0.4815],\n",
      "        [ 0.5028,  0.3402]])), ('_encoder_logstd.convs.0.convs.0.conv.lin_l.bias', tensor([ 0.4090, -0.5809])), ('_encoder_logstd.convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.1292, -0.2530],\n",
      "        [ 0.6851, -0.3919]])), ('_encoder_logstd.convs.0.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.0.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.0.convs.1.conv.lin.weight', tensor([[-0.6311,  0.4723],\n",
      "        [ 0.1573,  0.2110]])), ('_encoder_logstd.convs.0.convs.1.conv.lin.bias', tensor([0.4630, 0.5210])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.5912,  0.6443],\n",
      "        [-0.3678,  0.6832]])), ('_encoder_logstd.convs.0.convs.1.conv.lin_l.bias', tensor([-0.3827, -0.5202])), ('_encoder_logstd.convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.6105, -0.5760],\n",
      "        [ 0.1377,  0.1916]])), ('_encoder_logstd.convs.1.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.0.conv.lin.weight', tensor([[-0.6451,  0.4029],\n",
      "        [ 0.5793, -0.1449]])), ('_encoder_logstd.convs.1.convs.0.conv.lin.bias', tensor([-0.1196,  0.0143])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.weight', tensor([[-0.1171, -0.3016],\n",
      "        [-0.0097,  0.1460]])), ('_encoder_logstd.convs.1.convs.0.conv.lin_l.bias', tensor([ 0.2209, -0.0220])), ('_encoder_logstd.convs.1.convs.0.conv.lin_r.weight', tensor([[-0.5179,  0.5242],\n",
      "        [-0.5410, -0.1366]])), ('_encoder_logstd.convs.1.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.1.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.1.convs.1.conv.lin.weight', tensor([[-0.4015, -0.0603],\n",
      "        [ 0.3521, -0.0848]])), ('_encoder_logstd.convs.1.convs.1.conv.lin.bias', tensor([-0.5632, -0.3094])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.5423,  0.0747],\n",
      "        [-0.1920, -0.0082]])), ('_encoder_logstd.convs.1.convs.1.conv.lin_l.bias', tensor([-0.4665,  0.1602])), ('_encoder_logstd.convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.6889,  0.5639],\n",
      "        [-0.4929,  0.5890]])), ('_encoder_logstd.convs.2.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.0.conv.lin.weight', tensor([[-0.1197,  0.0832],\n",
      "        [ 0.6150,  0.5739]])), ('_encoder_logstd.convs.2.convs.0.conv.lin.bias', tensor([ 0.1049, -0.0532])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.4597,  0.1112],\n",
      "        [-0.2382,  0.1207]])), ('_encoder_logstd.convs.2.convs.0.conv.lin_l.bias', tensor([0.3543, 0.6268])), ('_encoder_logstd.convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2328,  0.3172],\n",
      "        [-0.1067,  0.0331]])), ('_encoder_logstd.convs.2.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.2.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.2.convs.1.conv.lin.weight', tensor([[-0.0647, -0.3672],\n",
      "        [-0.1592,  0.5463]])), ('_encoder_logstd.convs.2.convs.1.conv.lin.bias', tensor([-0.5875,  0.1702])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.weight', tensor([[-0.4893, -0.0349],\n",
      "        [-0.5909,  0.3053]])), ('_encoder_logstd.convs.2.convs.1.conv.lin_l.bias', tensor([0.4528, 0.5002])), ('_encoder_logstd.convs.2.convs.1.conv.lin_r.weight', tensor([[0.3357, 0.2939],\n",
      "        [0.1015, 0.0901]])), ('_encoder_logstd.convs.3.convs.0.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.0.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.0.conv.lin.weight', tensor([[ 0.4002,  0.0617],\n",
      "        [ 0.6608, -0.3810]])), ('_encoder_logstd.convs.3.convs.0.conv.lin.bias', tensor([-0.2786,  0.0246])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.weight', tensor([[ 0.4951,  0.3764],\n",
      "        [ 0.2404, -0.1268]])), ('_encoder_logstd.convs.3.convs.0.conv.lin_l.bias', tensor([0.0488, 0.6291])), ('_encoder_logstd.convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.7016,  0.1639],\n",
      "        [-0.3196, -0.1674]])), ('_encoder_logstd.convs.3.convs.1.norm.weight', tensor([1., 1.])), ('_encoder_logstd.convs.3.convs.1.norm.bias', tensor([0., 0.])), ('_encoder_logstd.convs.3.convs.1.conv.lin.weight', tensor([[-0.0640, -0.1557],\n",
      "        [ 0.1767, -0.1065]])), ('_encoder_logstd.convs.3.convs.1.conv.lin.bias', tensor([0.0568, 0.0250])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.weight', tensor([[-0.2622, -0.2702],\n",
      "        [-0.3971, -0.3468]])), ('_encoder_logstd.convs.3.convs.1.conv.lin_l.bias', tensor([0.2797, 0.6370])), ('_encoder_logstd.convs.3.convs.1.conv.lin_r.weight', tensor([[ 0.5445,  0.1887],\n",
      "        [-0.2439,  0.4652]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.0054, -0.2031, -0.0314, -0.2394,  0.2686, -0.3836],\n",
      "        [-0.3950,  0.2310,  0.3105, -0.2955, -0.3816, -0.3703],\n",
      "        [ 0.0674, -0.2796,  0.2716, -0.2575,  0.1144,  0.3309],\n",
      "        [ 0.3514,  0.2478,  0.0679, -0.3832, -0.3897,  0.1669]])), ('lin1.bias', tensor([-0.1543, -0.1334,  0.3143, -0.0931])), ('lin2.weight', tensor([[ 0.2334, -0.2410,  0.3189,  0.4304],\n",
      "        [ 0.4109, -0.3183, -0.0542,  0.1895],\n",
      "        [-0.4163, -0.2093, -0.0465, -0.2016]])), ('lin2.bias', tensor([ 0.0053, -0.4309,  0.4162])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[0.0146, 0.3763],\n",
      "        [0.5879, 0.3477]])), ('convs.0.convs.0.conv.lin.bias', tensor([ 0.6043, -0.1345])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.4270, -0.4815],\n",
      "        [ 0.5028,  0.3402]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([ 0.4090, -0.5809])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[ 0.1292, -0.2530],\n",
      "        [ 0.6851, -0.3919]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.6311,  0.4723],\n",
      "        [ 0.1573,  0.2110]])), ('convs.0.convs.1.conv.lin.bias', tensor([0.4630, 0.5210])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[ 0.5912,  0.6443],\n",
      "        [-0.3678,  0.6832]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.3827, -0.5202])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.6105, -0.5760],\n",
      "        [ 0.1377,  0.1916]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.6451,  0.4029],\n",
      "        [ 0.5793, -0.1449]])), ('convs.1.convs.0.conv.lin.bias', tensor([-0.1196,  0.0143])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[-0.1171, -0.3016],\n",
      "        [-0.0097,  0.1460]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.2209, -0.0220])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[-0.5179,  0.5242],\n",
      "        [-0.5410, -0.1366]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[-0.4015, -0.0603],\n",
      "        [ 0.3521, -0.0848]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.5632, -0.3094])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[ 0.5423,  0.0747],\n",
      "        [-0.1920, -0.0082]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.4665,  0.1602])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[ 0.6889,  0.5639],\n",
      "        [-0.4929,  0.5890]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[-0.1197,  0.0832],\n",
      "        [ 0.6150,  0.5739]])), ('convs.2.convs.0.conv.lin.bias', tensor([ 0.1049, -0.0532])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.4597,  0.1112],\n",
      "        [-0.2382,  0.1207]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([0.3543, 0.6268])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2328,  0.3172],\n",
      "        [-0.1067,  0.0331]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[-0.0647, -0.3672],\n",
      "        [-0.1592,  0.5463]])), ('convs.2.convs.1.conv.lin.bias', tensor([-0.5875,  0.1702])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.4893, -0.0349],\n",
      "        [-0.5909,  0.3053]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([0.4528, 0.5002])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[0.3357, 0.2939],\n",
      "        [0.1015, 0.0901]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.4002,  0.0617],\n",
      "        [ 0.6608, -0.3810]])), ('convs.3.convs.0.conv.lin.bias', tensor([-0.2786,  0.0246])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[ 0.4951,  0.3764],\n",
      "        [ 0.2404, -0.1268]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([0.0488, 0.6291])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[ 0.7016,  0.1639],\n",
      "        [-0.3196, -0.1674]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-0.0640, -0.1557],\n",
      "        [ 0.1767, -0.1065]])), ('convs.3.convs.1.conv.lin.bias', tensor([0.0568, 0.0250])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[-0.2622, -0.2702],\n",
      "        [-0.3971, -0.3468]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([0.2797, 0.6370])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[ 0.5445,  0.1887],\n",
      "        [-0.2439,  0.4652]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.2069,  0.2229,  0.0383,  0.0180,  0.0883,  0.2456],\n",
      "        [-0.3949,  0.0344, -0.2330, -0.0659, -0.2363, -0.2055],\n",
      "        [-0.1614, -0.1606, -0.3862,  0.3437, -0.3458, -0.0019],\n",
      "        [-0.0784,  0.2087,  0.4053, -0.2976,  0.3410,  0.1618]])), ('lin1.bias', tensor([-0.2483,  0.1345,  0.3746,  0.0937])), ('lin2.weight', tensor([[ 0.4846, -0.0844, -0.2578, -0.3446],\n",
      "        [ 0.0149,  0.4080, -0.4526,  0.3784],\n",
      "        [-0.3600, -0.2582,  0.1504, -0.2708]])), ('lin2.bias', tensor([-0.2519,  0.2434,  0.1186])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.convs.0.norm.weight', tensor([1., 1.])), ('convs.0.convs.0.norm.bias', tensor([0., 0.])), ('convs.0.convs.0.conv.lin.weight', tensor([[-0.2267,  0.6022],\n",
      "        [-0.0239, -0.6242]])), ('convs.0.convs.0.conv.lin.bias', tensor([-0.0164, -0.5859])), ('convs.0.convs.0.conv.lin_l.weight', tensor([[ 0.1888,  0.3423],\n",
      "        [-0.3902, -0.2755]])), ('convs.0.convs.0.conv.lin_l.bias', tensor([ 0.6926, -0.2892])), ('convs.0.convs.0.conv.lin_r.weight', tensor([[-0.0860, -0.3561],\n",
      "        [ 0.5024, -0.4829]])), ('convs.0.convs.1.norm.weight', tensor([1., 1.])), ('convs.0.convs.1.norm.bias', tensor([0., 0.])), ('convs.0.convs.1.conv.lin.weight', tensor([[-0.0564, -0.0684],\n",
      "        [ 0.3398,  0.4225]])), ('convs.0.convs.1.conv.lin.bias', tensor([0.3329, 0.0030])), ('convs.0.convs.1.conv.lin_l.weight', tensor([[-0.3034, -0.5949],\n",
      "        [-0.3108, -0.4007]])), ('convs.0.convs.1.conv.lin_l.bias', tensor([-0.6313,  0.1179])), ('convs.0.convs.1.conv.lin_r.weight', tensor([[ 0.4542, -0.5805],\n",
      "        [-0.6374,  0.1322]])), ('convs.1.convs.0.norm.weight', tensor([1., 1.])), ('convs.1.convs.0.norm.bias', tensor([0., 0.])), ('convs.1.convs.0.conv.lin.weight', tensor([[-0.2223, -0.0024],\n",
      "        [ 0.5252,  0.1772]])), ('convs.1.convs.0.conv.lin.bias', tensor([ 0.4300, -0.6146])), ('convs.1.convs.0.conv.lin_l.weight', tensor([[ 0.1243,  0.0015],\n",
      "        [-0.3334, -0.0134]])), ('convs.1.convs.0.conv.lin_l.bias', tensor([ 0.2236, -0.0980])), ('convs.1.convs.0.conv.lin_r.weight', tensor([[ 0.2621, -0.3204],\n",
      "        [-0.4315, -0.1549]])), ('convs.1.convs.1.norm.weight', tensor([1., 1.])), ('convs.1.convs.1.norm.bias', tensor([0., 0.])), ('convs.1.convs.1.conv.lin.weight', tensor([[ 0.2514,  0.6689],\n",
      "        [ 0.2730, -0.0525]])), ('convs.1.convs.1.conv.lin.bias', tensor([-0.4456, -0.3050])), ('convs.1.convs.1.conv.lin_l.weight', tensor([[-0.5756, -0.0405],\n",
      "        [ 0.6401,  0.0142]])), ('convs.1.convs.1.conv.lin_l.bias', tensor([-0.6854,  0.6192])), ('convs.1.convs.1.conv.lin_r.weight', tensor([[-1.1812e-01,  6.3304e-01],\n",
      "        [ 1.4208e-01,  5.4789e-04]])), ('convs.2.convs.0.norm.weight', tensor([1., 1.])), ('convs.2.convs.0.norm.bias', tensor([0., 0.])), ('convs.2.convs.0.conv.lin.weight', tensor([[-0.5506,  0.5808],\n",
      "        [ 0.4755, -0.1085]])), ('convs.2.convs.0.conv.lin.bias', tensor([ 0.6535, -0.6913])), ('convs.2.convs.0.conv.lin_l.weight', tensor([[ 0.0458,  0.6219],\n",
      "        [-0.2181, -0.6882]])), ('convs.2.convs.0.conv.lin_l.bias', tensor([-0.3495, -0.2523])), ('convs.2.convs.0.conv.lin_r.weight', tensor([[-0.2491, -0.3502],\n",
      "        [ 0.5041, -0.6441]])), ('convs.2.convs.1.norm.weight', tensor([1., 1.])), ('convs.2.convs.1.norm.bias', tensor([0., 0.])), ('convs.2.convs.1.conv.lin.weight', tensor([[ 0.3082,  0.0648],\n",
      "        [-0.6376, -0.5532]])), ('convs.2.convs.1.conv.lin.bias', tensor([ 0.5833, -0.1440])), ('convs.2.convs.1.conv.lin_l.weight', tensor([[-0.3444,  0.3145],\n",
      "        [-0.6138,  0.5859]])), ('convs.2.convs.1.conv.lin_l.bias', tensor([-0.1156,  0.4184])), ('convs.2.convs.1.conv.lin_r.weight', tensor([[-0.0198, -0.2733],\n",
      "        [ 0.6305, -0.5540]])), ('convs.3.convs.0.norm.weight', tensor([1., 1.])), ('convs.3.convs.0.norm.bias', tensor([0., 0.])), ('convs.3.convs.0.conv.lin.weight', tensor([[ 0.3593, -0.4489],\n",
      "        [-0.6007, -0.5099]])), ('convs.3.convs.0.conv.lin.bias', tensor([0.1263, 0.3657])), ('convs.3.convs.0.conv.lin_l.weight', tensor([[-0.5746,  0.0189],\n",
      "        [ 0.0391,  0.0488]])), ('convs.3.convs.0.conv.lin_l.bias', tensor([ 0.2973, -0.1904])), ('convs.3.convs.0.conv.lin_r.weight', tensor([[-0.4705,  0.4192],\n",
      "        [ 0.5346,  0.7009]])), ('convs.3.convs.1.norm.weight', tensor([1., 1.])), ('convs.3.convs.1.norm.bias', tensor([0., 0.])), ('convs.3.convs.1.conv.lin.weight', tensor([[-0.6586,  0.3934],\n",
      "        [-0.4657, -0.5717]])), ('convs.3.convs.1.conv.lin.bias', tensor([ 0.2181, -0.4675])), ('convs.3.convs.1.conv.lin_l.weight', tensor([[ 0.4174, -0.2520],\n",
      "        [-0.5828,  0.2882]])), ('convs.3.convs.1.conv.lin_l.bias', tensor([ 0.3432, -0.4348])), ('convs.3.convs.1.conv.lin_r.weight', tensor([[ 0.4427,  0.3356],\n",
      "        [-0.0147, -0.3548]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 4, 'out_channels': 3, 'num_convs': 4, 'dropout': 0.0, 'project': True, 'root_weight': True, 'aggr': 'mean', 'num_groups': 2, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): RevSAGEConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=4, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (1): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (2): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "        (3): GroupAddRev(SAGEConvBlock(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): SAGEConv(2, 2, aggr=mean)\n",
      "        ), num_groups=2)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "VGAEv2                                                            --\n",
      "├─VGEncoder: 1-1                                                  --\n",
      "│    └─RevSAGEConvEncoder: 2-1                                    --\n",
      "│    │    └─Linear: 3-1                                           28\n",
      "│    │    └─Linear: 3-2                                           15\n",
      "│    │    └─LayerNorm: 3-3                                        8\n",
      "│    │    └─ModuleList: 3-4                                       160\n",
      "│    └─RevSAGEConvEncoder: 2-2                                    --\n",
      "│    │    └─Linear: 3-5                                           28\n",
      "│    │    └─Linear: 3-6                                           15\n",
      "│    │    └─LayerNorm: 3-7                                        8\n",
      "│    │    └─ModuleList: 3-8                                       160\n",
      "├─InnerProductDecoder: 1-2                                        --\n",
      "==========================================================================================\n",
      "Total params: 422\n",
      "Trainable params: 422\n",
      "Non-trainable params: 0\n",
      "==========================================================================================\n",
      "forward() original\n",
      "(tensor([0.9753, 0.9970, 0.9753, 1.0000, 0.9970, 1.0000, 0.9999, 0.2517, 0.9999,\n",
      "        0.2517], grad_fn=<SigmoidBackward0>), tensor([[-0.0262,  0.5307, -0.4288],\n",
      "        [ 0.0978,  0.4828, -0.4509],\n",
      "        [-0.1619,  0.6237, -0.4595],\n",
      "        [-0.1808,  0.6250, -0.4481],\n",
      "        [-0.2496,  0.6755, -0.4683]], grad_fn=<AddmmBackward0>), tensor([[ 0.5445, -0.5226,  0.3376],\n",
      "        [ 0.5313, -0.5013,  0.3234],\n",
      "        [ 0.5459, -0.5228,  0.3374],\n",
      "        [ 0.5335, -0.4012,  0.2378],\n",
      "        [ 0.5056, -0.5105,  0.3387]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.9566, 0.0062, 0.9566, 0.0296, 0.0062, 0.0296, 0.7474, 0.9542, 0.7474,\n",
      "        0.9542], grad_fn=<SigmoidBackward0>), tensor([[-0.0262,  0.5307, -0.4288],\n",
      "        [ 0.0978,  0.4828, -0.4509],\n",
      "        [-0.1619,  0.6237, -0.4595],\n",
      "        [-0.1808,  0.6250, -0.4481],\n",
      "        [-0.2496,  0.6755, -0.4683]], grad_fn=<AddmmBackward0>), tensor([[ 0.5445, -0.5226,  0.3376],\n",
      "        [ 0.5313, -0.5013,  0.3234],\n",
      "        [ 0.5459, -0.5228,  0.3374],\n",
      "        [ 0.5335, -0.4012,  0.2378],\n",
      "        [ 0.5056, -0.5105,  0.3387]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.9999, 0.9958, 0.6537, 0.9410, 0.5385],\n",
      "        [0.9958, 0.9798, 0.8560, 0.8850, 0.8499],\n",
      "        [0.6537, 0.8560, 0.9944, 0.8625, 0.9992],\n",
      "        [0.9410, 0.8850, 0.8625, 0.7921, 0.9123],\n",
      "        [0.5385, 0.8499, 0.9992, 0.9123, 1.0000]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.9999, 0.2573, 0.0026, 0.9651, 0.0363],\n",
      "        [0.2573, 0.9925, 0.9662, 0.9986, 0.9741],\n",
      "        [0.0026, 0.9662, 0.9974, 0.9535, 0.9881],\n",
      "        [0.9651, 0.9986, 0.9535, 1.0000, 0.9917],\n",
      "        [0.0363, 0.9741, 0.9881, 0.9917, 0.9780]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-1.1022, -0.6896,  0.2729],\n",
      "        [ 1.2915,  0.2542, -0.5808],\n",
      "        [-0.2816,  0.9495,  0.2899],\n",
      "        [ 0.9852,  0.6913,  1.0353],\n",
      "        [-1.6049,  1.3541, -0.8018]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-0.7940, -0.1047,  1.1893],\n",
      "        [ 0.1973,  0.8043, -0.2691],\n",
      "        [-3.3506,  0.2579, -0.1012],\n",
      "        [-0.7452, -0.2540, -3.3284],\n",
      "        [ 0.8954,  1.2167,  0.1819]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.0262,  0.5307, -0.4288],\n",
      "        [ 0.0978,  0.4828, -0.4509],\n",
      "        [-0.1619,  0.6237, -0.4595],\n",
      "        [-0.1808,  0.6250, -0.4481],\n",
      "        [-0.2496,  0.6755, -0.4683]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[ 0.5445, -0.5226,  0.3376],\n",
      "        [ 0.5313, -0.5013,  0.3234],\n",
      "        [ 0.5459, -0.5228,  0.3374],\n",
      "        [ 0.5335, -0.4012,  0.2378],\n",
      "        [ 0.5056, -0.5105,  0.3387]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.0262,  0.5307, -0.4288],\n",
      "        [ 0.0978,  0.4828, -0.4509],\n",
      "        [-0.1619,  0.6237, -0.4595],\n",
      "        [-0.1808,  0.6250, -0.4481],\n",
      "        [-0.2496,  0.6755, -0.4683]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[ 0.5445, -0.5226,  0.3376],\n",
      "        [ 0.5313, -0.5013,  0.3234],\n",
      "        [ 0.5459, -0.5228,  0.3374],\n",
      "        [ 0.5335, -0.4012,  0.2378],\n",
      "        [ 0.5056, -0.5105,  0.3387]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.7475, 0.0172, 0.7475, 0.0266, 0.0172, 0.0266, 0.0045, 0.2027, 0.0045,\n",
      "        0.2027], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.0136, 0.1101, 0.0136, 0.9496, 0.1101, 0.9496, 0.6853, 0.6127, 0.6853,\n",
      "        0.6127], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(1.7182, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(4.2548, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.52, 0.6311111111111112)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.6799999999999999, 0.7833333333333332)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Simple GCN VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[ 0.2248,  0.2199,  0.0854,  0.3621,  0.1168, -0.3751],\n",
      "        [-0.1974,  0.1816,  0.3137,  0.3898,  0.3925, -0.3722],\n",
      "        [ 0.2425, -0.1870,  0.0100, -0.3819,  0.2926,  0.2410],\n",
      "        [ 0.1969, -0.0047, -0.1880, -0.1704, -0.3336, -0.0995],\n",
      "        [ 0.2327, -0.1698, -0.0139,  0.1601,  0.1483,  0.2936]])), ('_encoder_mu.lin1.bias', tensor([ 0.0251,  0.1722,  0.2082,  0.0151, -0.4043])), ('_encoder_mu.lin2.weight', tensor([[-0.1109, -0.2049,  0.1401, -0.4133],\n",
      "        [ 0.1056, -0.1854,  0.2260,  0.0815],\n",
      "        [-0.1163,  0.3263,  0.1478,  0.2408]])), ('_encoder_mu.lin2.bias', tensor([ 0.2901, -0.0183,  0.0418])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.lin.weight', tensor([[-0.2176,  0.5155, -0.2033,  0.6700, -0.4511],\n",
      "        [-0.2110,  0.6186,  0.4356,  0.2022, -0.3172],\n",
      "        [-0.4305,  0.1417,  0.6277, -0.1489,  0.1959],\n",
      "        [ 0.4398, -0.1723, -0.7668,  0.7254,  0.3304],\n",
      "        [ 0.1949, -0.3097,  0.1252, -0.3337, -0.2886]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.lin.weight', tensor([[ 0.1232, -0.3913, -0.7053,  0.5778, -0.0485],\n",
      "        [ 0.4011, -0.2855,  0.1756,  0.0497,  0.7085],\n",
      "        [ 0.4835,  0.4669, -0.0836, -0.4442,  0.6381],\n",
      "        [-0.2236,  0.1549, -0.3676, -0.4440,  0.7365],\n",
      "        [-0.0549, -0.0718, -0.1887, -0.4597,  0.4199]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.lin.weight', tensor([[ 0.6272, -0.1427, -0.7604, -0.3005, -0.1945],\n",
      "        [-0.3419, -0.2833, -0.5327, -0.0815,  0.2473],\n",
      "        [-0.7277,  0.2255,  0.4014, -0.7936,  0.4193],\n",
      "        [ 0.6818, -0.7018,  0.0734,  0.2618,  0.5891]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.lin.weight', tensor([[-0.2021,  0.1805, -0.4196,  0.7363],\n",
      "        [ 0.2056,  0.3526,  0.7191,  0.2964],\n",
      "        [ 0.2737,  0.2613,  0.2111, -0.4782],\n",
      "        [ 0.1657, -0.1159, -0.1890, -0.6451]])), ('_encoder_logstd.lin1.weight', tensor([[-0.3564, -0.3574, -0.3677,  0.2776,  0.1814,  0.3179],\n",
      "        [ 0.2592, -0.3592,  0.2931,  0.3011, -0.1246,  0.0012],\n",
      "        [ 0.3839,  0.2365,  0.3713, -0.0460, -0.3518,  0.3662],\n",
      "        [-0.2837, -0.0550, -0.1604,  0.1781,  0.0810,  0.2494],\n",
      "        [-0.3609,  0.3753, -0.1708,  0.3580,  0.3682,  0.1555]])), ('_encoder_logstd.lin1.bias', tensor([-0.2245, -0.2325, -0.0899,  0.0874, -0.0676])), ('_encoder_logstd.lin2.weight', tensor([[ 0.1948,  0.4462, -0.2516, -0.0504],\n",
      "        [ 0.3694, -0.4388,  0.2575, -0.0949],\n",
      "        [ 0.2376,  0.1008,  0.2512,  0.0352]])), ('_encoder_logstd.lin2.bias', tensor([-0.2247,  0.1511, -0.0840])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.lin.weight', tensor([[ 0.3240,  0.2634,  0.6641,  0.5339, -0.3029],\n",
      "        [ 0.5033, -0.4949, -0.5668,  0.5715,  0.0979],\n",
      "        [ 0.3069, -0.1107, -0.0987, -0.5132,  0.2239],\n",
      "        [-0.7387, -0.2692, -0.2384,  0.3394, -0.4401],\n",
      "        [-0.5576, -0.4107, -0.2304,  0.7157, -0.1639]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.lin.weight', tensor([[ 0.3859, -0.7495, -0.0421,  0.7614, -0.1407],\n",
      "        [-0.4872,  0.6854, -0.3376,  0.3466, -0.6748],\n",
      "        [-0.5678, -0.2463,  0.4060, -0.2720, -0.5237],\n",
      "        [-0.4068, -0.7478, -0.0233,  0.1536,  0.3842],\n",
      "        [-0.5821,  0.0117, -0.4548,  0.5026, -0.7615]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.lin.weight', tensor([[-0.6923,  0.6941,  0.7387, -0.8067, -0.4148],\n",
      "        [ 0.6905, -0.6874, -0.2493, -0.4592, -0.4355],\n",
      "        [ 0.0685, -0.1482,  0.0834,  0.2358, -0.6758],\n",
      "        [ 0.5315,  0.3024,  0.1702, -0.0346, -0.5030]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.lin.weight', tensor([[ 0.2309, -0.7039, -0.8442,  0.7273],\n",
      "        [-0.7153,  0.2967, -0.4979,  0.3782],\n",
      "        [ 0.4966,  0.6103,  0.2290, -0.2149],\n",
      "        [ 0.2529,  0.5242,  0.8624,  0.5818]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.3564, -0.3574, -0.3677,  0.2776,  0.1814,  0.3179],\n",
      "        [ 0.2592, -0.3592,  0.2931,  0.3011, -0.1246,  0.0012],\n",
      "        [ 0.3839,  0.2365,  0.3713, -0.0460, -0.3518,  0.3662],\n",
      "        [-0.2837, -0.0550, -0.1604,  0.1781,  0.0810,  0.2494],\n",
      "        [-0.3609,  0.3753, -0.1708,  0.3580,  0.3682,  0.1555]])), ('lin1.bias', tensor([-0.2245, -0.2325, -0.0899,  0.0874, -0.0676])), ('lin2.weight', tensor([[ 0.1948,  0.4462, -0.2516, -0.0504],\n",
      "        [ 0.3694, -0.4388,  0.2575, -0.0949],\n",
      "        [ 0.2376,  0.1008,  0.2512,  0.0352]])), ('lin2.bias', tensor([-0.2247,  0.1511, -0.0840])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[ 0.3240,  0.2634,  0.6641,  0.5339, -0.3029],\n",
      "        [ 0.5033, -0.4949, -0.5668,  0.5715,  0.0979],\n",
      "        [ 0.3069, -0.1107, -0.0987, -0.5132,  0.2239],\n",
      "        [-0.7387, -0.2692, -0.2384,  0.3394, -0.4401],\n",
      "        [-0.5576, -0.4107, -0.2304,  0.7157, -0.1639]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.3859, -0.7495, -0.0421,  0.7614, -0.1407],\n",
      "        [-0.4872,  0.6854, -0.3376,  0.3466, -0.6748],\n",
      "        [-0.5678, -0.2463,  0.4060, -0.2720, -0.5237],\n",
      "        [-0.4068, -0.7478, -0.0233,  0.1536,  0.3842],\n",
      "        [-0.5821,  0.0117, -0.4548,  0.5026, -0.7615]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[-0.6923,  0.6941,  0.7387, -0.8067, -0.4148],\n",
      "        [ 0.6905, -0.6874, -0.2493, -0.4592, -0.4355],\n",
      "        [ 0.0685, -0.1482,  0.0834,  0.2358, -0.6758],\n",
      "        [ 0.5315,  0.3024,  0.1702, -0.0346, -0.5030]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[ 0.2309, -0.7039, -0.8442,  0.7273],\n",
      "        [-0.7153,  0.2967, -0.4979,  0.3782],\n",
      "        [ 0.4966,  0.6103,  0.2290, -0.2149],\n",
      "        [ 0.2529,  0.5242,  0.8624,  0.5818]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.2248,  0.2199,  0.0854,  0.3621,  0.1168, -0.3751],\n",
      "        [-0.1974,  0.1816,  0.3137,  0.3898,  0.3925, -0.3722],\n",
      "        [ 0.2425, -0.1870,  0.0100, -0.3819,  0.2926,  0.2410],\n",
      "        [ 0.1969, -0.0047, -0.1880, -0.1704, -0.3336, -0.0995],\n",
      "        [ 0.2327, -0.1698, -0.0139,  0.1601,  0.1483,  0.2936]])), ('lin1.bias', tensor([ 0.0251,  0.1722,  0.2082,  0.0151, -0.4043])), ('lin2.weight', tensor([[-0.1109, -0.2049,  0.1401, -0.4133],\n",
      "        [ 0.1056, -0.1854,  0.2260,  0.0815],\n",
      "        [-0.1163,  0.3263,  0.1478,  0.2408]])), ('lin2.bias', tensor([ 0.2901, -0.0183,  0.0418])), ('norm.weight', tensor([1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.lin.weight', tensor([[-0.2176,  0.5155, -0.2033,  0.6700, -0.4511],\n",
      "        [-0.2110,  0.6186,  0.4356,  0.2022, -0.3172],\n",
      "        [-0.4305,  0.1417,  0.6277, -0.1489,  0.1959],\n",
      "        [ 0.4398, -0.1723, -0.7668,  0.7254,  0.3304],\n",
      "        [ 0.1949, -0.3097,  0.1252, -0.3337, -0.2886]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.lin.weight', tensor([[ 0.1232, -0.3913, -0.7053,  0.5778, -0.0485],\n",
      "        [ 0.4011, -0.2855,  0.1756,  0.0497,  0.7085],\n",
      "        [ 0.4835,  0.4669, -0.0836, -0.4442,  0.6381],\n",
      "        [-0.2236,  0.1549, -0.3676, -0.4440,  0.7365],\n",
      "        [-0.0549, -0.0718, -0.1887, -0.4597,  0.4199]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.bias', tensor([0., 0., 0., 0.])), ('convs.2.conv.lin.weight', tensor([[ 0.6272, -0.1427, -0.7604, -0.3005, -0.1945],\n",
      "        [-0.3419, -0.2833, -0.5327, -0.0815,  0.2473],\n",
      "        [-0.7277,  0.2255,  0.4014, -0.7936,  0.4193],\n",
      "        [ 0.6818, -0.7018,  0.0734,  0.2618,  0.5891]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.bias', tensor([0., 0., 0., 0.])), ('convs.3.conv.lin.weight', tensor([[-0.2021,  0.1805, -0.4196,  0.7363],\n",
      "        [ 0.2056,  0.3526,  0.7191,  0.2964],\n",
      "        [ 0.2737,  0.2613,  0.2111, -0.4782],\n",
      "        [ 0.1657, -0.1159, -0.1890, -0.6451]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'conv_dims': [5, 5, 4, 4], 'dropout': 0.0, 'improved': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'bias': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): SimpleGCNEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=4, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (1): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 5)\n",
      "        )\n",
      "        (2): GCNConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(5, 4)\n",
      "        )\n",
      "        (3): GCNConvBlock(\n",
      "          (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCNConv(4, 4)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "VGAEv2                                                  --\n",
      "├─VGEncoder: 1-1                                        --\n",
      "│    └─SimpleGCNEncoder: 2-1                            --\n",
      "│    │    └─Linear: 3-1                                 35\n",
      "│    │    └─Linear: 3-2                                 15\n",
      "│    │    └─LayerNorm: 3-3                              8\n",
      "│    │    └─ModuleList: 3-4                             142\n",
      "│    └─SimpleGCNEncoder: 2-2                            --\n",
      "│    │    └─Linear: 3-5                                 35\n",
      "│    │    └─Linear: 3-6                                 15\n",
      "│    │    └─LayerNorm: 3-7                              8\n",
      "│    │    └─ModuleList: 3-8                             142\n",
      "├─InnerProductDecoder: 1-2                              --\n",
      "================================================================================\n",
      "Total params: 400\n",
      "Trainable params: 400\n",
      "Non-trainable params: 0\n",
      "================================================================================\n",
      "forward() original\n",
      "(tensor([0.3615, 0.7619, 0.3615, 0.1864, 0.7619, 0.1864, 0.8993, 0.8681, 0.8993,\n",
      "        0.8681], grad_fn=<SigmoidBackward0>), tensor([[-0.0390, -0.3162,  0.5659],\n",
      "        [-0.0389, -0.3160,  0.5657],\n",
      "        [-0.0382, -0.3154,  0.5646],\n",
      "        [-0.0390, -0.3161,  0.5659],\n",
      "        [-0.0348, -0.3123,  0.5591]], grad_fn=<AddmmBackward0>), tensor([[-0.1520, -0.1024, -0.0089],\n",
      "        [-0.1521, -0.1042, -0.0083],\n",
      "        [-0.1537, -0.1176, -0.0038],\n",
      "        [-0.1519, -0.1013, -0.0093],\n",
      "        [-0.1803, -0.1028, -0.0062]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.4598, 0.6707, 0.4598, 0.4465, 0.6707, 0.4465, 0.5709, 0.5059, 0.5709,\n",
      "        0.5059], grad_fn=<SigmoidBackward0>), tensor([[-0.0390, -0.3162,  0.5659],\n",
      "        [-0.0389, -0.3160,  0.5657],\n",
      "        [-0.0382, -0.3154,  0.5646],\n",
      "        [-0.0390, -0.3161,  0.5659],\n",
      "        [-0.0348, -0.3123,  0.5591]], grad_fn=<AddmmBackward0>), tensor([[-0.1520, -0.1024, -0.0089],\n",
      "        [-0.1521, -0.1042, -0.0083],\n",
      "        [-0.1537, -0.1176, -0.0038],\n",
      "        [-0.1519, -0.1013, -0.0093],\n",
      "        [-0.1803, -0.1028, -0.0062]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7905, 0.2174, 0.5113, 0.7849, 0.2925],\n",
      "        [0.2174, 0.9960, 0.1094, 0.0110, 0.0507],\n",
      "        [0.5113, 0.1094, 0.7392, 0.8006, 0.8549],\n",
      "        [0.7849, 0.0110, 0.8006, 0.9895, 0.8863],\n",
      "        [0.2925, 0.0507, 0.8549, 0.8863, 0.9808]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[0.9159, 0.6580, 0.9381, 0.5740, 0.6807],\n",
      "        [0.6580, 0.8412, 0.9726, 0.5123, 0.5561],\n",
      "        [0.9381, 0.9726, 0.9998, 0.5657, 0.6985],\n",
      "        [0.5740, 0.5123, 0.5657, 0.5273, 0.5942],\n",
      "        [0.6807, 0.5561, 0.6985, 0.5942, 0.8016]], grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-1.4449,  1.1947, -1.0657],\n",
      "        [-0.0969,  0.0383,  1.2178],\n",
      "        [ 0.1847, -1.3966,  1.2028],\n",
      "        [-0.9031, -1.3225,  0.4813],\n",
      "        [ 0.4342, -0.8905,  2.0329]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-1.0547, -0.9781,  2.0166],\n",
      "        [ 0.1171, -0.8771,  0.0552],\n",
      "        [ 1.3683,  0.0271, -0.0464],\n",
      "        [ 0.0253, -0.8143,  1.3241],\n",
      "        [-0.2772,  0.5675,  1.7302]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[-0.0390, -0.3162,  0.5659],\n",
      "        [-0.0389, -0.3160,  0.5657],\n",
      "        [-0.0382, -0.3154,  0.5646],\n",
      "        [-0.0390, -0.3161,  0.5659],\n",
      "        [-0.0348, -0.3123,  0.5591]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.1520, -0.1024, -0.0089],\n",
      "        [-0.1521, -0.1042, -0.0083],\n",
      "        [-0.1537, -0.1176, -0.0038],\n",
      "        [-0.1519, -0.1013, -0.0093],\n",
      "        [-0.1803, -0.1028, -0.0062]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[-0.0390, -0.3162,  0.5659],\n",
      "        [-0.0389, -0.3160,  0.5657],\n",
      "        [-0.0382, -0.3154,  0.5646],\n",
      "        [-0.0390, -0.3161,  0.5659],\n",
      "        [-0.0348, -0.3123,  0.5591]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.1520, -0.1024, -0.0089],\n",
      "        [-0.1521, -0.1042, -0.0083],\n",
      "        [-0.1537, -0.1176, -0.0038],\n",
      "        [-0.1519, -0.1013, -0.0093],\n",
      "        [-0.1803, -0.1028, -0.0062]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.5220, 0.5789, 0.5220, 0.1558, 0.5789, 0.1558, 0.9911, 0.2257, 0.9911,\n",
      "        0.2257], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.1620, 0.2341, 0.1620, 0.5331, 0.2341, 0.5331, 0.3002, 0.0623, 0.3002,\n",
      "        0.0623], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(2.3174, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(3.4665, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.64, 0.6116666666666666)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.56, 0.5726190476190476)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Residual GCN2 VGAE\n",
      "Constructor params: \n",
      "{'encoder': {'state_dict': OrderedDict([('_encoder_mu.lin1.weight', tensor([[ 0.3857,  0.0020,  0.1215, -0.0490,  0.0601,  0.2493],\n",
      "        [ 0.2323, -0.3704,  0.1014, -0.3682, -0.1721, -0.3488],\n",
      "        [ 0.2810,  0.3587,  0.2448,  0.3681, -0.0511,  0.3387],\n",
      "        [-0.0138,  0.1082, -0.3722, -0.2828, -0.3228, -0.0199],\n",
      "        [-0.1047, -0.2874,  0.1671, -0.0632, -0.1388,  0.2172]])), ('_encoder_mu.lin1.bias', tensor([-0.3949,  0.2957, -0.3635, -0.0145, -0.3307])), ('_encoder_mu.lin2.weight', tensor([[-0.1569,  0.1135, -0.2182,  0.3929, -0.1340],\n",
      "        [-0.3569,  0.1026, -0.0773,  0.1928, -0.0458],\n",
      "        [-0.0286,  0.1395, -0.1300, -0.3277,  0.3102]])), ('_encoder_mu.lin2.bias', tensor([0.3921, 0.4310, 0.2407])), ('_encoder_mu.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.0.conv.weight1', tensor([[ 0.7305,  0.0997,  0.4152, -0.7657, -0.5346],\n",
      "        [ 0.0126,  0.3372,  0.3836,  0.3113, -0.5589],\n",
      "        [ 0.0878,  0.6758, -0.6088, -0.2848,  0.0342],\n",
      "        [ 0.7721,  0.4847,  0.0862,  0.4207,  0.4720],\n",
      "        [ 0.7176,  0.1381,  0.7277,  0.4738,  0.3269]])), ('_encoder_mu.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.1.conv.weight1', tensor([[ 0.3728, -0.0931, -0.0380, -0.7341,  0.6262],\n",
      "        [ 0.3824,  0.4954,  0.5836,  0.1796, -0.7139],\n",
      "        [ 0.2492,  0.1866, -0.1461,  0.2939, -0.5862],\n",
      "        [ 0.3414, -0.2273, -0.4895,  0.6473,  0.7660],\n",
      "        [-0.2593, -0.4402,  0.5652,  0.2391, -0.6928]])), ('_encoder_mu.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.2.conv.weight1', tensor([[ 0.4712, -0.3133,  0.1375,  0.3948,  0.3388],\n",
      "        [-0.7108,  0.6070,  0.6632,  0.1035,  0.6479],\n",
      "        [-0.3546,  0.4628, -0.5311,  0.5108, -0.2241],\n",
      "        [ 0.4371, -0.0731,  0.4877,  0.7034, -0.0933],\n",
      "        [ 0.2234, -0.6920,  0.1167, -0.6125, -0.6420]])), ('_encoder_mu.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_mu.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_mu.convs.3.conv.weight1', tensor([[-0.2140,  0.4849, -0.6459, -0.4975, -0.4411],\n",
      "        [ 0.6347,  0.0126,  0.5276,  0.1134, -0.1747],\n",
      "        [ 0.4208, -0.0104,  0.6976, -0.1656, -0.0137],\n",
      "        [ 0.6342,  0.5461, -0.6322, -0.2548,  0.0162],\n",
      "        [ 0.6140,  0.2944,  0.1540, -0.4633, -0.6785]])), ('_encoder_logstd.lin1.weight', tensor([[-0.3636, -0.1829, -0.2934, -0.2767,  0.3166, -0.0624],\n",
      "        [-0.3105, -0.3720, -0.0971, -0.2459, -0.2888,  0.1892],\n",
      "        [ 0.3729,  0.3504, -0.3977, -0.2174, -0.4074,  0.3241],\n",
      "        [-0.2746,  0.0626, -0.0576,  0.0666,  0.2752, -0.1297],\n",
      "        [-0.3559, -0.2984,  0.3484, -0.0572,  0.1144,  0.2528]])), ('_encoder_logstd.lin1.bias', tensor([-0.3127, -0.2960,  0.1981,  0.2100,  0.2083])), ('_encoder_logstd.lin2.weight', tensor([[ 0.0583, -0.1721, -0.3076, -0.0371, -0.3939],\n",
      "        [-0.0956,  0.1582, -0.0997, -0.0635,  0.4299],\n",
      "        [ 0.3171, -0.0904, -0.4378, -0.3357, -0.3626]])), ('_encoder_logstd.lin2.bias', tensor([0.4145, 0.3845, 0.3897])), ('_encoder_logstd.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.0.conv.weight1', tensor([[ 0.0888,  0.6905,  0.4239, -0.2236,  0.1973],\n",
      "        [ 0.0013,  0.1179,  0.4383, -0.6409,  0.6041],\n",
      "        [-0.3241,  0.6805, -0.7465, -0.3661, -0.4623],\n",
      "        [ 0.5020, -0.2988,  0.6757,  0.4594, -0.2997],\n",
      "        [ 0.1901, -0.3687,  0.5049,  0.4384,  0.1731]])), ('_encoder_logstd.convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.1.conv.weight1', tensor([[-0.0533, -0.4994,  0.1897,  0.1044, -0.7017],\n",
      "        [-0.1469,  0.7258, -0.4568,  0.5909, -0.1437],\n",
      "        [ 0.5268,  0.5979, -0.5506, -0.2160,  0.7622],\n",
      "        [ 0.2314, -0.3699,  0.5731,  0.2036, -0.7353],\n",
      "        [-0.2804,  0.2004, -0.7130,  0.1457,  0.0029]])), ('_encoder_logstd.convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.2.conv.weight1', tensor([[ 0.0056, -0.1124,  0.2573,  0.0183, -0.6072],\n",
      "        [-0.6744,  0.2042, -0.6715,  0.5683,  0.1031],\n",
      "        [-0.2225,  0.1479,  0.7742, -0.5605, -0.0025],\n",
      "        [ 0.7331,  0.2506,  0.1290,  0.5292, -0.0572],\n",
      "        [-0.2229,  0.6322,  0.3389,  0.4231, -0.6605]])), ('_encoder_logstd.convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('_encoder_logstd.convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('_encoder_logstd.convs.3.conv.weight1', tensor([[-0.3692, -0.2899,  0.0329, -0.0373,  0.5442],\n",
      "        [-0.2439,  0.4065, -0.2022, -0.3213, -0.5090],\n",
      "        [-0.2799,  0.6432,  0.2420,  0.5794,  0.6081],\n",
      "        [-0.7720, -0.1243,  0.5995, -0.0286,  0.1363],\n",
      "        [-0.3260, -0.1046, -0.6114, -0.7387, -0.2335]]))]), 'constructor_params': {'encoder_logstd_given': False, 'encoder_logstd': {'state_dict': OrderedDict([('lin1.weight', tensor([[-0.3636, -0.1829, -0.2934, -0.2767,  0.3166, -0.0624],\n",
      "        [-0.3105, -0.3720, -0.0971, -0.2459, -0.2888,  0.1892],\n",
      "        [ 0.3729,  0.3504, -0.3977, -0.2174, -0.4074,  0.3241],\n",
      "        [-0.2746,  0.0626, -0.0576,  0.0666,  0.2752, -0.1297],\n",
      "        [-0.3559, -0.2984,  0.3484, -0.0572,  0.1144,  0.2528]])), ('lin1.bias', tensor([-0.3127, -0.2960,  0.1981,  0.2100,  0.2083])), ('lin2.weight', tensor([[ 0.0583, -0.1721, -0.3076, -0.0371, -0.3939],\n",
      "        [-0.0956,  0.1582, -0.0997, -0.0635,  0.4299],\n",
      "        [ 0.3171, -0.0904, -0.4378, -0.3357, -0.3626]])), ('lin2.bias', tensor([0.4145, 0.3845, 0.3897])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[ 0.0888,  0.6905,  0.4239, -0.2236,  0.1973],\n",
      "        [ 0.0013,  0.1179,  0.4383, -0.6409,  0.6041],\n",
      "        [-0.3241,  0.6805, -0.7465, -0.3661, -0.4623],\n",
      "        [ 0.5020, -0.2988,  0.6757,  0.4594, -0.2997],\n",
      "        [ 0.1901, -0.3687,  0.5049,  0.4384,  0.1731]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[-0.0533, -0.4994,  0.1897,  0.1044, -0.7017],\n",
      "        [-0.1469,  0.7258, -0.4568,  0.5909, -0.1437],\n",
      "        [ 0.5268,  0.5979, -0.5506, -0.2160,  0.7622],\n",
      "        [ 0.2314, -0.3699,  0.5731,  0.2036, -0.7353],\n",
      "        [-0.2804,  0.2004, -0.7130,  0.1457,  0.0029]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[ 0.0056, -0.1124,  0.2573,  0.0183, -0.6072],\n",
      "        [-0.6744,  0.2042, -0.6715,  0.5683,  0.1031],\n",
      "        [-0.2225,  0.1479,  0.7742, -0.5605, -0.0025],\n",
      "        [ 0.7331,  0.2506,  0.1290,  0.5292, -0.0572],\n",
      "        [-0.2229,  0.6322,  0.3389,  0.4231, -0.6605]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.3692, -0.2899,  0.0329, -0.0373,  0.5442],\n",
      "        [-0.2439,  0.4065, -0.2022, -0.3213, -0.5090],\n",
      "        [-0.2799,  0.6432,  0.2420,  0.5794,  0.6081],\n",
      "        [-0.7720, -0.1243,  0.5995, -0.0286,  0.1363],\n",
      "        [-0.3260, -0.1046, -0.6114, -0.7387, -0.2335]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}, 'encoder_mu': {'state_dict': OrderedDict([('lin1.weight', tensor([[ 0.3857,  0.0020,  0.1215, -0.0490,  0.0601,  0.2493],\n",
      "        [ 0.2323, -0.3704,  0.1014, -0.3682, -0.1721, -0.3488],\n",
      "        [ 0.2810,  0.3587,  0.2448,  0.3681, -0.0511,  0.3387],\n",
      "        [-0.0138,  0.1082, -0.3722, -0.2828, -0.3228, -0.0199],\n",
      "        [-0.1047, -0.2874,  0.1671, -0.0632, -0.1388,  0.2172]])), ('lin1.bias', tensor([-0.3949,  0.2957, -0.3635, -0.0145, -0.3307])), ('lin2.weight', tensor([[-0.1569,  0.1135, -0.2182,  0.3929, -0.1340],\n",
      "        [-0.3569,  0.1026, -0.0773,  0.1928, -0.0458],\n",
      "        [-0.0286,  0.1395, -0.1300, -0.3277,  0.3102]])), ('lin2.bias', tensor([0.3921, 0.4310, 0.2407])), ('norm.weight', tensor([1., 1., 1., 1., 1.])), ('norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.0.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.0.conv.weight1', tensor([[ 0.7305,  0.0997,  0.4152, -0.7657, -0.5346],\n",
      "        [ 0.0126,  0.3372,  0.3836,  0.3113, -0.5589],\n",
      "        [ 0.0878,  0.6758, -0.6088, -0.2848,  0.0342],\n",
      "        [ 0.7721,  0.4847,  0.0862,  0.4207,  0.4720],\n",
      "        [ 0.7176,  0.1381,  0.7277,  0.4738,  0.3269]])), ('convs.1.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.1.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.1.conv.weight1', tensor([[ 0.3728, -0.0931, -0.0380, -0.7341,  0.6262],\n",
      "        [ 0.3824,  0.4954,  0.5836,  0.1796, -0.7139],\n",
      "        [ 0.2492,  0.1866, -0.1461,  0.2939, -0.5862],\n",
      "        [ 0.3414, -0.2273, -0.4895,  0.6473,  0.7660],\n",
      "        [-0.2593, -0.4402,  0.5652,  0.2391, -0.6928]])), ('convs.2.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.2.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.2.conv.weight1', tensor([[ 0.4712, -0.3133,  0.1375,  0.3948,  0.3388],\n",
      "        [-0.7108,  0.6070,  0.6632,  0.1035,  0.6479],\n",
      "        [-0.3546,  0.4628, -0.5311,  0.5108, -0.2241],\n",
      "        [ 0.4371, -0.0731,  0.4877,  0.7034, -0.0933],\n",
      "        [ 0.2234, -0.6920,  0.1167, -0.6125, -0.6420]])), ('convs.3.norm.weight', tensor([1., 1., 1., 1., 1.])), ('convs.3.norm.bias', tensor([0., 0., 0., 0., 0.])), ('convs.3.conv.weight1', tensor([[-0.2140,  0.4849, -0.6459, -0.4975, -0.4411],\n",
      "        [ 0.6347,  0.0126,  0.5276,  0.1134, -0.1747],\n",
      "        [ 0.4208, -0.0104,  0.6976, -0.1656, -0.0137],\n",
      "        [ 0.6342,  0.5461, -0.6322, -0.2548,  0.0162],\n",
      "        [ 0.6140,  0.2944,  0.1540, -0.4633, -0.6785]]))]), 'constructor_params': {'in_channels': 6, 'hidden_channels': 5, 'out_channels': 3, 'alpha': 0.3, 'num_convs': 4, 'dropout': 0.0, 'shared_weights': True, 'cached': False, 'add_self_loops': True, 'normalize': True, 'normalize_hidden': True}}}}, 'decoder': None}\n",
      "VGAEv2(\n",
      "  (encoder): VGEncoder(\n",
      "    (_encoder_mu): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (_encoder_logstd): ResGCN2ConvEncoder(\n",
      "      (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (lin2): Linear(in_features=5, out_features=3, bias=True)\n",
      "      (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "      (convs): ModuleList(\n",
      "        (0): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (1): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (2): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "        (3): GCN2ConvBlock(\n",
      "          (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "          (conv): GCN2Conv(5, alpha=0.3, beta=1.0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "VGAEv2                                             --\n",
      "├─VGEncoder: 1-1                                   --\n",
      "│    └─ResGCN2ConvEncoder: 2-1                     --\n",
      "│    │    └─Linear: 3-1                            35\n",
      "│    │    └─Linear: 3-2                            18\n",
      "│    │    └─LayerNorm: 3-3                         10\n",
      "│    │    └─ModuleList: 3-4                        140\n",
      "│    └─ResGCN2ConvEncoder: 2-2                     --\n",
      "│    │    └─Linear: 3-5                            35\n",
      "│    │    └─Linear: 3-6                            18\n",
      "│    │    └─LayerNorm: 3-7                         10\n",
      "│    │    └─ModuleList: 3-8                        140\n",
      "├─InnerProductDecoder: 1-2                         --\n",
      "===========================================================================\n",
      "Total params: 406\n",
      "Trainable params: 406\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n",
      "forward() original\n",
      "(tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], grad_fn=<SigmoidBackward0>), tensor([[ 0.1479, -0.1739,  0.2338],\n",
      "        [ 0.1482, -0.1737,  0.2343],\n",
      "        [ 0.1469, -0.1746,  0.2325],\n",
      "        [ 0.1445, -0.1776,  0.2302],\n",
      "        [ 0.1450, -0.1758,  0.2297]], grad_fn=<AddmmBackward0>), tensor([[-0.0689,  0.8170, -0.2164],\n",
      "        [-0.0686,  0.8174, -0.2147],\n",
      "        [-0.0754,  0.8270, -0.2154],\n",
      "        [-0.0887,  0.8454, -0.2190],\n",
      "        [-0.0822,  0.8350, -0.2193]], grad_fn=<AddmmBackward0>))\n",
      "forward() deserialized (should be ok if they are different because of the randomization)\n",
      "(tensor([0.9974, 0.0326, 0.9974, 0.0043, 0.0326, 0.0043, 0.1810, 0.8983, 0.1810,\n",
      "        0.8983], grad_fn=<SigmoidBackward0>), tensor([[ 0.1479, -0.1739,  0.2338],\n",
      "        [ 0.1482, -0.1737,  0.2343],\n",
      "        [ 0.1469, -0.1746,  0.2325],\n",
      "        [ 0.1445, -0.1776,  0.2302],\n",
      "        [ 0.1450, -0.1758,  0.2297]], grad_fn=<AddmmBackward0>), tensor([[-0.0689,  0.8170, -0.2164],\n",
      "        [-0.0686,  0.8174, -0.2147],\n",
      "        [-0.0754,  0.8270, -0.2154],\n",
      "        [-0.0887,  0.8454, -0.2190],\n",
      "        [-0.0822,  0.8350, -0.2193]], grad_fn=<AddmmBackward0>))\n",
      "Reconstruction forward_all() original\n",
      "tensor([[0.7674, 0.5292, 0.1377, 0.6406, 0.6121],\n",
      "        [0.5292, 0.9984, 0.7944, 0.8171, 0.1009],\n",
      "        [0.1377, 0.7944, 0.9623, 0.3556, 0.2734],\n",
      "        [0.6406, 0.8171, 0.3556, 0.6564, 0.3752],\n",
      "        [0.6121, 0.1009, 0.2734, 0.3752, 0.8939]], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[9.8068e-01, 2.2120e-05, 7.6071e-01, 9.7014e-01, 1.4176e-01],\n",
      "        [2.2120e-05, 1.0000e+00, 1.5628e-01, 1.0755e-04, 9.4349e-01],\n",
      "        [7.6071e-01, 1.5628e-01, 9.5000e-01, 9.6216e-01, 2.1177e-02],\n",
      "        [9.7014e-01, 1.0755e-04, 9.6216e-01, 9.9961e-01, 2.5689e-02],\n",
      "        [1.4176e-01, 9.4349e-01, 2.1177e-02, 2.5689e-02, 9.9461e-01]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Latent space encoding original\n",
      "tensor([[-0.6331,  0.5322,  0.4073],\n",
      "        [ 0.3024, -3.3830, -0.6587],\n",
      "        [ 1.5673,  2.4785, -2.0417],\n",
      "        [-1.5374, -1.9293,  2.1301],\n",
      "        [-1.5683,  3.5668, -0.6542]], grad_fn=<AddBackward0>)\n",
      "Latent space encoding deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([[-0.4417, -2.3416,  0.1718],\n",
      "        [ 1.9327,  1.8255,  1.8031],\n",
      "        [-0.2169, -4.2509,  0.3967],\n",
      "        [ 0.6797,  2.5421, -0.3391],\n",
      "        [ 1.3358, -2.6271, -1.2790]], grad_fn=<AddBackward0>)\n",
      "Mu original\n",
      "tensor([[ 0.1479, -0.1739,  0.2338],\n",
      "        [ 0.1482, -0.1737,  0.2343],\n",
      "        [ 0.1469, -0.1746,  0.2325],\n",
      "        [ 0.1445, -0.1776,  0.2302],\n",
      "        [ 0.1450, -0.1758,  0.2297]], grad_fn=<AddmmBackward0>)\n",
      "log(std) original\n",
      "tensor([[-0.0689,  0.8170, -0.2164],\n",
      "        [-0.0686,  0.8174, -0.2147],\n",
      "        [-0.0754,  0.8270, -0.2154],\n",
      "        [-0.0887,  0.8454, -0.2190],\n",
      "        [-0.0822,  0.8350, -0.2193]], grad_fn=<AddmmBackward0>)\n",
      "Mu deserialized (should be equal to original)\n",
      "tensor([[ 0.1479, -0.1739,  0.2338],\n",
      "        [ 0.1482, -0.1737,  0.2343],\n",
      "        [ 0.1469, -0.1746,  0.2325],\n",
      "        [ 0.1445, -0.1776,  0.2302],\n",
      "        [ 0.1450, -0.1758,  0.2297]], grad_fn=<AddmmBackward0>)\n",
      "log(std) deserialized (should be equal to original)\n",
      "tensor([[-0.0689,  0.8170, -0.2164],\n",
      "        [-0.0686,  0.8174, -0.2147],\n",
      "        [-0.0754,  0.8270, -0.2154],\n",
      "        [-0.0887,  0.8454, -0.2190],\n",
      "        [-0.0822,  0.8350, -0.2193]], grad_fn=<AddmmBackward0>)\n",
      "Reconstruction decode() original\n",
      "tensor([0.3920, 0.9489, 0.3920, 0.0603, 0.9489, 0.0603, 0.2865, 0.9998, 0.2865,\n",
      "        0.9998], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\n",
      "tensor([0.8800, 0.0718, 0.8800, 0.1373, 0.0718, 0.1373, 0.0843, 0.0873, 0.0843,\n",
      "        0.0873], grad_fn=<SigmoidBackward0>)\n",
      "Reconstruction loss original\n",
      "tensor(3.1920, grad_fn=<AddBackward0>)\n",
      "Reconstruction loss deserialized (should be ok if they are different because of the randomization)\n",
      "tensor(1.5819, grad_fn=<AddBackward0>)\n",
      "AUC and precision metric test original\n",
      "(0.56, 0.7142857142857142)\n",
      "AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\n",
      "(0.2, 0.521031746031746)\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reversible residual GAT VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gat_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, RevGATConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_attr=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Reversible residual SAGE VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=sage_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, RevSAGEConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Simple GCN VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, SimpleGCNEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"Residual GCN2 VGAE\")\n",
    "vgae_enc = VGEncoder(encoder_mu=gcn2_enc)\n",
    "vgae = VGAEv2(encoder=vgae_enc)\n",
    "print(\"Constructor params: \")\n",
    "constr_params = vgae.serialize_constructor_params()\n",
    "state_dict = vgae.state_dict()\n",
    "print(constr_params)\n",
    "vgae2 = VGAEv2.from_constructor_params(constr_params, VGEncoder, ResGCN2ConvEncoder)\n",
    "vgae2.load_state_dict(state_dict)\n",
    "print(vgae2)\n",
    "print(torchinfo.summary(vgae2))\n",
    "print(\"forward() original\")\n",
    "print(vgae(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"forward() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() original\")\n",
    "print(vgae.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Reconstruction forward_all() deserialized (should be ok if they are different because of the randomization)\")\n",
    "print(vgae2.forward_all(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight))\n",
    "print(\"Latent space encoding original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Latent space encoding deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(z)\n",
    "print(\"Mu original\")\n",
    "mu, logstd = vgae.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) original\")\n",
    "print(logstd)\n",
    "print(\"Mu deserialized (should be equal to original)\")\n",
    "mu, logstd = vgae2.encoder(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(mu)\n",
    "print(\"log(std) deserialized (should be equal to original)\")\n",
    "print(logstd)\n",
    "print(\"Reconstruction decode() original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction decode() deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.decode(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.recon_loss(z, pyg.edge_index))\n",
    "print(\"Reconstruction loss deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.recon_loss(z, pyg.edge_index))\n",
    "neg_edge_index = negative_sampling(pyg.edge_index, z.size(0))\n",
    "print(\"AUC and precision metric test original\")\n",
    "z = vgae.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"AUC and precision metric test deserialized (should be ok if they are different because of the randomization)\")\n",
    "z = vgae2.encode(x=pyg.x, edge_index=pyg.edge_index, edge_weight=pyg.edge_weight)\n",
    "print(vgae2.test(z, pyg.edge_index, neg_edge_index=neg_edge_index))\n",
    "print(\"--------------------------------------------------------------------\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-8469545d",
   "language": "python",
   "display_name": "PyCharm (connectome-nn-generators)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}